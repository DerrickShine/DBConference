HaLoop: Efficient iterative data processing on large clusters,Yingyi Bu; Bill Howe; Magdalena Balazinska; Michael D Ernst,Abstract The growing demand for large-scale data mining and data analysis applicationshas led both industry and academia to design new types of highly scalable data-intensivecomputing platforms. MapReduce and Dryad are two popular platforms in which thedataflow takes the form of a directed acyclic graph of operators. These platforms lack built-insupport for iterative programs; which arise naturally in many applications including datamining; web ranking; graph analysis; model fitting; and so on. This paper presents HaLoop;a modified version of the Hadoop MapReduce framework that is designed to serve theseapplications. HaLoop not only extends MapReduce with programming support for iterativeapplications; it also dramatically improves their efficiency by making the task scheduler loop-aware and by adding various caching mechanisms. We evaluated HaLoop on real …,Proceedings of the VLDB Endowment,2010,863,1
Skewtune: mitigating skew in mapreduce applications,YongChul Kwon; Magdalena Balazinska; Bill Howe; Jerome Rolia,Abstract We present an automatic skew mitigation approach for user-defined MapReduceprograms and present SkewTune; a system that implements this approach as a drop-inreplacement for an existing MapReduce implementation. There are three key challenges:(a)require no extra input from the user yet work for all MapReduce applications;(b) becompletely transparent; and (c) impose minimal overhead if there is no skew. The SkewTuneapproach addresses these challenges and works as follows: When a node in the clusterbecomes idle; SkewTune identifies the task with the greatest expected remaining processingtime. The unprocessed input data of this straggling task is then proactively repartitioned in away that fully utilizes the nodes in the cluster and preserves the ordering of the input data sothat the original output can be reconstructed by concatenation. We implement SkewTune …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,349,2
Skew-resistant parallel processing of feature-extracting scientific user-defined functions,YongChul Kwon; Magdalena Balazinska; Bill Howe; Jerome Rolia,Abstract Scientists today have the ability to generate data at an unprecedented scale andrate and; as a result; they must increasingly turn to parallel data processing engines toperform their analyses. However; the simple execution model of these engines can make itdifficult to implement efficient algorithms for scientific analytics. In particular; many scientificanalytics require the extraction of features from data represented as either amultidimensional array or points in a multidimensional space. These applications exhibitsignificant computational skew; where the runtime of different partitions depends on morethan just input size and can therefore vary dramatically and unpredictably. In this paper; wepresent SkewReduce; a new system implemented on top of Hadoop that enables users toeasily express feature extraction analyses and execute them efficiently. At the heart of the …,Proceedings of the 1st ACM symposium on Cloud computing,2010,145,10
The HaLoop approach to large-scale iterative data analysis,Yingyi Bu; Bill Howe; Magdalena Balazinska; Michael D Ernst,Abstract The growing demand for large-scale data mining and data analysis applicationshas led both industry and academia to design new types of highly scalable data-intensivecomputing platforms. MapReduce has enjoyed particular success. However; MapReducelacks built-in support for iterative programs; which arise naturally in many applicationsincluding data mining; web ranking; graph analysis; and model fitting. This paper (This is anextended version of the VLDB 2010 paper" HaLoop: Efficient Iterative Data Processing onLarge Clusters" PVLDB 3 (1): 285---296; 2010.) presents HaLoop; a modified version of theHadoop MapReduce framework; that is designed to serve these applications. HaLoopallows iterative applications to be assembled from existing Hadoop programs withoutmodification; and significantly improves their efficiency by providing inter-iteration caching …,The VLDB Journal—The International Journal on Very Large Data Bases,2012,129,7
Hadoop's adolescence: an analysis of Hadoop usage in scientific workloads,Kai Ren; YongChul Kwon; Magdalena Balazinska; Bill Howe,Abstract We analyze Hadoop workloads from three di? erent research clusters from a user-centric perspective. The goal is to better understand data scientists' use of the system andhow well the use of the system matches its design. Our analysis suggests that Hadoopusage is still in its adolescence. We see underuse of Hadoop features; extensions; andtools. We see significant diversity in resource usage and application styles; including someinteractive and iterative workloads; motivating new tools in the ecosystem. We also observesignificant opportunities for optimizations of these workloads. We find that job customizationand configuration are used in a narrow scope; suggesting the future pursuit of automatictuning systems. Overall; we present the first user-centered measurement study of Hadoopand find significant opportunities for improving its efficient use for data scientists.,Proceedings of the VLDB Endowment,2013,94,1
A study of skew in mapreduce applications,YongChul Kwon; Magdalena Balazinska; Bill Howe; Jerome Rolia,Abstract—This paper presents a study of skew—highly variable task runtimes—inMapReduce applications. We describe various causes and manifestations of skew asobserved in real world Hadoop applications. Runtime task distributions from theseapplications demonstrate the presence and negative impact of skew on performancebehavior. We discuss best practices recommended for avoiding such behavior and theirlimitations.,Open Cirrus Summit,2011,91,22
Voyager: Exploratory analysis via faceted browsing of visualization recommendations,Kanit Wongsuphasawat; Dominik Moritz; Anushka Anand; Jock Mackinlay; Bill Howe; Jeffrey Heer,General visualization tools typically require manual specification of views: analysts mustselect data variables and then choose which transformations and visual encodings to apply.These decisions often involve both domain and visualization design expertise; and mayimpose a tedious specification process that impedes exploration. In this paper; we seek tocomplement manual chart construction with interactive navigation of a gallery ofautomatically-generated visualizations. We contribute Voyager; a mixed-initiative systemthat supports faceted browsing of recommended charts chosen according to statistical andperceptual measures. We describe Voyager's architecture; motivating design principles; andmethods for generating and interacting with visualization recommendations. In a studycomparing Voyager to a manual visualization specification tool; we find that Voyager …,IEEE transactions on visualization and computer graphics,2016,84,8
Data markets in the cloud: An opportunity for the database community,Magdalena Balazinska; Bill Howe; Dan Suciu,ABSTRACT Cloud-computing is transforming many aspects of data management. Mostrecently; the cloud is seeing the emergence of digital markets for data and associatedservices. We observe that our community has a lot to offer in building successful cloud-based data markets. We outline some of the key challenges that such markets face anddiscuss the associated research problems that our community can help solve.,Proc. of the VLDB Endowment,2011,84,15
Analyzing massive astrophysical datasets: Can Pig/Hadoop or a relational DBMS help?,Sarah Loebman; Dylan Nunley; YongChul Kwon; Bill Howe; Magdalena Balazinska; Jeffrey P Gardner,As the datasets used to fuel modern scientific discovery grow increasingly large; theybecome increasingly difficult to manage using conventional software. Parallel databasemanagement systems (DBMSs) and massive-scale data processing systems such asMapReduce hold promise to address this challenge. However; since these systems have notbeen expressly designed for scientific applications; their efficacy in this domain has not beenthoroughly tested. In this paper; we study the performance of these engines in one specificdomain: massive astrophysical simulations. We develop a use case that comprises fiverepresentative queries. We implement this use case in one distributed DBMS and in thePig/Hadoop system. We compare the performance of the tools to each other and to hand-written IDL scripts. We find that certain representative analyses are easy to express in …,Cluster Computing and Workshops; 2009. CLUSTER'09. IEEE International Conference on,2009,74,4
Scalable clustering algorithm for N-body simulations in a shared-nothing cluster,YongChul Kwon; Dylan Nunley; Jeffrey P Gardner; Magdalena Balazinska; Bill Howe; Sarah Loebman,Abstract Scientists' ability to generate and collect massive-scale datasets is increasing. As aresult; constraints in data analysis capability rather than limitations in the availability of datahave become the bottleneck to scientific discovery. MapReduce-style platforms hold thepromise to address this growing data analysis problem; but it is not easy to express manyscientific analyses in these new frameworks. In this paper; we study data analysischallenges found in the astronomy simulation domain. In particular; we present a scalable;parallel algorithm for data clustering in this domain. Our algorithm makes two contributions.First; it shows how a clustering problem can be efficiently implemented in a MapReduce-style framework. Second; it includes optimizations that enable scalability; even in thepresence of skew. We implement our solution in the Dryad parallel data processing …,International Conference on Scientific and Statistical Database Management,2010,69,7
Query-based data pricing,Paraschos Koutris; Prasang Upadhyaya; Magdalena Balazinska; Bill Howe; Dan Suciu,Abstract Data is increasingly being bought and sold online; and Web-based marketplaceservices have emerged to facilitate these activities. However; current mechanisms for pricingdata are very simple: buyers can choose only from a set of explicit views; each with aspecific price. In this article; we propose a framework for pricing data on the Internet that;given the price of a few views; allows the price of any query to be derived automatically. Wecall this capability query-based pricing. We first identify two important properties that thepricing function must satisfy; the arbitrage-free and discount-free properties. Then; we provethat there exists a unique function that satisfies these properties and extends the seller'sexplicit prices to all queries. Central to our framework is the notion of query determinacy; andin particular instance-based determinacy: we present several results regarding the …,Journal of the ACM (JACM),2015,68,7
Virtual appliances; cloud computing; and reproducible research,Bill Howe,As science becomes increasingly computational; reproducibility has become increasinglydifficult; perhaps surprisingly. In many contexts; virtualization and cloud computing canmitigate the issues involved without significant overhead to the researcher; enabling the nextgeneration of rigorous and reproducible computational science.,Computing in Science & Engineering,2012,68,7
The bigdawg polystore system,Jennie Duggan; Aaron J Elmore; Michael Stonebraker; Magda Balazinska; Bill Howe; Jeremy Kepner; Sam Madden; David Maier; Tim Mattson; Stan Zdonik,Abstract This paper presents a new view of federated databases to address the growingneed for managing information that spans multiple data models. This trend is fueled by theproliferation of storage engines and query languages based on the observation that “no onesize fits all”. To address this shift; we propose a polystore architecture; it is designed to unifyquerying over multiple data models. We consider the challenges and opportunitiesassociated with polystores. Open questions in this space revolve around query optimizationand the assignment of objects to storage engines. We introduce our approach to thesetopics and discuss our prototype in the context of the Intel Science and Technology Centerfor Big Data,ACM Sigmod Record,2015,62,8
Astronomy in the cloud: using mapreduce for image co-addition,Keith Wiley; Andrew Connolly; Jeff Gardner; S Krughoff; Magdalena Balazinska; Bill Howe; Y Kwon; Yingyi Bu,Abstract In the coming decade; astronomical surveys of the sky will generate tens ofterabytes of images and detect hundreds of millions of sources every night. The study ofthese sources will involve computation challenges such as anomaly detection andclassification and moving-object tracking. Since such studies benefit from the highest-qualitydata; methods such as image co-addition; ie; astrometric registration followed by per-pixelsummation; will be a critical preprocessing step prior to scientific investigation. With arequirement that these images be analyzed on a nightly basis to identify moving sourcessuch as potentially hazardous asteroids or transient objects such as supernovae; these datastreams present many computational challenges. Given the quantity of data involved; thecomputational load of these problems can only be addressed by distributing the workload …,Publications of the Astronomical Society of the Pacific,2011,57,7
Vizdeck: self-organizing dashboards for visual analytics,Alicia Key; Bill Howe; Daniel Perry; Cecilia Aragon,Abstract We present VizDeck; a web-based tool for exploratory visual analytics ofunorganized relational data. Motivated by collaborations with domain scientists who searchfor complex patterns in hundreds of data sources simultaneously; VizDeck automaticallyrecommends appropriate visualizations based on the statistical properties of the data andadopts a card game metaphor to help organize the recommended visualizations intointeractive visual dashboard applications in seconds with zero programming. Thedemonstration allows users to derive; share; and permanently store their own dashboardfrom hundreds of real science datasets using a production system deployed at the Universityof Washington.,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,56,20
A demonstration of the bigdawg polystore system,Aaron Elmore; Jennie Duggan; Mike Stonebraker; Magdalena Balazinska; Ugur Cetintemel; Vijay Gadepally; Jeffrey Heer; Bill Howe; Jeremy Kepner; Tim Kraska; Samuel Madden; David Maier; Timothy Mattson; Stavros Papadopoulos; Jeff Parkhurst; Nesime Tatbul; Manasi Vartak; Stan Zdonik,Abstract This paper presents BigDAWG; a reference implementation of a new architecturefor" Big Data" applications. Such applications not only call for large-scale analytics; but alsofor real-time streaming support; smaller analytics at interactive speeds; data visualization;and cross-storage-system queries. Guided by the principle that" one size does not fit all"; webuild on top of a variety of storage engines; each designed for a specialized use case. Toillustrate the promise of this approach; we demonstrate its effectiveness on a hospitalapplication using data from an intensive care unit (ICU). This complex application serves theneeds of doctors and researchers and provides real-time support for streams of patient data.It showcases novel approaches for querying across multiple storage engines; datavisualization; and scalable real-time analytics.,Proceedings of the VLDB Endowment,2015,55,22
Demonstration of the Myria big data management service,Daniel Halperin; Victor Teixeira de Almeida; Lee Lee Choo; Shumo Chu; Paraschos Koutris; Dominik Moritz; Jennifer Ortiz; Vaspol Ruamviboonsuk; Jingjing Wang; Andrew Whitaker; Shengliang Xu; Magdalena Balazinska; Bill Howe; Dan Suciu,Abstract In this demonstration; we will showcase Myria; our novel cloud service for big datamanagement and analytics designed to improve productivity. Myria's goal is for users tosimply upload their data and for the system to help them be self-sufficient data scienceexperts on their data--self-serve analytics. Using a web browser; Myria users can uploaddata; author efficient queries to process and explore the data; and debug correctness andperformance issues. Myria queries are executed on a scalable; parallel cluster that usesboth state-of-the-art and novel methods for distributed query processing. Our interactivedemonstration will guide visitors through an exploration of several key Myria features byinterfacing with the live system to analyze big datasets over the web.,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,53,4
Algebraic manipulation of scientific datasets,Bill Howe; David Maier,Abstract We investigate algebraic processing strategies for large numeric datasets equippedwith a (possibly irregular) grid structure. Such datasets arise; for example; in computationalsimulations; observation networks; medical imaging; and 2-D and 3-D rendering. Existingapproaches for manipulating these datasets are incomplete: The performance of SQLqueries for manipulating large numeric datasets is not competitive with specialized tools.Database extensions for processing multidimensional discrete data can only model regular;rectilinear grids. Visualization software libraries are designed to process arbitrary griddeddatasets efficiently; but no algebra has been developed to simplify their use and affordoptimization. Further; these libraries are data dependent–physical changes to datarepresentation or organization break user programs. In this paper; we present an algebra …,The VLDB journal,2005,53,2
Database-as-a-service for long-tail science,Bill Howe; Garret Cole; Emad Souroush; Paraschos Koutris; Alicia Key; Nodira Khoussainova; Leilani Battle,Abstract Database technology remains underused in science; especially in the long tail—thesmall labs and individual researchers that collectively produce the majority of scientificoutput. These researchers increasingly require iterative; ad hoc analysis over ad hocdatabases but cannot individually invest in the computational and intellectual infrastructurerequired for state-of-the-art solutions. We describe a new “delivery vector” for databasetechnology called SQLShare that emphasizes ad hoc integration; query; sharing; andvisualization over pre-defined schemas. To empower non-experts to write complex queries;we synthesize example queries from the data itself and explore limited English hints toaugment the process. We integrate collaborative visualization via a web-based servicecalled VizDeck that uses automated visualization techniques with a card game metaphor …,International Conference on Scientific and Statistical Database Management,2011,52,2
Parallel visualization on large clusters using MapReduce,Huy T Vo; Jonathan Bronson; Brian Summa; Joao LD Comba; Juliana Freire; Bill Howe; Valerio Pascucci; Cláudio T Silva,Large-scale visualization systems are typically designed to efficiently “push” datasetsthrough the graphics hardware. However; exploratory visualization systems are increasinglyexpected to support scalable data manipulation; restructuring; and querying capabilities inaddition to core visualization algorithms. We posit that new emerging abstractions forparallel data processing; in particular computing clouds; can be leveraged to support large-scale data exploration through visualization. In this paper; we take a first step in evaluatingthe suitability of the MapReduce framework to implement large-scale visualizationtechniques. MapReduce is a lightweight; scalable; general-purpose parallel data processingframework increasingly popular in the context of cloud computing. Specifically; weimplement and evaluate a representative suite of visualization tasks (mesh rendering …,Large Data Analysis and Visualization (LDAV); 2011 IEEE Symposium on,2011,47,2
Scientific exploration in the era of ocean observatories,António Baptista; Bill Howe; Juliana Freire; David Maier; Cláudio T Silva,Copublished by the IEEE CS and the AIP 1521-9615/08/$25.00 ©2008 IEEE 53 … Editors: CláudioSilva; csilva@cs.utah.edu Joel E. Tohline; tohline@rouge.phys.lsu.edu … By AntónioBaptista; Bill Howe; Juliana Freire; David Maier; and Cláudio T. Silva … The authors introducean ocean observatory; offer a vision of observatory-enabled scientific exploration; and discussthe requirements and approaches for generating provenance-aware products in suchenvironments … An Observatory in Evolution CORIE (for Columbia River Estuary) is a coastalmargin observatory op- erated at Oregon Health & Science University since 1996 as anend-to- end; data-to-stakeholder system.3 In 2004; CORIE became a founding contributing nodeto the Northwest Association of Networked Ocean Observing Systems (NANOOS); a regionalassociation of IOOS. Since 2006; CORIE has anchored the devel- opment of an …,Computing in Science & Engineering,2008,41,15
Managing Skew in Hadoop.,YongChul Kwon; Kai Ren; Magdalena Balazinska; Bill Howe; Jerome Rolia,Abstract Challenges in Big Data analytics stem not only from volume; but also variety:extreme diversity in both data types (eg; text; images; and graphs) and in operations beyondrelational algebra (eg; machine learning; natural language processing; image processing;and graph analysis). As a result; any competitive Big Data system must support some form ofparallel user-defined operations (UDOs) that can capture complex data processing tasksover complex data types without changing the core of the parallel data processing engine.Hadoop and other popular systems have been shown to provide a convenient programmingmodel for implementing parallel UDOs; but the “black-box” nature of UDOs complicates theautomatic load balancing required to achieve parallel scalability. In this paper; we presentan overview of some of our recent work that tackles the problem of load imbalance (aka …,IEEE Data Eng. Bull.,2013,37,15
Hadoop's Adolescence; A Comparative Workloads Analysis from Three Research Clusters.,Kai Ren; Garth Gibson; YongChul Kwon; Magdalena Balazinska; Bill Howe,ABSTRACT We analyze Hadoop workloads from three different research clusters from anapplication-level perspective; with two goals:(1) explore new issues in application patternsand user behavior and (2) understand key performance challenges related to IO and loadbalance. Our analysis suggests that Hadoop usage is still in its adolescence. We seeunderuse of Hadoop features; extensions; and tools as well as significant opportunities foroptimization. We see significant diversity in application styles; including some “interactive”workloads; motivating new tools in the ecosystem. We find that some conventionalapproaches to improving performance are not especially effective and suggest somealternatives. Overall; we find significant opportunity for simplifying the use and optimizationof Hadoop; and make recommendations for future research. Acknowledgements: This …,SC Companion,2012,37,15
End-to-end escience: Integrating workflow; query; visualization; and provenance at an ocean observatory,Bill Howe; Peter Lawson; Renee Bellinger; Erik Anderson; Emanuele Santos; Juliana Freire; Carlos Scheidegger; António Baptista; Cláudio Silva,Data analysis tasks at an Ocean Observatory require integrative and and domain-specialized use of database; workflow; visualization systems. We describe a platform tosupport these tasks developed as part of the cyberinfrastructure at the NSF Science andTechnology Center for Coastal Margin Observation and Prediction integrating a provenance-aware workflow system; 3D visualization; and a remote query engine for large-scale oceancirculation models. We show how these disparate tools complement each other and giveexamples of real scientific insights delivered by the integrated system. We conclude thatdata management solutions for eScience require this kind of holistic; integrative approach;explain how our approach may be generalized; and recommend a broader; application-oriented research agenda to explore relevant architectures.,eScience; 2008. eScience'08. IEEE Fourth International Conference on,2008,34,4
Deciphering ocean carbon in a changing world,Mary Ann Moran; Elizabeth B Kujawinski; Aron Stubbins; Rob Fatland; Lihini I Aluwihare; Alison Buchan; Byron C Crump; Pieter C Dorrestein; Sonya T Dyhrman; Nancy J Hess; Bill Howe; Krista Longnecker; Patricia M Medeiros; Jutta Niggemann; Ingrid Obernosterer; Daniel J Repeta; Jacob R Waldbauer,Abstract Dissolved organic matter (DOM) in the oceans is one of the largest pools of reducedcarbon on Earth; comparable in size to the atmospheric CO 2 reservoir. A vast number ofcompounds are present in DOM; and they play important roles in all major element cycles;contribute to the storage of atmospheric CO 2 in the ocean; support marine ecosystems; andfacilitate interactions between organisms. At the heart of the DOM cycle lie molecular-levelrelationships between the individual compounds in DOM and the members of the oceanmicrobiome that produce and consume them. In the past; these connections have eludedclear definition because of the sheer numerical complexity of both DOM molecules andmicroorganisms. Emerging tools in analytical chemistry; microbiology; and informatics arebreaking down the barriers to a fuller appreciation of these connections. Here we …,Proceedings of the National Academy of Sciences,2016,33,7
Toward practical query pricing with QueryMarket,Paraschos Koutris; Prasang Upadhyaya; Magdalena Balazinska; Bill Howe; Dan Suciu,Abstract We develop a new pricing system; QueryMarket; for flexible query pricing in a datamarket based on an earlier theoretical framework (Koutris et al.; PODS 2012). To build sucha system; we show how to use an Integer Linear Programming formulation of the pricingproblem for a large class of queries; even when pricing is computationally hard. Further; weleverage query history to avoid double charging when queries purchased over time haveoverlapping information; or when the database is updated. We then present a technique thatfairly shares revenue when multiple sellers are involved. Finally; we implement ourapproach in a prototype and evaluate its performance on several query workloads.,proceedings of the 2013 ACM SIGMOD international conference on management of data,2013,29,14
Quarrying dataspaces: Schemaless profiling of unfamiliar information sources,Bill Howe; David Maier; Nicolas Rayner; James Rucker,Traditional data integration and analysis approaches tend to assume intimate familiarity withthe structure; semantics; and capabilities of the available information sources beforeapplicable tools can be used effectively. This assumption often does not hold in practice. Weintroduce dataspace profiling as the cardinal activity when beginning a project in anunfamiliar dataspace. Dataspace profiling is an analysis of the structures and propertiesexposed by an information source; allowing 1) assessment of the utility and importance ofthe information source as a whole; 2) assessment of compatibility with the services of adataspace support platform; and 3) determination and externalization of structure inpreparation for specific data applications. In this paper; we define dataspace profiling andarticulate requirements for dataspace profilers. We then describe the Quarry system …,Data Engineering Workshop; 2008. ICDEW 2008. IEEE 24th International Conference on,2008,29,7
Embracing Uncertainty in Large-Scale Computational Astrophysics.,Dan Suciu; Andrew J Connolly; Bill Howe,Abstract. A revolution is underway in astronomy resulting from massive astrophysicalsurveys providing a panchromatic view of the night sky. The next generation of surveys andthe simulations used to calibrate them can produce in two nights what the previousgeneration produced over many years. This enormous image acquisition capability allowsthe telescope to revisit areas of the sky with sufficient frequency to expose dynamic featuresand transient events; eg; asteroids whose trajectories may intersect Earth. At least threesuch surveys are planned; their collective output must be integrated and calibrated againstcomputational simulations; prior surveys; and each other. Relational datbases have beenshown to be effective for astronomy at yesterday's scale; but new access to the temporaldimension and increased intercomparison of multiple sources generate new sources of …,MUD,2009,23,4
Optimizing large-scale Semi-Naïve datalog evaluation in hadoop,Marianne Shaw; Paraschos Koutris; Bill Howe; Dan Suciu,Abstract We explore the design and implementation of a scalable Datalog system usingHadoop as the underlying runtime system. Observing that several successful projectsprovide a relational algebra-based programming interface to Hadoop; we argue that anatural extension is to add recursion to support scalable social network analysis; internettraffic analysis; and general graph query. We implement semi-naive evaluation in Hadoop;then apply a series of optimizations spanning fundamental changes to the Hadoopinfrastructure to basic configuration guidelines that collectively offer a 10x improvement inour experiments. This work lays the foundation for a more comprehensive cost-basedalgebraic optimization framework for parallel recursive Datalog queries.,*,2012,22,7
Querymarket demonstration: Pricing for online data markets,Paraschos Koutris; Prasang Upadhyaya; Magdalena Balazinska; Bill Howe; Dan Suciu,Abstract Increasingly data is being bought and sold online. To facilitate such transactions;online data market-places have emerged to provide a service for sellers to price views ontheir data; and buyers to buy such views. These marketplaces neither support the sale of ad-hoc queries (that are not one of the specified views); nor do they support queries that joindatasets. We present QueryMarket; a prototype data marketplace that automaticallyextrapolates prices to ad-hoc queries; including those with joins; from the manually pricedviews. We call this capability" query-based pricing" and describe how it is superior toexisting pricing methods; and how it provides more flexible pricing for the sellers. We thenshow how QueryMarket implements query-based pricing and how it generates explanationsfor the prices it computes.,Proceedings of the VLDB Endowment,2012,21,1
Astronomical image processing with hadoop,Keith Wiley; Andrew Connolly; Simon Krughoff; Jeff Gardner; Magdalena Balazinska; Bill Howe; Y Kwon; Yingyi Bu,5. Results Fig. 1 shows an example of image coaddition. A single r-band frame is shown onthe left,Astronomical Data Analysis Software and Systems XX,2011,20,10
Gridfields: model-driven data transformation in the physical sciences,Bill Howe,Abstract Scientists' ability to generate and store simulation results is outpacing their ability toanalyze them via ad hoc programs. We observe that these programs exhibit an algebraicstructure that can be used to facilitate reasoning and improve performance. In thisdissertation; we present a formal data model that exposes this algebraic structure; thenimplement the model; evaluate it; and use it to express; optimize; and reason about datatransformations in a variety of scientific domains.,*,2006,18,7
A language for spatial data manipulation,Bill Howe; David Maier; Antonio Baptista,ABSTRACT. Environmental Observation and Forecasting Systems (EOFS) create newopportunities and challenges for generation and use of environmental data products. Thenumber and diversity of these data products; however; has been artificially constrained bythe lack of a simple descriptive language for expressing them. Data products that can bedescribed simply in English take pages of obtuse scripts to generate. The scripts obfuscatethe original intent of the data product; making it difficult for users and scientists to understandthe overall product catalog. The problem is exacerbated by the evolution of modern EOFSinto data product “factories” subject to reliability requirements and daily productionschedules. New products must be developed and assimilated into the product suite asquickly as they are imagined. Reliability must be maintained despite changing hardware …,Journal of Environmental Informatics,2003,18,22
Skewtune in action: Mitigating skew in mapreduce applications,YongChul Kwon; Magdalena Balazinska; Bill Howe; Jerome Rolia,Abstract We demonstrate SkewTune; a system that automatically mitigates skew in user-defined MapReduce programs and is a drop-in replacement for Hadoop. The demonstrationhas two parts. First; we demonstrate how SkewTune mitigates skew in real MapReduceapplications at runtime by running a real application in a public cloud. Second; through aninteractive graphical interface; we demonstrate the details of the skew mitigation processusing both real and synthetic workloads that represent various skew configurations.,Proceedings of the VLDB Endowment,2012,17,20
Client+ cloud: Evaluating seamless architectures for visual data analytics in the ocean sciences,Keith Grochow; Bill Howe; Mark Stoermer; Roger Barga; Ed Lazowska,Abstract Science is becoming data-intensive; requiring new software architectures that canexploit resources at all scales: local GPUs for interactive visualization; server-side multi-coremachines with fast processors and large memories; and scalable; pay-as-you-go cloudresources. Architectures that seamlessly and flexibly exploit all three platforms are largelyunexplored. Informed by a long-term collaboration with ocean scientists; we articulate a suiteof representative visual data analytics workflows and use them to design and implement amulti-tier immersive visualization system. We then analyze a variety of candidatearchitectures spanning all three platforms; articulate their tradeoffs and requirements; andevaluate their performance. We conclude that although “pushing the computation to thedata” is generally the optimal strategy; no one single architecture is optimal in all cases …,International Conference on Scientific and Statistical Database Management,2010,17,7
Smoothing the ROI Curve for Scientific Data Management Applications.,Bill Howe; David Maier; Laura Bright,ABSTRACT Physical scientists increasingly use large; shared data repositories to makediscoveries. The technology to manage these repositories tends to be developed ad hoc;database technology has not significantly penetrated this market. Diverse requirements;terabyte and petabyte scale; non-standard data types; and rapid change are the norm forscientific data management applications; each pose challenges for existing technology. Inthis paper; we argue that traditional database systems are too monolithic anduncompromising to be generally successful in these extreme environments. We argue thatthese negative characteristics are reflected in the crooked shape of the Return OnInvestment curve; and that a smoother ROI can be achieved by adopting a few simplestrategies. We then describe our experiences applying these strategies to build data …,CIDR,2007,17,10
Bioinformatics and data-intensive scientific discovery in the beginning of the 21st century,Roger Barga; Bill Howe; David Beck; Stuart Bowers; William Dobyns; Winston Haynes; Roger Higdon; Chris Howard; Christian Roth; Elizabeth Stewart; Dean Welch; Eugene Kolker,Mary Ann Liebert; Inc. is committed to working closely with librarians to create collections of contentthat fulfill the informational needs of institutions while providing excellent value … 3 SeattleChildren's Research Institute; Seattle; Washington … This article is a summary of the bioinformaticsissues and challenges of data-intensive science as discussed in the NSF-funded Data-IntensiveScience (DIS) workshop in Seattle; September 19–20; 2010 … B ioinformatics is increasinglya data-driven science. Future success for life scientists will depend upon the ability to leveragethe large-scale data. By adopting the advances in information technology made by fields thathave already faced the type of inflection point bioinformatics face; such as cloud computing; webelieve bioinformatics can weave the computational environments that exist today into a solutionfor our data problems. In our breakout discussions; we examined the current state of the …,Omics: a journal of integrative biology,2011,16,7
Massive scale cyber traffic analysis: a driver for graph database research,Cliff Joslyn; Sutanay Choudhury; David Haglin; Bill Howe; Bill Nickless; Bryan Olsen,Abstract We consider cyber traffic analysis (TA) as a challenge problem for research ingraph database systems. TA involves observing and analyzing connections between clients;servers; hosts; and actors within IP networks; over time; to detect suspicious patterns.Towards that end; NetFlow (or more generically; IPFLOW) data are available from routersand servers which summarize coherent groups of IP packets flowing through the network.The ability to cast IPFLOW data as a massive graph and query it interactively is potentiallytransformative for cybersecurity; but issues of scale and data complexity pose challenges forcurrent technology. In this paper; we outline requirements and opportunities for graph-structured IPFLOW analytics based on our experience with real IPFLOW databases. Wedescribe real use cases from the security domain; cast them as graph patterns; show how …,First International Workshop on Graph Data Management Experiences and Systems,2013,14,7
A discussion on pricing relational data,Magdalena Balazinska; Bill Howe; Paraschos Koutris; Dan Suciu; Prasang Upadhyaya,Abstract There exists a growing market for structured data on the Internet today; and thismotivates a theoretical study of how relational data should be priced. We advocate for aframework where the seller defines a pricing scheme; by essentially stipulating the price ofsome queries; and the buyer is allowed to purchase data expressed by any query they wish:the system will derive the price automatically from the pricing scheme. We show that; inorder to understand pricing; one needs to understand determinacy first. We also discusssome other open problems in pricing relational data.,*,2013,14,20
Sqlshare: Results from a multi-year sql-as-a-service experiment,Shrainik Jain; Dominik Moritz; Daniel Halperin; Bill Howe; Ed Lazowska,Abstract We analyze the workload from a multi-year deployment of a database-as-a-serviceplatform targeting scientists and data scientists with minimal database experience. Ourhypothesis was that relatively minor changes to the way databases are delivered canincrease their use in ad hoc analysis environments. The web-based SQLShare systememphasizes easy dataset-at-a-time ingest; relaxed schemas and schema inference; easyview creation and sharing; and full SQL support. We find that these features have helpedattract workloads typically associated with scripts and files rather than relational databases:complex analytics; routine processing pipelines; data publishing; and collaborative analysis.Quantitatively; these workloads are characterized by shorter dataset" lifetimes"; higher querycomplexity; and higher data complexity. We report on usage scenarios that suggest SQL …,Proceedings of the 2016 International Conference on Management of Data,2016,13,17
Scalable flow-based community detection for large-scale network analysis,Seung-Hee Bae; Daniel Halperin; Jevin West; Martin Rosvall; Bill Howe,Community-detection is a powerful approach to uncover important structures in largenetworks. Since networks often describe flow of some entity; flow-based community-detection methods are particularly interesting. One such algorithm is called Info map; whichoptimizes the objective function known as the map equation. While Info map is known to bean effective algorithm; its serial implementation cannot take advantage of multicoreprocessing in modern computers. In this paper; we propose a novel parallel generalizationof Info map called Relax Map. This algorithm relaxes concurrency assumptions to avoid lockoverhead; achieving 70% parallel efficiency in shared-memory multicore experiments whileexhibiting similar convergence properties and finding similar community structures as theserial algorithm. We evaluate our approach on a variety of real graph datasets as well as …,Data Mining Workshops (ICDMW); 2013 IEEE 13th International Conference on,2013,13,7
Emergent semantics: Towards self-organizing scientific metadata,Bill Howe; Kuldeep Tanna; Paul Turner; David Maier,Abstract Tasked with designing a metadata management system for a large scientific datarepository; we find that the customary database application development procedure exhibitsseveral disadvantages in this environment. Data cannot be accessed until the system is fullydesigned and implemented; specialized data modeling skills are required to design anappropriate schema; and once designed; such schemas are intolerant of change. Weminimize setup and maintenance costs by automating the database design; data load; anddata transformation tasks. Data creators are responsible only for extracting data fromheterogeneous sources according to a simple RDF-based data model. The system thenloads the data into a generic RDBMS schema. Additional grouping structures to supportquery formulation and processing are discovered by the system or defined by the users …,*,2004,13,7
SQL is dead; long live SQL: Lightweight query services for ad hoc research data,Bill Howe; Garret Cole,*,4th Microsoft eScience Workshop,2010,12
The Myria Big Data Management and Analytics System and Cloud Services.,Jingjing Wang; Tobin Baker; Magdalena Balazinska; Daniel Halperin; Brandon Haynes; Bill Howe; Dylan Hutchison; Shrainik Jain; Ryan Maas; Parmita Mehta; Dominik Moritz; Brandon Myers; Jennifer Ortiz; Dan Suciu; Andrew Whitaker; Shengliang Xu,ABSTRACT In this paper; we present an overview of the Myria stack for big datamanagement and analytics that we developed in the database group at the University ofWashington and that we have been operating as a cloud service aimed at domain scientistsaround the UW campus. We highlight Myria's key design choices and innovations and reporton our experience with using Myria for various data science use-cases.,CIDR,2017,10,7
Designing good algorithms for MapReduce and beyond,Foto N Afrati; Magdalena Balazinska; Anish Das Sarma; Bill Howe; Semih Salihoglu; Jeffrey D Ullman,Abstract As MapReduce/Hadoop grows in importance; we find more exotic applicationsbeing written this way. Not every program written for this platform performs as well as wemight wish. There are several reasons why a MapReduce program can underperformexpectations. One is the need to balance the communication cost of transporting data fromthe mappers to the reducers against the computation done at the mappers and reducersthemselves. A second important issue is selecting the number of rounds of MapReduce. Athird issue is that of skew. If wall-clock time is important; then using many different reduce-keys and many compute nodes may minimize the time to finish the job. Yet if the data isuncooperative; and no provision is made to distribute the data evenly; much of the work isdone by a single node.,Proceedings of the Third ACM Symposium on Cloud Computing,2012,10,7
Automatic example queries for ad hoc databases,Bill Howe; Garret Cole; Nodira Khoussainova; Leilani Battle,Abstract Motivated by eScience applications; we explore automatic generation of example"starter" queries over unstructured collections of tables without relying on a schema; a querylog; or prior input from users. Such example queries are demonstrably sufficient to have non-experts self-train and become productive using SQL; helping to increase the uptake ofdatabase technology among scientists. Our method is to learn a model for each relationaloperator based on example queries from public databases; then assemble queriessyntactically operator-by-operator. For example; the likelihood that a pair of attributes will beused as a join condition in an example query depends on the cardinality of their intersection;among other features. Our demonstration illustrates that datasets with different statisticalproperties lead to different sets of example queries with different properties.,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,10,15
Perfopticon: Visual query analysis for distributed databases,Dominik Moritz; Daniel Halperin; Bill Howe; Jeffrey Heer,Abstract Distributed database performance is often unpredictable due to issues such assystem complexity; network congestion; or imbalanced data distribution. These issues aredifficult for users to assess in part due to the opaque mapping between declarativelyspecified queries and actual physical execution plans. Database developers currently mustexpend significant time and effort scanning log files to isolate and debug the root causes ofperformance issues. In response; we present Perfopticon; an interactive query profiling toolthat enables rapid insight into common problems such as performance bottlenecks and dataskew. Perfopticon combines interactive visualizations of (1) query plans;(2) overall queryexecution;(3) data flow among servers; and (4) execution traces. These views coordinatemultiple levels of abstraction to enable detection; isolation; and understanding of …,Computer Graphics Forum,2015,8,1
Scientific mashups: Runtime-configurable data product ensembles,Bill Howe; Harrison Green-Fishback; David Maier,Abstract Mashups are gaining popularity as a rapid-development; re-use-orientedprogramming model to replace monolithic; bottom-up application development. Thisprogramming style is attractive for the “long tail” of scientific data management applications;characterized by exploding data volumes; increasing requirements for data sharing andcollaboration; but limited software engineering budgets. We observe that scientists alreadyroutinely construct a primitive; static form of mashup—an ensemble of related visualizationsthat convey a specific scientific message encoded as; eg; a Powerpoint slide. Inspired bytheir ubiquity; we adopt these conventional data-product ensembles as a core model; endowthem with interactivity; publish them online; and allow them to be repurposed at runtime bynon-programmers. We observe that these scientific mashups must accommodate a wider …,International Conference on Scientific and Statistical Database Management,2009,8,22
Viziometrics: Analyzing visual information in the scientific literature,Po-shen Lee; Jevin D West; Bill Howe,Scientific results are communicated visually in the literature through diagrams;visualizations; and photographs. These information-dense objects have been largelyignored in bibliometrics and scientometrics studies when compared to citations and text. Inthis paper; we use techniques from computer vision and machine learning to classify morethan 8 million figures from PubMed into 5 figure types and study the resulting patterns ofvisual information as they relate to scholarly impact. We find that the distribution of figuresand figure types in the literature has remained relatively constant over time; but can varywidely across field and topic. Remarkably; we find a significant correlation between scientificimpact and the use of visual information; where higher impact papers tend to include morediagrams; and to a lesser extent more plots. To explore these results and other ways of …,IEEE Transactions on Big Data,2017,7,20
GossipMap: A distributed community detection algorithm for billion-edge directed graphs,Seung-Hee Bae; Bill Howe,In this paper; we describe a new distributed community detection algorithm for billion-edgedirected graphs that; unlike modularity-based methods; achieves cluster quality on par withthe best-known algorithms in the literature. We show that a simple approximation to the best-known serial algorithm dramatically reduces computation and enables distributed evaluationyet incurs only a very small impact on cluster quality. We present three main results: First; weshow that the clustering produced by our scalable approximate algorithm comparesfavorably with prior results on small synthetic benchmarks and small real-world datasets (70million edges). Second; we evaluate our algorithm on billion-edge directed graphs (a 1.5 Bedge social network graph; and a 3.7 B edge web crawl); and show that the results exhibitthe structural properties predicted by analysis of much smaller graphs from similar …,High Performance Computing; Networking; Storage and Analysis; 2015 SC-International Conference for,2015,7,7
AZDBLab: a laboratory information system for large-scale empirical DBMS studies,Young-Kyoon Suh; Richard T Snodgrass; Rui Zhang,Abstract In the database field; while very strong mathematical and engineering work hasbeen done; the scientific approach has been much less prominent. The deep understandingof query optimizers obtained through the scientific approach can lead to better engineereddesigns. Unlike other domains; there have been few DBMS-dedicated laboratories; focusingon such scientific investigation. In this demonstration; we present a novel DBMS-orientedresearch infrastructure; called Arizona Database Laboratory (AZDBLab); to assist databaseresearchers in conducting a large-scale empirical study across multiple DBMSes. For themto test their hypotheses on the behavior of query optimizers; AZDBLab can run and monitor alarge-scale experiment with thousands (or millions) of queries on different DBMSes.Furthermore; AZDBLab can help users automatically analyze these queries. In the demo …,Proceedings of the VLDB Endowment,2014,7,23
Should we all be teaching intro to data science instead of intro to databases?,Bill Howe; Michael J Franklin; Juliana Freire; James Frew; Tim Kraska; Raghu Ramakrishnan,Abstract The Database Community has a unique perspective on the challenges andsolutions of long-term management of data and the value of data as a resource. In currentcomputer science curricula; however; these insights are typically locked up in the context ofthe traditional Intro to Databases class that was developed years (or in some cases;decades) before the modern concept of Data Science arose and embedded in thediscussion of legacy data management systems. We consider how to bring these conceptsfront and center into the emerging wave of Data Science courses; degree programs andeven departments.,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,7,1
Voyager 2: Augmenting visual analysis with partial view specifications,Kanit Wongsuphasawat; Zening Qu; Dominik Moritz; Riley Chang; Felix Ouk; Anushka Anand; Jock Mackinlay; Bill Howe; Jeffrey Heer,Abstract Visual data analysis involves both open-ended and focused exploration. Manualchart specification tools support question answering; but are often tedious for early-stageexploration where systematic data coverage is needed. Visualization recommenders canencourage broad coverage; but irrelevant suggestions may distract users once they committo specific questions. We present Voyager 2; a mixed-initiative system that blends manualand automated chart specification to help analysts engage in both open-ended explorationand targeted question answering. We contribute two partial specification interfaces:wildcards let users specify multiple charts in parallel; while related views suggestvisualizations relevant to the currently specified chart. We present our interface design andapplications of the CompassQL visualization query language to enable these interfaces …,Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems,2017,6,15
From NoSQL Accumulo to NewSQL Graphulo: Design and utility of graph algorithms inside a BigTable database,Dylan Hutchison; Jeremy Kepner; Vijay Gadepally; Bill Howe,Google BigTable's scale-out design for distributed key-value storage inspired a generationof NoSQL databases. Recently the NewSQL paradigm emerged in response to analyticworkloads that demand distributed computation local to data storage. Many such analyticstake the form of graph algorithms; a trend that motivated the GraphBLAS initiative tostandardize a set of matrix math kernels for building graph algorithms. In this article we showhow it is possible to implement the GraphBLAS kernels in a BigTable database bypresenting the design of Graphulo; a library for executing graph algorithms inside theApache Accumulo database. We detail the Graphulo implementation of two graphalgorithms and conduct experiments comparing their performance to two main-memorymatrix math systems. Our results shed insight into the conditions that determine when …,High Performance Extreme Computing Conference (HPEC); 2016 IEEE,2016,6,4
Dismantling Composite Visualizations in the Scientific Literature.,Po-Shen Lee; Bill Howe,Abstract: We are analyzing the visualizations in the scientific literature to enhance searchservices; detect plagiarism; and study bibliometrics. An immediate problem is the ubiquitoususe of multi-part figures: single images with multiple embedded sub-visualizations. Suchfigures account for approximately 35% of the figures in the scientific literature. Conventionalimage segmentation techniques and other existing approaches have been shown to beineffective for parsing visualizations. We propose an algorithm to automatically segmentmulti-chart visualizations into a set of single-chart visualizations; thereby enablingdownstream analysis. Our approach first splits an image into fragments based onbackground color and layout patterns. An SVM-based binary classifier then distinguishescomplete charts from auxiliary fragments such as labels; ticks; and legends; achieving an …,ICPRAM (2),2015,6,7
Collaborative science workflows in SQL,Bill Howe; Daniel Halperin; Francois Ribalet; Sagar Chitnis; E Virginia Armbrust,SQLShare is a Web-based application that emphasizes a simple upload-query-shareprotocol over conventional database design and uses ad hoc interactive query over general-purpose programming. Here; a case study examines the use of SQLShare as an alternativeto script-based scientific workflows for a project in observational biological oceanography.,Computing in Science & Engineering,2013,6,10
Advancing Declarative Query in the Long Tail of Science.,Bill Howe; Daniel Halperin,Abstract Relational databases remain underused in the long tail of science; despite anumber of significant success stories and a natural correspondence between scientificinquiry and ad hoc database query. Barriers to adoption have been articulated in the past;but spreadsheets and other file-oriented approaches still dominate. At the University ofWashington eScience Institute; we are exploring a new “delivery vector” for selecteddatabase features targeting researchers in the long tail: a web-based query-as-a-servicesystem called SQLShare that eschews conventional database design; instead emphasizinga simple Upload-Query-Share workflow and exposing a direct; full-SQL query interface over“raw” tabular data. We augment the basic query interface with services for cleaning andintegrating data; recommending and authoring queries; and automatically generating …,IEEE Data Eng. Bull.,2012,6,7
Cove: a visual environment for multidisciplinary ocean science collaboration,Keith Grochow; Mark Stoermer; James Fogarty; Charlotte Lee; Bill Howe; Ed Lazowska,Advances in cyber infrastructure for virtual observatories are poised to allow scientists fromdisparate fields to conduct experiments together; monitor large collections of instruments;and explore extensive archives of observed and simulated data. Such systems; however;focus on the 'plumbing'and frequently ignore the critical importance of rich; 3D interactivevisualization; asset management; and collaboration necessary for interdisciplinarycommunication. The NSF Ocean Observatories Initiative (OOI) is typical of modernobservatory-oriented projects–its goal is to transform ocean science from an expeditionaryscience to an observatory science. This paper explores the design of an interactive tool tosupport this new way of conducting ocean science. Working directly with teams of scientists;we designed and deployed the Collaborative Ocean Visualization Environment (COVE) …,e-Science (e-Science); 2010 IEEE Sixth International Conference on,2010,6,20
The sensitivity and response of terrestrial South American vegetation to interannual climatic variability induced by the ENSO,M Manobavan; NS Lucas; DS Boyd; N Petford,ABSTRACT. The sensitivity of vegetation to climatic variations operates over a range ofspatio-temporal scales. Whilst comprehensive and extensive studies that involve the spatialchanges in terrestrial systems using remotely sensed data have been undertaken; only afew investigations have focused on temporal change in these systems. In this studyeconometric time-series modelling techniques were applied to National Oceanographic andAtmospheric Administration Advanced Very High Resolution Radiometer NormalizedDifference Vegetation Index data sets in order to evaluate the resistance and resilience ofterrestrial South American vegetation to the interannual El Niño Southern Oscillationperturbations. Lags between vegetation response and the El Niño Southern Oscillationperturbations are identified and quantified. The results indicate that the terrestrial …,Journal of Environmental Informatics,2003,6,11
Viziometrix: A platform for analyzing the visual information in big scholarly data,Po-shen Lee; Jevin D West; Bill Howe,Abstract We present VizioMetrix; a platform that extracts visual information from the scientificliterature and makes it available for use in new information retrieval applications and forstudies that look at patterns of visual information across millions of papers. New ideas areconveyed visually in the scientific literature through figures---diagrams; photos;visualizations; tables---but these visual elements remain ensconced in the surroundingpaper and difficult to use directly to facilitate information discovery tasks or longitudinalanalytics. Very few applications in information retrieval; academic search; or bibliometricsmake direct use of the figures; and none attempt to recognize and exploit the type of figure;which can be used to augment interactions with a large corpus of scholarly literature.,Proceedings of the 25th international conference companion on world wide web,2016,5,7
Gaussian mixture models use-case: in-memory analysis with myria,Ryan Maas; Jeremy Hyrkas; Olivia Grace Telford; Magdalena Balazinska; Andrew Connolly; Bill Howe,Abstract In our work with scientists; we find that Gaussian Mixture Modeling is a commontype of analysis applied to increasingly large datasets. We implement this algorithm in theMyria shared-nothing relational data management system; which performs the computationin memory. We study resulting memory utilization challenges and implement severaloptimizations that yield an efficient and scalable solution. Empirical evaluations on largeastronomy and oceanography datasets confirm that our Myria approach scales well andperforms up to an order of magnitude faster than Hadoop.,Proceedings of the 3rd VLDB Workshop on In-Memory Data Mangement and Analytics,2015,5,5
Compiled plans for in-memory path-counting queries,Brandon Myers; Jeremy Hyrkas; Daniel Halperin; Bill Howe,Abstract Dissatisfaction with relational databases for large-scale graph processing hasmotivated a new class of graph databases that offer fast graph processing but sacrifice theability to express basic relational idioms. However; we hypothesize that the performancebenefits amount to implementation details; not a fundamental limitation of the relationalmodel. To evaluate this hypothesis; we are exploring code-generation to produce fast in-memory algorithms and data structures for graph patterns that are inaccessible toconventional relational optimizers. In this paper; we present preliminary results for thisapproach on path-counting queries; which includes triangle counting as a special case. Wecompile Datalog queries into main-memory pipelined hash-join plans in C++; and show thatthe resulting programs easily outperform PostgreSQL on real graphs with different …,*,2015,5,0
Helping scientists reconnect their datasets,Abdussalam Alawini; David Maier; Kristin Tufte; Bill Howe,Abstract It seems inevitable that the datasets associated with a research project proliferateover time: collaborators may extend datasets with new measurements and new attributes;new experimental runs result in new files with similar structures; and subsets of data areextracted for independent analysis. As these" residual" datasets begin to accrete over time;scientists can lose track of the derivation history that connects them; complicating datasharing; provenance tracking; and scientific reproducibility. In this paper; focusing on data inspreadsheets; we consider how observable relationships between two datasets can helpscientists recall their original derivation connection. For instance; if dataset A is whollycontained in dataset B; B may be a more recent version of A and should be preferred whenarchiving or publishing. We articulate a space of relevant relationships; develop a set of …,Proceedings of the 26th International Conference on Scientific and Statistical Database Management,2014,5,12
Real-time collaborative analysis with (almost) pure SQL: a case study in biogeochemical oceanography,Daniel Halperin; Francois Ribalet; Konstantin Weitz; Mak A Saito; Bill Howe; E Armbrust,Abstract We consider a case study using SQL-as-a-Service to support" instant analysis" ofweakly structured relational data at a multi-investigator science retreat. Here;" weaklystructured" means tabular; rows-and-columns datasets that share some common context; butthat have limited a priori agreement on file formats; relationships; types; schemas; metadata;or semantics. In this case study; the data were acquired from hundreds of distinct locationsduring a multi-day oceanographic cruise using a variety of physical; biological; and chemicalsensors and assays. Months after the cruise when preliminary data processing wascomplete; 40+ researchers from a variety of disciplines participated in a two-day" datasynthesis workshop." At this workshop; two computer scientists used a web-based query-as-a-service platform called SQLShare to perform" SQL stenography": capturing the scientific …,Proceedings of the 25th International Conference on Scientific and Statistical Database Management,2013,5,4
SciDB Examples from Environmental Observation and Modeling,Bill Howe,Datasets in environmental observation and modeling domain are fields defined over 4-Dspacetime of the form (x; y; z; t)→(v0; v1;...; vn); possibly extended with topologyrelationships. These datasets vary in which quantities are being measured or simulated (v0;v1;...; vn); but also in which dimensions; if any; are fixed and implicit. For example; aimmobile buoy equipped with a Conductivity Temperature Depth (CTD) sensor at 1 meterbelow the surface has the form (t)→(salinity; temperature; elevation); since (x; y; z) need notbe recorded. A profiling station can move vertically in the water column; but not horizontally;producing datasets of the form (z; t)→(salinity; temperature; elevation). AutonomousUnderwater Vehicles (AUVs) are free to swim in any direction; so all attributes must berecorded. Simulations may involve 1-D; 2-D; or 3-D spatial domains. The dependent …,Oregon Health & Science University Center for Coastal Margin Observation and Prediction,2008,5,22
LaraDB: A minimalist kernel for linear and relational algebra computation,Dylan Hutchison; Bill Howe; Dan Suciu,Abstract Analytics tasks manipulate structured data with variants of relational algebra (RA)and quantitative data with variants of linear algebra (LA). The two computational modelshave overlapping expressiveness; motivating a common programming model that affordsunified reasoning and algorithm design. At the logical level we propose LARA; a leanalgebra of three operators; that expresses RA and LA as well as relevant optimization rules.We show a series of proofs that position LARA at just the right level of expressiveness for amiddleware algebra: more explicit than MapReduce but more general than RA or LA. At thephysical level we find that the LARA operators afford efficient implementations using a singleprimitive that is available in a variety of backend engines: range scans over partitionedsorted maps. To evaluate these ideas; we implemented the LARA operators as range …,Proceedings of the 4th Algorithms and Systems on MapReduce and Beyond,2017,4,15
Towards a general-purpose query language for visualization recommendation,Kanit Wongsuphasawat; Dominik Moritz; Anushka Anand; Jock Mackinlay; Bill Howe; Jeffrey Heer,Abstract Creating effective visualizations requires domain familiarity as well as design andanalysis expertise; and may impose a tedious specification process. To address thesedifficulties; many visualization tools complement manual specification withrecommendations. However; designing interfaces; ranking metrics; and scalablerecommender systems remain important research challenges. In this paper; we propose acommon framework for facilitating the development of visualization recommender systems inthe form of a specification language for querying over the space of visualizations. Wepresent the preliminary design of CompassQL; which defines (1) a partial specification thatdescribes enumeration constraints; and (2) methods for choosing; ranking; and groupingrecommended visualizations. To demonstrate the expressivity of the language; we …,Proceedings of the Workshop on Human-In-the-Loop Data Analytics,2016,4,2
Towards automated prediction of relationships among scientific datasets,Abdussalam Alawini; David Maier; Kristin Tufte; Bill Howe; Rashmi Nandikur,Abstract Before scientists can analyze; publish; or share their data; they often need todetermine how their datasets are related. Determining relationships helps scientists identifythe most complete version of a dataset; detect versions of datasets that complement eachother; and determine multiple datasets that overlap. In previous work; we showed howobservable relationships between two datasets help scientists recall their original derivationconnection. While that work helped with identifying relationships between two datasets; it isinfeasible for scientists to use it for finding relationships between all possible pairs in a largecollection of datasets. In order to deal with larger numbers of datasets; we are extending ourmethodology with a relationship-prediction system; ReDiscover; a tool to identify pairs from acollection of datasets that are most likely related and the relationship between them. We …,Proceedings of the 27th International Conference on Scientific and Statistical Database Management,2015,4,10
The power of data use management in action,Prasang Upadhyaya; Nick Anderson; Magdalena Balazinska; Bill Howe; Raghav Kaushik; Ravi Ramamurthy; Dan Suciu,Abstract In this demonstration; we show-case a database management system extendedwith a new type of component that we call a Data Use Manager (DUM). The DUM enablesDBAs to attach policies to data loaded into the DBMS. It then monitors how users query thedata; flags potential policy violations; recommends possible fixes; and supports offlineanalysis of user activities related to data policies. The demonstration uses real healthcaredata.,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,4,7
Sqlshare: Scientific workflow via relational view sharing,Bill Howe; Francois Ribalet; Daniel Halperin; Sagar Chitnis; E Virginia Armbrust,Abstract We consider a case study in using a web-based query-as-a-service platform as analternative to scriptbased scientific workflows. The context is a project in observationalbiological oceanography to share and process data from a ship-based continuous profiler ofmicrobial populations called SeaFlow. The representative tasks involve aggregating andcleaning SeaFlow measurements; integrating the cleaned dataset with other data sources;and sharing the results with colleagues for ad hoc interactive analysis. We find thatexpressing these tasks as hierarchies of queries instead of chains of scripts can reducedevelopment effort while offering transparency; provenance; versioning; and automaticscalability beyond main memory. In order to realize these benefits; we relax assumptionsmade by conventional databases about the availability of up-front schemas and eliminate …,Computing in Science & Engineering; Special Issue on Science Data Management,2013,4,7
VizDeck: Streamlining exploratory visual analytics of scientific data,Daniel B Perry; Bill Howe; Alicia MF Key; Cecilia Aragon,As research becomes increasingly data-intensive; scientists are relying on visualization veryearly in the data analysis cycle. We find that existing tools assume a “one-at-a-time”workflow for creating visualizations and impose a steep learning curve that makes it difficultto rapidly create and review visualizations. At the same time; scientists are becoming morecognitively overloaded; spending an increasing proportion of time on data “handling” tasksrather than scientific analysis. In response; we present VizDeck; a web-based visualanalytics tool for relational data that automatically recommends a set of appropriatevisualizations based on the statistical properties of the data and adopts a card gamemetaphor to present the results to the user. We describe the design of VizDeck and discussthe results of a usability evaluation comparing VizDeck with three other popular …,*,2013,4,20
Stop That Query! The Need for Managing Data Use.,Prasang Upadhyaya; Nick R Anderson; Magdalena Balazinska; Bill Howe; Raghav Kaushik; Ravishankar Ramamurthy; Dan Suciu,ABSTRACT When valuable data is exchanged or bought; it is frequently encumbered byrestrictions on how it may be used. For example; clinical data must not be used in such away as to expose the patients' identities. To date; these restrictions are enforced onlycontractually and compliance is checked only manually; if at all. To meet the needs of thisgrowing set of applications; we present the vision for a Data Use Manager (DUM). The DUMis a component of a database system that enables the declarative specification andenforcement of sophisticated data use policies and provides capabilities for both their onlineenforcement and offline audit.,CIDR,2013,4,4
Modeling data product generation,Bill Howe; Dave Maier,We have been working closely with environmental scientists who develop and maintain adata product generation engine to support an Environmental Observation and ForecastingSystem used to study the Columbia River Estuary. Provenance issues have beenencountered as artifacts of the complexity and variability of the legacy system; and we havemade some observation about their nature. Below we introduce the application and arguethat a notion of multiple binding times is critical in a provenance scheme designed for dataproduct generation.,Workshop on Data Derivation and Provenance; Chicago,2002,4,15
Managing the Forecast Factory,Laura Bright; David Maier; Bill Howe,The CORIE forecast factory consists of a set of data product generation runs that areexecuted daily on dedicated local resources. The goal is to maximize productivity andresource utilization while still ensuring timely completion of all forecasts. Many existingworkflow management systems address low-level workflow specification and executionchallenges; but do not directly address the high-level challenges posed by large-scale dataproduct factories. In this paper we discuss several specific challenges to managing theCORIE forecast factory including planning and scheduling; improving data flow; andanalyzing log data; and point out their analogs in the" physical" manufacturing world. Wepresent solutions we have implemented to address these challenges; and presentexperimental results that show the benefits of these solutions.,Data Engineering Workshops; 2006. Proceedings. 22nd International Conference on,2006,3,4
Retrofitting a Data Model to Existing Environmental Data.,Bill Howe; David Maier,Abstract Environmental data repositories are frequently stored as a collection of packedbinary files arranged in an intricate directory structure; rather than in a database. In previouswork; we 1) show that environmental data is often logically equipped with a topological gridstructure and 2) provide a data model and algebra of gridfields for manipulating suchgridded datasets. In this paper; we show how to expose native data sources as gridfieldswithout preprocessing; bulkloading; or other prohibitively expensive operations. Wedescribe native directory structures and file contents using a simple schema languagebased on nested; variable-length arrays. This language is capable of describing generalbinary file formats as well as custom formats such as those used in the CORIEEnvironmental Observation and Forecasting System. We provide optimization techniques …,SSDBM,2005,3,7
Computational Astrophysics,SAEG Falle; SS Komissarov; DA Clarke; MJ West,*,*,1997,3
DataSynthesizer: Privacy-preserving synthetic datasets,Haoyue Ping; Julia Stoyanovich; Bill Howe,Abstract To facilitate collaboration over sensitive data; we present DataSynthesizer; a toolthat takes a sensitive dataset as input and generates a structurally and statistically similarsynthetic dataset with strong privacy guarantees. The data owners need not release theirdata; while potential collaborators can begin developing models and methods with someconfidence that their results will work similarly on the real dataset. The distinguishing featureof DataSynthesizer is its usability---the data owner does not have to specify any parametersto start generating and sharing data safely and effectively. DataSynthesizer consists of threehigh-level modules---DataDescriber; DataGenerator and ModelInspector. The first;DataDescriber; investigates the data types; correlations and distributions of the attributes inthe private dataset; and produces a data summary; adding noise to the distributions to …,Proceedings of the 29th International Conference on Scientific and Statistical Database Management,2017,2,5
Lara: A Key-Value Algebra underlying Arrays and Relations,Dylan Hutchison; Bill Howe; Dan Suciu,Abstract: Data processing systems roughly group into families such as relational; array;graph; and key-value. Many data processing tasks exceed the capabilities of any one family;require data stored across families; or run faster when partitioned onto multiple families.Discovering ways to execute computation among multiple available systems; let alonediscovering an optimal execution plan; is challenging given semantic differences betweendisparate families of systems. In this paper we introduce a new algebra; Lara; whichunderlies and unifies algebras representing the families above in order to facilitatetranslation between systems. We describe the operations and objects of Lara---union; join;and ext on associative tables---and show her properties and equivalences to other algebras.Multi-system optimization has a bright future; in which we proffer Lara for the role of …,arXiv preprint arXiv:1604.03607,2016,2,7
Scalable clustering algorithms for continuous environmental flow cytometry,Jeremy Hyrkas; Sophie Clayton; Francois Ribalet; Daniel Halperin; E Virginia Armbrust; Bill Howe,Abstract Motivation: Recent technological innovations in flow cytometry now allowoceanographers to collect high-frequency flow cytometry data from particles in aquaticenvironments on a scale far surpassing conventional flow cytometers. The SeaFlowcytometer continuously profiles microbial phytoplankton populations across thousands ofkilometers of the surface ocean. The data streams produced by instruments such asSeaFlow challenge the traditional sample-by-sample approach in cytometric analysis andhighlight the need for scalable clustering algorithms to extract population information fromthese large-scale; high-frequency flow cytometers. Results: We explore how availablealgorithms commonly used for medical applications perform at classification of such a large-scale; environmental flow cytometry data. We apply large-scale Gaussian mixture models …,Bioinformatics,2015,2,7
VizDeck: a card game metaphor for fast visual data exploration,Bill Howe; Alicia Key; Daniel Perry; Cecilia Aragon,Abstract Scientists in all fields are acquiring data at a rate that is challenging the limits ofhuman cognitive capacity. At the same time; researchers' attention is increasingly claimed byever more diverse demands on their time. Visual perception is the highest bandwidthchannel into the human brain; yet many existing visualization tools require a period oftraining rendering them inaccessible from a practical standpoint for many users. In addition;appropriate visualizations for cognitively overloaded users may differ from those optimizedfor analysis. We present VizDeck; a web-based visualization system for relational data thatuses a card game metaphor and automatic visualization techniques to assist scientists andresearchers in creating interactive visual dashboard applications in seconds with noprogramming necessary.,CHI'12 Extended Abstracts on Human Factors in Computing Systems,2012,2,7
Fides: Towards a platform for responsible data science,Julia Stoyanovich; Bill Howe; Serge Abiteboul; Gerome Miklau; Arnaud Sahuguet; Gerhard Weikum,Issues of responsible data analysis and use are coming to the forefront of the discourse indata science research and practice; with most significant efforts to date on the part of thedata mining; machine learning; and security and privacy communities. In these fields; theresearch has been focused on analyzing the fairness; accountability and transparency (FAT)properties of specific algorithms and their outputs. Although these issues are most apparentin the social sciences where fairness is interpreted in terms of the distribution of resourcesacross protected groups; management of bias in source data affects a variety of fields.Consider climate change studies that require representative data from geographicallydiverse regions; or supply chain analyses that require data that represents the diversity ofproducts and customers. Any domain that involves sparse or sampled data has exposure …,SSDBM'17-29th International Conference on Scientific and Statistical Database Management,2017,1,4
Wide-Open: Accelerating public data release by automating detection of overdue datasets,Maxim Grechkin; Hoifung Poon; Bill Howe,Open data is a vital pillar of open science and a key enabler for reproducibility; data reuse;and novel discoveries. Enforcement of open-data policies; however; largely relies onmanual efforts; which invariably lag behind the increasingly automated generation ofbiological data. To address this problem; we developed a general approach to automaticallyidentify datasets overdue for public release by applying text mining to identify datasetreferences in published articles and parse query results from repositories to determine if thedatasets remain private. We demonstrate the effectiveness of this approach on 2 popularNational Center for Biotechnology Information (NCBI) repositories: Gene ExpressionOmnibus (GEO) and Sequence Read Archive (SRA). Our Wide-Open system identified alarge number of overdue datasets; which spurred administrators to respond directly by …,PLoS biology,2017,1,7
Deep mapping of the visual literature,Bill Howe; Po-shen Lee; Maxim Grechkin; Sean T Yang; Jevin D West,Abstract We consider how patterns of figure use in the scientific literature relate to impact;change over time; and vary across disciplines. We use a convolutional neural network toembed figures as feature vectors in a high-dimensional space; then visualize this space as a2D heatmap to expose patterns. We consider how these patterns vary with respect to time;impact; and discipline; concluding that high-impact papers tend to include significantly moredata-carrying figures (ie; visualizations); despite a downward trend in such figures overall.We also show how this approach can be used to bootstrap targeted information extractionprojects for specific figure types; describing one such project involving phylogenetic trees.,Proceedings of the 26th International Conference on World Wide Web Companion,2017,1,7
Scalable and efficient flow-based community detection for large-scale graph analysis,Seung-Hee Bae; Daniel Halperin; Jevin D West; Martin Rosvall; Bill Howe,Abstract Community detection is an increasingly popular approach to uncover importantstructures in large networks. Flow-based community detection methods rely oncommunication patterns of the network rather than structural properties to determinecommunities. The Infomap algorithm in particular optimizes a novel objective function calledthe map equation and has been shown to outperform other approaches in third-partybenchmarks. However; Infomap and its variants are inherently sequential; limiting their usefor large-scale graphs. In this article; we propose a novel algorithm to optimize the mapequation called RelaxMap. RelaxMap provides two important improvements over Infomap:parallelization; so that the map equation can be optimized over much larger graphs; andprioritization; so that the most important work occurs first; iterations take less time; and the …,ACM Transactions on Knowledge Discovery from Data (TKDD),2017,1,4
High variety cloud databases,Shrainik Jain; Dominik Moritz; Bill Howe,Big Data is colloquially described in terms of the three Vs: Volume; Velocity; and Variety.Volume and velocity receive a disproportionate amount of research attention; however;variety is frequently cited by practitioners as the Big Data problem that “keeps them up atnight”-the problem that resists direct attacks in terms of new algorithms; systems; andapproaches. We find that the cloud-based data management platform attracts higher varietyworkloads; therefore motivating a new classes of High Variety Database ManagementSystems (HVDBMS). This work provides an operational model of variety emphasizing thecomplexity of user intent as well as the complexity of the data itself. The proposed modelcaptures intuitive notions of variety that are distinct from; and broader than; conventionaldata integration challenges; establishes criteria for a “High Variety benchmark” that can …,Data Engineering Workshops (ICDEW); 2016 IEEE 32nd International Conference on,2016,1,7
Data Cleaning in the Wild: Reusable Curation Idioms from a Multi-Year SQL Workload,Shrainik Jain; Bill Howe,ABSTRACT In this work-in-progress paper; we extract a set of curation idioms from a five-year corpus of hand-written SQL queries collected from a Database-as-a-Service platformcalled SQLShare. The idioms we discover in the corpus include structural manipulationtasks (eg; vertical and horizontal recomposition); schema manipulation tasks (eg; columnrenaming and reordering); and value manipulation tasks (eg; manual type coercion; nullstandardization; and arithmetic transformations). These idioms suggest that users find SQLto be an appropriate language for certain data curation tasks; but we find that applying theseidioms in practice is sufficiently awkward to motivate a set of new services to help automatecleaning and curation tasks. We present these idioms; the workload from which they werederived; and the features they motivate in SQL to help automate tasks. Looking ahead; we …,Proceedings of the 11th International Workshop on Quality in Databases; QDB,2016,1,7
Time-Varying Clusters in Large-Scale Flow Cytometry.,Jeremy Hyrkas; Daniel Halperin; Bill Howe,Abstract Flow cytometers measure the optical properties of particles to classify microbes.Recent innovations have allowed oceanographers to collect flow cytometry datacontinuously during research cruises; leading to an explosion of data and new challengesfor the classification task. The massive scale; time-varying underlying populations; and noisymeasurements motivate the development of new classification methods. We describe theproblem; the data; and some preliminary results demonstrating the difficulty withconventional methods.,AAAI,2015,1,4
Dynamic Client-Server Optimization for Scalable Interactive Visualization on the Web,Dominik Moritz; Jeffrey Heer; Bill Howe,Abstract—Low latency interactive data visualizations of large volumes of data are still rareon the web today. Their development requires expertise in server development; API design;dataflow optimization; and browser technologies; developers rarely have the time tooptimize the whole stack from server to browser. To lift the burden of client-server co-development; we propose a system that generates visualization applications fromdeclarative visualization and interaction specifications. We envision a system thatautomatically optimizes a visualization plan to reduce latencies; especially in low-connectivity or mobile networks. In this paper; we investigate the design of automatedtechniques to determine a partition of work across server and client that minimizes latency.Our cost model is based on a combination of data statistics; network performance …,Workshop on Data Systems for Interactive Analysis (DSIA’15),2015,1,11
Compiling queries for high-performance computing,Brandon Myers; Bill Howe; Mark Oskin,Abstract Data-intensive applications motivate the integration of highproductivity querylanguages with high-performance computing runtimes. We present a technique Compiledparallel pipelines (CPP) for compiling relational query plans to programs suitable for high-performance computing platforms. Rather than compose a sequential query compiler with ahigh-performance communication library like MPI; we take a holistic approach that leveragesthe capabilities of parallel languages. For each pipeline in the query plan; CPP generates aparallel partitioned global address space (PGAS) program. This approach affords modulardesign; and it allows the compiler to reason about whole pipelines that include parallelismand communication. Using PGAS to efficiently execute queries requires designing efficientshared data structures; generating code that avoids extra messages; and mitigating the …,Submitt. Rev,2015,1,7
Big Data Science Needs Big Data Middleware.,Bill Howe,There has been a “Cambrian explosion” of big data systems proposed and evaluated in thelast eight years; but relatively little understanding of how these systems or the ideas theyrepresent compare and complement one another. In enterprise and science situations;“onesize is unlikely to fit all”: we see analytics teams running multiple systems simultaneously.However; the highest level of abstraction for interoperability achieved in practice is basicallyat the file system; for example; HDFS. At the same time; there has been some convergencearound higher-level data models (relations; arrays; graphs) and higher-level computationalmodels (relational algebra; parallel data-flow; iteration; linear algebra). As a result; thedesign space seems narrower than the implementation space; suggesting an opportunity tobuild a common “complexity hiding” interface to all these seemingly disparate systems to …,CIDR,2015,1,20
Reproducibility; Virtual Appliances; and Cloud Computing,Bill Howe,Science in every discipline increasingly relies on computational and datadriven methods.Perhaps paradoxically; these in silico experiments are often more difficult to reproduce thantraditional laboratory techniques. Software pipelines designed to acquire and process datahave complex version-sensitive interdependencies; their interfaces are often complex andunderdocumented; and the datasets on which they operate are frequently too large toefficiently transport. At the University of Washington eScience Institute; we are exploring therole of cloud computing in mitigating these challenges. A virtual machine (VM) can snapshota researcher's entire working environment; including data; software; dependencies; notes;logs; and scripts. Snapshots of these images can be saved; hosted publicly; and cited inpublications. This approach not only facilitates reproducibility; but incurs very little …,Implementing Reproducible Research,2014,1,7
Radish: Compiling Efficient Query Plans for Distributed Shared Memory,Brandon Myers; Daniel Halperin; Jacob Nelson; Mark Oskin; Luis Ceze; Bill Howe,ABSTRACT We present Radish; a query compiler that generates distributed programs.Recent efforts have shown that compiling queries to machine code for a single-core canremove iterator and control overhead for significant performance gains. So far; systems thatgenerate distributed programs only compile plans for single processors and stitch themtogether with messaging. In this paper; we describe an approach for translating query plansinto distributed programs by targeting the partitioned global address space (PGAS) parallelprogramming model as an intermediate representation. This approach affords a naturaladaptation of pipelining techniques used in singlecore query compilers and an overallsimpler design. We adapt pipelined algorithms to PGAS languages; describe efficient datastructures for PGAS query execution; and implement techniques for mitigating the …,*,2014,1,2
SQLShare: Scientific Workflow Management via Relational View Sharing,Bill Howe; Francois Ribalet; Sagar Chitnis; Ginger Armbrust; Daniel Halperin,*,Computing in Science & Engineering,2013,1
Analog means; digital means; or both and the drive: which method is amore important platform to use toward learning,B Howe; Todd Rose,The goal of this paper is to provide an interdisciplinary research-based framework fordesigning for children in the preschool to elementary years. The research spans fromvarious fields such as neuroscience; psychology; education; human computer interaction;and design/architecture. The end products of the design could be educational toys or spacesfor young children to interact after formal instruction in the classroom. This framework isinterested in the learning process from teaching to reinforcement in open-ended free-play.How can we motivate children to explore new toys and spaces on their own whileseamlessly providing educational reinforcement of important concepts learned in class?How would one go about introducing a concept and then creating a play area that thechildren can build upon that learning? What structures are necessary to know in the brain …,Graduate Paper. Harvard Graduate School of Education,2012,1,4
Towards efficient and precise queries over ten million asteroid trajectory models,Yusra AlSayyad; K Simon Krughoff; Bill Howe; Andrew J Connolly; Magdalena Balazinska; Lynne Jones,Abstract The new generation of telescopes under construction return to the same area of thesky with sufficient frequency to enable tracking of moving objects such as asteroids; near-earth objects; and comets [4; 5]. To detect these moving objects; one image may besubtracted from another (separated by several days or weeks) to differentiate variable andmoving sources from the dense background of stars and galaxies. Moving sources may thenbe identified by querying against a database of expected positions of known asteroids. At ahigh-level; this task maps onto executing the query:“Return all known asteroids that areexpected to be located within a given region at a given time.” We consider the problem ofquerying for asteroids in a specified interval in space and time; specifically as applied topopulating the simulations of the data flow from the Large Synoptic Survey Telescope …,International Conference on Scientific and Statistical Database Management,2011,1,12
Query-driven visualization in the cloud with mapreduce,Bill Howe; Huy Vo; Claudio Silva; J Freire,We explore the MapReduce programming model for massivescale query-driven visualanalytics. Massively parallel programming frameworks such as MapReduce are increasinglypopular for simplifying data processing on hundreds and thousands of cores; offering faulttolerance; linear scale-up; and a high-level programming interface. However; these tools arebatch-oriented and are awkward to use directly for visualization. Informed by the successand popularity of MapReduce in the database research community; we evaluate thetradeoffs of using MapReduce to support massivescale query-driven visualization; where“query" implies not just simple subsetting; but database-style algebraic manipulation. Cloudcomputing promises an economy of scale for hardware; power; facilities; management; and;increasingly; software by moving computation and data to large; shared data centers. Two …,Proceedings of the Fourth Annual Workshop on Ultrascale Visualization,2009,1,7
Logical and Physical Data Independence for Native Scientific Data Repositories.,Bill Howe; David Maier,Abstract Many datasets in the physical sciences; especially the results of simulations; aredefined over a topological grid structure. Applications in these domains would benefit from aprincipled interface to gridded datasets via a specialized data model. Traditionally; benefitsof a data model are realized only after data is ensconced within a managed databaseenvironment. However; massive bulk-loading and reloading operations in large-scale datarepositories are prohibitively expensive. Instead; we superimpose a specialized data modelover native data repositories stored on directly on OS filesystems rather than managed by adatabase system. Views in a specialized data model can be defined via references to nativedirectory structures and file content; providing physical and logical data independence. Thisnon-intrusive approach appears to reduce space requirements; speed development; and …,IEEE Data Eng. Bull.,2004,1,10
The forest portal: a multidisciplinary project,Marianne Koch; Lois Delcambre; Patricia Toccalino; Eric Landis; Fred Phillips; Tim Tolle; Len Shapiro; Nicole Steckler; David Maier; Mathew Weaver; Shawn Bowers; Balbinder Banga; Jason Brewster; Afrem Gutema; Sudarshan Murthy; Bill Howe; Rupa Tummala; Julia Norman; Kirsten Zillman; David Drake; Craig Palmer; Ashley Burt,Abstract This project partners the USDA Forest Service with researchers at severaluniversities and federal agencies. The goal of the project is to improve the management ofnatural resources by providing easy access to documents. These documents may includedecision notices; environmental impact statements; and specialist reports. They areproduced and stored by natural resource managers at many different places across thePacific Northwest in many differing forms; some of them not electronic (Delcambre; Tolle; etal.; 2003).,Proceedings of the 2003 annual national conference on Digital government research,2003,1,7
Ocean acoustics observatories alternate source test (AST) cruise report,B Howe,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,http://atoc. ucsd. edu/,1996,1,7
A Language for Environmental Data Manipulation,B Howe; D Maier; A Baptista,Abstract Environmental Observation and Forecasting Systems (EOFS) create newopportunities and challenges for generation and use of environmental data products (eg;see Baptista et al. companion paper). The number and diversity of these data products;however; has been artificially constrained by the lack of a simple descriptive language forexpressing them. Data products that can be described simply in English take pages ofobtuse scripts to generate. The scripts obfuscate the original intent of the data productmaking it difficult for users and scientists to understand the overall product catalog. Theproblem is exacerbated by the evolution of modern EOFS into data product “factories”subject to reliability requirements and daily production schedules. New products must bedeveloped and assimilated into the product suite as quickly as they are imagined …,Journal of Environmental Informatics; To appear,*,1,7
Query2Vec: NLP Meets Databases for Generalized Workload Analytics,Shrainik Jain; Bill Howe,Abstract: We propose methods for learning vector representations of SQL workloads tosupport a variety of administration tasks and application features; including queryrecommendation; workload summarization; index selection; identifying expensive queries;and predicting query reuse. We consider vector representations of both raw SQL text andoptimized query plans under various assumptions and pre-processing strategies; andevaluate these methods on multiple real SQL workloads by comparing with results of taskand application feature metrics in the literature. We find that simple algorithms based onthese generic vector representations compete favorably with previous approaches thatrequire a number of assumptions and task-specific heuristics. We then present a newembedding strategy specialized for queries based on tree-structured Long Short Term …,arXiv preprint arXiv:1801.05613,2018,*,10
PhyloParser: A Hybrid Algorithm for Extracting Phylogenies from Dendrograms,Po-shen Lee; Sean T Yang; Jevin D West; Bill Howe,*,2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR),2017,*
Synthetic Data for Social Good,Bill Howe; Julia Stoyanovich; Haoyue Ping; Bernease Herman; Matt Gee,Abstract: Data for good implies unfettered access to data. But data owners must beconservative about how; when; and why they share data or risk violating the trust of thepeople they aim to help; losing their funding; or breaking the law. Data sharing agreementscan help prevent privacy violations; but require a level of specificity that is premature duringpreliminary discussions; and can take over a year to establish.,arXiv preprint arXiv:1710.08874,2017,*,4
EZLearn: Exploiting Organic Supervision in Large-Scale Data Annotation,Maxim Grechkin; Hoifung Poon; Bill Howe,Abstract: We propose Extreme Zero-shot Learning (EZLearn) for classifying data intopotentially thousands of classes; with zero labeled examples. The key insight is to leveragethe abundant unlabeled data together with two sources of organic supervision: a lexicon forthe annotation classes; and text descriptions that often accompany unlabeled data. Suchindirect supervision is readily available in science and other high-value applications. Theclasses represent the consensus conceptualization of a given domain; and their standardreferences can be easily obtained; often readily available in an existing domain ontology.Likewise; to facilitate reuse; public datasets typically include text descriptions; some of whichmention the relevant classes. To exploit such organic supervision; EZLearn introduces anauxiliary natural language processing system; which uses the lexicon to generate initial …,arXiv preprint arXiv:1709.08600,2017,*,14
Profiling a GPU database implementation: a holistic view of GPU resource utilization on TPC-H queries,Emily Furst; Mark Oskin; Bill Howe,Abstract General Purpose computing on Graphics Processing Units (GPGPU) has becomean increasingly popular option for accelerating database queries. However; GPUs are notwell-suited for all types of queries as data transfer costs can often dominate query execution.We develop a methodology for quantifying how well databases utilize GPU architecturesusing proprietary profiling tools. By aggregating various profiling metrics; we break down thedifferent aspects that comprise occupancy on the GPU across the runtime of queryexecution. We show that for the Alenka GPU database; only a small minority of executiontime; roughly 5% is spent on the GPU. We further show that even on queries with seeminglygood performance; a large portion of the achieved occupancy can actually be attributed tostalls and scalar instructions.,Proceedings of the 13th International Workshop on Data Management on New Hardware,2017,*,10
Data Science Education: We're Missing the Boat; Again,Bill Howe; Michael Franklin; Laura Haas; Tim Kraska; Jeffrey Ullman,In the first wave of data science education programs; data engineering topics (systems;scalable algorithms; data management; integration) tended to be de-emphasized in favor ofmachine learning and statistical modeling. The anecdotal evidence suggests this was amistake: data scientists report spending most of their time grappling with data far upstream ofmodeling activities. A second wave of data science education is emerging; one withincreased emphasis on practical issues in ethics; legal compliance; scientific reproducibility;data quality; and algorithmic bias. The data engineering community has a second chance toinfluence these programs beyond just providing a set of tools. In this panel; we'll discuss therole of data engineering in data science education programs; and how best to capitalize onemerging opportunities in this space.,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,*,14
Transforming Data into the Appropriate Context,Bill Howe,Data acquired from sensors; experiments; or simulations or identified in external databasesmust be transformed into the right context to make discoveries. These transformations relyon establishing a common structure and semantics tailored for the given task. Top-downapproaches to data integration that rely on establishing universal consensus about themeaning and interpretation of data—global ontologies; schemas; and metadata standards—are incomplete. At the frontier of research; such universal consensus is elusive; by definition.If the data are understood well enough to construct a permanent global schema; then itwould not be the subject of research. We argue that there will always exist data that are not“born into compliance” with any such schema or standard. Heterogeneity; ambiguity; andquality issues cannot be “designed away” and must be tolerated at runtime by any …,Data-Intensive Science,2016,*,4
Deciphering ocean carbon in a changing world,Krista Longnecker; Ingrid Obernosterer; Pieter C Dorrestein; Daniel J Repeta; Rob Fatland; Bill Howe; Aron Stubbins; Patricia M Medeiros; Elizabeth B Kujawinski; Lihini I Aluwihare; Jutta Niggemann; Jacob R Waldbauer; Nancy J Hess; Byron C Crump; Mary Ann Moran; Alison Buchan; Sonya T Dyhrman,*,*,2016,*
Uncovering regional variations in the balance of physical and biological controls on phytoplankton ecology with underway flow cytometry,S Clayton; D Halperin; F Ribalet; J Swalwell; B Howe; V Armbrust,Abstract The balance of physical and biological controls on phytoplankton abundance andcommunity structure remains an open question in biological oceanography. In the simplestcase; where physical dynamics are the dominant control on biological distributions; thescales of variation of biological properties should match physical scales. However; we mightalso expect alternative scenarios where biological processes are the dominant control onbiomass distributions and community structure; in which case physical and biological scalesof variation would diverge. Here we test this hypothesis with an extensive; global dataset ofcontinuously collected flow cytometry and underway data. We examine the relationshipbetween the decorrelation length scales of physical and biological quantities. Although weoften find that biological and physical scales coincide (ie physical processes dominate) …,American Geophysical Union; Ocean Sciences Meeting 2016; abstract# ME23A-04,2016,*,1
MusicDB: A Platform for Longitudinal Music Analytics.,Jeremy Hyrkas; Bill Howe,ABSTRACT With public data sources such as Million Song dataset; researchers can nowstudy longitudinal questions about the patterns of popular music; but the scale andcomplexity of the data complicate analysis. We propose MusicDB; a new approach forlongitudinal music analytics that adapts techniques from relational databases to the musicsetting. By representing song timeseries data relationally; we aim to dramatically decreasethe programming effort required for complex analytics while significantly improvingscalability. We show how our platform can improve performance by reducing the amount ofdata accessed for many common analytics tasks; and how such tasks can be implementedquickly in relational languages—variants of SQL. We further show that expressing musicanalytics tasks over relational representations allows the system to automatically …,ISMIR,2016,*,7
University of Washington's eScience Institute Promotes New Training and Career Pathways in Data Science,S Stone; MS Parker; B Howe; E Lazowska,Abstract Rapid advances in technology are transforming nearly every field from" data-poor"to" data-rich." The ability to extract knowledge from this abundance of data is the cornerstoneof 21st century discovery. At the University of Washington eScience Institute; our mission isto engage researchers across disciplines in developing and applying advancedcomputational methods and tools to real world problems in data-intensive discovery. Ourresearch team consists of individuals with diverse backgrounds in domain sciences such asastronomy; oceanography and geology; with complementary expertise in advancedstatistical and computational techniques such as data management; visualization; andmachine learning. Two key elements are necessary to foster careers in data science:individuals with cross-disciplinary training in both method and domain sciences; and …,AGU Fall Meeting Abstracts,2015,*,7
Cloud-Based Computational Tools for Earth Science Applications,AA Arendt; R Fatland; B Howe,Abstract Earth scientists are increasingly required to think across disciplines and utilize awide range of datasets in order to solve complex environmental challenges. Althoughsignificant progress has been made in distributing data; researchers must still invest heavilyin developing computational tools to accommodate their specific domain. Here we documentour development of lightweight computational data systems aimed at enabling rapid datadistribution; analytics and problem solving tools for Earth science applications. Our goal isfor these systems to be easily deployable; scalable and flexible to accommodate newresearch directions. As an example we describe" Ice2Ocean"; a software system aimed atpredicting runoff from snow and ice in the Gulf of Alaska region. Our backend componentsinclude relational database software to handle tabular and vector datasets; Python tools …,AGU Fall Meeting Abstracts,2015,*,5
Lightweight Data Systems in the Cloud: Costs; Benefits and Best Practices,R Fatland; AA Arendt; B Howe; NJ Hess; J Futrelle,Abstract We present here a simple analysis of both the cost and the benefit of using thecloud in environmental science circa 2016. We present this set of ideas to enable thepotential'cloud adopter'research scientist to explore and understand the tradeoffs in movingsome aspect of their compute work to the cloud. We present examples; design patterns andbest practices as an evolving body of knowledge that help optimize benefit to the researchteam. Thematically this generally means not starting from a blank page but rather learninghow to find 90% of the solution to a problem pre-built. We will touch on four topics ofinterest.(1) Existing cloud data resources (NASA; WHOI BCO DMO; etc) and how they canbe discovered; used and improved.(2) How to explore; compare and evaluate cost andcompute power from many cloud options; particularly in relation to data scale (size …,AGU Fall Meeting Abstracts,2015,*,7
Detecting and Dismantling Composite Visualizations in the Scientific Literature,Po-Shen Lee; Bill Howe,Abstract We are analyzing the visualizations in the scientific literature to enhance searchservices; detect plagiarism; and study bibliometrics. An immediate problem is the ubiquitoususe of multi-part figures: single images with multiple embedded sub-visualizations. Suchfigures account for approximately 35% of the figures in the scientific literature. Conventionalimage segmentation techniques and other existing approaches have been shown to beineffective for parsing visualizations. We propose an algorithm to automatically recognizemulti-chart visualizations and segment them into a set of single-chart visualizations; therebyenabling downstream analysis. Our approach first splits an image into fragments based onbackground color and layout patterns. An SVM-based binary classifier then distinguishescomplete charts from auxiliary fragments such as labels; ticks; and legends; achieving an …,International Conference on Pattern Recognition Applications and Methods,2015,*,7
Professional preparation,Subhonmesh Bose,1. Postdoctoral Fellow (2014 – 2015) With E. Bitar at the School of Electrical and ComputerEngineering; Cornell University … 2. PhD (2014) Co-advised by S. Low; A. Wierman; KM Chandyand B. Hassibi at Dept. of Electrical Engineering; California Institute of Technology … 3. Masterof Science (2012) Dept. of Electrical Engineering; California Institute of Technology … 4. Bachelorof Technology (2009) Dept. of Electrical Engineering; Indian Institute of Technology; Kanpur.… 1. Received the Atkinson Center Postdoctoral Fellowship in Sustainability at Cornell University(2014) … 2. Received the Best Paper award in System Operations and Market Economics atIEEE Power and Energy Systems General Meeting (2013) … 3. Finalist at Resnick graduatestudies fellowship in Sustainability Science; Caltech (2013) … 4. Received the Directors' GoldMedal for all-round best performance in graduating batch at IIT Kanpur (2009).,IEEE Trans. on Automatic Control,2015,*,7
SQL is Dead; Long-live SQL: Relational Database Technology in Science Contexts,B Howe; D Halperin,Abstract Relational databases are often perceived as a poor fit in science contexts: Rigidschemas; poor support for complex analytics; unpredictable performance; significantmaintenance and tuning requirements---these idiosyncrasies often make databasesunattractive in science contexts characterized by heterogeneous data sources; complexanalysis tasks; rapidly changing requirements; and limited IT budgets. In this talk; I'll arguethat although the value proposition of typical relational database systems are weak inscience; the core ideas that power relational databases have become incredibly prolific inopen source science software; and are emerging as a universal abstraction for both big dataand small data. In addition; I'll talk about two open source systems we are building to"jailbreak" the core technology of relational databases and adapt them for use in science …,AGU Fall Meeting Abstracts,2014,*,20
Myria: Scalable Analytics as a Service,B Howe; D Halperin; A Whitaker,Abstract At the UW eScience Institute; we're working to empower non-experts; especially inthe sciences; to write and use data-parallel algorithms. To this end; we are building Myria; aweb-based platform for scalable analytics and data-parallel programming. Myria's internalmodel of computation is the relational algebra extended with iteration; such that everyprogram is inherently data-parallel; just as every query in a database is inherently data-parallel. But unlike databases; iteration is a first class concept; allowing us to expressmachine learning tasks; graph traversal tasks; and more. Programs can be expressed in anumber of languages and can be executed on a number of execution environments; but weemphasize a particular language called MyriaL that supports both imperative anddeclarative styles and a particular execution engine called MyriaX that uses an in …,AGU Fall Meeting Abstracts,2014,*,15
The database group at the University of Washington,Magdalena Balazinska; Bill Howe; Dan Suciu,The database group at the University of Washington (UW) was founded in 1998 when thedepartment hired Alon Halevy (now at Google). The group currently consists of about twentyresearchers: three faculty members (the authors); four postdocs; and fifteen students. Alumniinclude faculty members at Computer Science Departments at British Columbia; Michigan;Pennsylvania; Stanford; UMass; Wisconsin; one faculty member at the CMU Tepper Schoolof Business; and several researchers and engineers at Facebook; Google; Microsoft; Nokia;Twitter; and other technology companies. The group has funding from NSF; the Gordon andBetty Moore Foundation; the Alfred P. Sloan Foundation; and several companies includingAmazon; EMC; Google; HP; Intel; Microsoft; NEC; and Yahoo. The group has beenrecognized through several best paper awards and two ACM SIGMOD Best Dissertation …,ACM SIGMOD Record,2014,*,4
usenix conference policies,Rodrigo Fonseca; Dave Maltz; Hitesh Balani; Byung-Gon Chun; Ali Ghodsi; Sharon Goldberg; Jeff Hammerbacher; Joe Hellerstein; Bill Howe; Srikanth Kandula; Dejan Kostić; Michael A Kozuch; Hui Lei; Michael Locasto; David Oppenheimer; KyoungSoo Park; George Porter; Thomas Ristenpart; Xiaowei Yang; Lihua Yuan; John Arrasjid; Erich Nahum; Sambit Sahu; Margo Seltzer; Ion Stoica; John Wilkes; Dongyan Xu,Abstract: Kernel concurrency bugs are notoriously difficult to find during testing since theyare only triggered under certain instruction interleavings. Unfortunately; no tools forsystematically subjecting kernel code to concurrency tests have been proposed to date. Thisgap in tool support may be explained by the challenge of controlling precisely which kernelinterleavings are executed without modifying the kernel under test itself. Furthermore; to bepractical; prohibitive runtime overheads must be avoided and tools must remain portable asthe kernel evolves.,*,2014,*,7
Implementing reproducible research,Alexander A Aarts; Anita Alexander; Peter Attridge; Štěpán Bahník; Michael Barnett-Cowan; Elizabeth Bartmess; Frank A Bosco; Mikio Braun; Benjamin Brown; C Titus Brown; Kristina Brown; Jesse J Chandler; Russ Clay; Hayley Cleary; Michael Cohn; Giulio Costantini; Jan Crusius; Andrew Davison; Jamie DeCoster; Michelle DeGaetano; Ryan Donohue; Elizabeth Dunn; Scott Edmunds; Casey Eggleston; Vivien Estel; Frank J Farach; Susann Fiedler; James G Field; Stanka Fitneva; Ian Foster; Joshua D Foster; Rebecca S Frazier; Juliana Freire; Elisa M Galliani; Roger Giner-Sorolla; Lars Goellner; R Justin Goss; Jesse Graham; James A Grange; Philip Guo; Joshua Hartshorne; Timothy B Hayes; Grace Hicks; Holger Hoefling; Bill Howe; Iain Hrynaszkiewicz; Denise Humphries; Christophe Hurlin; Luis Ibanez; Georg Jahn; Kate Johnson; Jennifer A Joy-Gaba; Heather B Kappes; Calvin K Lai; Daniel Lakens; Kristin A Lane; Etienne P LeBel; Minha Lee; Kristi Lemm; Melissa Lewis; Stephanie C Lin; Peter Li; Sean Mackinnon; Heather Mainard; Tanu Malik; Nathaniel Mann; Michael May; Jarrod Millman; Katherine Moore; Matt Motyl; Stephanie M Müller; Dave Murray-Rust; Peter Murray-Rust; Brian A Nosek; Catherine Olsson; Cheng S Ong; Fernando Perez; Christophe Perignon; Marco Perugini; Quan Pham; Michael Pitts; Kate Ratliff; Frank Renkewitz; Anthony Rossini; Abraham M Rutchick; Gillian Sandstrom; Dylan Selterman; William Simpson; Colin T Smith; Jeffrey R Spies; Victoria Stodden; Thomas Talhelm; Anna Veer; Michelangelo Vianello; Yihui Xie,Abstract In computational science; reproducibility requires that researchers make code anddata available to others so that the data can be analyzed in a similar manner as in theoriginal publication. Code must be available to be distributed; data must be accessible in areadable format; and a platform must be available for widely distributing the data and code.In addition; both data and code need to be licensed permissively enough so that others canreproduce the work without a substantial legal burden. Implementing ReproducibleResearch covers many of the elements necessary for conducting and distributingreproducible research. It explains how to accurately reproduce a scientific result. Dividedinto three parts; the book discusses the tools; practices; and dissemination platforms forensuring reproducibility in computational science. It describes: Computational tools; such …,*,2014,*,7
Education and career paths for data scientists,Magdalena Balazinska; Susan B Davidson; Bill Howe; Alexandros Labrinidis,Abstract MOTIVATION: As industry and science are increasingly data-driven; the need forskilled data scientists is exceeding what our universities are producing. According to aMckinsey report:" By 2018; the United States alone could face a shortage of 140;000 to190;000 people with deep analytical skills". Similarly; the ability to extract knowledge fromscientific data is accelerating discovery and we need the next generation of domainscientists to be experts not only in their domain but also in data management. At the sametime; however; researchers in academia who focus on building instruments or datamanagement tools are often less recognized for their contributions than researchersfocusing purely on the actual science. OVERVIEW: The goal of this panel will be to discussall these challenges. We will discuss various aspects of how we should be educating both …,Proceedings of the 25th International Conference on Scientific and Statistical Database Management,2013,*,7
Semih Salihoglu,M Balazinska; A Das Sarma; B Howe,My graduate work focuses on new theories; algorithms; and systems for performing large-scalejoins of record-oriented data and processing extremely large graphs … Education StanfordUniversity; Stanford; CA Ph.D.; Computer Science (expected summer 2015) • Advisor: JenniferWidom • Thesis Area: Infrastructures for Massive-Scale Data Processing … Yale University;New Haven; CT BS; Computer Science and Economics; 2002-2006 • Summa cum laude; PhiBeta Kappa … Work Experience Microsoft Research Summer Intern; Redmond; WA … Workedon automatically splitting and merging distributed shards of relational tables in SQL Azure basedon real-time queries … Google; Inc. Software Engineer; New York; NY … • SportsBackend: Developed a sports data source for several Google applications including search;Google Alerts; and Android. • Google Notebook: Worked on a browser tool to help users …,Conference on Scientific and Statistical Database Management (SSDBM),2013,*,22
Beyond MapReduce: New Requirements for Scalable Data Processing,Bill Howe; Magdalena Balazinska,The MapReduce programming model has had a transformative impact on dataintensivecomputing; enabling a single programmer to harness hundreds or thousands of computersfor a single task and get up and running in a matter of hours. Processing with thousands ofcomputers require a different set of design considerations dominate: I/O scalability; faulttolerance; and ﬂexibility rather than absolute performance. MapReduce; and the open-source implementation Hadoop; are optimized for these considerations and have becomevery successful as a result. It is difﬁcult to quantify the popularity of the MapReduceframework directly; but one indication of the uptake is the frequency of the search term.Figure 8.1 illustrates the search popularity for terms “mapreduce” and “hadoop” over theperiod 2006 to 2012.1 We see a spike in popularity for the term “mapreduce” in late 2007 …,Data-Intensive Computing: Architectures; Algorithms; and Applications,2012,*,7
Data markets in the cloud,Magdalena Balazinska; Bill Howe; Dan Suciu,Abstract Cloud-computing is transforming many aspects of data management. Most recently;the cloud is seeing the emergence of digital markets for data and associated services. Weobserve that our community has a lot to over in building successful cloud-based datamarkets. We outline some of the key challenges that such markets face and discuss theassociated research problems that our community can help solve.© 2011 VLDBEndowment.,*,2011,*,7
Smart Services for Ad Hoc Databases,Bill Howe,We consider the management of ad hoc databases. An ad hoc database is a collection oftables with possibly unknown relationships gathered to serve a specific; often transient; oftenurgent; purpose. Consider these examples:• A scientist assembles an ad hoc database ofrecent experimental results to prepare a paper or proposal.• Emergency workers respondingto a natural disaster assemble an ad hoc data-base from lists of addresses of nearbyschools; locations of resources (eg; ambulances); and contact information for emergencyworkers.• A consulting business analyst assembles an ad hoc database from a set offinancial spreadsheets provided by management for a short term engagement.• A paralegalassembles an ad hoc database of call logs; transaction records; and other potentialevidence to prepare for litigation. Spreadsheets remain more popular than relational …,*,2011,*,15
Efficient Prediction of Asteroid Positions from Solar System Models,Yusra AlSayyad; S Krughoff; AJ Connolly; L Jones; T Budavari; B Howe,Abstract When simulating the distribution of sources across the night sky; querying forstationary objects; such as galaxies; is relatively simple. For moving objects; such as nearearth objects (NEOs) and main belt asteroids (MBAs); this becomes increasing morecomplex. Each family of solar system objects has a range of abundances and speedsthrough ra/dec space. For example; MBAs are plentiful (10 7) but move slowly (< 1 deg/day);and NEOs are rare (10 5) but can move up to 70 deg/day. How do we optimally store andquery all families of moving objects? We describe performance results and experiencesusing different methods; such as storing bounding boxes for the trajectories; and spatialabstraction tools; such as MSSQL geospatial support and SkyServer's HTM index and libraryof spatial constructs. We apply these results to simulations of the data flow from the Large …,Bulletin of the American Astronomical Society,2011,*,7
CSE 599c Scientific Data Management,Magdalena Balazinska; Bill Howe,Page 1. CSE 599c Scientific Data Management Magdalena Balazinska and Bill Howe Spring2010 Lecture 4 – Data Intensive Analytics Page 2. CSE 599c - Spring 2010 2 References • ParallelDatabase Systems: The Future of High Performance Database Systems. Dave DeWitt and JimGray. Com. of the ACM. 1992. Also in Red Book 4th Ed. Sec. 1 and 2. • MapReduce: SimplifiedData Processing on Large Clusters. Jeffrey Dean and Sanjay Ghemawat. OSDI 2004. Sec. 1 -4. • Pig Latin: A Not-So-Foreign Language for Data Processing. C. Olston; B. Reed; U. Srivastava;R. Kumar and A. Tomkins. SIGMOD 2008. Introduction. • CloudBurst: highly sensitive read mappingwith MapReduce. Michael C. Schatz. Bioinformatics 2009 25(11):1363-1369 • Skew-ResistantParallel Processing of Feature-Extracting Scientific User-Defined Functions. YongChul Kwon;Magdalena Balazinska; Bill Howe; and Jerome Rolia …,*,2010,*,1
Beyond mapreduce,Bill Howe; Magdalena Balazinska,Abstract Introduction and Background The MapReduce programming model has had atransformative impact on dataintensive computing; enabling a single programmer to harnesshundreds or thousands of computers for a single task and get up and running in a matter ofhours. Processing with thousands of computers require a different set of designconsiderations dominate: I/O scalability; fault tolerance; and flexibility rather than absoluteperformance. MapReduce; and the open-source implementation Hadoop; are optimized forthese considerations and have become very successful as a result. It is difficult to quantifythe popularity of the MapReduce framework directly; but one indication of the uptake is thefrequency of the search term. Figure 8.1 illustrates the search popularity for terms“mapreduce” and “hadoop” over the period 2006 to 2012. We see a spike in popularity for …,*,2009,*,1
Scientific Mashups: Runtime-Configurable Data Product Ensembles,Harrison Green-Fishback; Bill Howe,The concept of a mashup is gaining popularity as a rapid-development; reuse-orientedprogramming model to replace monolithic; bottom-up application development---aprogramming style well-suited to scientific data management applications. A variety ofmashup development frameworks exist; but none fully address the needs of the scientificcommunity. Specifically; scientists may be proficient programmers; but they use differenttools than are usually supported in mashup frameworks (eg; arrays and MATLAB rather thanXML and Javascript). Further; typical scientific mashups may extract tens of thousands ofrecords from terabyte-scale datasets. At this scale; visualization techniques must beemployed to quickly convey the gross features of the data---paging through 10 records at atime is not sufficient. Finally; scientific mashups must accommodate users across a wide …,eScience; 2008. eScience'08. IEEE Fourth International Conference on,2008,*,7
The Ocean Appliance: Complete Platform Provisioning for Low-Cost Data Sharing,Bill Howe; Nicholas Hagerty; Ethan Van Matre; David Maier; Antonio Baptista; Charles Seaton; Paul Turner,We report on our progress towards an Ocean Appliance-envisioned as a complete; pre-built"server-in-a-box" equipped with an ocean observation database; a forecast engine; a webserver publishing an extensible web interface; a suite of web services establishinginteroperability; and a library of data ingest and processing functions. Collectively; theseservices allow efficient ingest; organization; analysis; and distribution of observations andmodel results with minimal on-site configuration. By packaging the hardware as well as thesoftware; the effort required to install and adapt the tools to the environment of the local dataprovider is minimized; streamlining the adoption of interoperability standards and simplifyingenvironmental data management. We report results from a pilot project using the applianceto support cruise operations and describe preparations for an upcoming multi-ship …,OCEANS 2007,2007,*,7
GridFields: Model-Driven Query Services for Simulation Results in the Physical Sciences,Bill Howe,As physical scientists and engineers work on increasingly complex problems; numericalsimulation becomes increasingly ubiquitous. Complex problems do not lend themselves toanalytic solutions; and largescale domains are difficult to measure directly. Also; the rapidincrease in available compute resources has removed obstacles to widespread use ofsimulation. However; our collective ability to store; manage; and analyze the results of thesesimulations has fallen behind. A physical system is usually modeled with a set of governingpartial differential equations. An analytical solution to these equations is not available forany but the most trivial problems. An approximate numerical solution is obtained by derivinga set of algebraic equations that can be solved within the computer. The methods forderiving algebraic equations from a set of partial differential equations (Finite Difference …,*,2005,*,22
Querying and visualizing gridded datasets for e-science,Bill Howe; David Maier,We demonstrate a Web service and client application for querying and visualizing datasetsdefined over a topological grid structure. The context for our interest in gridded datasets isCORIE; an environmental observation and forecasting system designed to support scientificand industrial interests in the Columbia River estuary. The CORIE system both measuresand simulates the physical properties of the estuary; generating 5GB of data and thousandsof data products for each simulation run; including visualizations; aggregated results andderived datasets. In the current production CORIE system;" canned" visualizations areproduced eagerly for every run. Users cannot customize their data products nor access thedata directly; inhibiting data sharing. The term e-science is used to connote global;distributed collaboration enabled by sharing of both data and compute resources.,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,*,2
Representing; exploiting; and extracting metadata using metadata++,Mathew Weaver; Bill Howe; Lois Delcambre; Tim Tolle; Dave Maier,1 Introduction Metadata++ is a superimposed metadata model that provides enhanced flexibilityand functionality for creating; maintaining; and searching document metadata. The Metadata++model has its roots in a traditional thesaurus … The Merriam-Webster dictionary defines thesaurusas … Metadata++ provides a more flexible and usable mechanism for the organization andretrieval of documents within an application domain. The motivating domain for developing Metadata++is natural resource management; with the USDA Forest Service as our government partner …There are two main building blocks used in the Metadata++ model: terms and documentproxies. A term is a word or a phrase that represent some thing or concept within the applicationdomain. Terms such as “Wenatchee National Forest”; “air pollution”; and “potentialvegetation” exist within the forestry domain. The basis of Metadata++ is a finite set of terms.,Proceedings of the 2002 annual national conference on Digital government research,2002,*,14
Pilot-Scale CFBC Testing for Evaluating the Feasibility of Capacity Addition-The EGAT MAE MOH Project,MD Mann; B Howe; J Phillips; SN Nakorn,*,ANNUAL INTERNATIONAL PITTSBURGH COAL CONFERENCE,1992,*
Comparison of computational methods for rectangular silencer insertion loss prediction,R Ramakrishnan; R Stevens; B Howe,Abstract The insertion loss (IL) of duct silencers with absorbent material can be predicted bya number numerical techniques. Two of the most common methods are the boundaryelement method and the modal finite element method. These two procedures are applied topredict the IL of rectangular silencers and comparative results are presented,Canadian Acoustics,1991,*,7
Viziometrics: Identifying Central Figures in Scientific Papers,Olga Kazakova; Poshen Lee; Bum Mook Oh; Jevin West; Bill Howe,*,*,*,*
NSF III-2010 PI Workshop Report on “Future Directions for III”,Peggy Agouris; Vassilis Athitsos; Ramazan Aygun; Vineet Bafna; Arindam Banerjee; Chaitan Baru; Juan Bello; Tanya Berger-Wolf; Catherine Blake; Jamie Callan; Yi Chen; Evangelos Christidis; Fernand Cohen; David Cooper; Susan Davidson; Brian Davison; Lois Delcambre; Yanlei Diao; UC Amr El Abbadi; Michael Genesereth; Venu Govindaraju; Jiawei Han; UIUC Brent Heeringa; Bill Howe; Yan Huang; Richard Hull; Watson Christopher Jermaine; Patrick Juola; Richard Karp; Jay Kesan; Alexandros Labrinidis; Kristina Lerman; Chen Li; Boon Thau Loo; Bill Manaris; BS Manjunath,● Spatiotemporal modeling; especially as it relates to fuzzy and abstract information●Support for seamless navigation through space and time datasets o Continuous updates ofdatabases o Fully 3-D spaces o Space/time prediction (eg for event monitoring; resourceallocation; alert issues) o Legacy and historical data integration o Now and then in GoogleEarth: continuously updating its content; accessing legacy and timely data and information;predicting emerging situations● Event-driven approaches: o Event modeling o Automatedattribute recognition o Event similarity assessment o Spatiotemporal event mining oReasoning o Risk assessment; etc. o Integration in a spatiotemporal algebra● Globalmonitoring: cross temporal-and spatial-scale analysis● Mobility; flow; and evolution: fromsingle to composite objects (eg cars; pollution front; groups of people; disease risk) …,*,*,*,14
Workshop of Works in Progress Program Committee,José F Rodrigues Jr; Alexey Lastovetsky; Anshu Dubey; Aristóteles Goés; Arun Konagurthu; Bill Howe; Eduardo Ogasawara; Gilberto Pastorello; Grace Eden; Hongliang Li; Jane Hunter; Lukasz Miroslaw; Lutz Gross; Madhusudhan Govindaraju; Maria Cavalcanti; Narayan Ganesan; Rosane Minghim; Silvia Olabarriaga; Simon Cox; Simon Lin; Susumu Date; Suzanne Shontz; Timoleon Kipouros; Vanessa Braganholo; Vasa Curcin,Page 1. Workshop of Works in Progress Program Committee Chair José F. Rodrigues Jr.;University of São Paulo Program Committee Alexey Lastovetsky; University College DublinAnshu Dubey; Lawrence Berkeley National Laboratory Aristóteles Goés; Universidade Estadualde Feira de Santana Arun Konagurthu; Monash University Bill Howe; University of WashingtonEduardo Ogasawara; Centro Federal de Educação Tecnológica Gilberto Pastorello; LawrenceBerkeley National Laboratory Grace Eden; University of Oxford Hongliang Li; Jilin UniversityJane Hunter; Chinese Academy of Sciences Lukasz Miroslaw; Wroclaw University of TechnologyLutz Gross; The University of Queensland Madhusudhan Govindaraju; Binghamton UniversityMaria Cavalcanti; Instituto Militar de Engenharia Narayan Ganesan; Stevens Institute ofTechnology Rosane Minghim; University of São Paulo …,*,*,*,5
Dear Dr. Lakshmi Kumar Matukumalli; Please accept this letter of intent to submit a proposal to Program# A1201. The requested information is provided below. i. Pro...,Bill Howe,Page 1. Dear Dr. Lakshmi Kumar Matukumalli; Please accept this letter of intent to submit aproposal to Program #A1201. The requested information is provided below. i. Project Director:Steven Roberts Associate Professor School of Aquatic and Fishery Sciences University ofWashington sr320@uw.edu Collaborating Investigators: Bill Howe Director of Research; ScalableData Analytics; eScience Institute Affiliate Assistant Professor Department of Computer Scienceand Engineering University of Washington Eric Peatman Assistant Professor School of Fisheries;Aquaculture and Aquatic Sciences Auburn University Mohamed Salem Assistant Professor Animaland Veterinary Sciences West Virginia University ii. Program Area and the Priority …,*,*,*,4
Symposium Committee,David Rogers; Claudio Silva; Berk Geveci; Hanspeter Pfister; Venkatram Vishwanath; PoSTER CHAIRS; Danny Dunlavy; Huy Vo; Greg Abram; David Bader; Jeff Baumes; Carlos Correa; Carsten Dachsbacher; Steven Drucker; Niklas Elmquist; Tiago Etiene; Issei Fujishiro; Markus Hadwiger; Charles Hansen; Bill Howe; Won-Ki Jeong; Daniel Keim; James Klosowski; Peter Lindstrom; Kwan-Liu Ma; Kenneth Moreland; Klaus Mueller; Torsten Möller; Vijay Natarajan; Marc Olano; Onkar Sahni; Allen Sanderson; Han-Wei Shen; Philipp Slusallek; Madhusudhanan Srinivasan; Rüdiger Westermann; Pak Chung Wong; Hongfeng Yu; Sean Ahern; James Ahrens; Chris R Johnson; Michael Papka,Page 1. Symposium Committee SyMPoSIUM CHAIRS David Rogers Los Alamos NationalLaboratory Claudio Silva Polytechnic Institute of New York University PRoGRAM CHAIRS BerkGeveci Kitware Inc. Hanspeter Pfister Harvard University Venkatram Vishwanath Argonne NationalLaboratory PoSTER CHAIRS Danny Dunlavy Sandia National Laboratories Huy Vo PolytechnicInstitute of New York University International Program Committee Greg Abram University of Texasat Austin David Bader Georgia Institute of Technology Jeff Baumes Kitware Inc. Carlos CorreaGoogle Carsten Dachsbacher Karlsruhe Institute of Technology Steven Drucker MicrosoftResearch Niklas Elmquist Purdue University Tiago Etiene University of Utah Issei Fujishiro KeioUniversity Markus Hadwiger King Abdullah University of Science and Technology Charles HansenUniversity of Utah Bill Howe University of Washington …,*,*,*,7
NSF III-2010 Workshop: PI Reports,Peggy Agouris; Vassilis Athitsos; Ramazan Aygun; Vineet Bafna; Arindam Banerjee; Chaitan Baru; Juan Bello; Tanya Berger-Wolf; Catherine Blake; Jamie Callan; Yi Chen; Evangelos Christidis; Fernand Cohen; David Cooper; Susan Davidson; Brian Davison; Lois Delcambre; Yanlei Diao; UC Amr El Abbadi; Michael Genesereth; Venu Govindaraju; Jiawei Han; UIUC Brent Heeringa; Bill Howe; Yan Huang; Richard Hull; Watson Christopher Jermaine; Patrick Juola; Richard Karp; Jay Kesan; Alexandros Labrinidis; Kristina Lerman; Chen Li; Boon Thau Loo; Bill Manaris; BS Manjunath,The workshop brought together the most active researchers in spatiotemporal informaticsfrom the fields of computer science; geoinformation science; engineering and geography.Because participants included representatives from industry; government; and K-12educators; the presented views represented all facets of the field; and thus contributedtowards a well-rounded exchange of ideas as to future trends and needs. More specifically;workshop participants gave presentations which addressed the following questions aboutthe field of geospatial and geotemporal informatics: 1. What is solved? Include expected andsurprise successes. 2. What is almost solved? Include on-going hot areas. 3. What hasfailed? Include surprise failures. 4. What is missing? Discuss areas not currently on theradar. 5. What is next? Include both high risk and needed topics.,*,*,*,7
Symposium committee,Chris Johnson; Michael Papka; Roger Barga; Hanspeter Pfister; David Rogers; PoSTERS CHAIRS; Venkatram Vishwanath; Danny Dunlavy; Wes Bethel; Min Chen; Hank Childs; Pat Crossno; Carsten Dachsbacher; Mike Dobin; Michael Doggett; Steven Drucker; Niklas Elmqvist; Thomas Ertl; Issei Fujishiro; Kelly Gaither; Berk Geveci; Marcus Hadwiger; Bill Howe; Won-Ki Jeong; Ming Jiang; Kirk Jordan; Ken Joy; Jens Kruger; Kwan-Liu Ma; Patrick McCormick; Klaus Mueller; Marc Olano; Rob Ross; Allen Sanderson; Claudio Silva; Philipp Slusallek; Ruediger Westermann; Hongfeng Yu; Sean Ahern; James Ahrens; Patricia Crossno; Mark Dobin; Markus Hadwiger; Jens Krueger; Robert Ross; Rüdiger Westermann,Page 1. Symposium Committee SyMPoSIUM CHAIRS Chris Johnson University of Utah MichaelPapka Argonne National Laboratory PRoGRAM CHAIRS Roger Barga Microsoft ResearchHanspeter Pfister Harvard University David Rogers Sandia National Laboratories PoSTERSCHAIRS Venkatram Vishwanath Argonne National Laboratory Danny Dunlavy Sandia NationalLaboratories International Program Committee Wes Bethel Lawrence Berkeley National LabMin Chen Oxford University Hank Childs Lawrence Berkeley National Labo- ratories Pat CrossnoSandia National Laboratories Carsten Dachsbacher Karlsruhe Institute of Technology Mike DobinExxon Michael Doggett Lund University Steven Drucker Microsoft Research Niklas ElmqvistPurdue University Thomas Ertl University of Stuttgart Issei Fujishiro Keio University Kelly GaitherUniversity of Austin; Texas Berk Geveci Kitware; Inc …,*,*,*,11
Incorporating Scientific Judgment into Workflow Systems for Ocean Science,Nicholas Hagerty; Bill Howe; David Maier; António Baptista,Recent improvements in technology have increased rates of scientific data acquisition sothat scientists are now more often limited by data processing and data management. Anexisting technology beginning to address these problems is workflow management systems(WMS); software applications that facilitate modeling and execution of workflows (egscientific research procedures). However; existing scientific WMS support onlycomputational tasks; lacking the ability to pause for and incorporate user input. Instead;scientific judgment in real time is crucial to workflows in labs and on research cruise at theCenter for Coastal Margin Observation and Prediction (CMOP). Our goal was to create aworkflow system that can display task-specific information and incorporate user input. Icreated and deployed a configurable; dynamic user interface for cruise workflow …,*,*,*,8
VizDeck: Self-Organizing Data Dashboards for eScience,Alicia Key; Bill Howe,We present VizDeck; a web-based visualization client for relational data that uses a cardgame metaphor to assist users in creating interactive visual dashboard applications inseconds with zero programming. VizDeck generates a “hand” of ranked visualizations andUI widgets; and the user plays these “cards” into a dashboard template; where they areautomatically synchronized into a coherent web application that can be saved and sharedwith other users. By manipulating the hand dealt—playing one's “good” cards anddiscarding unwanted cards—the system learns statistically which visualizations areappropriate for a given dataset; improving the quality of the hand dealt for future users. Ourmotivation is that science has been transformed by automated high-throughput dataacquisition technology [17; 2; 8]. DNA sequencers; high-resolution simulations of the …,*,*,*,15
Emergent Semantics: Metadata Organization in a Scientific Data Repository using RDF and RDBMS,Bill Howe; Kuldeep Tanna; Paul Turner; David Maier,*,*,*,*
