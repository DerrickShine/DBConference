Keyword proximity search in complex data graphs,Konstantin Golenberg; Benny Kimelfeld; Yehoshua Sagiv,Abstract In keyword search over data graphs; an answer is a nonredundant subtree thatincludes the given keywords. An algorithm for enumerating answers is presented within anarchitecture that has two main components: an engine that generates a set of candidateanswers and a ranker that evaluates their score. To be effective; the engine must have threefundamental properties. It should not miss relevant answers; has to be efficient and mustgenerate the answers in an order that is highly correlated with the desired ranking. It isshown that none of the existing systems has implemented an engine that has all of theseproperties. In contrast; this paper presents an engine that generates all the answers withprovable guarantees. Experiments show that the engine performs well in practice. It is alsoshown how to adapt this engine to queries under the OR semantics. In addition; this …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,180,19
Finding and approximating top-k answers in keyword proximity search,Benny Kimelfeld; Yehoshua Sagiv,Abstract Various approaches for keyword proximity search have been implemented inrelational databases; XML and the Web. Yet; in all of them; an answer is a Q-fragment;namely; a subtree T of the given data graph G; such that T contains all the keywords of thequery Q and has no proper subtree with this property. The rank of an answer is inverselyproportional to its weight. Three problems are of interest: finding an optimal (ie; top-ranked)answer; computing the top-k answers and enumerating all the answers in ranked order. It isshown that; under data complexity; an efficient algorithm for solving the first problem issufficient for solving the other two problems with polynomial delay. Similarly; an efficientalgorithm for finding a θ-approximation of the optimal answer suffices for carrying out thefollowing two tasks with polynomial delay; under query-and-data complexity. First …,Proceedings of the twenty-fifth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2006,176,20
Query efficiency in probabilistic XML models,Benny Kimelfeld; Yuri Kosharovsky; Yehoshua Sagiv,Abstract Various known models of probabilistic XML can be represented as instantiations ofabstract p-documents. Such documents have; in addition to ordinary nodes; distributionalnodes that specify the probabilistic process of generating a random document. Within thisabstraction; families of pdocuments; which are natural extensions and combinations ofprevious models; are considered. The focus is on efficiency of applying twig queries (withprojection) to p-documents. A closely related issue is the ability to (efficiently) translate agiven document of one family into another family. Furthermore; both of these tasks have twovariants that correspond to the value-based and object-based semantics. The translationrelationships among different families of p-documents are studied. An efficient algorithm forevaluating twig queries over one specific family is given. This algorithm generalizes a …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,108,0
Matching twigs in probabilistic XML,Benny Kimelfeld; Yehoshua Sagiv,Abstract Evaluation of twig queries over probabilistic XML is investigated. Projection isallowed and; in particular; a query may be Boolean. It is shown that for a well-known modelof probabilistic XML; the evaluation of twigs with projection is tractable under datacomplexity (whereas in other probabilistic data models; projection is intractable). Underquery-and-data complexity; the problem becomes intractable even without projection (andfor rather simple twigs and data). In earlier work on probabilistic XML; answers are alwayscomplete. However; there is often a need to produce partial answers because XML data mayhave missing sub-elements and; furthermore; complete answers may be deemed irrelevantif their probabilities are too low. It is shown how to define a semantics that provides partialanswers that are maximal with respect to a probability threshold; which is specified by the …,Proceedings of the 33rd international conference on Very large data bases,2007,101,10
Interconnection semantics for keyword search in XML,Sara Cohen; Yaron Kanza; Benny Kimelfeld; Yehoshua Sagiv,Abstract A framework for describing semantic relationships among nodes in XML documentsis presented. In contrast to earlier work; the XML documents may have ID references (ie;they correspond to graphs and not just trees). A specific interconnection semantics in thisframework can be defined explicitly or derived automatically. The main advantage ofinterconnection semantics is the ability to pose queries on XML data in the style of keywordsearch. Several methods for automatically deriving interconnection semantics arepresented. The complexity of the evaluation and the satisfiability problems under the derivedsemantics is analyzed. For many important cases; the complexity is tractable and hence; theproposed interconnection semantics can be efficiently applied to real-world XML documents.,Proceedings of the 14th ACM international conference on Information and knowledge management,2005,96,0
On the expressiveness of probabilistic XML models,Serge Abiteboul; Benny Kimelfeld; Yehoshua Sagiv; Pierre Senellart,Abstract Various known models of probabilistic XML can be represented as instantiations ofthe abstract notion of p-documents. In addition to ordinary nodes; p-documents havedistributional nodes that specify the possible worlds and their probabilistic distribution.Particular families of p-documents are determined by the types of distributional nodes thatcan be used as well as by the structural constraints on the placement of those nodes in a p-document. Some of the resulting families provide natural extensions and combinations ofpreviously studied probabilistic XML models. The focus of the paper is on the expressivepower of families of p-documents. In particular; two main issues are studied. The first is theability to (efficiently) translate a given p-document of one family into another family. Thesecond is closure under updates; namely; the ability to (efficiently) represent the result of …,The VLDB Journal,2009,92,10
Query evaluation over probabilistic XML,Benny Kimelfeld; Yuri Kosharovsky; Yehoshua Sagiv,Abstract Query evaluation over probabilistic XML is explored. The queries are twig patternswith projection; and the data is represented in terms of three models of probabilistic XML(that extend existing ones in the literature). The first model makes an assumption ofindependence among the probabilistic junctions; whereas the second model can encodeprobabilistic dependencies. The third model combines the first two and; hence; is the mostgeneral. An efficient algorithm (under data complexity) is given for query evaluation in thefirst model. In addition; various optimizations are proposed; and their effectiveness is shownboth analytically and experimentally. For the other two models; it is shown that every query iseither intractable or trivial. Nonetheless; efficient (additive and multiplicative) approximationalgorithms are given for these two models. Finally; Boolean queries are enriched by …,The VLDB Journal,2009,68,20
Design and implementation of the LogicBlox system,Molham Aref; Balder ten Cate; Todd J Green; Benny Kimelfeld; Dan Olteanu; Emir Pasalic; Todd L Veldhuizen; Geoffrey Washburn,Abstract The LogicBlox system aims to reduce the complexity of software development formodern applications which enhance and automate decision-making and enable their usersto evolve their capabilities via a``self-service''model. Our perspective in this area is informedby over twenty years of experience building dozens of mission-critical enterpriseapplications that are in use by hundreds of large enterprises across industries such as retail;telecommunications; banking; and government. We designed and built LogicBlox to be thesystem we wished we had when developing those applications. In this paper; we discuss thedesign considerations behind the LogicBlox system and give an overview of itsimplementation; highlighting innovative aspects. These include: LogiQL; a unified anddeclarative language based on Datalog; the use of purely functional data structures; …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,64,10
Incorporating constraints in probabilistic XML,Sara Cohen; Benny Kimelfeld; Yehoshua Sagiv,Abstract Constraints are important; not only for maintaining data integrity; but also becausethey capture natural probabilistic dependencies among data items. A probabilistic XMLdatabase (PXDB) is the probability subspace comprising the instances of a p-document thatsatisfy a set of constraints. In contrast to existing models that can express probabilisticdependencies; it is shown that query evaluation is tractable in PXDBs. The problems ofsampling and determining well-definedness (ie; whether the aforesaid subspace isnonempty) are also tractable. Furthermore; queries and constraints can include theaggregate functions count; max; min; and ratio. Finally; this approach can be easilyextended to allow a probabilistic interpretation of constraints.,ACM Transactions on Database Systems (TODS),2009,58,10
Jerusalem,Sara Cohen; Lior Ebel; Benny Kimelfeld,Abstract Social networks are ubiquitous; with online networks garnering a large portion ofWeb traffic. Both online and offline; social networks structures are an interesting data sourcewhose importance has been recognized for over a hundred years. Research on socialnetwork analysis has dealt with properties of entire networks; in addition to properties ofnodes or sets of nodes. A user queries a social network in pursuit of a desired outcome;such as an expert on a specific medical condition; a set of influential people to promote anew product; or a well-balanced group of database experts to form a program committee.The user may know what the desired outcome is; and may even be able to express it in aformal query language; given the right abstract predicates to represent typical social-networkmeasures (eg; the importance of a node or its relevance to some keywords). However …,*,1977,56,0
Running tree automata on probabilistic XML,Sara Cohen; Benny Kimelfeld; Yehoshua Sagiv,Abstract Tree automata (specifically; bottom-up and unranked) form a powerful tool forquerying and maintaining validity of XML documents. XML with uncertain data can bemodeled as a probability space of labeled trees; and that space is often represented by atree with distributional nodes. This paper investigates the problem of evaluating a treeautomaton over such a representation; where the goal is to compute the probability that theautomaton accepts a random possible world. This problem is generally intractable; but forthe case where the tree automaton is deterministic (and its transitions are defined bydeterministic string automata); an efficient algorithm is presented. The paper discusses theapplications of this result; including the ability to sample and to evaluate queries (eg; inmonadic second-order logic) while requiring a-priori conformance to a schema (eg; DTD) …,Proceedings of the twenty-eighth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2009,55,20
Probabilistic XML: Models and complexity,Benny Kimelfeld; Pierre Senellart,Abstract Uncertainty in data naturally arises in various applications; such as data integrationand Web information extraction. Probabilistic XML is one of the concepts that have beenproposed to model and manage various kinds of uncertain data. In essence; a probabilisticXML document is a compact representation of a probability distribution over ordinary XMLdocuments. Various models of probabilistic XML provide different languages; with variousdegrees of expressiveness; for such compact representations. Beyond representation;probabilistic XML systems are expected to support data management in a way that properlyreflects the uncertainty. For instance; query evaluation entails probabilistic inference; andupdate operations need to properly change the entire probability space. Efficiently andeffectively accomplishing data-management tasks in that manner is a major technical …,*,2013,54,20
Revisiting redundancy and minimization in an XPath fragment,Benny Kimelfeld; Yehoshua Sagiv,Abstract Redundancy and minimization of queries are investigated in a well known fragmentof XPath that includes child and descendant edges; branches; wildcards; and multiple outputnodes. Contrary to a published result; a proposed technique does not guarantee minimalityor even non-redundancy; and it is unknown whether a non-redundant query is also minimal.It is shown that for two sub-fragments; non-redundancy and minimality are the same; andcan be realized by means of simple (local) tests. The latter property is used to prove thattesting non-redundancy is NP-complete.,Proceedings of the 11th international conference on Extending database technology: Advances in database technology,2008,35,10
A dichotomy in the complexity of deletion propagation with functional dependencies,Benny Kimelfeld,Abstract A classical variant of the view-update problem is deletion propagation; where tuplesfrom the database are deleted in order to realize a desired deletion of a tuple from the view.This operation may cause a (sometimes necessary) side effect---deletion of additional tuplesfrom the view; besides the intentionally deleted one. The goal is to propagate deletion so asto maximize the number of tuples that remain in the view. In this paper; a view is defined by aself-join-free conjunctive query (sjf-CQ) over a schema with functional dependencies. Acondition is formulated on the schema and view definition at hand; and the followingdichotomy in complexity is established. If the condition is met; then deletion propagation issolvable in polynomial time by an extremely simple algorithm (very similar to the oneobserved by Buneman et al.). If the condition is violated; then the problem is NP-hard; and …,Proceedings of the 31st ACM SIGMOD-SIGACT-SIGAI symposium on Principles of Database Systems,2012,33,0
Probabilistic data exchange,Ronald Fagin; Benny Kimelfeld; Phokion G Kolaitis,Abstract The work reported here lays the foundations of data exchange in the presence ofprobabilistic data. This requires rethinking the very basic concepts of traditional dataexchange; such as solution; universal solution; and the certain answers of target queries.We develop a framework for data exchange over probabilistic databases; and make a casefor its coherence and robustness. This framework applies to arbitrary schema mappings; andfinite or countably infinite probability spaces on the source and target instances. Afterestablishing this framework and formulating the key concepts; we study the application of theframework to a concrete and practical setting where probabilistic databases are compactlyencoded by means of annotations formulated over random Boolean variables. In this setting;we study the problems of testing for the existence of solutions and universal solutions …,Journal of the ACM (JACM),2011,32,19
Maximizing conjunctive views in deletion propagation,Benny Kimelfeld; Jan Vondrák; Ryan Williams,Abstract In deletion propagation; tuples from the database are deleted in order to reflect thedeletion of a tuple from the view. Such an operation may result in the (often necessary)deletion of additional tuples from the view; besides the intentionally deleted one. The articlestudies the complexity of deletion propagation; where the view is defined by a conjunctivequery (CQ); and the goal is to maximize the number of tuples that remain in the view.Buneman et al. showed that for some simple CQs; this problem can be solved by astraightforward algorithm; which is called here the unidimensional algorithm. The articleidentifies additional cases of CQs where the unidimensional algorithm succeeds; and incontrast; shows that for some other CQs the problem is NP-hard to approximate better thansome constant ratio. In fact; it is shown here that among the CQs without self joins; the …,ACM Transactions on Database Systems (TODS),2012,30,20
Full disjunctions: Polynomial-delay iterators in action,Sara Cohen; Itzhak Fadida; Yaron Kanza; Benny Kimelfeld; Yehoshua Sagiv,Abstract Full disjunctions are an associative extension of the outer-join operator to anarbitrary number of relations. Their main advantage is the ability to maximally combine datafrom different relations while preserving all the original information. An algorithm forefficiently computing full disjunctions is presented. This algorithm is superior to previousones in three ways. First; it is the first algorithm that computes a full disjunction with apolynomial delay between tuples. Hence; it can be implemented as an iterator that producesa stream of tuples; which is important in many cases (eg; pipelined query processing andWeb applications). Second; the total runtime is linear in the size of the output. Third; thealgorithm employs a novel optimization that divides the relation schemes into biconnectedcomponents; uses a separate iterator for each component and applies outerjoins …,Proceedings of the 32nd international conference on Very large data bases,2006,29,8
Understanding queries in a search database system,Ronald Fagin; Benny Kimelfeld; Yunyao Li; Sriram Raghavan; Shivakumar Vaithyanathan,Abstract It is well known that a search engine can significantly benefit from an auxiliarydatabase; which can suggest interpretations of the search query by means of the involvedconcepts and their interrelationship. The difficulty is to translate abstract notions like conceptand interpretation into a concrete search algorithm that operates over the auxiliary database.To surpass existing heuristics; there is a need for a formal basis; which is realized in thispaper through the framework of a search database system; where an interpretation isidentified as a parse. It is shown that the parses of a query can be generated in polynomialtime in the combined size of the input and the output; even if parses are restricted to thosehaving a nonempty evaluation. Identifying that one parse is more specific than another isimportant for ranking answers; and this framework captures the precise semantics of …,Proceedings of the twenty-ninth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2010,28,0
On rewriting XPath queries using views,Foto Afrati; Rada Chirkova; Manolis Gergatsoulis; Benny Kimelfeld; Vassia Pavlaki; Yehoshua Sagiv,Abstract The problem of rewriting a query using a materialized view is studied for a wellknown fragment of XPath that includes the following three constructs: wildcards; descendantedges and branches. In earlier work; determining the existence of a rewriting was shown tobe coNP-hard; but no tight complexity bound was given. While it was argued that Σ 3 p is anupper bound; the proof was based on results that have recently been refuted. Consequently;the exact complexity (and even decidability) of this basic problem has been unknown; andthere have been no practical rewriting algorithms if the query and the view use all the threeconstructs mentioned above. It is shown that under fairly general conditions; there are onlytwo candidates for rewriting and hence; the problem can be practically solved by twocontainment tests. In particular; under these conditions; determining the existence of a …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,28,0
Efficient Engines for Keyword Proximity Search.,Benny Kimelfeld; Yehoshua Sagiv,ABSTRACT This paper presents a formal framework for investigating keyword proximitysearch. Within this framework; three variants of keyword proximity search are defined. For eachvariant; there are algorithms for enumerating all the results in an arbitrary order; in the exact orderand in an approx- imate order. The algorithms for enumerating in the exact order make the inevitableassumption that the size of the query (ie; the number of keywords) is fixed; but the other algorithmsdo not make this assumption. All the algorithms are provably efficient; that is; run with polynomialdelay. The algorithms for enumerating in an approximate order are provably correct for a naturalnotion of approximation that is defined in this paper … 1. INTRODUCTION The World-WideWeb is a catalyst for the amalgamation of two data-extraction paradigms: Information retrievaland database querying. An early work that combined the two paradigms is proximity …,WebDB,2005,26,20
Modeling and querying probabilistic XML data,Benny Kimelfeld; Yehoshua Sagiv,We survey recent results on modeling and querying probabilistic XML data. The literaturecontains a plethora of probabilistic XML models [2; 13; 14; 18; 21; 24; 27]; and most of themcan be represented by means of p-documents [18] that have; in addition to ordinary nodes;distributional nodes that specify the probabilistic process of generating a random document.The above models are families of p-documents that differ in the types of distributional nodesin use. The focus of this survey is on the tradeoff between the ability to express real-worldprobabilistic data (in particular; by taking correlations between atomic events into account)and the efficiency of query evaluation. We concentrate on two important issues. The first isthe ability to efficiently translate a pdocument of one family into that of another. The secondis the complexity of query evaluation over pdocuments (under the usual semantics of …,ACM SIGMOD Record,2009,25,17
The complexity of mining maximal frequent subgraphs,Benny Kimelfeld; Phokion G Kolaitis,Abstract A frequent subgraph of a given collection of graphs is a graph that is isomorphic toa subgraph of at least as many graphs in the collection as a given threshold. Frequentsubgraphs generalize frequent itemsets and arise in various contexts; from bioinformatics tothe Web. Since the space of frequent subgraphs is typically extremely large; research ingraph mining has focused on special types of frequent subgraphs that can be orders ofmagnitude smaller in number; yet encapsulate the space of all frequent subgraphs. Maximalfrequent subgraphs (ie; the ones not properly contained in any frequent subgraph) constitutethe most useful such type. In this article; we embark on a comprehensive investigation of thecomputational complexity of mining maximal frequent subgraphs. Our study is carried out byconsidering the effect of three different parameters: possible restrictions on the class of …,ACM Transactions on Database Systems (TODS),2014,24,15
Maximally joining probabilistic data,Benny Kimelfeld; Yehoshua Sagiv,Abstract Conceptually; the common approach to manipulating probabilistic data is toevaluate relational queries and then calculate the probability of each tuple in the result. Thisapproach ignores the possibility that the probabilities of complete answers are too low and;hence; partial answers (with sufficiently high probabilities) become important. Therefore; weconsider the semantics in which answers are maximal (ie; have the smallest degree ofincompleteness); subject tothe constraint that the probability is still above a given threshold.We investigate the complexity of joining relations under the above semantics. In contrast tothe deterministic case; this approach gives rise to two different enumeration problems. Thefirst is finding all maximal sets of tuples that are join consistent; connected and have a jointprobability above the threshold. The second is computing all maximal tuples that are …,Proceedings of the twenty-sixth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2007,24,15
Document spanners: A formal approach to information extraction,Ronald Fagin; Benny Kimelfeld; Frederick Reiss; Stijn Vansummeren,Abstract An intrinsic part of information extraction is the creation and manipulation ofrelations extracted from text. In this article; we develop a foundational framework where thecentral construct is what we call a document spanner (or just spanner for short). A spannermaps an input string into a relation over the spans (intervals specified by bounding indices)of the string. The focus of this article is on the representation of spanners. Conceptually;there are two kinds of such representations. Spanners defined in a primitive representationextract relations directly from the input string; those defined in an algebra apply algebraicoperations to the primitively represented spanners. This framework is driven by SystemT; anIBM commercial product for text analysis; where the primitive representation is that of regularexpressions with capture variables. We define additional types of primitive spanner …,Journal of the ACM (JACM),2015,23,20
Efficiently enumerating results of keyword search,Benny Kimelfeld; Yehoshua Sagiv,Abstract Various approaches for keyword search in different settings (eg; relationaldatabases; XML and the Web) actually deal with the problem of enumerating K-fragments.For a given set of keywords K; a K-fragment is a subtree T of the given data graph; such thatT contains all the keywords of K and no proper subtree of T has this property. There arethree types of K-fragments: rooted; undirected and strong. This paper describes the firstprovably efficient algorithms for enumerating K-fragments. Specifically; for all three types ofK-fragments; algorithms are given for enumerating all K-fragments with polynomial delay.For rooted K-fragments and acyclic data graphs; an algorithm is given for enumerating withpolynomial delay in the order of increasing weight (ie; the ranked order); assuming that K isof a fixed size. Finally; an efficient algorithm is described for enumerating K-fragments in a …,International Workshop on Database Programming Languages,2005,23,4
Adaptive parser-centric text normalization,Congle Zhang; Tyler Baldwin; Howard Ho; Benny Kimelfeld; Yunyao Li,Abstract Text normalization is an important first step towards enabling many NaturalLanguage Processing (NLP) tasks over informal text. While many of these tasks; such asparsing; perform the best over fully grammatically correct text; most existing textnormalization approaches narrowly define the task in the word-to-word sense; that is; thetask is seen as that of mapping all out-of-vocabulary non-standard words to their in-vocabulary standard forms. In this paper; we take a parser-centric view of normalization thataims to convert raw informal text into grammatically correct text. To understand the real effectof normalization on the parser; we tie normalization performance directly to parserperformance. Additionally; we design a customizable framework to address the oftenoverlooked concept of domain adaptability; and illustrate that the system allows for …,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),2013,22,20
Efficiently enumerating results of keyword search over data graphs,Benny Kimelfeld; Yehoshua Sagiv,Abstract Various approaches for keyword search in different settings (eg; relationaldatabases and XML) actually deal with the problem of enumerating K-fragments. For a givenset of keywords K; a K-fragment is a subtree T of the given data graph; such that T containsall the keywords of K and no proper subtree of T has this property. There are three types of K-fragments: directed; undirected and strong. This paper describes efficient algorithms forenumerating K-fragments. Specifically; for all three types of K-fragments; algorithms aregiven for enumerating all K-fragments with polynomial delay and polynomial space. It isshown how these algorithms can be enhanced to enumerate K-fragments in a heuristicorder. For directed K-fragments and acyclic data graphs; an algorithm is given forenumerating with polynomial delay in the order of increasing weight (ie; the ranked order) …,Information Systems,2008,22,19
A survey on proximity measures for social networks,Sara Cohen; Benny Kimelfeld; Georgia Koutrika,Abstract Measuring proximity in a social network is an important task; with many interestingapplications; including person search and link prediction. Person search is the problem offinding; by means of keyword search; relevant people in a social network. In user-centricperson search; the search query is issued by a person participating in the social networkand the goal is to find people that are relevant not only to the keywords; but also to thesearcher herself. Link prediction is the task of predicting new friendships (links) that arelikely to be added to the network. Both of these tasks require the ability to measure proximityof nodes within a network; and are becoming increasingly important as social networksbecome more ubiquitous. This chapter surveys recent work on scoring measures fordetermining proximity between nodes in a social network. We broadly identify various …,*,2012,20,20
Cleaning inconsistencies in information extraction via prioritized repairs,Ronald Fagin; Benny Kimelfeld; Frederick Reiss; Stijn Vansummeren,Abstract The population of a predefined relational schema from textual content; commonlyknown as Information Extraction (IE); is a pervasive task in contemporary computationalchallenges associated with Big Data. Since the textual content varies widely in nature andstructure (from machine logs to informal natural language); it is notoriously difficult to write IEprograms that extract the sought information without any inconsistencies (eg; a substringshould not be annotated as both an address and a person name). Dealing withinconsistencies is hence of crucial importance in IE systems. Industrial-strength IE systemslike GATE and IBM SystemT therefore provide a built-in collection of cleaning operations toremove inconsistencies from extracted relations. These operations; however; are collectedin an ad-hoc fashion through use cases. Ideally; we would like to allow IE developers to …,Proceedings of the 33rd ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2014,19,0
New algorithms for computing Steiner trees for a fixed number of terminals,Benny Kimelfeld; Yehoshua Sagiv,*,To be found in the first author’s home page (http://www. cs. huji. ac. il/∼ bennyk),2006,19
Using language models and the HITS algorithm for XML retrieval,Benny Kimelfeld; Eitan Kovacs; Yehoshua Sagiv; Dan Yahav,Abstract Our submission to the INEX 2006 Ad-hoc retrieval track is described. We study howto utilize the Wikipedia structure (XML documents with hyperlinks) by combining XML andWeb retrieval. In particular; we experiment with different combinations of language modelsand the HITS algorithm. An important feature of our techniques is a filtering phase thatidentifies the relevant part of the corpus; prior to the processing of the actual XML elements.We analyze the effect of the above techniques based on the results of our runs in INEX2006.,International Workshop of the Initiative for the Evaluation of XML Retrieval,2006,18,15
A graph approach to spelling correction in domain-centric search,Zhuowei Bao; Benny Kimelfeld; Yunyao Li,Abstract Spelling correction for keyword-search queries is challenging in restricted domainssuch as personal email (or desktop) search; due to the scarcity of query logs; and due to thespecialized nature of the domain. For that task; this paper presents an algorithm that isbased on statistics from the corpus data (rather than the query log). This algorithm; whichemploys a simple graph-based approach; can incorporate different types of data sourceswith different levels of reliability (eg; email subject vs. email body); and can handle complexspelling errors like splitting and merging of words. An experimental study shows thesuperiority of the algorithm over existing alternatives in the email domain.,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,2011,17,20
Generating all maximal induced subgraphs for hereditary and connected-hereditary graph properties,Sara Cohen; Benny Kimelfeld; Yehoshua Sagiv,Abstract This paper investigates a graph enumeration problem; called the maximal P-subgraphs problem; where P is a hereditary or connected-hereditary graph property.Formally; given a graph G; the maximal P-subgraphs problem is to generate all maximalinduced subgraphs of G that satisfy P. This problem differs from the well-known node-deletion problem; studied by Yannakakis and Lewis [J. Lewis; On the complexity of themaximum subgraph problem; in: Proc. 10th Annual ACM Symposium on Theory ofComputing; ACM Press; New York; USA; 1978; pp. 265–274; M. Yannakakis; Node-andedge-deletion NP-complete problems; in: Proc. 10th Annual ACM Symposium on Theory ofComputing; ACM Press; New York; USA; 1978; pp. 253–264; J. Lewis; M. Yannakakis; Thenode-deletion problem for hereditary properties is NP-complete; J. Comput. System Sci …,Journal of Computer and System Sciences,2008,17,19
Spanners: a formal framework for information extraction,Ronald Fagin; Benny Kimelfeld; Frederick Reiss; Stijn Vansummeren,Abstract An intrinsic part of information extraction is the creation and manipulation ofrelations extracted from text. In this paper; we develop a foundational framework where thecentral construct is what we call a spanner. A spanner maps an input string into relationsover the spans (intervals specified by bounding indices) of the string. The focus of this paperis on the representation of spanners. Conceptually; there are two kinds of suchrepresentations. Spanners defined in a primitive representation extract relations directly fromthe input string; those defined in an algebra apply algebraic operations to the primitivelyrepresented spanners. This framework is driven by SystemT; an IBM commercial product fortext analysis; where the primitive representation is that of regular expressions with capturevariables. We define additional types of primitive spanner representations by means of …,Proceedings of the 32nd ACM SIGMOD-SIGACT-SIGAI symposium on Principles of database systems,2013,16,0
Exploratory keyword search on data graphs,Hilit Achiezra; Konstantin Golenberg; Benny Kimelfeld; Yehoshua Sagiv,Abstract A system for keyword search on data graphs is demonstrated on two challengingdatasets: the large DBLP and Mondial (which is highly cyclic and has a complex schema).The system supports search; exploration and question answering. The demonstration showshow the system copes with the main challenges in keywords search on data graphs. Inparticular; the system generates answers efficiently and completely (ie; it does not missanswers). It has an effective ranking mechanism that also takes into account redundanciesamong answers. Finally; the system uses a novel technique for displaying multi-nodesubtrees in a compact graphical form that facilitates quick and easy understanding; which isessential for effective browsing of the answers.,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,16,15
Querying parse trees of stochastic context-free grammars,Sara Cohen; Benny Kimelfeld,Abstract Stochastic context-free grammars (SCFGs) have long been recognized as useful fora large variety of tasks including natural language processing; morphological parsing;speech recognition; information extraction; Web-page wrapping and even analysis of RNA.A string and an SCFG jointly represent a probabilistic interpretation of the meaning of thestring; in the form of a (possibly infinite) probability space of parse trees. The problem ofevaluating a query over this probability space is considered under the conventionalsemantics of querying a probabilistic database. For general SCFGs; extremely simplequeries may have results that include irrational probabilities. But; for a large subclass ofSCFGs (that includes all the standard studied subclasses of SCFGs) and the language oftree-pattern queries with projection (and child/descendant edges); it is shown that query …,Proceedings of the 13th International Conference on Database Theory,2010,16,20
Incrementally computing ordered answers of acyclic conjunctive queries,Benny Kimelfeld; Yehoshua Sagiv,Abstract Evaluations of SQL queries with the ORDER BY clause is considered. The naiveapproach of first computing the result and then sorting the tuples is not suitable for Webapplications; since the result could be very large while users expect to get quickly the top-ktuples. Tractability; in this case; amounts to enumerating answers in sorted order withpolynomial delay; under query-and-data complexity. It is proved that an efficient algorithm forfinding the top-ranked tuple of a conjunctive query is a sufficient (and not just necessary)condition for tractability. Several classes of orders are shown to have this property whenqueries are acyclic.,International Workshop on Next Generation Information Technologies and Systems,2006,16,10
Dichotomies in the complexity of preferred repairs,Ronald Fagin; Benny Kimelfeld; Phokion G Kolaitis,Abstract The framework of database repairs provides a principled approach to managinginconsistencies in databases. Informally; a repair of an inconsistence database is aconsistent database that differs from the inconsistent one in a" minimal way." A fundamentalproblem in this framework is the repair-checking problem: given two instances; is the seconda repair of the first? Here; all repairs are taken into account; and they are treated on a parwith each other. There are situations; however; in which it is natural and desired to preferone repair over another; for example; one data source is regarded to be more reliable thananother; or timestamp information implies that a more recent fact should be preferred overan earlier one. Motivated by these considerations; Staworko; Chomicki and Marcinkowskiintroduced the framework of preferred repairs. The main characteristic of this framework is …,Proceedings of the 34th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,2015,15,0
A system for management and analysis of preference data,Marie Jacob; Benny Kimelfeld; Julia Stoyanovich,Abstract Preference data arises in a wide variety of domains. Over the past decade; we haveseen a sharp increase in the volume of preference data; in the diversity of applications thatuse it; and in the richness of preference data analysis methods. Examples of applicationsinclude rank aggregation in genomic data analysis; management of votes in elections; andrecommendation systems in e-commerce. However; little attention has been paid to thechallenges of building a system for preference-data management; which would helpincorporate sophisticated analytics into larger applications; support computationalabstractions for usability by data scientists; and enable scaling up to modern volumes. Thisvision paper proposes a management system for preference data that aims to address thesechallenges. We adopt the relational database model; and propose extensions that are …,Proceedings of the VLDB Endowment,2014,15,0
Efficient enumeration of maximal k-plexes,Devora Berlowitz; Sara Cohen; Benny Kimelfeld,Abstract The problem of enumerating (ie; generating) all maximal cliques in a graph hasreceived extensive treatment; due to the plethora of applications in various areas such asdata mining; bioinformatics; network analysis and community detection. However; requiringthe enumerated subgraphs to be full cliques is too restrictive in common real-life scenarioswhere" almost cliques" are equally useful. Hence; the notion of a k-plex; a clique relaxationthat allows every node to be" missing" k neighbors; has been introduced. But this seeminglyminor relaxation casts existing algorithms for clique enumeration inapplicable; for inherentreasons. This paper presents the first provably efficient algorithms; both for enumerating themaximal k-plexes and for enumerating the maximal connected k-plexes. Our algorithms runin polynomial delay for a constant k and incremental FPT delay when k is a parameter …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,14,11
Transducing markov sequences,Benny Kimelfeld; Christopher Ré,Abstract A Markov sequence is a basic statistical model representing uncertain sequentialdata; and it is used within a plethora of applications; including speech recognition; imageprocessing; computational biology; radio-frequency identification (RFID); and informationextraction. The problem of querying a Markov sequence is studied under the conventionalsemantics of querying a probabilistic database; where queries are formulated as finite-statetransducers. Specifically; the complexity of two main problems is analyzed. The first problemis that of computing the confidence (probability) of an answer. The second is theenumeration of the answers in the order of decreasing confidence (with the generation of thetop-k answers as a special case); or in an approximate order thereof. In particular; it isshown that enumeration in any sub-exponential-approximate order is generally …,Proceedings of the twenty-ninth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2010,14,20
Multi-tuple deletion propagation: approximations and complexity,Benny Kimelfeld; Jan Vondrák; David P Woodruff,Abstract This paper studies the computational complexity of the classic problem of deletionpropagation in a relational database; where tuples are deleted from the base relations inorder to realize a desired deletion of tuples from the view. Such an operation may result in a(sometimes unavoidable) side effect: deletion of additional tuples from the view; besides theintentionally deleted ones. The goal is to minimize the side effect. The complexity of thisproblem has been well studied in the case where only a single tuple is deleted from theview. However; only little is known within the more realistic scenario of multi-tuple deletion;which is the topic of this paper. The class of conjunctive queries (CQs) is among the mostwell studied in the literature; and we focus here on views defined by CQs that are self-joinfree (sjf-CQs). Our main result is a trichotomy in complexity; classifying all sjf-CQs into …,Proceedings of the VLDB Endowment,2013,13,22
Automatic suggestion of query-rewrite rules for enterprise search,Zhuowei Bao; Benny Kimelfeld; Yunyao Li,Abstract Enterprise search is challenging for several reasons; notably the dynamicterminology and jargon that are specific to the enterprise domain. This challenge is partlyaddressed by having domain experts maintaining the enterprise search engine andadapting it to the domain specifics. Those administrators commonly address user complaintsabout relevant documents missing from the top matches. For that; it has been proposed toallow administrators to influence search results by crafting query-rewrite rules; eachspecifying how queries of a certain pattern should be modified or augmented with additionalqueries. Upon a complaint; the administrator seeks a semantically coherent rule that iscapable of pushing the desired documents up to the top matches. However; the creation andmaintenance of rewrite rules is highly tedious and time consuming. Our goal in this work …,Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,2012,12,15
Twig patterns: From XML trees to graphs,Benny Kimelfeld; Yehoshua Sagiv,ABSTRACT Existing approaches for querying XML (eg; XPath and twig patterns) assumethat the data form a tree. Often; however; XML documents have a graph structure; due to IDreferences. The common way of adapting known techniques to XML graphs isstraightforward; but may result in a huge number of results; where only a small portion ofthem has valuable information. We propose two mechanisms. Filtering is used foreliminating semantically weak answers. Ranking is used for presenting the remaininganswers in the order of decreasing semantic significance. We show how to integrate thesefeatures in a language for querying XML graphs. Query evaluation is tractable in thefollowing sense. For a wide range of ranking functions; it is possible to generate answers inranked order with polynomial delay; under query-and-data complexity. This result holds …,International Workshop on Web and Databases,2006,12,20
Rewrite rules for search database systems,Ronald Fagin; Benny Kimelfeld; Yunyao Li; Sriram Raghavan; Shivakumar Vaithyanathan,Abstract The results of a search engine can be improved by consulting auxiliary data. In asearch database system; the association between the user query and the auxiliary data isdriven by rewrite rules that augment the user query with a set of alternative queries. Thispaper develops a framework that formalizes the notion of a rewrite program; which isessentially a collection of hedge-rewriting rules. When applied to a search query; the rewriteprogram produces a set of alternative queries that constitutes a least fixpoint (lfp). The mainfocus of the paper is on the lfp-convergence of a rewrite program; where a rewrite program islfp-convergent if the least fixpoint of every search query is finite. Determining whether agiven rewrite program is lfp-convergent is undecidable; to accommodate that; the paperproposes a safety condition; and shows that safety guarantees lfp-convergence; and that …,Proceedings of the thirtieth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2011,10,0
Combining incompleteness and ranking in tree queries,Benny Kimelfeld; Yehoshua Sagiv,Abstract In many cases; users may want to consider incomplete answers to their queries.Often; however; there is an overwhelming number of such answers; even if subsumedanswers are ignored and only maximal ones are considered. Therefore; it is important torank answers according to their degree of incompleteness and; moreover; this rankingshould be combined with other; conventional ranking techniques that are already in use (eg;the relevance of answers to keywords). Query evaluation should take the ranking intoaccount by computing answers incrementally; ie; in ranked order. In particular; theevaluation process should generate the top-k answers efficiently. We show how a semanticsfor incomplete answers to tree queries can be combined with common ranking techniques.In our approach; answers are rewarded for relevancy and penalized for incompleteness …,International Conference on Database Theory,2007,10,19
Research directions for principles of data management (abridged),Serge Abiteboul; Marcelo Arenas; Pablo Barceló; Meghyn Bienvenu; Diego Calvanese; Claire David; Richard Hull; Eyke Hüllermeier; Benny Kimelfeld; Leonid Libkin; Wim Martens; Tova Milo; Filip Murlak; Frank Neven; Magdalena Ortiz; Thomas Schwentick; Julia Stoyanovich; Jianwen Su; Dan Suciu; Victor Vianu; Ke Yi,In April 2016; a community of researchers working in the area of Principles of DataManagement (PDM) joined in a workshop at the Dagstuhl Castle in Germany. The workshopwas organized jointly by the Executive Committee of the ACM Symposium on Principles ofDatabase Systems (PODS) and the Council of the International Conference on DatabaseTheory (ICDT). The mission of the workshop was to identify and explore some of the mostimportant research directions that have high relevance to society and to Computer Sciencetoday; and where the PDM community has the potential to make significant contributions.This article presents a summary of the report created by the workshop [4]. That reportdescribes the family of research directions that the workshop focused on from threeperspectives: potential practical relevance; results already obtained; and research …,ACM SIGMOD Record,2017,9,20
On Principles of Egocentric Person Search in Social Networks.,Sara Cohen; Benny Kimelfeld; Georgia Koutrika; Jan Vondrák,ABSTRACT Person search is the problem of finding; by means of keyword search; relevantpeople in a social network. In egocentric person search; the search query is issued by aperson s participating in the social network; and the goal is to find people that possess twoqualities: relevancy to the query; and relevancy to s herself. This position paper considersthe latter quality; and specifically; scoring functions that rank persons by their relevancy to s.In particular; the paper proposes general principles (ie; properties) that should be held bysuch scoring functions. Several functions; which were proposed in the past for measuringnode connectivity; are analyzed with respect to the proposed principles. It is shown thatnone of these functions sufficiently satisfy the principles. In contrast; the paper presents twoadditional functions that satisfy the principles in a strong sense.,VLDS,2011,9,15
Flexible caching in trie joins,Oren Kalinsky; Yoav Etsion; Benny Kimelfeld,Abstract: Traditional algorithms for multiway join computation are based on rewriting theorder of joins and combining results of intermediate subqueries. Recently; severalapproaches have been proposed for algorithms that are" worst-case optimal" wherein allrelations are scanned simultaneously. An example is Veldhuizen's Leapfrog Trie Join(LFTJ). An important advantage of LFTJ is its small memory footprint; due to the fact thatintermediate results are full tuples that can be dumped immediately. However; since thealgorithm does not store intermediate results; recurring joins must be reconstructed from thesource relations; resulting in excessive memory traffic. In this paper; we address thisproblem by incorporating caches into LFTJ. We do so by adopting recent developments onjoin optimization; tying variable ordering to tree decomposition. While the traditional …,arXiv preprint arXiv:1602.08721,2016,8,10
Database principles in information extraction,Benny Kimelfeld,Abstract Information Extraction commonly refers to the task of populating a relationalschema; having predefined underlying semantics; from textual content. This task ispervasive in contemporary computational challenges associated with Big Data. This tutorialgives an overview of the algorithmic concepts and techniques used for performingInformation Extraction tasks; and describes some of the declarative frameworks that provideabstractions and infrastructure for programming extractors. In addition; the tutorial highlightsopportunities for research impact through principles of data management; illustrates theseopportunities through recent work; and proposes directions for future research.,Proceedings of the 33rd ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2014,8,15
Optimizing and parallelizing ranked enumeration,Konstantin Golenberg; Benny Kimelfeld; Yehoshua Sagiv,ABSTRACT Lawler-Murty's procedure is a general tool for designing algorithms forenumeration problems (ie; problems that involve the production of a large set of answers inranked order); which naturally arise in database management. Lawler-Murty's procedure isused in a variety of modern database applications; particularly in those related to keywordsearch over structured data. Essentially; this procedure enumerates by invoking a series ofinstances of an optimization problem (ie; finding the best solution); solving the optimizationproblem is the only part that depends on the specific task at hand. The topic of optimizingand parallelizing Lawler-Murty's procedure is investigated. Naive parallelism can be carriedout by concurrently solving independent instances of the optimization problem. This can beimproved by printing the next answer; in the enumeration order; as soon as none of the …,Proceedings of the VLDB Endowment,2011,8,15
Declarative probabilistic programming with datalog,Vince Bárány; Balder Ten Cate; Benny Kimelfeld; Dan Olteanu; Zografoula Vagena,Abstract Probabilistic programming languages are used for developing statistical models.They typically consist of two components: a specification of a stochastic process (the prior)and a specification of observations that restrict the probability space to a conditionalsubspace (the posterior). Use cases of such formalisms include the development ofalgorithms in machine learning and artificial intelligence. In this article; we establish aprobabilistic-programming extension of Datalog that; on the one hand; allows for defining arich family of statistical models; and on the other hand retains the fundamental properties ofdeclarativity. Our proposed extension provides mechanisms to include common numericalprobability functions; in particular; conclusions of rules may contain values drawn from suchfunctions. The semantics of a program is a probability distribution over the possible …,ACM Transactions on Database Systems (TODS),2017,7,10
A Social Network Database that Learns How to Answer Queries.,Sara Cohen; Lior Ebel; Benny Kimelfeld,ABSTRACT Social networks are ubiquitous; with online networks garnering a large portionof Web traffic. Both online and offline; social networks structures are an interesting datasource whose importance has been recognized for over a hundred years. Research onsocial network analysis has dealt with properties of entire networks; in addition to propertiesof nodes or sets of nodes. A user queries a social network in pursuit of a desired outcome;such as an expert on a specific medical condition; a set of influential people to promote anew product; or a well-balanced group of database experts to form a program committee.The user may know what the desired outcome is; and may even be able to express it in aformal query language; given the right abstract predicates to represent typical social-networkmeasures (eg; the importance of a node or its relevance to some keywords). However …,CIDR,2013,7,20
SVO-based taxonomy-driven text analytics,*,Textual data is organized into statement clusters. Sentences are extracted from textual dataand parsed. A verb usage pattern is identified and an SVO triplet is determined. The SVOtriplet is compared to a taxonomy associated with the domain of the data and a sentiment isderived. A statement cluster is constructed comprising a higher level SVO triplet sensitive tothe taxonomy and verb usage pattern; as well as the derived sentiment. Accordingly; thestatement clusters may be organized by grouping.,*,2017,6,20
Declarative statistical modeling with Datalog,Vince Barany; Balder ten Cate; Benny Kimelfeld; Dan Olteanu; Zografoula Vagena,Abstract: Formalisms for specifying statistical models; such as probabilistic-programminglanguages; typically consist of two components: a specification of a stochastic process (theprior); and a specification of observations that restrict the probability space to a conditionalsubspace (the posterior). Use cases of such formalisms include the development ofalgorithms in machine learning and artificial intelligence. We propose and investigate adeclarative framework for specifying statistical models on top of a database; through anappropriate extension of Datalog. By virtue of extending Datalog; our framework offers anatural integration with the database; and has a robust declarative semantics. Our Datalogextension provides convenient mechanisms to include numerical probability functions; inparticular; conclusions of rules may contain values drawn from such functions. The …,arXiv preprint arXiv:1412.2221,2014,4,19
Interconnection semantics for XML,Benny Kimelfeld; בני קימלפלד,Abstract A framework for defining and automatically discovering semantic relationshipsamong nodes in XML documents is presented. A specific interconnection semantics in thisframework consists of a set of patterns. Interconnection semantics can be specified explicitlyor derived automatically. Several methods to automatically derive interconnection semanticsare presented. The complexity of determining when nodes are interconnected under thesesemantics is analyzed. For many important cases; the complexity is tractable and hence; theproposed interconnection semantics can be efficiently applied to real-world documents. Inparticular; for acyclically-labeled documents; determining interconnection for a boundedsizeset of nodes is polynomial for most of these semantics. The inverse problem of constructinga document from a given set of objects and the interconnections that hold among those …,*,2004,4,22
Automatic suggestion for query-rewrite rules,*,Embodiments of the invention relate to automatically suggesting query-rewrite rules. Oneembodiment includes providing a missing search result for a query. A collection ofsemantically coherent rewrite rules are generated based on the missing search result.Generating the missing search result includes: selecting candidates includingsubsequences of the query and subsequences of particular fields of a document; invoking asearch engine using the candidates for providing search results; filtering out particularcandidates that fail to achieve a desired search result; and classifying remaining candidatesbased on a learned classifier. Query rewrite rules for document searching are suggestedbased on the classified remaining candidates.,*,2016,3,10
Declarative cleaning of inconsistencies in information extraction,Ronald Fagin; Benny Kimelfeld; Frederick Reiss; Stijn Vansummeren,Abstract The population of a predefined relational schema from textual content; commonlyknown as Information Extraction (IE); is a pervasive task in contemporary computationalchallenges associated with Big Data. Since the textual content varies widely in nature andstructure (from machine logs to informal natural language); it is notoriously difficult to write IEprograms that unambiguously extract the sought information. For example; during extraction;an IE program could annotate a substring as both an address and a person name. When thishappens; the extracted information is said to be inconsistent; and some way of removinginconsistencies is crucial to compute the final output. Industrial-strength IE systems likeGATE and IBM SystemT therefore provide a built-in collection of cleaning operations toremove inconsistencies from extracted relations. These operations; however; are …,ACM Transactions on Database Systems (TODS),2016,3,1
Transducing Markov sequences,Benny Kimelfeld; Christopher Re,Abstract A Markov sequence is a basic statistical model representing uncertain sequentialdata; and it is used within a plethora of applications; including speech recognition; imageprocessing; computational biology; radio-frequency identification (RFID); and informationextraction. The problem of querying a Markov sequence is studied under the conventionalsemantics of querying a probabilistic database; where queries are formulated as finite-statetransducers. Specifically; the complexity of two main problems is analyzed. The first problemis that of computing the confidence (probability) of an answer. The second is theenumeration of the answers in the order of decreasing confidence (with the generation of thetop-k answers as a special case); or in an approximate order thereof. In particular; it isshown that enumeration in any subexponential-approximate order is generally intractable …,Journal of the ACM (JACM),2014,3,20
Finding a minimal tree pattern under neighborhood constraints,Benny Kimelfeld; Yehoshua Sagiv,Abstract Tools that automatically generate queries are useful when schemas are hard tounderstand due to size or complexity. Usually; these tools find minimal tree patterns thatcontain a given set (or bag) of labels. The labels could be; for example; XML tags or relationnames. The only restriction is that; in a tree pattern; adjacent labels must be among somespecified pairs. A more expressive framework is developed here; where a schema is amapping of each label to a collection of bags of labels. A tree pattern conforms to theschema if for all nodes v; the bag comprising the labels of the neighbors is contained in oneof the bags to which the label of v is mapped. The problem at hand is to find a minimal treepattern that conforms to the schema and contains a given bag of labels. This problem is NP-hard even when using the simplest conceivable language for describing schemas. In …,Proceedings of the thirtieth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2011,3,0
ExQueX: exploring and querying XML documents,Benny Kimelfeld; Yehoshua Sagiv; Gidi Weber,Abstract ExQueX is an interactive system for exploring and querying XML documents. Theexploration is done by searching; ranking and filtering; and it enables users to discoverrelationships that exist in a given document. The results of the exploration can be usedeither directly as tree queries or as building blocks in the process of formulating morecomplex queries. The latter is done by formulating an abstract tree query; whose edgesrepresent relationships that are resolved by using concrete results from the explorationphase. ExQueX facilitates fast and clear understanding of both the contents and complexstructures of XML documents.,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,3,10
Counting and enumerating (preferred) database repairs,Ester Livshits; Benny Kimelfeld,Abstract In the traditional sense; a subset repair of an inconsistent database refers to aconsistent subset of facts (tuples) that is maximal under set containment. Preferencesbetween pairs of facts allow to distinguish a set of preferred repairs based on relativereliability (source credibility; extraction quality; recency; etc.) of data items. Previous studiesexplored the problem of categoricity; where one aims to determine whether preferencessuffice to repair the database unambiguously; or in other words; whether there is preciselyone preferred repair. In this paper we study the ability to quantify ambiguity; by investigatingtwo classes of problems. The first is that of counting the number of subset repairs; bothpreferred (under various common semantics) and traditional. We establish dichotomies indata complexity for the entire space of (sets of) functional dependencies. The second …,Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,2017,2,20
Efficiently Enumerating Minimal Triangulations,Nofar Carmeli; Batya Kenig; Benny Kimelfeld,Abstract We present an algorithm that enumerates all the minimal triangulations of a graphin incremental polynomial time. Consequently; we get an algorithm for enumerating all theproper tree decompositions; in incremental polynomial time; where``proper''means that thetree decomposition cannot be improved by removing or splitting a bag. The algorithm canincorporate any method for (ordinary; single result) triangulation or tree decomposition; andcan serve as an anytime algorithm to improve such a method. We describe an extensiveexperimental study of an implementation on real data from different fields. Our experimentsshow that the algorithm improves upon central quality measures over the underlying treedecompositions; and is able to produce a large number of high-quality decompositions.,Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,2017,2,0
Joining extractions of regular expressions,Dominik D Freydenberger; Benny Kimelfeld; Liat Peterfreund,Abstract: Regular expressions with capture variables; also known as" regex formulas;"extract relations of spans (interval positions) from text. These relations can be furthermanipulated via Relational Algebra as studied in the context of document spanners; Fagin etal.'s formal framework for information extraction. We investigate the complexity of queryingtext by Conjunctive Queries (CQs) and Unions of CQs (UCQs) on top of regex formulas. Weshow that the lower bounds (NP-completeness and W [1]-hardness) from the relational worldalso hold in our setting; in particular; hardness hits already single-character text! Yet; theupper bounds from the relational world do not carry over. Unlike the relational world; acyclicCQs; and even gamma-acyclic CQs; are hard to compute. The source of hardness is that itmay be intractable to instantiate the relation defined by a regex formula; simply because it …,arXiv preprint arXiv:1703.10350,2017,2,15
Detecting ambiguity in prioritized database repairing,Benny Kimelfeld; Ester Livshits; Liat Peterfreund,Abstract In its traditional definition; a repair of an inconsistent database is a consistentdatabase that differs from the inconsistent one in a" minimal way." Often; repairs are notequally legitimate; as it is desired to prefer one over another; for example; one fact isregarded more reliable than another; or a more recent fact should be preferred to an earlierone. Motivated by these considerations; researchers have introduced and investigated theframework of preferred repairs; in the context of denial constraints and subset repairs. There;a priority relation between facts is lifted towards a priority relation between consistentdatabases; and repairs are restricted to the ones that are optimal in the lifted sense. Threenotions of lifting (and optimal repairs) have been proposed: Pareto; global; and completion.In this paper we investigate the complexity of deciding whether the priority relation …,LIPIcs-Leibniz International Proceedings in Informatics,2017,2,20
Lossless separation of web pages into layout code and data,Adi Omari; Benny Kimelfeld; Eran Yahav; Sharon Shoham,Abstract A modern web page is often served by running layout code on data; producing anHTML document that enhances the data with front/back matters and layout/style operations.In this paper; we consider the opposite task: separating a given web page into a datacomponent and a layout program. This separation has various important applications: pageencoding may be significantly more compact (reducing web traffic); data representation isnormalized across web designs (facilitating wrapping; retrieval and extraction); andrepetitions are diminished (expediting site updates and redesign). We present a frameworkfor defining the separation task; and devise an algorithm for synthesizing layout code from aweb page while distilling its data in a lossless manner. The main idea is to synthesize layoutcode hierarchically for parts of the page; and use a combined program-data …,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2016,2,3
Unambiguous prioritized repairing of databases,Benny Kimelfeld; Ester Livshits; Liat Peterfreund,Abstract: In its traditional definition; a repair of an inconsistent database is a consistentdatabase that differs from the inconsistent one in a" minimal way". Often; repairs are notequally legitimate; as it is desired to prefer one over another; for example; one fact isregarded more reliable than another; or a more recent fact should be preferred to an earlierone. Motivated by these considerations; researchers have introduced and investigated theframework of preferred repairs; in the context of denial constraints and subset repairs. There;a priority relation between facts is lifted towards a priority relation between consistentdatabases; and repairs are restricted to the ones that are optimal in the lifted sense. Threenotions of lifting (and optimal repairs) have been proposed: Pareto; global; and completion.In this paper we investigate the complexity of deciding whether the priority relation …,arXiv preprint arXiv:1603.01820,2016,2,20
Extending datalog with analytics in LogicBlox,Molham Aref; Benny Kimelfeld; Emir Pasalic; Nikolaos Vasiloglou,LogicBlox is a database product designed for enterprise software development; combiningtransactions and analytics. The underying data model is a relational database; and thequery language; LogiQL; is an extension of Datalog [13]. As such; LogiQL features a simpleand unified syntax for traditional relational manipulation as well as deeper analytics.Moreover; its declarative nature allows for substantial static analysis for optimizingevaluation schemes; parallelization; and incremental maintenance; and it allows forsophisticated transactional management [11]. In this paper; we describe various extensionsof Datalog for supporting prescriptive and predictive analytics. These extensions come in theform of mathematical optimization (mixed integer programming); machine-learningcapabilities; statistical relational models; and probabilistic programming. Some of these …,Proceedings of the 9th Alberto Mendelzon International Workshop on Foundations of Data Management,2015,2,19
Next generation data analytics at IBM research,Oktie Hassanzadeh; Anastasios Kementsietsidis; Benny Kimelfeld; Rajasekar Krishnamurthy; Fatma Özcan; Ippokratis Pandis,IBM Research has a rich history of innovation in information management with severalrevolutionary breakthroughs; including the invention of relational databases; advanced textanalytics demonstrated by Watson; and the first data mining algorithms to name a few. IBMResearch has been committed to contributing to the community via seminal papers;exemplified by several 10-year awards received by IBM researchers. This short abstract isintended as a quick tour of some of the current information management projects; and notmeant to be an exhaustive list by any means. There has been many disruptive technologicaldevelopments over the last decade. The emergence of cloud computing; and several largescale data processing platforms; advances in on-line social media; the explosion of datavolumes; and the advances in hardware have all forced us to rethink the information …,Proceedings of the VLDB Endowment,2013,2,8
Extracting minimum-weight tree patterns from a schema with neighborhood constraints,Benny Kimelfeld; Yehoshua Sagiv,Abstract The task of formulating queries is greatly facilitated when they can be generatedautomatically from some given data values; schema concepts or both (eg; names ofparticular entities and XML tags). This automation is the basis of various databaseapplications; such as keyword search and interactive query formulation. Usually; automaticquery generation is realized by finding a set of small tree patterns that contain some givenlabels. More formally; the computational problem at hand is to find top-k patterns; that is; kminimum-weight tree patterns that contain a given bag of labels; conform to the schema; andare non-redundant. A plethora of systems and research papers include a component thatdeals with this problem. This paper presents an algorithm for this problem; with complexityguarantees; that allows nontrivial schema constraints and; hence; avoids generating …,Proceedings of the 16th International Conference on Database Theory,2013,2,15
The Complexity of Computing a Cardinality Repair for Functional Dependencies,Ester Livshits; Benny Kimelfeld,Abstract: For a relation that violates a set of functional dependencies; we consider the task offinding a maximum number of pairwise-consistent tuples; or what is known as a" cardinalityrepair." We present a polynomial-time algorithm that; for certain fixed relation schemas (withfunctional dependencies); computes a cardinality repair. Moreover; we prove that on any ofthe schemas not covered by the algorithm; finding a cardinality repair is; in fact; an NP-hardproblem. In particular; we establish a dichotomy in the complexity of computing a cardinalityrepair; and we present an efficient algorithm to determine whether a given schema belongsto the positive side or the negative side of the dichotomy. Subjects: Databases (cs. DB) Citeas: arXiv: 1708.09140 [cs. DB](or arXiv: 1708.09140 v1 [cs. DB] for this version) Submissionhistory From: Ester Livshits [view email][v1] Wed; 30 Aug 2017 07: 03: 58 GMT (247kb; D),arXiv preprint arXiv:1708.09140,2017,1,19
A Relational Framework for Classifier Engineering,Benny Kimelfeld; Christopher Ré,Abstract In the design of analytical procedures and machine-learning solutions; a critical andtime-consuming task is that of feature engineering; for which various recipes and toolingapproaches have been developed. In this framework paper; we embark on theestablishment of database foundations for feature engineering. We propose a formalframework for classification in the context of a relational database. The goal of thisframework is to open the way to research and techniques to assist developers with the taskof feature engineering by utilizing the database's modeling and understanding of data andqueries; and by deploying the well studied principles of database management. As a firststep; we demonstrate the usefulness of this framework by formally defining three keyalgorithmic challenges. The first challenge is that of separability; which is the problem of …,Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,2017,1,14
Querying probabilistic preferences in databases,Batya Kenig; Benny Kimelfeld; Haoyue Ping; Julia Stoyanovich,Abstract We propose a novel framework wherein probabilistic preferences can be naturallyrepresented and analyzed in a probabilistic relational database. The framework augmentsthe relational schema with a special type of a relation symbol---a preference symbol. Adeterministic instance of this symbol holds a collection of binary relations. Abstractly; theprobabilistic variant is a probability space over databases of the augmented form (ie;probabilistic database). Effectively; each instance of a preference symbol can berepresented as a collection of parametric preference distributions such as Mallows. Weestablish positive and negative complexity results for evaluating Conjunctive Queries (CQs)over databases where preferences are represented in the Repeated Insertion Model (RIM);Mallows being a special case. We show how CQ evaluation reduces to a novel inference …,Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,2017,1,0
Adaptive parser-centric text normalization,*,Embodiments of the present invention relate to a customizable text normalization frameworkproviding for domain adaptability through modular replacement generators. In oneembodiment; a method of and computer program product for text normalization are provided.An input sequence comprising a plurality of tokens is received. A plurality of generators isapplied to the input sequence to generate a set of candidate replacements of the tokens ofthe sequence. A plurality of subsets of the set of candidate replacements is determined suchthat the candidate replacements of each subset are syntactically consistent. A probability isdetermined for each of the subsets. A subset of the plurality of subsets having the highestprobability is selected. Each candidate replacement of the selected subset is applied to theinput sequence to generate an output sequence. The output sequence is outputted.,*,2016,1,20
Facilitating information extraction via semantic abstraction,*,A method includes receiving one or more natural language dependency parse trees asinput. A hardware processor is used for processing the dependency parse trees by creatinga mapping from nodes of the one or more dependency parse trees into actions; roles andcontextual predicates. The mapping is used for information extraction. The actions includethe verbs along with attributes of the verbs. The roles include arguments for the verbs. Thecontextual predicates include modifiers for the verbs.,*,2016,1,1
On the enumeration of all minimal triangulations,Nofar Carmeli; Batya Kenig; Benny Kimelfeld,Abstract: We present an algorithm that enumerates all the minimal triangulations of a graphin incremental polynomial time. Consequently; we get an algorithm for enumerating all theproper tree decompositions; in incremental polynomial time; where" proper" means that thetree decomposition cannot be improved by removing or splitting a bag. Subjects: DataStructures and Algorithms (cs. DS) Cite as: arXiv: 1604.02833 [cs. DS](or arXiv: 1604.02833v1 [cs. DS] for this version) Submission history From: Batya Kenig [view email][v1] Mon; 11Apr 2016 08: 39: 28 GMT (38kb; D),arXiv preprint arXiv:1604.02833,2016,1,10
Extending datalog intelligence,Benny Kimelfeld,Abstract Prominent sources of Big Data include technological and social trends; such asmobile computing; blogging; and social networking. The means to analyse such data arebecoming more accessible with the development of business models like cloud computing;open-source and crowd sourcing. But that data have characteristics that pose challenges totraditional database systems. Due to the uncontrolled nature by which data is produced;much of it is free text; often in informal natural language; leading to computing environmentswith high levels of uncertainty and error. In this talk I will offer a vision of a database systemthat aims to facilitate the development of modern data-centric applications; by naturallyunifying key functionalities of databases; text analytics; machine learning and artificialintelligence. I will also describe my past research towards pursuing the vision by …,International Conference on Web Reasoning and Rule Systems,2015,1,11
PPDL: probabilistic programming with Datalog,Balder ten Cate; Benny Kimelfeld; Dan Olteanu,There has been a substantial recent focus on the concept of probabilistic programming [6]towards its positioning as a prominent paradigm for advancing and facilitating thedevelopment of machine-learning applications. 4 A probabilisticprogramming languagetypically consists of two components: a specification of a stochastic process (the prior); and aspecification of observations that restrict the probability space to a conditional subspace (theposterior). This paper gives a brief overview of Probabilistic Programming DataLog (PPDL);a recently proposed declarative framework for specifying statistical models on top of adatabase; through an appropriate extension of Datalog [1]. By virtue of extending Datalog;PPDL offers a natural integration with the database; and has a robust declarative semantics;that is; semantic independence from the algorithmic evaluation of rules; and semantic …,Alberto Mendelzon International Workshop on Foundations of Data Management,2015,1,19
Search quality via query provenance visualization,*,Methods and arrangements for enhancing search quality. Query search results aredisplayed; and search query provenance related to the search results is graphicallydepicted. There is graphically accorded an investigative function to avail investigation of atleast one aspect of the search query provenance.,*,2014,1,15
Gumshoe quality toolkit: Administering programmable search,Zhuowei Bao; Benny Kimelfeld; Yunyao Li; Sriram Raghavan; Huahai Yang,Abstract Enterprise search is challenging due to various reasons; notably the dynamicterminology and domain structure that are specific to the enterprise; combined with the factthat search deployments are typically managed by domain experts who are not necessarilysearch experts. To address that; it has been proposed to design search architectures thatfeature two principles: comprehensibility of the ranking mechanism and customizability ofthe search engine by means of intuitive runtime rules. The proposed demonstration operateson top of an engine implementation based on this search philosophy; and provides anadministrator toolkit to realize the two principles. In particular; the toolkit provides a completevisualization of the provenance (hence ranking) of search results; embeds an editor forprogramming runtime rules; facilitates the investigation of (the cause of) missing or low …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,1,10
Querying Paradigms for the Web,Benny Kimelfeld,*,*,2008,1
A Formal Framework For Probabilistic Unclean Databases,Christopher De Sa; Ihab F Ilyas; Benny Kimelfeld; Christopher Re; Theodoros Rekatsinas,Abstract: Traditional modeling of inconsistency in database theory casts all possible"repairs" equally likely. Yet; effective data cleaning needs to incorporate statistical reasoning.For example; yearly salary of\$100 k and age of 22 are more likely than\$100 k and 122 andtwo people with same address are likely to share their last name (ie; a functionaldependency tends to hold but may occasionally be violated). We propose a formalframework for unclean databases; where two types of statistical knowledge are incorporated.The first represents a belief of how intended (clean) data is generated; and the secondrepresents a belief of how the actual database is realized through the introduction of noise.Formally; a Probabilistic Unclean Database (PUD) is a triple that consists of a probabilisticdatabase that we call the" intention"; a probabilistic data transformator that we call the" …,arXiv preprint arXiv:1801.06750,2018,*,0
Recursive Programs for Document Spanners,Liat Peterfreund; Balder ten Cate; Ronald Fagin; Benny Kimelfeld,Abstract: A document spanner models a program for Information Extraction (IE) as a functionthat takes as input a text document (string over a finite alphabet) and produces a relation ofspans (intervals in the document) over a predefined schema. A well studied language forexpressing spanners is that of the regular spanners: relational algebra over regex formulas;which are obtained by adding capture variables to regular expressions. Equivalently; theregular spanners are the ones expressible in non-recursive Datalog over regex formulas(extracting relations that play the role of EDBs from the input document). In this paper; weinvestigate the expressive power of recursive Datalog over regex formulas. Our main resultis that such programs capture precisely the document spanners computable in polynomialtime. Additional results compare recursive programs to known formalisms such as the …,arXiv preprint arXiv:1712.08198,2017,*,0
Computing Optimal Repairs for Functional Dependencies,Ester Livshits; Benny Kimelfeld; Sudeepa Roy,Abstract: We investigate the complexity of computing an optimal repair of an inconsistentdatabase; in the case where integrity constraints are Functional Dependencies (FDs). Wefocus on two types of repairs: an optimal subset repair (optimal S-repair) that is obtained bya minimum number of tuple deletions; and an optimal update repair (optimal U-repair) that isobtained by a minimum number of value (cell) updates. For computing an optimal S-repair;we present a polynomial-time algorithm that succeeds on certain sets of FDs and fails onothers. We prove the following about the algorithm. When it succeeds; it can also incorporateweighted tuples and duplicate tuples. When it fails; the problem is NP-hard; and in fact; APX-complete (hence; cannot be approximated better than some constant). Thus; we establish adichotomy in the complexity of computing an optimal S-repair. We present general …,arXiv preprint arXiv:1712.07705,2017,*,18
Ranked Enumeration of Minimal Triangulations,Noam Ravid; Dori Medini; Benny Kimelfeld,Abstract: Tree decompositions facilitate computations on complex graphs by groupingvertices into bags interconnected in an acyclic structure; hence their importance in aplethora of problems such as query evaluation over databases and inference overprobabilistic graphical models. Different applications take varying benefits from different treedecompositions; and hence; measure them by diverse (sometime complex) cost functions.For generic cost functions (such as width or fill-in); an optimal tree decomposition can becomputed in some cases; notably when the number of minimal separators is bounded by apolynomial (due to Bouchitte and Todinca); we refer to this assumption as" poly-MS." Yet; ingeneral; finding an optimal tree decomposition is computationally intractable even for thesecost functions; and approximations or heuristics are commonly used. Furthermore; the …,arXiv preprint arXiv:1709.10254,2017,*,20
eLinda: Explorer for Linked Data,Oren Mishali; Tal Yahav; Oren Kalinsky; Benny Kimelfeld,Abstract: To realize the premise of the Semantic Web towards knowledgeable machines;one might often integrate an application with emerging RDF graphs. Nevertheless; capturingthe content of a rich and open RDF graph by existing tools requires both time and expertise.We demonstrate eLinda-an explorer for Linked Data. The challenge addressed by eLinda isthat of understanding the rich content of a given RDF graph. The core functionality is anexploration path; where each step produces a bar chart (histogram) that visualizes thedistribution of classes in a set of nodes (URIs). In turn; each bar represents a set of nodesthat can be further expanded through the bar chart in the path. We allow three types ofexplorations: subclass distribution; property distribution; and object distribution for a propertyof choice. Subjects: Databases (cs. DB) Cite as: arXiv: 1707.07623 [cs. DB](or arXiv …,arXiv preprint arXiv:1707.07623,2017,*,10
Visualizing and exploring natural-language text,*,An embodiment provides methods and arrangements for visualizing and exploring natural-language text. In an embodiment; natural language text is received; and this is parsed toform a directed graph comprising a plurality of nodes. The directed graph is converted to anoutline graph comprising core nodes and layer nodes. The outline graph is simplified; andthere is created; for display on a user interface; an interactive visual representation of thesimplified outline graph. Other variants and embodiments are broadly contemplated herein.,*,2017,*,0
Technical Perspective: Optimizing Tree Patterns for Querying Graph-and Tree-Structured Data,Benny Kimelfeld,From the early days of databases; practitioners and researchers have pursued techniquesfor rewriting queries into equivalent ones that are easier to evaluate. The following papercloses a fundamental gap that we have had in our understanding of this challenge in thecontext of tree patterns. Such patterns are common and basic components of querylanguages for graph and tree data such as SPARQL; Cypher and XQuery. The authors studythe question of whether the given tree pattern can be replaced with a smaller one; thequestion of whether it involves redundant conditions; and most importantly; the relationshipbetween these two questions. Formally; a tree pattern p is matched in a labeled graph G ifthe nodes of p can be mapped to the nodes of G in a way that all the constraints of p aresatisfied. A node constraint is either a label match (eg; the label is “person”) or wildcard …,ACM SIGMOD Record,2017,*,20
Domain centric natural language query answering,*,Embodiments of the present invention disclose a method; computer program product; andsystem for searching a database using a user entered search query. A search query for adatabase is received by the computer and the computer applies condition-action rulesbased on natural language processing rules to identify one or more phrases within thesearch query that is associated an entity identifier. The computer further identifies anytaxonomy variants that have been established for the identified phrases. The computercreates a search string that includes search query and the entity identifiers. The databasesearch is conducted by the computer and the results are displayed for the user.,*,2017,*,8
A PLUG AND PLAY ARCHITECTURE FOR PROBABILISTIC PROGRAMMING,Molham Aref; Yannis Kassios; Benny Kimelfeld; Emir Pasalic; Zografoula Vagena,Abstract: In the probabilistic-programming paradigm; the application logic is specified bymeans of a description of a probabilistic model (by stating how a sample is being produced)using a Probabilistic Programming Language (PPL). The principal value one obtains from aprobabilistic program lies in the inference thereof; that is; reasoning about the entireprobability distribution that the program defines (eg; finding a likely event or estimating itsmarginal probability). The PPAML kickoff meeting highlighted several research challengesregarding the development of inference infrastructure for PPL; for both increasing softwareefficiency and reducing software complexity; towards the goal of broadening the PPLapplications and the community of implementers and programmers. These challengesinclude the design of an Application Program Interface (API); or alternatively an …,*,2017,*,14
A Relational Framework for Information Extraction,Ronald Fagin; Benny Kimelfeld; Frederick Reiss; Stijn Vansummeren,Abstract Information Extraction commonly refers to the task of populating a relationalschema; having predefined underlying semantics; from textual content. This task ispervasive in contemporary computational challenges associated with Big Data. In this articlewe provide an overview of our work on document spanners--a relational framework forInformation Extraction that is inspired by rule-based systems such as IBM's SystemT.,ACM SIGMOD Record,2016,*,4
Unsupervised learning of deep patterns for semantic parsing,*,Using exemplary sentences; usage patterns and thematic roles ascribed in VerbNet togenerate “deep pattern trees” for the exemplary sentences. Then; when an arbitrary naturallanguage subject sentence is input; these deep pattern trees can be matched to the naturallanguage subject sentence in order to assign thematic roles to at least some of the“grammatical portions” of the natural language subject sentence.,*,2016,*,10
Recognizing Determinism in Prioritized Repairing of Inconsistent Databases.,Benny Kimelfeld; Ester Livshits; Liat Peterfreund,Abstract. A repair of an inconsistent database is traditionally defined as a consistentdatabase that differs from the inconsistent one in a “minimal way.” As there are often reasonsto prefer one repair over another; researchers have introduced and investigated theframework of preferred repairs; where a priority relation between facts is lifted towards apriority relation between consistent databases; and repairs are restricted to ones that areoptimal in the lifted sense. In this paper we describe our recent results on the complexity ofdeciding whether the priority relation suffices to clean the database unambiguously; or inother words; whether there is exactly one optimal repair. In particular; we show that differentconventional semantics of priority lifting entail highly different complexities.,AMW,2016,*,15
On the Enumeration of Tree Decompositions.,Nofar Carmeli; Batya Kenig; Benny Kimelfeld,Many intractable computational problems on graphs admit tractable algorithms whenapplied to trees or forests. Tree decomposition extracts a tree structure from a graph bygrouping nodes into bags; where each bag corresponds to a single node in of the tree. Thecorresponding operation on hypergraphs is that of a generalized hypertree decomposition[10]; which entails a tree decomposition of the primal graph (which has the same set ofnodes; and an edge between every two nodes that co-occur in a hyperedge) and anassignment of a hyperedge cover to each bag [11]. Tree decomposition and generalizedhypertree decomposition have a plethora of applications; including join optimization indatabases [7; 10; 21]; constraint-satisfaction problems [17]; computation of Nash equilibria ingames [10]; analysis of probabilistic graphical models [18]; and weighted model counting …,AMW,2016,*,13
A Database Framework for Classifier Engineering,Benny Kimelfeld; Christopher Ré,In the design of machine-learning solutions; a critical and often the most resourceful task isthat of feature engineering [7; 4]; for which recipes and tooling have been developed [3; 7].In this vision paper we embark on the establishment of database foundations for featureengineering. We propose a formal framework for classification; in the context of a relationaldatabase; towards investigating the application of database and knowledge management toassist with the task of feature engineering. We demonstrate the usefulness of this frameworkby formally defining two key algorithmic challenges within:(1) separability refers todetermining the existence of feature queries that agree with the given training examples;and (2) identifiability is the task of testing for the property of independence among features(given as queries). Moreover; we give preliminary results on these challenges; in the …,CEUR workshop proceedings,2015,*,19
Estimating the total sales over streaming bids,*,A mechanism is provided for computing an estimation of maximum total sales overstreaming items. Each item having an associated value is designated as an item value pair.Value ranges are established to place the item value pairs. The value ranges are distinct.Each of the item value pairs is added into the value ranges according to each of theassociated values for the item value pairs. Repeated item value pairs are removed that arein the same value ranges. A number of the item value pairs is reduced in each of the valueranges respectively based on an error factor; by randomly selecting the item value pairs toremove from each of the value ranges. An estimate of a total maximum value of the bids forthe item value pairs in all of the value ranges is computed based on a scale factor.,*,2014,*,20
Probabilistic Databases-Article 15 (55 pages)-Probabilistic Data Exchange,R Fagin; B Kimelfeld; PG Kolaitis,*,Journal of the ACM-Association for ComputingMachinery,2011,*
On rewriting Xpath Queries Using Views,Μανώλης Γεργατσούλης; Φώτο Αφράτη; Rada Chirkova; B Kimelfeld; Βάσια Παυλάκη; Y Sagiv; Manolis Gergatsoulis; Foto Afrati; Vassia Pavlaki,The problem of rewriting a query using a materialized view is studied for a well knownfragment of XPath that includes the following three constructs: wildcards; descendant edgesand branches. In earlier work; determining the existence of a rewriting was shown to becoNP-hard; but no tight complexity bound was given. While it was argued that Σ 3 p is anupper bound; the proof was based on results that have recently been refuted. Consequently;the exact complexity (and even decidability) of this basic problem has been unknown; andthere have been no practical rewriting algorithms if the query and the view use all the threeconstructs mentioned above. It is shown that under fairly general conditions; there are onlytwo candidates for rewriting and hence; the problem can be practically solved by twocontainment tests. In particular; under these conditions; determining the existence of a …,*,2009,*,17
Selected Papers from the Tenth International Symposium on Database Programming Languages (DBPL 2005),Benny Kimelfeld; Yehoshua Sagiv; Diego Calvanese; Giuseppe De Giacomo; Domenico Lembo; Maurizio Lenzerini; Riccardo Rosati; Claus Brabrand; Anders Møller; Michael I Schwartzbach; Leopoldo Bertossi; Loreto Bravo; Enrico Franconi; Andrei Lopatenko; Jan Hidders; Stefania Marrara; Jan Paredaens; Roel Vercammen; Giorgio Busatto; Markus Lohrey; Sebastian Maneth,Read the latest articles of Information Systems at ScienceDirect.com; Elsevier'sleading platform of peer-reviewed scholarly literature.,*,2008,*,10
TOIS reviewers January 2006 through May 2007,Gary Marchionini; Ahmed Abbasi; Eugene Agichtein; Khurshid Ahmad; Azzah Al-Maskari; Gianni Amati; Sihem Amer Yahia; Shlomo Argamon; Daniel Ashbrook; Paolo Atzeni; Michela Bacchin; Godmar Back; Antonio Badia; Andras Banczur; Bettina Berendt; Elisa Bertino; B Bhagyavati; Suresh Bhavnani; Devdutta Bhosale; David Bodoff; Paolo Boldi; Johan Bollen; Angela Bonifati; Pia Borlund; Jit Bose; Athman Bouguettaya; Michael Brinkmeier; Peter Brown; Peter Brusilovsky; Peter Bruza; Christopher Burges; Robin Burke; Ben Carterette; Arthur Cater; Kuiyu Chang; Hsin Hsi Chen; Zheng Chen; James Cheney; Pu Jen Cheng; Roger Chiang; Byron Choi; Tat Seng Chua; Charlie Clarke; Paul Clough; Mariano Consens; Gordon Cormack; Nick Craswell; Fabio Crestani; Carolyn Crouch; Silviu Petru Cucerzan; Hang Cui; Sally Jo Cunningham; Edward Cutrell; Pablo De La Fuente; Arjen De Vries; Anne Diekema; Sandor Dominich; Shyamala Doraisamy; Mark Dunlop; Georges Dupret; Miles Efron; Jeremy Ellman; Peter Enser; Gunes Erkan; Laura Fochtmann; Anders Fongen; Nigel Ford; Martin Franz; Xin Fu; Paolo Garza; Susan Gauch; Pierre Geneves; Henry Gladney; Melanie Gnasa; Andrew Goldberg; Marcos Goncalves; Cyril Goutte; David Grossman; Dennis Groth; Jacek Gwizdka; Stephanie Haas; Sanda Harabagiu; Donna Harman; Andreas Henrich; Djoerd Hiemstra; Lee Hollaar; Chun Nan Hsu; Fei Huang; Zan Huang; Mike Huhns; Carlos Hurtado; Keisuke Innoue; Panagiotis Ipeirotis; Bernard Jansen; Wang Jianqiang; Rong Jin; Marko Junkkari; Patrick Juola; Vinay Kakade; Jaap Kamps; In Ho Kang; Damianos Karakos; Vangelis Karkaletsis; Martin Kaszkiel; Siddharth Kaza; Jaana Kekäläinen; Diane Kelly; Benny Kimelfeld; Alek Kolcz; Joseph Konstan; Kui Lam Kwok; Abhimanyu Lad; Alberto Laender; Mounia Lalmas; Leah Larkey; Ray Larson; Nabil Layaida; Zhang Le; Dik Lun Lee; Dongwon Lee; Jochen Leidner; Gina Levow; Hang Li; Xin Li; Chin Yew Lin; Jimmy Lin; Tie Yan Liu; Zehua Liu; David Losada; Jie Lu; Yiming Ma; Inderjeet Mani; Murali Mani; Ioana Manolescu; Catherine Marshall; Mercedes Martinez; Yosi Mass; Paul McNamee; Sean McNee; Brahim Medjahed; Lokman Meho; Donald Metzler; Rada Mihalcea; Ruslan Mitkov; Bamshad Mobasher; Marina Mongiello; Ani Nenkova; Frank Neven; Dorbin Ng; Wilfred Ng,Marchionini; Gary; Abbasi; Ahmed; Agichtein; Eugene; Ahmad; Khurshid; Al-Maskari; Azzah;Amati; Gianni; Yahia; Sihem Amer; Argamon; Shlomo; Ashbrook; Daniel; Atzeni; Paolo;Bacchin; Michela; Back; Godmar; Badia; Antonio; Banczur; Andras; Berendt; Bettina; Bertino;Elisa; Bhagyavati; B.; Bhavnani; Suresh; Bhosale; Devdutta; Bodoff; David; Boldi; Paolo;Bollen; Johan; Bonifati; Angela; Borlund; Pia; Bose; Jit; Bouguettaya; Athman; Brinkmeier;Michael; Brown; Peter; Brusilovsky; Peter; Bruza; Peter; Burges; Christopher; Burke; Robin;Carterette; Ben; Cater; Arthur; Chang; Kuiyu; Chen; Hsin Hsi; Chen; Zheng; Cheney; James;Cheng; Pu Jen; Chiang; Roger; Choi; Byron; Chua; Tat Seng; Clarke; Charlie; Clough; Paul;Consens; Mariano; Cormack; Gordon; Craswell; Nick; Crestani; Fabio; Crouch … In: ACMTransactions on Information Systems; Vol. 25; No. 4; 15; 01.10.2007.,ACM Transactions on Information Systems,2007,*,20
" Offizielle" elektronische Version der Publikation (entsprechend ihrem Digital Object Identifier-DOI),S Abiteboul; M Arenas; P Barceló; M Bienvenu; D Calvanese; C David; R Hull; E Hüllermeier; B Kimelfeld; L Libkin; W Martens; T Milo; F Murlak; F Neven; M Ortiz de la Fuente; T Schwentick; J Stoyanovich; J Su; D Suciu; V Vianu; K Yi,S. Abiteboul; M. Arenas; P. Barceló; M. Bienvenu; D. Calvanese; C. David; R. Hull; E.Hüllermeier; B. Kimelfeld; L. Libkin; W. Martens; T. Milo; F. Murlak; F. Neven; M. Ortiz de laFuente; T. Schwentick; J. Stoyanovich; J. Su; D. Suciu; V. Vianu; K. Yi: "Research Directions forPrinciples of Data Management (Abridged)"; ACM SIGMOD Record (eingeladen); 45 (2016);4; 13 S … Erstellt aus der Publikationsdatenbank der Technischen Universität Wien.,*,*,*,12
1095 Languages not recognizable in real time by one-dimensional cellular automata,Katsuhiko Nakamura; Nadia Creignou; Phokion Kolaitis; Bruno Zanuttini; Michael Domaratzki; Kai Salomaa; Haik Grigorian; Samvel Shoukourian; Devdatta Gangal; Abhiram Ranade; Sara Cohen; Benny Kimelfeld; Yehoshua Sagiv; Guomin Yang; Duncan S Wong; Huaxiong Wang; Xiaotie Deng; Christian Glaßer; Alan L Selman; Stephen Travers; Klaus W Wagner; Jianer Chen; Fedor V Fomin; Yang Liu; Songjian Lu; Yngve Villanger; Martin Gairing; Thomas Lücking; Marios Mavronicolas; Burkhard Monien; Manuel Rode,*,*,*,*
A Database Framework for Probabilistic Preferences,Batya Kenig; Benny Kimelfeld; Haoyue Ping; Julia Stoyanovich,Preferences are statements about the relative quality or desirability of items. Ever largeramounts of preference information are being collected and analyzed in a variety of domains;including recommendation systems [2; 16; 18]; polling and election analysis [3; 6; 7; 15]; andbioinformatics [1; 11; 19]. Preferences are often inferred from indirect input (eg; a ranked listmay be inferred from individual choices); and are therefore uncertain in nature. Thismotivates a rich body of work on uncertain preference models in the statistics literature [14].More recently; the machine learning community has been developing methods for effectivemodeling and efficient inference over preferences; with the Mallows model [13] receivingparticular attention [4; 5; 12; 17]. In this paper; we take the position that preference modelingand analysis should be accommodated within a general-purpose probabilistic database …,*,*,*,20
A Probabilistic Graphical Model for Mallows Preferences,Batya Kenig; Benny Kimelfeld,Abstract Reasoning about preference distributions is an important task in various areas (eg;recommender systems; social choice); and is critical for learning the parameters of thedistribution. We consider the Mallows model with arbitrary pairwise comparisons asevidence. Existing inference methods are able to reason only with evidence that abides to arestrictive form. We establish the conditional independences in the Mallows model; andapply them to develop a Bayesian network that enables querying and sampling from theMallows posterior (the conditional probability space with the evidence incorporated). Whileinference over the Mallows posterior is computationally hard in general; our translationallows to utilize the wealth of tools for inference over Bayesian networks. Moreover; we showhow our translation gives rise to new results on significant cases with a polynomial-time …,*,*,*,20
Keyword Proximity Search on Graphs: Enumerating Results in Exact and Approximate Order,Benny Kimelfeld; Yehoshua Sagiv; Edmond J Safra Campus,*,*,*,*
