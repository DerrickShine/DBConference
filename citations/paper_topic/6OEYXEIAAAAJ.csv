Concurrency control and recovery in database systems,Philip A Bernstein; Vassos Hadzilacos; Nathan Goodman,Abstract This book is an introduction to the design and implementation of concurrencycontrol and recovery mechanisms for transaction management in centralized and distributeddatabase systems. Concurrency control and recovery have become increasingly importantas businesses rely more and more heavily on their on-line data processing activities. Forhigh performance; the system must maximize concurrency by multiprogrammingtransactions. But this can lead to interference between queries and updates; whichconcurrency control mechanisms must avoid. In addition; a satisfactory recovery system isnecessary to ensure that inevitable transaction and database system failures do not corruptthe database.,*,1987,5860,0
A survey of approaches to automatic schema matching,Erhard Rahm; Philip A Bernstein,Abstract. Schema matching is a basic problem in many database application domains; suchas data integration; E-business; data warehousing; and semantic query processing. Incurrent implementations; schema matching is typically performed manually; which hassignificant limitations. On the other hand; previous research papers have proposed manytechniques to achieve a partial automation of the match operation for specific applicationdomains. We present a taxonomy that covers many of these existing approaches; and wedescribe the approaches in some detail. In particular; we distinguish between schema-leveland instance-level; element-level and structure-level; and language-based and constraint-based matchers. Based on our classification we review some previous matchimplementations thereby indicating which part of the solution space they cover. We intend …,the VLDB Journal,2001,4080,22
Generic schema matching with cupid,Jayant Madhavan; Philip A Bernstein; Erhard Rahm,Abstract Schema matching is a critical step in many applications; such as XML messagemapping; data warehouse loading; and schema integration. In this paper; we investigatealgorithms for generic schema matching; outside of any particular data model or application.We first present a taxonomy for past solutions; showing that a rich range of techniques isavailable. We then propose a new algorithm; Cupid; that discovers mappings betweenschema elements based on their names; data types; constraints; and schema structure;using a broader set of techniques than past approaches. Some of our innovations are theintegrated use of linguistic and structural matching; context-dependent matching of sharedtypes; and a bias toward leaf structure where much of the schema content resides. Afterdescribing our algorithm; we present experimental results that compare Cupid to two …,Proceedings of the International Conference on Very Large Data Bases,2001,1885,0
Concurrency control in distributed database systems,Philip A Bernstein; Nathan Goodman,In this paper we survey; consolidate; and present the state of the art in distributed databaseconcurrency control. The heart of our analysts is a decomposition of the concurrency controlproblem into two major subproblems: read-write and write-write synchronization. Wedescribe a series of synchromzation techniques for solving each subproblem and show howto combine these techniques into algorithms for solving the entire concurrency controlproblem. Such algorithms are called" concurrency control methods." We describe 48principal methods; including all practical algorithms that have appeared m the literature plusseveral new ones. We concentrate on the structure and correctness of concurrency controlalgorithms. Issues of performance are given only secondary treatment.,ACM Computing Surveys (CSUR),1981,1433,22
Middleware: a model for distributed system services,Philip A Bernstein,A Model for Distributed System Services on which the application cannot run. So someappliances cannot access the application. Wide-area servers often can support only dumbterminals; which a desktop appliance must emulate to access a server. Sometimes adesktop appliance can gain access to a wide-area server only if a local-area server wasexplicitly programmed for access to the wide-area server. A user may have to log into eachserver separately with independently maintained passwords and through different userinterfaces; each with a different look and feel. Even if the desktop appliance can access aremote application; its spreadsheet or word processor often cannot access data provided bythat application without special programming. These are only some of the limitations of suchsystems. In response to their frustrations in implementing enterprise-wide information …,Communications of the ACM,1996,1018,12
Principles of transaction processing,Philip A Bernstein; Eric Newcomer,Principles of Transaction Processing is a comprehensive guide to developing applications;designing systems; and evaluating engineering products. The book provides detaileddiscussions of the internal workings of transaction processing systems; and it discusses howthese systems work and how best to utilize them. It covers the architecture of WebApplication Servers and transactional communication paradigms. The book is divided into11 chapters; which cover the following: Overview of transaction processing application andsystem structure Software abstractions found in transaction processing systems Architectureof multitier applications and the functions of transactional middleware and database serversQueued transaction processing and its internals; with IBM's Websphere MQ and Oracle'sStream AQ as examples Business process management and its mechanisms Description …,*,2009,728,10
Applying model management to classical meta data problems,Philip A Bernstein,Abstract Model management is a new approach to meta data management that offers ahigher level programming interface than current techniques. The main abstractions aremodels (eg; schemas; interface definitions) and mappings between models. It treats theseabstractions as bulk objects and offers such operators as Match; Merge; Diff; Compose;Apply; and ModelGen. This paper extends earlier treatments of these operators and appliesthem to three classical meta data management problems: schema integration; schemaevolution; and round-trip engineering.,*,2003,639,20
A language facility for designing database-intensive applications,John Mylopoulos; Philip A Bernstein; Harry KT Wong,Abstract TAXIS; a language for the design of interactive information systems (eg; credit cardverification; student-course registration; and airline reservations) is described. TAXIS offers(relational) database management facilities; a means of specifying semantic integrityconstraints; and an exception-handling mechanism; integrated into a single languagethrough the concepts of class; property; and the IS-A (generalization) relationship. Adescription of the main constructs of TAXIS is included and their usefulness illustrated withexamples.,ACM Transactions on Database Systems (TODS),1980,625,15
Synthesizing third normal form relations from functional dependencies,Philip A Bernstein,Abstract It has been proposed that the description of a relational database can be formulatedas a set of functional relationships among database attributes. These functionalrelationships can then be used to synthesize algorithmically a relational scheme. It is thepurpose of this paper to present an effective procedure for performing such a synthesis. Theschema that results from this procedure is proved to be in Codd's third normal form and tocontain the fewest possible number of relations. Problems with earlier attempts to constructsuch a procedure are also discussed.,ACM Transactions on Database Systems (TODS),1976,605,20
Query processing in a system for distributed databases (SDD-1),Philip A Bernstein; Nathan Goodman; Eugene Wong; Christopher L Reeve; James B Rothnie Jr,Abstract This paper describes the techniques used to optimize relational queries in the SDD-1 distributed database system. Queries are submitted to SDD-1 in a high-level procedurallanguage called Datalanguage. Optimization begins by translating each Datalanguagequery into a relational calculus form called an envelope; which is essentially an aggregate-free QUEL query. This paper is primarily concerned with the optimization of envelopes.Envelopes are processed in two phases. The first phase executes relational operations atvarious sites of the distributed database in order to delimit a subset of the database thatcontains all data relevant to the envelope. This subset is called a reduction of the database.The second phase transmits the reduction to one designated site; and the query is executedlocally at that site. The critical optimization problem is to perform the reduction phase …,ACM Transactions on Database Systems (TODS),1981,597,20
Using semi-joins to solve relational queries,Philip A Bernstein; Dah-Ming W Chiu,ABSTRACT. The semi-join is a relational algebraic operation that selects a set of tuples inone relation that match one or more tuples of another relation on the joining domains. Semi-joins have been used as a basic ingredient in query processing strategies for a number ofhardware and software database systems. However; not all queries can be solved entirelyusing semi-joins. In this paper the exact class of relational queries that can be solved usingsemi-joins is shown. It is also shown that queries outside of this class may not even bepartially solvable using" short" semi-join programs. In addition; a linear-time membershiptest for this class is presented.,Journal of the ACM (JACM),1981,544,3
Computational problems related to the design of normal form relational schemas,Catriel Beeri; Philip A Bernstein,Abstract Problems related to functional dependencies and the algorithmic design ofrelational schemas are examined. Specifically; the following results are presented:(1) a treemodel of derivations of functional dependencies from other functional dependencies;(2) alinear-time algorithm to test if a functional dependency is in the closure of a set of functionaldependencies;(3) a quadratic-time implementation of Bernstein's third normal form schemasynthesis algorithm. Furthermore; it is shown that most interesting algorithmic questionsabout Boyce-Codd normal form and keys are NP-complete and are therefore probably notamenable to fast algorithmic solutions.,ACM Transactions on Database Systems (TODS),1979,544,15
Methods and system for model matching,*,Systems and methods for automatically and generically matching models are provided; suchas may be provided in a matching application or matching component; or provided in ageneral purpose system for managing models. The methods are generic since the methodsapply to hierarchical data sets outside of any particular data model or application. Similaritycoefficients are calculated for; and mappings are discovered between; schema elementsbased on their names; data types; constraints; and schema structure; using a broad set oftechniques. Some of these techniques include the integrated use of linguistic and structuralmatching; context dependent matching of shared types; and a bias toward subtree; or leaf;structure where much of the schema content resides.,*,2004,513,20
Data management for peer-to-peer computing: A vision,Philip A Bernstein; Fausto Giunchiglia; Anastasios Kementsietsidis; John Mylopoulos; Luciano Serafini; Ilya Zaihrayeu,We motivate special database problems introduced by peer-to-peer computing and proposethe Local Relational Model (LRM) to solve some of them. As well; we summarize aformalization of LRM; present an architecture for a prototype implementation; and discussopen research questions.,*,2002,501,10
Corpus-based schema matching,Jayant Madhavan; Philip A Bernstein; AnHai Doan; Alon Halevy,Schema matching is the problem of identifying corresponding elements in different schemas.Discovering these correspondences or matches is inherently difficult to automate. Pastsolutions have proposed a principled combination of multiple algorithms. However; thesesolutions sometimes perform rather poorly due to the lack of sufficient evidence in theschemas being matched. In this paper we show how a corpus of schemas and mappingscan be used to augment the evidence about the schemas being matched; so they can bematched better. Such a corpus typically contains multiple schemas that model similarconcepts and hence enables us to learn variations in the elements and their properties. Weexploit such a corpus in two ways. First; we increase the evidence about each element beingmatched by including evidence from similar elements in the corpus. Second; we learn …,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,459,15
Multiversion concurrency control—theory and algorithms,Philip A Bernstein; Nathan Goodman,Abstract Concurrency control is the activity of synchronizing operations issued byconcurrently executing programs on a shared database. The goal is to produce an executionthat has the same effect as a serial (noninterleaved) one. In a multiversion database system;each write on a data item produces a new copy (or version) of that data item. This paperpresents a theory for analyzing the correctness of concurrency control algorithms formultiversion database systems. We use the theory to analyze some new algorithms andsome previously published ones.,ACM Transactions on Database Systems (TODS),1983,458,0
Rondo: A programming platform for generic model management,Sergey Melnik; Erhard Rahm; Philip A Bernstein,Abstract Model management aims at reducing the amount of programming needed for thedevelopment of metadata-intensive applications. We present a first complete prototype of ageneric model management system; in which high-level operators are used to manipulatemodels and mappings between models. We define the key conceptual structures: models;morphisms; and selectors; and describe their use and implementation. We specify thesemantics of the known model-management operators applied to these structures; suggestnew ones; and develop new algorithms for implementing the individual operators. Weexamine the solutions for two model-management tasks that involve manipulations ofrelational schemas; XML schemas; and SQL views.,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,425,0
An algorithm for concurrency control and recovery in replicated distributed databases,Philip A Bernstein; Nathan Goodman,Abstract In a one-copy distributed database; each data item is stored at exactly one site. In areplicated database; some data items may be stored at multiple sites. The main motivation isimproved reliability: by storing important data at multiple sites; the DBS can operate eventhough some sites have failed. This paper describes an algorithm for handling replicateddata; which allows users to operate on data so long as one copy is “available.” A copy is“available” when (i) its site is up; and (ii) the copy is not out-of-date because of an earliercrash. The algorithm handles clean; detectable site failures; but not Byzantine failures ornetwork partitions.,ACM Transactions on Database Systems (TODS),1984,412,19
On the correct translation of update operations on relational views,Umeshwar Dayal; Philip A Bernstein,Abstract Most relational database systems provide a facility for supporting user views.Permitting this level of abstraction has the danger; however; that update requests issued bya user within the context of his view may not translate correctly into equivalent updates onthe underlying database. The purpose of this paper is to formalize the notion of updatetranslation and derive conditions under which translation procedures will produce correcttranslations of view updates.,ACM Transactions on Database Systems (TODS),1982,394,15
Model management 2.0: manipulating richer mappings,Philip A Bernstein; Sergey Melnik,Abstract Model management is a generic approach to solving problems of dataprogrammability where precisely engineered mappings are required. Applications includedata warehousing; e-commerce; object-to-relational wrappers; enterprise informationintegration; database portals; and report generators. The goal is to develop a modelmanagement engine that can support tools for all of these applications. The engine supportsoperations to match schemas; compose mappings; diff schemas; merge schemas; translateschemas into different data models; and generate data transformations from mappings.Much has been learned about model management since it was proposed seven years ago.This leads us to a revised vision that differs from the original in two main respects: theoperations must handle more expressive mappings; and the runtime that executes …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,361,0
-Merging Models Based on Given Correspondences,Rachel A Pottinger; Philip A Bernstein,This chapter defines the Merge operator for model merging; both generically and for aspecific meta-meta-model; Vanilla. It defines and classifies the conflicts that arise incombining two models and describes when conflicts from different classes must be resolved.Resolution strategies for conflicts that must be resolved in Merge; both for Vanilla and ingeneral are presented. The chapter evaluates Merge by showing how Merge in Vanilla canbe used to subsume some previous merging algorithms and by testing Merge on two largereal-world ontologies. The chapter envisions several future directions. The first involvesshowing that the Merge result; when applied to models and mappings that are templates forinstances; has an appropriate interpretation on instances. This will demonstrate theusefulness of Merge in specific applications such as data integration and view integration …,*,2003,353,19
A sophisticate's introduction to database normalization theory,Catriel Beeri; Philip A Bernstein; Nathan Goodman,ABSTRACT Formal database semantics has concentrated on dependency constraints; suchas functional and multivalued dependencies; and on normal forms for relations.Unfortunately; much of this work has been inaccessible to researchers outside this field; dueto the unfamiliar formalism in which the work is couched. In addition; the lack of a single setof definitions has confused the relationships among certain results. This paper is intended toserve the two-fold purpose of introducing the main issues and theorems of formal databasesemantics to the uninitiated; and to clarify the terminology of the field.,*,1988,332,0
Third-generation database system manifesto,Michael Stonebraker; Lawrence A Rowe; Bruce G Lindsay; Jim Gray; Michael J Carey; Michael L Brodie; Philip A Bernstein; David Beech,Abstract We call the older hierarchical and network systems first generation datftha~ systemsand refer to the current collection of relmional systems as the second generation. In thispaper we consider the characteristics that must be~ ri~ fied by the next generation of datamanagexs; which we call third generation database systems.,ACM sIGMOD record,1990,318,0
Representing and reasoning about mappings between domain models,Jayant Madhavan; Philip A Bernstein; Pedro Domingos; Alon Y Halevy,Abstract Mappings between disparate models are fundamental to any application thatrequires interoperability between heterogeneous data and applications. Generatingmappings is a laborintensive and error prone task. To build a system that helps usersgenerate mappings; we need an explicit representation of mappings. This representationneeds to have well-defined semantics to enable reasoning and comparison betweenmappings. This paper first presents a powerful framework for defining languages forspecifying mappings and their associated semantics. We examine the use of mappings andidentify the key inference problems associated with mappings. These properties can beused to determine whether a mapping is adequate in a particular context. Finally; weconsider an instance of our framework for a language representing mappings between …,Proceedings of the National Conference on Artificial Intelligence,2002,314,10
Introduction to a system for distributed databases (SDD-1),James B Rothnie Jr; Philip A Bernstein; Stephen Fox; Nathan Goodman; Michael Hammer; Terry A Landers; Christopher Reeve; David W Shipman; Eugene Wong,Abstract The declining cost of computer hardware and the increasing data processing needsof geographically dispersed organizations have led to substantial interest in distributed datamanagement. SDD-1 is a distributed database management system currently beingdeveloped by Computer Corporation of America. Users interact with SDD-1 precisely as if itwere a nondistributed database system because SDD-1 handles all issues arising from thedistribution of data. These issues include distributed concurrency control; distributed queryprocessing; resiliency to component failure; and distributed directory management. Thispaper presents an overview of the SDD-1 design and its solutions to the above problems.This paper is the first of a series of companion papers on SDD-1 (Bernstein and Shipman [2];Bernstein et al.[4]; and Hammer and Shipman [14]).,ACM Transactions on Database Systems (TODS),1980,311,23
Information integration in the enterprise,Philip A Bernstein; Laura M Haas,Software vendors offer numerous tools to reduce the effort; and hence the cost; of integrationand to improve the quality. Moreover; because information integration is a complex andmultifaceted task; many of these tools are highly specialized. The resulting profusion of toolscan be confusing. In this article; we try to clear up any confusion by:,Communications of the ACM,2008,304,20
Concurrency control in a system for distributed databases (SDD-1),Philip A Bernstein; David W Shipman; James B Rothnie Jr,Abstract This paper presents the concurrency control strategy of SDD-1. SDD-1; a System forDistributed Databases; is a prototype distributed database system being developed byComputer Corporation of America. In SDD-1; portions of data distributed throughout anetwork may be replicated at multiple sites. The SDD-1 concurrency control guaranteesdatabase consistency in the face of such distribution and replication. This paper is one of aseries of companion papers on SDD-1 [4; 10; 12; 21].,ACM Transactions on Database Systems (TODS),1980,289,15
A model for concurrency in nested transactions systems,Catriel Beeri; Philip A Bernstein; Nathan Goodman,Abstract Today's standard model for database concurrency control; called serializabilitytheory; represents executions of transactions as partial orders of operations. The theory tellswhen an execution is serializable; that is; when the set of operations of a transaction executeatomically with respect to those of other transactions. It has been used successfully to provecorrectness of most database concurrency control algorithms. Its most serious limitation is itsinability to represent nested computations conveniently. This paper presents a more generalmodel that permits nested transactions. In this model; transactions may executesubtransactions; giving rise to tree-structured computations. A serializability theory isdeveloped for this model; which can be used to prove the correctness of concurrency controlalgorithms for nested transactions and for multilevel database systems. The theory is …,Journal of the ACM (JACM),1989,264,20
Power of natural semijoins,Philip A Bernstein; Nathan Goodman,A semijoin is a relational operator that is used to reduce the cost of processing queries in theSDD-1 distributed database system; the RAP database machine; and similar systems.Semijoin is used in these systems as part of a query pre-processing phase; its function is to“reduce” the database by delimiting those portions of the database that contain data relevantto the query. For some queries; there exist sequences of semijoins that “fully reduce” thedatabase; those sequences delimit the exact portions of the database needed to answer thequery in the sense that if any less data were delimited then the query would produce adifferent answer. Such sequences are called full reducers. This paper characterizes thequeries for which full reducers exist and presents an efficient algorithm for constructing fullreducers where they do exist. This paper extends the results of Bernstein and Chiu [J …,SIAM Journal on Computing,1981,264,8
Multibase: integrating heterogeneous distributed database systems,John Miles Smith; Philip A Bernstein; Umeshwar Dayal; Nathan Goodman; Terry Landers; Ken WT Lin; Eugene Wong,Abstract Multibase is a software system for integrating access to preexisting; heterogeneous;distributed databases. The system suppresses differences of DBMS; language; and datamodels among the databases and provides users with a unified global schema and a singlehigh-level query language. Autonomy for updating is retained with the local databases. Thearchitecture of Multibase does not require any changes to local databases or DBMSs. Thereare three principal research goals of the project. The first goal is to develop appropriatelanguage constructs for accessing and integrating heterogeneous databases. The secondgoal is to discover effective global and local optimization techniques. The final goal is todesign methods for handling incompatible data representations and inconsistent data.Currently the project is in the first year of a planned three year effort. This paper describes …,Proceedings of the May 4-7; 1981; national computer conference,1981,257,20
Formal aspects of serializability in database concurrency control,Philip A.  Bernstein; David W.  Shipman; Wing S.  Wong,An arbitrary interleaved execution of transactions in a database system can lead to aninconsistent database state. A number of synchronization mechanisms have been proposedto prevent such spurious behavior. To gain insight into these mechanisms; we analyze themin a simple centralized system that permits one read operation and one write operation pertransaction. We show why locking mechanisms lead to correct operation; we show that twoproposed mechanisms for distributed environments are special cases of locking; and wepresent a new version of lockdng that alows more concurrency than past methods. We alsoexamine conflict graph analysis; the method used in the SDD-1 distributed database system;we prove its correctness; and we show that it can be used to substantially improve theperformance of almost any synchronization mechanisn.,IEEE Transactions on Software Engineering,1979,247,10
Composition of mappings given by embedded dependencies,Alan Nash; Philip A Bernstein; Sergey Melnik,Abstract Composition of mappings between schemas is essential to support schemaevolution; data exchange; data integration; and other data management tasks. In manyapplications; mappings are given by embedded dependencies. In this article; we study theissues involved in composing such mappings. Our algorithms and results extend those ofFagin et al.[2004]; who studied the composition of mappings given by several kinds ofconstraints. In particular; they proved that full source-to-target tuple-generatingdependencies (tgds) are closed under composition; but embedded source-to-target tgds arenot. They introduced a class of second-order constraints; SO tgds; that is closed undercomposition and has desirable properties for data exchange.,ACM Transactions on Database Systems (TODS),2007,243,15
An overview of repository technology,Philip A Bernstein; Umeshwar Dayal,Abstract A repository is a shared database of information about engineered artifacts. Wedefine a repository manager to be a database application that suPports checkout/checkin;version and configuration management; notification; context management; and workflowcontrol. Since the main value of a repository is in the tools that use it; we discuss technicalissues of integrating tools with repositories. We also discuss how to implement a repositorymanager by layering it on a DBMS; focusing especially on issues of programming interface;performance; distribu-;; tion; and interoperability.,VLDB,1994,235,20
The failure and recovery problem for replicated databases,Philip A Bernstein; Nathan Goodman,Abstract A replicated database is a distributed database in which some data items are storedredundantly at multiple sites. The main goal is to improve system reliability. By storing criticaldata at multiple sites; the system can operate even though some sites have failed. However;few distributed database systems support replicated data; because it is difficult to manage assites fail and recover. A replicated data algorithm has two parts. One is a discipline forreading and writing data item copies. The other is a concurrency control algorithm forsynchronizing those operations. The read-write discipline ensures that if one transactionwrites logical data item×; and another transaction reads or writes x; there is some physicalmanifestation of that logical conflict. The concurrency control algorithm synchronizesphysical conflicts; it knows nothing about logical conflicts. In a correct replicated data …,Proceedings of the second annual ACM symposium on Principles of distributed computing,1983,216,15
Generic schema matching; ten years later,Philip A Bernstein; Jayant Madhavan; Erhard Rahm,ABSTRACT In a paper published in the 2001 VLDB Conference; we proposed treatinggeneric schema matching as an independent problem. We developed a taxonomy ofexisting techniques; a new schema matching algorithm; and an approach to comparativeevaluation. Since then; the field has grown into a major research topic. We briefly summarizethe new techniques that have been developed and applications of the techniques in thecommercial world. We conclude by discussing future trends and recommendations forfurther work.,Proceedings of the VLDB Endowment,2011,215,10
Timestamp-based algorithms for concurrency control in distributed database systems,Philip A Bernstein; Nathan Goodman,Abstract We decompose the problem of concurrency control into the sub-problems of read-write and write-write synchronization. We present a series of timestamp-based algorithms(called synchronization techniques) that achieve read-write and/or write-writesynchronization. And we show how to combine any read-write technique with any write-writetechnique to yield a complete concurrency control algorithm (called a method). Using thisframework we describe 12" principal" concurrency control methods in detail. Each principalmethod can be modified by refinements described in the paper; leading to more than 50distinct concurrency control algorithms.,Proceedings of the sixth international conference on Very Large Data Bases-Volume 6,1980,196,0
Sequoia: A fault-tolerant tightly coupled multiprocessor for transaction processing,Philip A.  Bernstein,The Sequoia computer is a tightly coupled multiprocessor that avoids most of the fault-tolerance disadvantages of tight coupling by using a fault-tolerant hardware-designapproach. An overview is give of how the hardware architecture and operating system (OS)work together to provide a high degree of fault tolerance with good system performance. Adescription of hardware is followed by a discussion of the multiprocessor synchronizationproblem. Kernel support for fault recovery and the recovery process itself are examined. It isshown the kernel; through a combination of locking; shadowed memory; and controlledflushing of non-write-through cache; maintains a consistent main memory state recoverablefrom any single-point failure. The user shared memory is also discussed.,Computer,1988,190,0
On the Updatability of Relational Views.,Umeshwar Dayal; Philip A Bernstein,Abstract Most relational database systems provide a facility for supporting user views.Permitting this level of abstraction has the danger; however; that update requests issued bya user within the context of his view may not translate correctly into equivalent updates onthe underlying database. It is the purpose of this paper to formalize the notion of correcttranslatability; and to derive constraints on view definitions that ensure the existence ofcorrect update mappings. In summary; our theorems show that there are very few situationsin which view updates are possible--even fewer; in fact; than intuition might suggest.,VLDB,1978,190,19
On matching schemas automatically,Erhard Rahm; Philip A Bernstein,Abstract Schema matching is a basic problem in many database application domains; suchas data integration; E-business; data warehousing; and semantic query processing. Incurrent implementations; schema matching is typically performed manually; which hassignificant limitations. On the other hand; in previous research many techniques have beenproposed to achieve a partial automation of the Match operation for specific applicationdomains. We present a taxonomy that covers many of the existing approaches; and wedescribe these approaches in some detail. In particular; we distinguish between schema-and instance-level; element-and structure-level; and language-and constraint-basedmatchers. Based on our classification we review some previous match implementationsthereby indicating which part of the solution space they cover. We intend our taxonomy …,VLDB journal,2001,187,10
Industrial-strength schema matching,Philip A Bernstein; Sergey Melnik; Michalis Petropoulos; Christoph Quix,Abstract Schema matching identifies elements of two given schemas that correspond toeach other. Although there are many algorithms for schema matching; little has been writtenabout building a system that can be used in practice. We describe our initial experiencebuilding such a system; a customizable schema matcher called Protoplasm.,ACM Sigmod Record,2004,186,0
The Claremont report on database research,Rakesh Agrawal; Anastasia Ailamaki; Philip A Bernstein; Eric A Brewer; Michael J Carey; Surajit Chaudhuri; AnHai Doan; Daniela Florescu; Michael J Franklin; Hector Garcia-Molina; Johannes Gehrke; Le Gruenwald; Laura M Haas; Alon Y Halevy; Joseph M Hellerstein; Yannis E Ioannidis; Hank F Korth; Donald Kossmann; Samuel Madden; Roger Magoulas; Beng Chin Ooi; Tim O'Reilly; Raghu Ramakrishnan; Sunita Sarawagi; Michael Stonebraker; Alexander S Szalay; Gerhard Weikum,Abstract In late May; 2008; a group of database researchers; architects; users and punditsmet at the Claremont Resort in Berkeley; California to discuss the state of the research fieldand its impacts on practice. This was the seventh meeting of this sort in twenty years; andwas distinguished by a broad consensus that we are at a turning point in the history of thefield; due both to an explosion of data and usage scenarios; and to major shifts in computinghardware and platforms. Given these forces; we are at a time of opportunity for researchimpact; with an unusually large potential for influential results across computing; thesciences and society. This report details that discussion; and highlights the group'sconsensus view of new focus areas; including new database engine architectures;declarative programming languages; the interplay of structured and unstructured data …,ACM Sigmod Record,2008,160,22
Implementing recoverable requests using queues,Philip A Bernstein; Meichun Hsu; Bruce Mann,Abstract Transactions have been rigorously defined and extensively studied in the databaseand transaction processing literature; but little has been said about the handling of therequests for transaction execution in commercial TP systems; especially distributed ones;managing the flow of requests is often as important as executing the transactionsthemselves. This paper studies fault-tolerant protocols for managing the flow of transactionrequests between clients that issue requests and servers that process them. We discuss howto implement these protocols using transactions and recoverable queuing systems. Queuingsystems are used to move requests reliably between clients and servers. The protocols usequeuing systems to ensure that the server processes each request exactly once and that aclient processes each reply at least once. We treat request-reply protocols for single …,ACM SIGMOD Record,1990,155,19
Microsoft repository version 2 and the open information model,Philip A Bernstein; Thomas Bergstraesser; Jason Carlson; Shankar Pal; Paul Sanders; David Shutt,Microsoft Repository is a persistent object manager and object model designed to helpusers manage descriptions of things; that is; meta-data. It is being used in Microsoft VisualStudio to manage reusable components and exchange object models; and in Microsoft SQLServer to manage database schemas and transformations used for data warehousing. It is ageneral purpose technology that is being applied by third parties to a variety of otherapplications; such as asset management; model management; and computer-aided design(CAD). The demand for such technology is growing rapidly; driven in part by multi-tierapplication environments [23] accessible via the World-Wide Web [25]. The first release ofMicrosoft Repository was in early 1997 in Visual Basic 5.0; and over a million copies haveshipped. The second release; which includes version and workspace management and a …,Information Systems,1999,146,10
The concurrency control mechanism of SDD-1: A system for distributed databases (the fully redundant case),Philip A.  Bernstein; JB Rothnie; Nathan Goodman; CHRISTOS A Papadimitriou,SDD-1; A System for Distributed Databases; is a distributed database system beingdeveloped by Computer Corporation of America (CCA); Cambridge; MA. SDD-1 permitsdata to be stored redundantly at several database sites in order to enhance the reliabilityand responsiveness of the system and to facilitate upward scaling of system capacity. Thispaper describes the method used by SDD-1 for updating data that are stored redundantly.,IEEE Transactions on Software Engineering,1978,143,6
Method and system for consistent cluster operational data in a server cluster using a quorum of replicas,*,A method and system for increasing server cluster availability by requiring at a minimumonly one node and a quorum replica set of replica members to form and operate a cluster.Replica members; independent from the nodes; maintain cluster operational data. A clusteroperates when one node possesses a majority of replica members; which ensures that anynew or surviving cluster includes consistent cluster operational data via at least one replicamember from the immediately prior cluster. Arbitration provides exclusive ownership by onenode of the replica members; including at cluster formation; and when the owning node fails.Arbitration uses a fast mutual exclusion algorithm and a reservation mechanism to challengefor and defend the exclusive reservation of each member. A quorum replica set algorithmbrings members online and offline with data consistency; including updating unreconciled …,*,2005,134,20
Synthesizing independent database schemas,Joachim Biskup; Umeshwar Dayal; Philip A Bernstein,Abstract We study the following database design problem. Given a universal relationscheme〈 U; F〉 where F is a set of functional dependencies; find an in some way normalizeddatabase schema D={〈 X 1; F 1〉;...;〈 X n; F n〉} where X i⊂ U and F i is inherited from F;such that D is an independent representation of the universal scheme〈 U; F〉. This meansthat D has both the lossless join property and the faithful closure property;(***** F i)+= F+;where+ denotes the closure of a set of functional dependencies. We show that this goal caneasily be achieved by an extension of the well-known synthetic approach of Bernstein andothers to database design. We merely have to check whether the usual synthesis procedurehas produced a key component〈 X i; F i〉 such that X i→ U ε F+; in case this is true the outputof the synthesis procedure is actually an independent (and not only faithful) …,Proceedings of the 1979 ACM SIGMOD international conference on Management of data,1979,132,20
Hyder-A Transactional Record Manager for Shared Flash.,Philip A Bernstein; Colin W Reid; Sudipto Das,Page 1. Hyder – A Transactional Record Manager for Shared Flash Philip A. Bernstein;Microsoft Corporation Colin Reid; Microsoft Corporation Sudipto Das; UC Santa Barbara ©2011 Microsoft Corporation CIDR 2011 January 10; 2011 Page 2. Hyder: The Big Picture •Goal: Enable scale-out without partitioning DB or app 2 • Store the whole DB in flash – whichis accessible to all servers – via a fast data center network • Main architectural features –Uses a log-structured DB in flash – Broadcast log to all servers – Roll forward log on allservers – Optimistic concurrency control Network Internet Hyder Log Server Hyder App ServerHyder App Server Hyder App • There's no cross-talk between servers – Hence; Hyderscales-out without partitioning Page 3. What is Hyder? 3 An incubation; ie research project.A software stack for transactional record management …,CIDR,2011,124,20
Fast maintenance of semantic integrity assertions using redundant aggregate data,Philip A Bernstein; Barbara T Blaustein; Edmund M Clarke,ABSTRACT Semantic integrity assertions are predicates that define consistent databasestates. To enforce such assertions; a database system must prevent any update frommapping a consistent state to an inconsistent one. In this paper; we describe an enforcementmethod that is efficient for a large class of relational calculus assertions. The methodautomatically selects minima and maxima of certain sets to maintain as redundant data inthe database. This redundant data is sufficient for enforcing all of the assertions in the class;yet it can be easily maintained. Correctness proofs are expressed in Hoare's program logic.,*,1988,123,20
System and method for consistent timestamping in distributed computer databases,*,A distributed database system has a plurality of databases located at distinct nodes; at leastone of the databases comprising a timestamping database. Distributed transactions arecommitted using a two phase protocol. During the first phase; each cohort to the transactionvotes to commit or abort the transaction; and also votes an earliest time and a latest time atwhich the transaction is to be committed. If all the cohorts vote to commit the transaction andthe intersection of the voted time ranges is not empty; then the transaction is committedduring the second phase of the protocol. A transaction time is selected from the intersectionof the voted time ranges and is used to timestamp all updated data that is durably storedwhen the transaction is committed. Before the first phase of the two phase commit protocol;each transaction read or write locks data at each node for which it needs read or write …,*,1993,121,23
Compiling mappings to bridge applications and databases,Sergey Melnik; Atul Adya; Philip A Bernstein,Abstract Translating data and data access operations between applications and databasesis a longstanding data management problem. We present a novel approach to this problem;in which the relationship between the application data and the persistent storage is specifiedusing a declarative mapping; which is compiled into bidirectional views that drive the datatransformation engine. Expressing the application model as a view on the database is usedto answer queries; while expressing the database schema as a view on the applicationmodel allows us to leverage view maintenance algorithms for update translation. Thisapproach has been implemented in a commercial product. It enables developers to interactwith a relational database via a conceptual schema and an object-oriented programmingsurface. We outline the implemented system and focus on the challenges of mapping …,ACM Transactions on Database Systems (TODS),2008,119,0
Implicit session context system with object state cache,*,An implicit session system with an object state cache. The implicit sessioning avoidsexplicitly passing session parameters in each function call to an object by implicitlyassociating the session context to a session object with each loaded object related to thesession so that each function call runs with the session context of the called object. Theobject state cache minimizes the system resource impact of having multiple instances of anobject in different sessions by sharing one copy of each respective unique object state in anobject state cache.,*,1999,119,15
Adapting microsoft SQL server for cloud computing,Philip A Bernstein; Istvan Cseri; Nishant Dani; Nigel Ellis; Ajay Kalhan; Gopal Kakivaya; David B Lomet; Ramesh Manne; Lev Novik; Tomas Talius,Cloud SQL Server is a relational database system designed to scale-out to cloud computingworkloads. It uses Microsoft SQL Server as its core. To scale out; it uses a partitioneddatabase on a shared-nothing system architecture. Transactions are constrained to executeon one partition; to avoid the need for two-phase commit. The database is replicated for highavailability using a custom primary-copy replication scheme. It currently serves as thestorage engine for Microsoft's Exchange Hosted Archive and SQL Azure.,Data Engineering (ICDE); 2011 IEEE 27th International Conference on,2011,117,20
Repositories and object oriented databases,Philip A Bernstein,Abstract A repository is a shared database of information about engineered artifacts. Anobject-oriented repository has many of the same features as an object-oriented database:properties; relationships; and versioning. However; the two technologies are different for tworeasons. First; a repository system has built-in information models; which are databaseschemas or object models that cover both generic and tool-specific kinds of information.Second; the features of a repository are often more functional than similar featuressupported by object-oriented databases. This paper is primarily a survey of the latterfeatures; drawing attention to capabilities that distinguish repositories from object-orienteddatabases.,ACM Sigmod Record,1998,116,10
Supporting executable mappings in model management,Sergey Melnik; Philip A Bernstein; Alon Halevy; Erhard Rahm,Abstract Model management is an approach to simplify the programming of metadata-intensive applications. It offers developers powerful operators; such as Compose; Diff; andMerge; that are applied to models; such as database schemas or interface specifications;and to mappings between models. Prior model management solutions focused on a simpleclass of mappings that do not have executable semantics. Yet many metadata applicationsrequire that mappings be executable; expressed in SQL; XSLT; or other data transformationlanguages. In this paper; we develop a semantics for model-management operators thatallows applying the operators to executable mappings. Our semantics captures previously-proposed desiderata and is language-independent: the effect of the operators is expressedin terms of what they do to the instances of models and mappings. We describe an …,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,110,20
Challenges and Opportunities with big data 2011-1,Divyakant Agrawal; Philip Bernstein; Elisa Bertino; Susan Davidson; Umeshwas Dayal; Michael Franklin; Johannes Gehrke; Laura Haas; Alon Halevy; Jiawei Han; HV Jagadish; Alexandros Labrinidis; Sam Madden; Yannis Papakonstantinou; Jignesh Patel; Raghu Ramakrishnan; Kenneth Ross; Cyrus Shahabi; Dan Suciu; Shiv Vaithyanathan; Jennifer Widom,Abstract The promise of data-driven decision-making is now being recognized broadly; andthere is growing enthusiasm for the notion of``Big Data.''While the promise of Big Data is real--for example; it is estimated that Google alone contributed 54 billion dollars to the USeconomy in 2009--there is currently a wide gap between its potential and its realization.,*,2011,107,0
Consistent cluster operational data in a server cluster using a quorum of replicas,*,A method and system for increasing server cluster availability by requiring at a minimumonly one node and a quorum replica set of replica members to form and operate a cluster.Replica members maintain cluster operational data. A cluster operates when one nodepossesses a majority of replica members; which ensures that any new or surviving clusterincludes consistent cluster operational data via at least one replica member from theimmediately prior cluster. Arbitration provides exclusive ownership by one node of thereplica members; including at cluster formation; and when the owning node fails. Arbitrationuses a fast mutual exclusion algorithm and a reservation mechanism to challenge for anddefend the exclusive reservation of each member. A quorum replica set algorithm bringsmembers online and offline with data consistency; including updating unreconciled …,*,2010,105,20
Incremental schema matching,Philip A Bernstein; Sergey Melnik; John E Churchill,Abstract The goal of schema matching is to identify correspondences between the elementsof two schemas. Most schema matching systems calculate and display the entire set ofcorrespondences in a single shot. Invariably; the result presented to the engineer includesmany false positives; especially for large schemas. The user is often overwhelmed by all ofthe edges; annoyed by the false positives; and frustrated at the inability to see second-andthird-best choices. We demonstrate a tool that circumvents these problems by doing thematching interactively. The tool suggests candidate matches for a selected schema elementand allows convenient navigation between the candidates. The ranking of match candidatesis based on lexical similarity; schema structure; element types; and the history of priormatching actions. The technical challenges are to make the match algorithm fast enough …,Proceedings of the 32nd international conference on Very large data bases,2006,104,20
What does Boyce-Codd normal form do?,Philip A Bernstein; Nathan Goodman,Abstract Normalization research has concentrated on defining normal forms for databaseschemas and developing efficient algorithms for attaining these normal forms. It has neverbeen proved that normal forms are good; ie that normal forms are beneficial to databaseusers. This paper considers one of the earliest normal forms (Boyce Codd normal form[Cod2]) whose benefits are intuitively understood. We formalize these benefits and attemptto prove that the normal form attains them. Instead we prove the opposite: Boyce-Coddnormal form fails to meet its goals except in trivial cases. This counterintuitive result is aconsequence of the" universal relation assumption" upon which normalization theory rests.Normalization theory will remain an isolated theoretical area; divorced from databasepractice; until this assumption is circumvented.,Proceedings of the sixth international conference on Very Large Data Bases-Volume 6,1980,103,20
A model theory for generic schema management,Suad Alagić; Philip A Bernstein,Abstract The core of a model theory for generic schema management is developed. Thistheory has two distinctive features: it applies to a variety of categories of schemas; and itapplies to transformations of both the schema structure and its integrity constraints. A subtleproblem of schema integration is considered in its general form; not bound to any particularcategory of schemas. The proposed solution; as well as the overall theory; is based entirelyon schema morphisms that carry both structural and semantic properties. Duality results thatapply to the schema and the data levels are established. These results lead to the maincontribution of this paper: a formal schema and data management framework for genericschema management. Implications of this theory are established that apply to integrityproblems in schema integration. The theory is illustrated by a particular category of …,International Workshop on Database Programming Languages,2001,102,15
The Claremont report on database research,Rakesh Agrawal; Anastasia Ailamaki; Philip A Bernstein; Eric A Brewer; Michael J Carey; Surajit Chaudhuri; Anhai Doan; Daniela Florescu; Michael J Franklin; Hector Garcia-Molina; Johannes Gehrke; Le Gruenwald; Laura M Haas; Alon Y Halevy; Joseph M Hellerstein; Yannis E Ioannidis; Hank F Korth; Donald Kossmann; Samuel Madden; Roger Magoulas; Beng Chin Ooi; Tim O'Reilly; Raghu Ramakrishnan; Sunita Sarawagi; Michael Stonebraker; Alexander S Szalay; Gerhard Weikum,Here; we explore the conclusions of this self-assessment. It is by definition somewhatinward-focused but may be of interest to the broader computing community as both a windowinto upcoming directions in database research and a description of some of the community issuesand initiatives that surfaced. We describe the group's consensus view of new focus areas forresearch; including database engine architectures; declarative programming languages; interplayof structured data and free text; cloud data services; and mobile and virtual worlds. We also reporton discussions of the database community's growth and processes that may be of interest toother research areas facing similar challenges … Over the past 20 years; small groups of databaseresearchers have periodically gathered to assess the state of the field and propose directionsfor future research. 1;3;4;5;6;7 Reports of the meetings served to foster debate within the …,Communications of the ACM,2009,100,0
Implementing mapping composition,Philip A Bernstein; Todd J Green; Sergey Melnik; Alan Nash,Abstract Mapping composition is a fundamental operation in metadata driven applications.Given a mapping over schemas¿ 1 and¿ 2 and a mapping over schemas¿ 2 and¿ 3; thecomposition problem is to compute an equivalent mapping over¿ 1 and¿ 3. We describe anew composition algorithm that targets practical applications. It incorporates view unfolding.It eliminates as many¿ 2 symbols as possible; even if not all can be eliminated. It coversconstraints expressed using arbitrary monotone relational operators and; to a lesser extent;non-monotone operators. And it introduces the new technique of left composition. Wedescribe our implementation; explain how to extend it to support user-defined operators; andpresent experimental results which validate its effectiveness.,The VLDB Journal—The International Journal on Very Large Data Bases,2008,98,15
Operating systems,Dionysios C Tsichritzis; Philip A Bernstein,Operating Systems deals with the fundamental concepts and principles that govern thebehavior of operating systems. Many issues regarding the structure of operating systems;including the problems of managing processes; processors; and memory; are examined.Various aspects of operating systems are also discussed; from input-output and files tosecurity; protection; reliability; design methods; performance evaluation; and implementationmethods. Comprised of 10 chapters; this volume begins with an overview of what constitutesan operating system; followed by a discussion on the definition and properties of the basicunit of computation within an operating system; the process. The reader is then introduced toprocessor allocation schemes as well as various classes of scheduling disciplines and theirimplementations; memory management functions; and virtual memory. Subsequent …,*,2014,97,20
Transaction processing monitors,Philip A Bernstein,Abstract A transaction processing (TP) application is a program that performs anadministrative function by accessing a shared database on behalf of an on-line user. A TPsystem is an integrated set of products that supports TP applications. These products includeboth hardware; such as processors; memories; disks and communications controllers; andsoftware such as operating systems (Oss); database management systems (DBMSs);computer networks and TP monitors. Much of the integration of these products is provided byTP monitors which coordinate the flow of transaction request between terminals that issuerequests and TP applications that can process them. Today; TP represents over 25 percentof the computer systems market and is one of the growing segments of the computerbusiness. TP applications appear in most sectors of large-scale enterprises such as …,Communications of the ACM,1990,97,0
Adapting a generic match algorithm to align ontologies of human anatomy,Peter Mork; Philip A Bernstein,The difficulty inherent in schema matching has led to the development of several genericmatch algorithms. We describe how we adapted general approaches to the specific task ofaligning two ontologies of human anatomy; the Foundational Model of Anatomy and theGALEN Common Reference Model. Our approach consists of three phases: lexical;structural and hierarchical; which leverage different aspects of the ontologies as they arerepresented in a generic meta-model. Lexical matching identifies concepts with similarnames. Structural matching identifies concepts whose neighbors are similar. Finally;hierarchical matching identifies concepts with similar descendants. We conclude byreporting on the lessons we learned.,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,91,0
Optimizing chain queries in a distributed database system,Dah-Ming Chiu; Philip A Bernstein; Yu-Chi Ho,This paper studies the problem of query optimization in a distributed database. Assuming alinear additive cost function (in volume of data moved); we present a fast algorithm forfinding the optimal program that answers a class of common queries; called chain queries.The key to the problem formulation and to the derivation of an efficient algorithm is anelegant parameterization of the database state against which the query is to be answered.This parameterization then enables us to characterize the set of potentially optimalprograms; which in turn leads to a fast dynamic programming algorithm. Since in practice theneeded parameters may not be available to the database system; we also discuss how todeal with partial parameterizations of the database state.,SIAM Journal on Computing,1984,88,1
A concurrency control theory for nested transactions (Preliminary Report),Catriel Beeri; Philip A Bernstein; Nathan Goodman; Ming-Yee Lai; Dennis E Shasha,Abstract Concurrency control is the activity of synchronizing transactions that access shareddata. A concurrency control algorithm is regarded as correct if it ensures that any interleavedexecution of transactions is equivalent to a serial one. Such executions are calledserializable. Serializability theory provides a method for modelling and analyzing thecorrectness of concurrency control algorithms [BSW; Pa]. The concept of nested transactionhas recently received much attention [GR];[Mo]. In a nested transaction model; eachtransaction can invoke sub-transactions; which can invoke sub-subtransactions; and so on.The natural modelling concept is the tree log. The leaves of a tree log are atomic operationsexecuted by the underlying system. Internal nodes are operations (as seen by their parents)implemented as transactions (as seen by their children). Nodes are related by a partial …,Proceedings of the second annual ACM symposium on Principles of distributed computing,1983,87,20
Model-independent schema translation,Paolo Atzeni; Paolo Cappellari; Riccardo Torlone; Philip A Bernstein; Giorgio Gianforme,Abstract We discuss a proposal for the implementation of the model management operatorModelGen; which translates schemas from one model to another; for example from object-oriented to SQL or from SQL to XML schema descriptions. The operator can be used togenerate database wrappers (eg; object-oriented or XML to relational); default userinterfaces (eg; relational to forms); or default database schemas from other representations.The approach translates schemas from a model to another; within a predefined; but largeand extensible; set of models: given a source schema S expressed in a source model; and atarget model TM; it generates a schema S¿ expressed in TM that is" equivalent" to S. A widefamily of models is handled by using a metamodel in which models can be succinctly andprecisely described. The approach expresses the translation as Datalog rules and …,The VLDB Journal—The International Journal on Very Large Data Bases,2008,85,20
Local relational model: A logical formalization of database coordination,Luciano Serafini; Fausto Giunchiglia; John Mylopoulos; Philip Bernstein,Abstract We propose a new data model intended for peer-to-peer (P2P) databases. Themodel assumes that each peer has a (relational) database and exchanges data with otherpeers (its acquaintances). In this context; one needs a data model that views the space ofavailable data within the P2P network as an open collection of possibly overlapping andinconsistent databases. Accordingly; the paper proposes the Local Relational Model;develops a semantics for coordination formulas. The main result of the paper generalizesReiter's characterization of a relational database in terms of a first order theory [1]; byproviding a syntactic characterization of a relational space in terms of a multi-context system.This work extends earlier work by Giunchiglia and Ghidini on Local Model Semantics [2].,International and Interdisciplinary Conference on Modeling and Using Context,2003,84,0
The microsoft repository,Philip A Bernstein; Brian Harry; Paul Sanders; David Shutt; Jason Zander,Abstract The Microsoft Repository is an object-oriented repository that ships as a componentof Visual Basic (Version 5.0). It includes a set of ActiveX interfaces that a developer can useto define information models; and a repository engine that is the underlying storagemechanism for these information models. The repository engine sits on top of a SQLdatabase system.,VLDB,1997,83,15
Generation of query and update views for object relational mapping,*,A data access architecture may includes a mapping architecture for mapping data as may beused by an application to data as persisted in a database. Such a mapping architecture usestwo types of “mapping views”—one for translating queries and the other for translatingupdates. A mechanism is provided that automatically generates query and update viewsfrom high-level mapping specifications. A validation may be performed to ensure that amapping specification; when used in conjunction with a mapping architecture; allows data to“roundtrip” from the application to the database; without loss of data.,*,2010,82,3
Model-independent schema and data translation,Paolo Atzeni; Paolo Cappellari; Philip A Bernstein,Abstract We describe MIDST; an implementation of the model management operatorModelGen; which translates schemas from one model to another; for example from OO toSQL or from SQL to XSD. It extends past approaches by translating database instances; notjust their schemas. The operator can be used to generate database wrappers (eg OO orXML to relational); default user interfaces (eg relational to forms); or default databaseschemas from other representations. The approach translates both schemas and data: givena source instance I of a schema S expressed in a source model; and a target model TM; itgenerates a schema S′ expressed in TM that is “equivalent” to S and an instance I′ ofS′“equivalent” to I. A wide family of models is handled by using a metamodel in whichmodels can be succinctly and precisely described. The approach expresses the …,International Conference on Extending Database Technology,2006,82,15
A sophisticate's introduction to distributed database concurrency control,Philip A Bernstein; Nathan Goodman,ABSTRACT. Dozens of articles have been published describing" new" concurrency controlalgorithms for distributed database systems. All of these algorithms can be derived andunderstood using a few basic concepts. We show how to decompose the concurrencycontrol problem into several subproblems; each of which has iust a few known solutions. Byappropriately combining known solutions to the subproblems; we show that all publishedconcurrency control algorithms and many new ones can be constructed. The glue that bindsthe subproblems and solutions together is a mathematical theory known as serializabilitytheory.,*,1982,80,15
The correctness of concurrency control mechanisms in a system for distributed databases (SDD-1),Philip A Bernstein; David W Shipman,Abstract This paper presents a formal analysis of the concurrency control strategy of SDD-1.SDD-1; a System for Distributed Databases; is a prototype distributed database systembeing developed by Computer Corporation of America. In SDD-1; portions of data distributedthroughout a network may be replicated at multiple sites. The SDD-1 concurrency controlguarantees database consistency in the face of such distribution and replication. This paperis one of a series of companion papers on SDD-1 [2; 8].,ACM Transactions on Database Systems (TODS),1980,79,0
Site initialization; recovery; and backup in a distributed database system,Rony Attar; Philip A Bernstein; Nathan Goodman,Site initialization is the problem of integrating a new site into a running distributed databasesystem (DDBS). Site recovery is the problem of integrating an old site into a DDBS when thesite recovers from failure. Site backup is the problem of creating a static backup copy of adatabase for archival or query purposes. We present an algorithm that solves the siteinitialization problem. By modifying the algorithm slightly; we get solutions to the other twoproblems as well. Our algorithm exploits the fact that a correct DDBS must run a serializableconcurrency control algorithm. Our algorithm relies on the concurrency control algorithm tohandle all intersite synchronization.,IEEE Transactions on Software Engineering,1984,76,14
An online bibliography on schema evolution,Erhard Rahm; Philip A Bernstein,Abstract We briefly motivate and present a new online bibliog- raphy on schema evolution; anarea which has recently gained much interest in both research and practice. 1 Introduction Schemaevolution is the ability to change deployed schemas; ie; metadata structures formally describingcomplex artifacts such as databases; messages; application programs or workflows. Typicalschemas thus include relational or object-oriented (OO) database schemas; conceptual ER orUML models; ontologies; XML schemas; software interfaces and workflow specifications.Obviously; the need for schema evolution occurs very often in order to deal with new or changedrequirements; to correct deficiencies in the current schemas or to migrate to a new platform. Effectivesupport for schema evolution is challeng- ing since schema changes may have to bepropagated; correctly and efficiently; to instance data; views; applica- tions and other …,ACM Sigmod Record,2006,74,1
Meta-data support for data transformations using Microsoft Repository,Philip A.  Bernstein; Thomas Bergstraesser,Abstract Data warehousing requires facilities for moving and transforming data and meta-data. This paper describes such facilities that are integrated with Microsoft SQL Server 7.0;particularly as they relate to meta-data and information models in its shared repository. Italso discusses the use of XML to move meta-data between tools.,IEEE Data Eng. Bull.,1999,73,15
V. Hadzilacos; and N. Goodman,PA Bernstein,*,Concurrency control and recovery in database systems,1987,72
Some computational problems related to database concurrency control,Christos H Papadimitriou; Philip A Bernstein; James B Rothnie,*,Proc. of the Conf. on Theoretical Computer Science,1977,70
Schema merging and mapping creation for relational sources,Rachel Pottinger; Philip A Bernstein,Abstract We address the problem of generating a mediated schema from a set of relationaldata source schemas and conjunctive queries that specify where those schemas overlap.Unlike past approaches that generate only the mediated schema; our algorithm alsogenerates view definitions; ie; source-to-mediated schema mappings. Our main goal is tounderstand the requirements that a mediated schema and views should satisfy; such ascompleteness; preservation of overlapping information; normalization; and minimality. Weshow how these requirements influence the detailed structure of schemas and viewdefinitions that are produced. We introduce a normal form for mediated schemas and viewdefinitions; show how to generate them; and prove that schemas and views in this normalform satisfy our requirements.,Proceedings of the 11th international conference on Extending database technology: Advances in database technology,2008,67,1
Serializability theory for replicated databases,Philip A Bernstein; Nathan Goodman,Abstract In a one-copy distributed database; each data item is stored at exactly one site of adistributed system. In a replicated database; some data items are stored at multiple sites.The main motivation for replicated data is improved reliability: by storing important data atmultiple sites; the system can tolerate failures more gracefully. This paper presents a theoryfor proving the correctness of algorithms that manage replicated data. The theory is anextension of serializability theory. We use the theory to give simple correctness proofs fortwo replicated data algorithms: Gifford's “quorum consensus” algorithm; and Eager andSevcik's “missing writes” algorithm.,Journal of Computer and System Sciences,1985,66,1
Relaxed-currency serializability for middle-tier caching and replication,Philip A Bernstein; Alan Fekete; Hongfei Guo; Raghu Ramakrishnan; Pradeep Tamma,Abstract Many applications; such as e-commerce; routinely use copies of data that are not insync with the database due to heuristic caching strategies used to enhance performance.We study concurrency control for a transactional model that allows update transactions toread out-of-date copies. Each read operation carries a" freshness constraint" that specifieshow fresh a copy must be in order to be read. We offer a definition of correctness for thismodel and present algorithms to ensure several of the most interesting freshnessconstraints. We outline a serializability-theoretic correctness proof and present the results ofa detailed performance study.,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,62,10
Fast methods for testing quantified relational calculus assertions,Philip A Bernstein; Barbara T Blaustein,Abstract Semantic integrity assertions are predicates that define consistent states. Adatabase system enforces assertions by ensuring that consistency is maintained as thedatabase is updated. Most research on the efficient enforcement of assertions hasconcentrated on assertion simplification algorithms---algorithms that produce simplifiedassertions that can be evaluated before the update is executed. This paper describes astrategy for further improving the efficiency of assertion enforcement. We develop an efficientalgorithm for evaluating an assertion produced by an assertion simplification algorithm. Wecharacterize a class of assertions that can be evaluated using a simple two-step procedure.The first step defines and evaluates simple selection queries on each relation. The secondstep applies set emptiness tests to the results of these selections. We also show how …,Proceedings of the 1982 ACM SIGMOD international conference on Management of data,1982,61,20
A unified approach to functional dependencies and relations,Philip A Bernstein; J Richard Swenson; Dionysios C Tsichritzis,Abstract In Codd's relational model; the relation name groups together a family of functionaldependencies over a set of attributes. For integrity and for maintenance purposes it isimportant to eliminate inherent redundancy within a relation due to the repetition ofinstances of a functional connection between attributes. This led Codd to propose a series ofthree normalizations. The manipulation of normal forms is governed by functionaldependencies that are explicitly declared to exist within the relation. Since functionaldependencies completely govern the decomposition rules of normalization; perhaps it ismore sensible to take them as the elementary notions to be later synthesized into morecomplex structures; such as relations. Our goals; then are twofold. First; we will discuss howthe use of functional dependencies lends itself to a rigorous and correct; yet clear and …,Proceedings of the 1975 ACM SIGMOD international conference on Management of data,1975,61,10
Fundamental Algorithms for Concurrency Control in Distributed Database Systems.,Philip A Bernstein; Nathan Goodman,Concurrency control is a necessary component of any multi-user database managementsystem (DBMS). Its role is to coordinate the database interactions of users who areaccessing a database at the same time. Concurrency control permits multiple users toaccess a database in a multi-programmed fashion while preserving the illusion that eachuser is executing alone on a dedicated system. The-main technical difficulty in attaining thisgoal is to prevent database updates performed by one user from interfering with databaseretrievals and updates performed by another. The nature of this problem is illustrated inSection 1.2. The concurrency control problem is exacerbated in a distributed databasemanagement system (DDBMS) for two reasons. First; users may access data stored in manydifferent computers in a distributed system. And second; a concurrency control …,*,1980,60,20
Versions and workspaces in an object repository,*,Maintaining versions and workspaces in an object repository is disclosed. The systemprovides an efficient way to manage versions of objects by only copying objects whenabsolutely necessary; ie when a property value in a particular object has changed. Inaddition; the system provides a mechanism to control whether or not relationships arepropagated to successor versions of an object. A further aspect of the system is thatresolution of objects during a relationship traversal can be customized depending onwhether or not an application accessing the objects is version-aware. If the application is notversion aware; a means for resolving the relationship to a particular object is provided. A stillfurther aspect of the system is that merge behavior is parameterized. When two versions ofan object are merged; flags control how conflicts in property values and relationship …,*,2010,59,10
Query processing in SDD-1: A system for distributed databases,Nathan Goodman; Philip A Bernstein; Eugene Wong; Christopher L Reeve; James B Rothnie,Abstract: This paper describes the techniques used to optimize relational queries in the SDD-1; distributed database system. Queries are submitted to SDD-1 in a high-level procedurallanguage called Datalanguage. Optimization begins by translating each Datalanguagequery into a relational calculus form called an envelope; which is essentially an aggregate-free QUEL query. This paper is primarily concerned with the optimization of envelopes.Envelopes are processed in two phases. The first phase executes relational operations atvarious sites of the distributed database in order to delimit a subset of the database thatcontains all data relevant to the envelope. This subset is called a reduction of the database.The second phase transmits the reduction to one designated site; and the query is executedlocally at that site. The critical optimization problem is to perform the reduction phase …,*,1979,59,10
A formal system for reasoning about programs accessing a relational database,Marco R Casanova; Phillip A Bernstein,Abstract A formal system for proving properties of programs accessing a database isintroduced. Proving that a program preserves consistency of the database is one of thepossible applications of the system. The formal system is a variant of dynamic logic andincorporates a data definition language (DDL) for describing relational databases and adata manipulation language (DML) whose programs access data in a database. The DDL isa many-sorted first-order language that accounts for data aggregations. The DML features amany-sorted assignment in place of the usual data manipulation statements; in addition tothe normal programming language constructs.,ACM Transactions on Programming Languages and Systems (TOPLAS),1980,58,20
Modelgen: Model independent schema translation,Paolo Atzeni; Paolo Cappellari; Philip A Bernstein,A customizable and extensible tool is proposed to implement ModelGen; the modelmanagement operator that translates a schema from one model to another. A wide family ofmodels is handled; by using a metamodel in which models can be succinctly and preciselydescribed. The approach is novel because the tool exposes the dictionary that storesmodels; schemas; and the rules used to implement translations. In this way; thetransformations can be customized and the tool can be easily extended.,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,54,12
Future directions in DBMS research,Philip A Bernstein; Umeshwar Dayal; David J DeWitt; D Gawlick; J Gray; M Jarke; BG Lindsay; PC Lockemann; D Maier; EJ Neuhold; A Reuter; LA Rowe; HJ Schek; JW Schmidt; M Schrefl; M Stonebraker,Kurzfassung: On February 4-5; 1988; the International Computer Science Institutesponsored a two day workshop at which 16 senior members of the data base researchcommunity discussed future research topics in the DBMS area. This paper summarizes thediscussion which took place.,SIGMOD Record,1989,54,20
Recovery algorithms for database systems,Philip A Bernstein; Nathan Goodman; Vassos Hadzilacos,*,*,1983,51
Generic model management: A database infrastructure for schema manipulation,Philip A Bernstein,Abstract This paper summarizes the model management approach to generic schemamanagement. The goal is to raise the level of abstraction of data manipulation forprogrammers of design tools and other model-driven applications. We explain the mainconcepts of model management; report on some recent progress on model matchingalgorithms; and sketch a category-theoretic approach to a formal semantics for modelmanagement.,International Conference on Cooperative Information Systems,2001,50,0
Developing metadata-intensive applications with Rondo,Sergey Melnik; Erhard Rahm; Philip A Bernstein,Abstract The future of the Semantic Web depends on whether or not we succeed to integratereliably thousands of online applications; services; and databases. These systems are tiedtogether using mediators; mappings; database views; and transformation scripts. Model-management aims at reducing the amount of programming needed for the development ofsuch integrated applications. We present a first complete prototype of a generic model-management system; in which high-level operators are used to manipulate models andmappings between models. We define the key operators and conceptual structures anddescribe their use and implementation. We examine the solutions for three model-management tasks: change propagation; view reuse; and reintegration.,Web Semantics: Science; Services and Agents on the World Wide Web,2003,49,15
Context-based prefetch for implementing objects on relations,Philip A Bernstein; Shankar Pal; David Shutt,Abstract When implementing persistent objects on a relational database; a majorperformance issue is prefetching data to minimize the number of roundtrips to the database.This is especially hard with navigational applications; since future accesses areunpredictable. We propose using the context in which an object is loaded as a predictor offuture accesses; where context can be a stored collection of relationships; a query result; ora complex object. When an object O's state is loaded; similar state for other objects in O'scontext is prefetched. We present a design for maintaining context and using it to guideprefetch. We give performance measurements of its implementation in Microsoft Repository;showing up to a 70% reduction in running time. We describe variations that selectively applythe technique; exploit asynchronous access; and use application-supplied performance …,VLDB,1999,49,20
Shared log-structured multi-version transactional datastore with metadata to enable melding trees,*,Architecture that includes an ordered and shared log of indexed transaction recordsrepresented as multi-version data structures of nodes and node pointers. The log is a solemonolithic source of datastore state and is used for enforcing concurrency control. Thearchitecture also includes a transaction processing component that appends transactionrecords to the log from concurrent transactions executing on different processors. Each nodeof a record is assigned a log address.,*,2013,48,20
The beckman report on database research,Daniel Abadi; Rakesh Agrawal; Anastasia Ailamaki; Magdalena Balazinska; Philip A Bernstein; Michael J Carey; Surajit Chaudhuri; Jeffrey Dean; AnHai Doan; Michael J Franklin; Johannes Gehrke; Laura M Haas; Alon Y Halevy; Joseph M Hellerstein; Yannis E Ioannidis; HV Jagadish; Donald Kossmann; Samuel Madden; Sharad Mehrotra; Tova Milo; Jeffrey F Naughton; Raghu Ramakrishnan; Volker Markl; Christopher Olston; Beng Chin Ooi; Christopher Ré; Dan Suciu; Michael Stonebraker; Todd Walter; Jennifer Widom,Abstract Every few years a group of database researchers meets to discuss the state ofdatabase research; its impact on practice; and important new directions. This reportsummarizes the discussion and conclusions of the eighth such meeting; held October 14-15;2013 in Irvine; California. It observes that Big Data has now become a defining challenge ofour time; and that the database research community is uniquely positioned to address it; withenormous opportunities to make transformative impact. To do so; the report recommendssignificantly more attention to five research areas: scalable big/fast data infrastructures;coping with diversity in the data management landscape; end-to-end processing andunderstanding of data; cloud services; and managing the diverse roles of people in the datalife cycle.,ACM SIGMOD Record,2014,47,15
Interactive schema translation with instance-level mappings,Philip A Bernstein; Sergey Melnik; Peter Mork,Abstract We demonstrate a prototype that translates schemas from a source metamodel (eg;OO; relational; XML) to a target metamodel. The prototype is integrated with Microsoft VisualStudio 2005 to generate relational schemas from an object-oriented design. It has four novelfeatures. First; it produces instance mappings to round-trip the data between the sourceschema and the generated target schema. It compiles the instance mappings into SQL viewsto reassemble the objects stored in relational tables. Second; it offers interactive editing; ie;incremental modifications of the source schema yield incremental modifications of the targetschema. Third; it incorporates a novel mechanism for mapping inheritance hierarchies torelations; which supports all known strategies and their combinations. Fourth; it is integratedwith a commercial product featuring a high-quality user interface. The schema translation …,Proceedings of the 31st international conference on Very large data bases,2005,46,13
The Beckman report on database research,Daniel Abadi; Rakesh Agrawal; Anastasia Ailamaki; Magdalena Balazinska; Philip A Bernstein; Michael J Carey; Surajit Chaudhuri; Surajit Chaudhuri; Jeffrey Dean; AnHai Doan; Michael J Franklin; Johannes Gehrke; Laura M Haas; Alon Y Halevy; Joseph M Hellerstein; Yannis E Ioannidis; HV Jagadish; Donald Kossmann; Samuel Madden; Sharad Mehrotra; Tova Milo; Jeffrey F Naughton; Raghu Ramakrishnan; Volker Markl; Christopher Olston; Beng Chin Ooi; Christopher Ré; Dan Suciu; Michael Stonebraker; Todd Walter; Jennifer Widom,A group of database researchers meets periodically to discuss the state of the field and its keydirections going forward. Past meetings were held in 1989; 6 1990; 11 1995; 12 1996; 101998; 7 2003; 1 and 2008. 2 Continuing this tradition; 28 database researchers and two invitedspeakers met in October 2013 at the Beckman Center on the University of California-Irvine campusfor two days of discussions. The meeting attendees represented a broad cross-section ofinterests; affiliations; seniority; and geography. Attendance was capped at 30 so the meetingwould be as interactive as possible. This article summarizes the conclusions from thatmeeting; an extended report and participant presentations are available at http://beckman.cs.wisc.edu … The meeting participants quickly converged on big data as a defining challengeof our time. Big data arose due to the confluence of three major trends. First; it has …,Communications of the ACM,2016,45,14
The local relational model: Model and proof theory,Luciano Serafini; Fausto Giunchiglia; John Mylopoulos; Philip A Bernstein,In this paper we identify desirable data management mechanisms for peer-to-peer (P2P)computing. P2P networks have to remain open and dynamic; while peers remainautonomous and need only be aware of their immediate acquaintances. In such a setting;we argue that one cannot assume the existence of a global schema for all the peerdatabases. Instead; one needs a data model which views the space of data being managedwithin the P2P network as an open collection of possibly overlapping and inconsistentdatabases. Accordingly; the paper proposes the Local Relational Model and others a formalsemantics for coordination between peer databases. Our result generalizes Reiter'scharacterization of a relational database in terms of a first order theory; by providing asyntactic characterization of a relational space in terms of a multicontext system.,*,2001,42,15
Normalization and functional dependencies in the relational data base model.,Philip Alan Bernstein,*,*,1975,42
Orleans: Distributed virtual actors for programmability and scalability,Philip A Bernstein; Sergey Bykov; Alan Geller; Gabriel Kliot; Jorgen Thelin,Abstract High-scale interactive services demand high throughput with low latency and highavailability; difficult goals to meet with the traditional stateless 3-tier architecture. The actormodel makes it natural to build a stateful middle tier and achieve the required performance.However; the popular actor model platforms still pass many distributed systems problems tothe developers. The Orleans programming model introduces the novel abstraction of virtualactors that solves a number of the complex distributed systems problems; such as reliabilityand distributed resource management; liberating the developers from dealing with thoseconcerns. At the same time; the Orleans runtime enables applications to attain highperformance; reliability and scalability. This paper presents the design principles behindOrleans and demonstrates how Orleans achieves a simple programming model that …,MSR-TR-2014–41,2014,40,20
HAMSTER: using search clicklogs for schema and taxonomy matching,Arnab Nandi; Philip A Bernstein,Abstract We address the problem of unsupervised matching of schema information from alarge number of data sources into the schema of a data warehouse. The matching process isthe first step of a framework to integrate data feeds from third-party data providers into astructured-search engine's data warehouse. Our experiments show that traditional schema-based and instance-based schema matching methods fall short. We propose a newtechnique based on the search engine's clicklogs. Two schema elements are matched if thedistribution of keyword queries that cause click-throughs on their instances are similar. Wepresent experiments on large commercial datasets that show the new technique has muchbetter accuracy than traditional techniques.,Proceedings of the VLDB Endowment,2009,40,0
A simplification algorithm for integrity assertions and concrete views,Philip A Bernstein; Barbara T Blaustein,*,Proc. COMPSAC,1981,38
Approaches to concurrency control in distributed data base systems,Philip A Bernstein; Nathan Goodman,Whenever multiple users or programs access a data base concurrently; the problem ofconcurrency control arises. The problem is to synchronize concurrent interactions so thateach reads consistent data from the data base; writes consistent data; and is ultimatelyprocessed to completion. In a distributed data base this problem is exacerbated because aconcurrency control mechanism at one site cannot instantaneously know about interactionsat other sites. No fewer than 30 papers on this topic have appeared to date. Our purpose isto survey this literature; concentrating on three approaches-locking; majority consensus; andSDD-I protocols-which together subsume the bulk of the literature.**,Proc. AFIPS,1979,37,10
Versions and workspaces in an object repository,*,Maintaining versions and workspaces in an object repository is disclosed. The systemprovides an efficient way to manage versions of objects by only copying objects whenabsolutely necessary; ie when a property value in a particular object has changed. Inaddition; the system provides a mechanism to control whether or not relationships arepropagated to successor versions of an object. A further aspect of the system is thatresolution of objects during a relationship traversal can be customized depending onwhether or not an application accessing the objects is version-aware. If the application is notversion aware; a means for resolving the relationship to a particular object is provided. A stillfurther aspect of the system is that merge behavior is parameterized. When two versions ofan object are merged; flags control how conflicts in property values and relationship …,*,2005,36,20
Panel: Is generic metadata management feasible?,Philip A Bernstein; Laura M Haas; Matthias Jarke; Erhard Rahm; Gio Wiederhold,The database field has worked on metadata-related problems for 30 years. Examplesinclude data translation and migration; schema evolution; database design;schema/ontology integration; XML wrapper generation; data scrubbing and transformationfor data warehouses; message mapping for e-business; and schema-driven web site design.Tools that address these problems are strikingly similar in their design. Arguably; we aremaking very little progress; since we keep reapplying the same old 1970's techniques ofdata translation [9] and views to one new problem after another; without getting muchleverage from each succeeding step. Despite all the research on the above tools; we haveso far been unable to offer generalpurpose database technology that factors out the similaraspects of these tools into generic database infrastructure.,VLDB,2000,36,15
General purpose schedulers for database systems,Marco A Casanova; Philip A Bernstein,Summary A family of simple models for database systems is defined; where a system iscomposed of a scheduler; a data manager and several user transactions. The basiccorrectness criterion for such systems is taken to be consistency preservation. The centralnotion of the paper is that of a general purpose scheduler; a database system scheduler thatis blind to the semantics of transactions and integrity assertions. Consistency preservation ofa database system is shown to be precisely equivalent to a restriction on the output of ageneral purpose scheduler GPS; called weak serializability. That is; any database systemusing GPS will preserve consistency iff the output of GPS is always weakly serializable. Thisestablishes a tight connection between database system correctness and schedulerbehavior. Also; aspects of restart facilities and predeclared data accesses are discussed …,Acta Informatica,1980,36,19
Meta data management,Philip A Bernstein; Sergey Melnik,By meta data management; we mean techniques for manipulating schemas and schema-like objects (such as interface definitions and web site maps) and mappings between them.Work on meta data problems goes back to at least the early 1970s; when data translationwas the hot database research topic; even before relational databases caught on. Manypopular research problems in the past five years are primarily meta data problems; such asdata warehouse tools (eg; ETL–to extract; transform and load); data integration; the semanticweb; generation of XML or object-oriented wrappers for SQL databases; and generation ofwrappers for web sites. Other classical meta data problems are information resourcemanagement; design tool support and integration; and schema evolution and datamigration. Despite its longevity and continued importance; there is no widely-accepted …,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,35,20
Rethinking eventual consistency,Philip A Bernstein; Sudipto Das,Abstract There has been a resurgence of work on replicated; distributed database systemsto meet the demands of intermittently-connected clients and of disaster-tolerant databasesthat span data centers. Many systems weaken the criteria for replica-consistency or isolation;and in some cases add new mechanisms; to improve partition-tolerance; availability; andperformance. We present a framework for comparing these criteria and mechanisms; to helparchitects navigate through this complex design space.,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,34,20
Selective schema matching,*,A system that automatically matches schema elements is provided. In one aspect; given aselected element of one schema; the system can calculate the best matching candidateelements of another schema. The calculation can be based on a heuristic combination offactors; such as element names; element types; schema structure; existing matches; and thehistory of actions taken by the user. Accordingly; the best candidate (according to thecalculation) can be emphasized and/or highlighted. The tool can auto-scroll to the bestchoice. Similarly; the user can request the calculation and display to best candidates bypressing a keyboard key or hot key. As well; the user can prompt display of the bestcandidates by using the mouse (eg; moving the mouse over the element E or clicking on E);or both (eg; mouse over with hot key depressed).,*,2007,34,10
A multilevel dictionary for model management,Paolo Atzeni; Paolo Cappellari; Philip A Bernstein,Abstract We discuss the main features of a multilevel dictionary based on a metamodelapproach. The application is an implementation of ModelGen; the model managementoperator that translates schemas from one model to another; for example from ER torelational or from XSD to object. The dictionary manages schemas and; at a metalevel; adescription of the models of interest. It describes all models in terms of a limited set ofmetaconstructs. It describes all the schemas in a unifying model; called the supermodel;which generalizes all the others. The dictionary is composed of four parts; based on thecombination of two features: schema level or model level; and model specific or modelgeneric. We also show how such a dictionary can be the basis for a model independentapproach to reporting; that provides a detailed textual and XML description of schemas.,International Conference on Conceptual Modeling,2005,34,0
Analyzing concurrency control algorithms when user and system operations differ,Philip A.  Bernstein; Nathan Goodman; Ming-Yee Lai,Concurrency control algorithms for database systems are usually regarded as methods forsynchronizing Read and Write operations. Such methods are judged to be correct if theyonly produce serializable executions. However; Reads and Writes are sometimes inaccuratemodels of the operations executed by a database system. In such cases; serializability doesnot capture all aspects of concurrency control executions. To capture these aspects; wedescribe a proof schema for analyzing concurrency control correctness. We illustrate theproof schema by presenting two new concurrency algorithms for distributed databasesystems.,IEEE Transactions on Software Engineering,1983,33,0
From science to engineering,Mark Guzdial,CS1 was in a series of studies by Elliot Soloway and his colleagues at Yale University. Theyregularly used the same problem; called “The Rainfall Problem”: Write a program thatrepeatedly reads in positive integers; until it reads the integer 99999. After seeing 99999; itshould print out the average. In one study; only 14% of students in Yale's CS1 could solvethis problem correctly. 9 The Rainfall Problem has been used under test conditions and as atake-home programming assignment; and is typically graded so that syntax errors don'tcount; though adding a negative value or 99999 into the total is an automatic zero. Everystudy that I've seen (the latest in 2009) that has used the Rainfall Problem has found similardismal performance; on a problem that seems amazingly simple. Mike McCracken realizedthe problem with Soloway's studies; or any similar study; could be that a single campus …,Communications of the ACM,2011,32,15
Hadzilacos V; Goodman N,Philip A Bernstein,*,Concurrency Control and Recovery in Database Systems,1987,32
Context-based prefetch–an optimization for implementing objects on relations,Philip A Bernstein; Shankar Pal; David Shutt,Abstract When implementing persistent objects on a relational database; a majorperformance issue is prefetching data to minimize the number of round-trips to the database.This is especially hard with navigational applications; since future accesses areunpredictable. We propose the use of the context in which an object is loaded as a predictorof future accesses; where a context can be a stored collection of relationships; a queryresult; or a complex object. When an object O's state is loaded; similar state for other objectsin O's context is prefetched. We present a design for maintaining context and for using it toguide prefetch. We give performance measurements of its implementation in MicrosoftRepository; showing up to a 70% reduction in running time. We describe several variationsof the optimization: selectively applying the technique based on application and database …,The VLDB Journal—The International Journal on Very Large Data Bases,2000,31,0
Implicit session context system with object state cache,*,An implicit session system with an object state cache. The implicit sessioning avoidsexplicitly passing session parameters in each function call to an object by implicitlyassociating the session context to a session object with each loaded object related to thesession so that each function call runs with the session context of the called object. Theobject state cache minimizes the system resource impact of having multiple instances of anobject in different sessions by sharing one copy of each respective unique object state in anobject state cache.,*,2000,31,10
Concurrency control algorithms for multiversion database systems,Philip A Bernstein; Nathan Goodman,Abstract Concurrency control is the activity of synchronizing operations issued byconcurrently executing programs on a shared database. The goal is to produce an executionthat has the same effect as a serial (noninterleaved) one. In a multiversion database system;each write on a data item produces a new copy (or version) of that data item. This paperpresents a theory for analyzing the correctness of concurrency control algorithms formultiversion database systems. We use the theory to analyze some new algorithms andsome previously published ones.,Proceedings of the first ACM SIGACT-SIGOPS symposium on Principles of distributed computing,1982,31,20
A multi-level architecture for relational data base systems,Hans Albrecht Schmid; Philip A Bernstein,Abstract Most of the literature on implementation of relations has been directed toward userfeatures; with little attention paid to an overall conceptual view of underlying structures.Performance oriented considerations have been treated only for isolated problems. Towarda solution to these problems we describe a multi-level architecture for relational data basesystems. This architecture distinguishes clearly between user oriented features; access pathstructures; data structures and file organization. It also allows efficiency problems to beisolated within levels and solved independently of each other; without impacting the logicalstructure of the user's virtual machine. Specific problems considered here in the context ofthis architecture include the mapping of relations into files; the implementation of fast accesspaths; and some file level optimizations that are particularly useful in relational systems.,Proceedings of the 1st International Conference on Very Large Data Bases,1975,30,20
Transactional record manager,*,Transactional record management methods and systems enabling multiple independentservers (such as database servers) using shared storage to initiate transactions in parallelwithout inter server communication and without locking the records used by the transaction.The in-flight transactions can be included in a shared transaction log without a finaldetermination of whether the transaction committed. The log updates can be broadcast toeach of the servers; which each parse the log; using the same rules of analysis; andtherefore each compute server can independently and asynchronously come to the sameconclusion as to which transactions aborted and which transactions committed.,*,2012,27,10
Prefetching and caching persistent objects,*,Prefetching and caching persistent objects is disclosed. The system creates a structurecontext used to identify a set containing a first object and other related objects. The objectshave attributes; where each attribute is identified by a name. Upon a fetch of an attribute inthe first object; the system also fetches related data. The related data includes otherattributes in the object; and attributes in the other objects of the set having the same name asthe attribute fetched for the first object.,*,2004,27,15
Optimistic concurrency control by melding trees,Colin Reid; Philip A Bernstein; Ming Wu; Xinhao Yuan,ABSTRACT This paper describes a new optimistic concurrency control algorithm for tree-structured data called meld. Each transaction executes on a snapshot of a multiversiondatabase and logs a record with its intended updates. Meld processes log records in logorder on a cached partial-copy of the last committed state to determine whether eachtransaction commits. If so; it merges the transaction's updates into that state. Meld is used inthe Hyder transaction system and enables Hyder to scale out without partitioning. Sincemeld is on the critical path of transaction execution; it must be very fast. The paper describesthe meld algorithm in detail and reports on an evaluation of an implementation. It canperform over 400K update transactions per second for transactions with two operations; and130K for transactions with eight operations.,Proceedings of the VLDB Endowment,2011,26,0
Creating a mediated schema based on initial correspondences,Rachel Pottinger; Philip A.  Bernstein,Video Place; a company that sells videos through its website; has entered a partnership withMovie Reviews; a website that lists movie facts and reviews. Video Place and MovieReviews wish to set up a data integration system to allow both databases to be accessed atonce. Much schema level work is required to do this: a mediated schema must bedeveloped; mappings must be created between the source schemas and the mediatedschema; and a mechanism must be provided for translating queries over the mediatedschema into queries over source schemas. In addition; if Video Place and Movie Reviewswant to change their previous queries to retrieve data from both sources; queries must betranslated from the source schemas to the mediated schema. First; we must create themediated schema. We can reduce the problem of creating the mediated schema to three …,IEEE Data Eng. Bull.,2002,26,20
Third-generation database system manifesto,Michael Stonebraker; Lawrence A Rowe; Bruce Lindsay; James Gray; Michael Carey; Michael Brodie; Philip Bernstein; David Beech,*,Computer Standards & Interfaces,1991,26
Two Part Proof Schema for Database Concurrency Control.,Philip A Bernstein; Nathan Goodman; Ming-Yee Lai,Concurrency control algorithms for database systems are usually regarded as methods forsynchronizing Read and write operations. Such methods are judged to be correct if they onlyproduce serializable executions. However; Reads and Writes are sometimes inaccuratemodels of the operations executed by a database system. In such cases; serializability doesnot capture all aspects of system executions that are relevant to correctness. To capturethese aspects; we describe a two part proof schema for analyzing concurrency controlcorrectness. We illustrate the proof schema by presenting two new concurrency algorithmsfor distributed database systems.,Berkeley Workshop,1981,26,0
A proof technique for concurrency control and recovery algorithms for replicated databases,Philip A Bernstein; Nathan Goodman,Abstract A replicated database is a distributed database in which copies of some data itemsare stored redundantly at multiple sites. In such a system; an execution of transactions iscorrect if it is equivalent to a serial execution of those transactions on a one copy database.We show that in any serializable execution; if all transactions see the failures and recoveriesof data item copies in a consistent order; then the execution is correct. We model thiscondition using a modified type of serialization graph; and show that if this graph is acyclicthen the corresponding execution is correct. We demonstrate the value of this model byusing it to prove the correctness of an algorithm for synchronizing access to a replicateddatabase.,Distributed Computing,1987,25,22
A language facility for designing interactive database-intensive applications,John Mylopoulos; Philip A Bernstein; Harry KT Wong,Abstract This paper describes TAXIS; a language for the design of Interactive InformationSystems (eg; credit card varification; student-course registration and airline reservations).TAXIS offers (relational) database management facilities; a means of specifying semanticintegrity constraints and an exception-handling mechanism; integrated into a singlelanguage through the concepts of class; property and the ISA (generalization) relationship.The paper includes a description of the main constructs of TAXIS and illustrates theirusefulness with examples.,Proceedings of the 1978 ACM SIGMOD international conference on management of data,1978,25,10
The concurrency control mechanism of SDD-1: A system for distributed databases (the general case),Philip A Bernstein; David W Shipman; James B Rothnie; Nathan Goodman,Abstract: SDD-1; a System for Distributed Databases; is a distributed database system beingdeveloped by CCA. SDD-1 permits data to be stored redundantly at several database sitesin order to enhance the reliability and responsiveness of the system and to facilitate upwardsscaling of system capacity. This paper describes the algorithm used by SDD-1 for updatingthat is stored redundantly. Descriptors:* ALGORITHMS;* DATA BASES;* DISTRIBUTEDDATA PROCESSING; COMPUTER ARCHITECTURE; DATA STORAGE SYSTEMS;GRAPHS; INFORMATION RETRIEVAL; INFORMATION SYSTEMS; LOGIC; MESSAGEPROCESSING; MODELS; MODULAR CONSTRUCTION; NETWORKS; READING;REDUNDANCY; RELIABILITY; SYSTEMS ENGINEERING; WRITING,*,1977,25,10
Analysis of Serializability of SDD-1: A System of Distributed Databases (the fully redundant case),Phillip A Bernstein; N Goodman; JB Rothnie; CH Papadimitriou,*,IEEE Transactions on Software Engineering,1978,24
Challenges in precisely aligning models of human anatomy using generic schema matching,M Fieschi,Abstract This paper describes how we used generic schema matching algorithms to alignthe Foundational Model of Anatomy (FMA) and the GALEN Common Reference Model(CRM); two large models of human anatomy. We summarize the generic schema matchingalgorithms we used to identify correspondences. We present sample results that highlightthe similarities and differences between the FMA and the CRM. We also identify uses ofaggregation; transitivity; and reification; for which generic schema matching fails to producean accurate mapping and present manually constructed solutions for them.,Medinfo 2004: Proceedings of the 11th World Congress on Medical Informatics,2004,23,20
Full reducers for relational queries using multi-attribute semi-joins,Philip A Bernstein; Nathan Goodman,*,*,1979,23
Append-based shared persistent storage,*,A shared storage system is described herein that is based on an append-only model ofupdating a storage device to allow multiple computers to access storage with lighter-weightsynchronization than traditional systems and to reduce wear on flash-based storagedevices. Appending data allows multiple computers to write to the same storage devicewithout interference and without synchronization between the computers. Computers canalso safely read a written page without using synchronization because the system limits howdata can be changed once written. The system may record a log of append operationsperformed and ensure idempotence by storing a key specified by the caller in the log alongwith each log entry. The system also provides broadcasts about appended data tocomputers so that coordination between computers can occur without direct …,*,2013,21,15
Challenges and Opportunities with Big Data,Elisa Bertino; Philip Bernstein; Divyakant Agrawal; Susan Davidson; Umeshwas Dayal; Michael Franklin; Johannes Gehrke; Laura Haas; Alon Halevy; Jiawei Han; HV Jadadish; Alexandros Labrinidis; Sam Madden; Yannis Papokonstantinou; Jignesh Patel; Raghu Ramakrishnan; Kenneth Ross; Cyrus Shahabi; Dan Suciu; Shiv Vaithyanathan; Jennifer Widom,Abstract The promise of data-driven decision-making is now being recognized broadly; andthere is growing enthusiasm for the notion of" Big Data". While the promise of Bid Data isreal-for example; it is estimated that Google alone contributed 54 billion dollars to the USeconomy in 2009-there is currently a wide gap between its potential and its realization.,*,2011,21,0
Model management and schema mappings: theory and practice,Philip A Bernstein; Howard Ho,Abstract We present an overview of a tutorial on model management---an approach tosolving data integration problems; such as data warehousing; e-commerce; object-to-relational mapping; schema evolution and enterprise information integration. Modelmanagement defines a small set of operations for manipulating schemas and mappings;such as Match; Compose; Inverse; and Merge. The long-term goal is to build genericimplementations of the operations that can be applied to a wide variety of data integrationproblems.,Proceedings of the 33rd international conference on Very large data bases,2007,21,20
Method and computer program product for implementing object relationships,*,In an interface-based binary object system capable of supporting multiple interfaces intoobjects created by class templates; a relationship is defined as a pair of complementarycollections on two separate interfaces; each interface found on separate objects. A linkbetween objects is formed when an interface of one object lists an object supporting therelated interface included in the object and vice versa. The collections may be of objectssupporting the related interfaces or may be of specific relationship objects leading to objectssupporting the related interfaces. By implementing a specific relationship object; behaviormay be imparted to the relationship itself thereby providing more robust system behavior.Objects thus linked can be easily traversed so that convenient navigation models can beimplemented allowing clients quick access to desired objects by navigating through …,*,2000,21,20
A model for concurrency in nested transactions systems,C Been; PA Bernstein; N Goodman,*,Journal of the ACM,1989,21
On the updatability of network views—extending relational view theory to the network model,Umeshwar Dayal; Philip A Bernstein,Abstract This paper studies the problem of supporting network views. First; an abstraction ofthe existing network data models is introduced. A non-procedural calculus-based languagefor data manipulation and view definition in the network model is described. Then; a functorthat transforms network schema and view extensions; operations and constraints intoequivalent relational ones is defined. This serves as a vehicle for transporting the theory ofview update translation in the relational model to views in the network model.,Information Systems,1982,21,15
The redundant update methodology of SDD-1: A system for distributed databases (The fully redundant case),JB Rothnie; N Goodman; PA Bernstein,*,Computer Corporation of America,1977,21
Comparing two approaches for aligning representations of anatomy,Songmao Zhang; Peter Mork; Olivier Bodenreider; Philip A Bernstein,Summary Objective To analyze the comparison; through their results; of two distinctapproaches applied to aligning two representations of anatomy. Materials Both approachesuse a combination of lexical and structural techniques. In addition; the first approach takesadvantage of domain knowledge; while the second approach treats alignment as a specialcase of schema matching. The same versions of FMA and GALEN were aligned by eachapproach. Two thousand one hundred and ninety-nine concept matches were obtained byboth approaches. Methods and results For matches identified by one approach only (337and 336; respectively); we analyzed the reasons that caused the other approach to fail.Conclusions The first approach could be improved by addressing partial lexical matchesand identifying matches based solely on structural similarity. The second approach may …,Artificial intelligence in medicine,2007,20,16
An algorithmic approach to normalization of relational database schemas,Philip A Bernstein; Catriel Beeri,*,*,1976,20
Optimizing optimistic concurrency control for tree-structured; log-structured databases,Philip A Bernstein; Sudipto Das; Bailu Ding; Markus Pilman,Abstract Scaling-out a database system typically requires partitioning the database acrossmultiple servers. If applications do not partition perfectly; then transactions accessingmultiple partitions end up being distributed; which has well-known scalability challenges. Toaddress them; we describe a high-performance transaction mechanism that uses optimisticconcurrency control on a multi-versioned tree-structured database stored in a shared log.The system scales out by adding servers; without partitioning the database. Our solution ismodeled on the Hyder architecture; published by Bernstein; Reid; and Das at CIDR 2011.We present the design and evaluation of the first full implementation of that architecture. Thecore of the system is a log roll-forward algorithm; called meld; that does optimisticconcurrency control. Meld is inherently sequential and is therefore the main bottleneck …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,18,0
The theory of semi-joins,Philip A Bernstein; Nathan Goodman,*,*,1979,18
The fragmentation problem: Lossless decomposition of relations into files,Umeshwar Dayal; Philip A Bernstein,*,*,1978,18
Teaching a schema translator to produce O/R views,Peter Mork; Philip A Bernstein; Sergey Melnik,Abstract This paper describes a rule-based algorithm to derive a relational schema from anextended entity-relationship model. Our work is based on an approach by Atzeni andTorlone in which the source EER model is imported into a universal metamodel; a series oftransformations are performed to eliminate constructs not appearing in the relationalmetamodel; and the result is exported. Our algorithm includes novel features that areneeded for practical object to relational mapping systems: First; it generates forward-andreverse-views that transform instances of the source model into instances of the target andback again. These views automate the object-to-relational (O/R) mapping. Second; itsupports a flexible mapping of inheritance hierarchies to flat relations that subsumes andextends prior approaches. Third; it propagates incremental updates of the source model …,International Conference on Conceptual Modeling,2007,17,20
The logic of a relational data manipulation language,Marco A Casanova; Philip A Bernstein,Abstract A logic for a relational data manipulation language is defined by augmenting aknown logic of programs with rules for two new statements: the relational assignment; whichassign a relational expression to a relation; and the random tuple selection; which extractsan arbitrary tuple from a relation. The usual operations on relations-retrieve; insert; delete;update-are then defined as special cases of the relational assignment; and the for-eachconstruct scanning a relation tuple by tuple is introduced with the help of the random tupleselection.,Proceedings of the 6th ACM SIGACT-SIGPLAN symposium on Principles of programming languages,1979,17,15
Versions and workspaces in Microsoft repository,Thomas Bergstraesser; Philip A Bernstein; Shankar Pal; David Shutt,Abstract This paper describes the version and workspace features of Microsoft Repository; alayer that implements fine-grained objects and relationships on top of Microsoft SQL Server.It supports branching and merging of versions; delta storage; checkout-checkin; and single-version views for version-unaware applications.,ACM SIGMOD Record,1999,16,0
STDL-a portable language for transaction processing,Philip A Bernstein; Per O Gyllstrom; Tom Wimberg,Note: OCR errors may be found in this Reference List extracted from the full text article. ACMhas opted to expose the complete List rather than only correct and linked references … [3]"Forms Interface Management System;" ISO/IEC DIS 11730; International Organization forStandardization; Dec. 7; 1992 … [8] "Information Processing Systems - Open Systems Interconnection- Distributed Transaction Processing;" (Part 1; Model; ISO/IEC 10026-1:1992; Part 2; ServiceDefinition; ISO/IEC 10026-2:1992; Part 3: Protocol Specification; ISO/IEC 10026-3:1992); InternationalOrganization for Standardization; 1992 … [9] Thomas G. Speer; Mark W. Storm: Digital's TransactionProcessing Monitors. Digital Technical Journal 3(1): 0-(1991) … [10] "Distributed TransactionProcessing: The TxRPC Specification;" X/Open Snapshot; ISB:1-872630-81-2 S218; The X/OpenCompany Ltd.; Reading; UK; Dec. 1992 … [11] "Distributed Transaction Processing …,Proceedings of the 19th International Conference on Very Large Data Bases,1993,16,20
The power of inequality semijoins,Philip A Bernstein; Nathan Goodman,Abstract Semijoin is a relational operator used in many relational query processingalgorithms. Semijoins can be used to “reduce” the database by delimitting portions of thedatabase that contain data relevant to a given query. For some queries; there existsequences of semijoins that delimit the exact portions of the database needed to answer thequery. Such sequences are called full reducers. This paper considers a class of queriescalled natural inequality queries (NI queries); and characterizes a subclass for which fullreducers exist. We also present an efficient algorithm that decides whether an NI query lieswithin this subclass; and constructs a full reducer for the query. The NI queries are a subsetof the aggregate-free; conjunctive queries of QUEL; and permit join clauses toinclude<;⩽;=;⩾;>.,Information Systems,1981,16,0
Mapping XML to a wide sparse table,Liang Jeff Chen; Philip A Bernstein; Peter Carlin; Dimitrije Filipovic; Michael Rys; Nikita Shamgunov; James F Terwilliger; Milos Todic; Sasa Tomasevic; Dragan Tomic,XML is commonly supported by SQL database systems. However; existing mappings of XMLto tables can only deliver satisfactory query performance for limited use cases. In this paper;we propose a novel mapping of XML data into one wide table whose columns are sparselypopulated. This mapping provides good performance for document types and queries thatare observed in enterprise applications but are not supported efficiently by existing work.XML queries are evaluated by translating them into SQL queries over the wide sparsely-populated table. We show how to translate full XPath 1.0 into SQL. Based on thecharacteristics of the new mapping; we present rewriting optimizations that dramaticallyreduce the number of joins. Experiments demonstrate that query evaluation over the newmapping delivers considerable improvements over existing techniques for the target use …,IEEE Transactions on Knowledge and Data Engineering,2014,15,20
Structural text search and comparison using automatically extracted schema,Michael Gubanov; Philip A Bernstein,ABSTRACT An enormous amount of unstructured information is present on the web; inproduct manuals; e-mails; text documents; and other information sources. However; there isnot enough support to automatically infer sufficient structure from these data sources to beable to pose queries comparable in power to SQL.,International Workshop on Web and Databases,2006,15,15
DECdta-Digital's distributed transaction processing architecture,Philip A Bernstein; William T Emberton; Vijay Trehan,Abstract o Atomicity. Either all Digital's Distributed of the transaction's TransactionProcessing operations execute; or Architecture (DECdta) the transaction has no describesthe modules and effect at all. interfaces that are common o Serializability. The set to Digital'stransaction of all operations that processing (DECtp) execute on behalf of the products. Thearchitecture transaction appears to allows easy distribution execute serially with of DECtpproducts. In respect to the set of particular; it supports operations executed by client/serverstyle every other transaction. applications. Distributed o Durability. The effects transactionmanagement is of the transaction's the main function that ties operations are resistantDECdta modules together. to failures. It ensures that application A transaction terminatesprograms; database systems; by executing the commit and other resource managers or …,Digital Technical Journal,1991,15,19
Concept expansion using web tables,Chi Wang; Kaushik Chakrabarti; Yeye He; Kris Ganjam; Zhimin Chen; Philip A Bernstein,Abstract We study the following problem: given the name of an ad-hoc concept as well as afew seed entities belonging to the concept; output all entities belonging to it. Sinceproducing the exact set of entities is hard; we focus on returning a ranked list of entities.Previous approaches either use seed entities as the only input; or inherently requirenegative examples. They suffer from input ambiguity and semantic drift; or are not viableoptions for ad-hoc tail concepts. In this paper; we propose to leverage the millions of tableson the web for this problem. The core technical challenge is to identify the``exclusive''tablesfor a concept to prevent semantic drift; existing holistic ranking techniques like personalizedPageRank are inadequate for this purpose. We develop novel probabilistic ranking methodsthat can model a new type of table-entity relationship. Experiments with real-life concepts …,Proceedings of the 24th International Conference on World Wide Web,2015,14,1
Totally ordered log on appendable storage,*,Computers are provided with a totally ordered; durable shared log. Shared storage is usedand can be directly accessed by the computers over a network. Append-log operations aremade atomic in the face of failures by committing provisional append ordering informationonto a log. The log may comprise multiple flash packages or non-volatile memory devices;referred to as segments; although any shared storage device (s) may be used. Each logrecord is a multi-page stripe; where each page of a stripe is written to a different segment.Fault-tolerant protocol variants append stripes to the log; such that stripes are totally orderedin the log and each stripe is written atomically.,*,2014,14,0
Worry-free database upgrades: automated model-driven evolution of schemas and complex mappings,James F Terwilliger; Philip A Bernstein; Adi Unnithan,Abstract Schema evolution is an unavoidable consequence of the application developmentlifecycle. The two primary schemas in an application; the client conceptual object model andthe persistent database model; must co-evolve or risk quality; stability; and maintainabilityissues. We present MoDEF; an extension to Visual Studio that supports automatic evolutionof object-relational mapping artifacts in the Microsoft Entity Framework. When starting with avalid mapping between client and store; MoDEF translates changes made to a client modelinto incremental changes to the store as an upgrade script; along with a new valid mappingto the new store. MoDEF mines the existing mapping for mapping patterns which MoDEFreuses for new client artifacts.,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,14,10
Prefetching and caching persistent objects,*,Prefetching and caching persistent objects is disclosed. The system creates a structurecontext used to identify a set containing a first object and other related objects. The objectshave attributes; where each attribute is identified by a name. Upon a fetch of an attribute inthe first object; the system also fetches related data. The related data includes otherattributes in the object; and attributes in the other objects of the set having the same name asthe attribute fetched for the first object.,*,2009,14,15
Language-integrated querying of XML data in SQL server,James F Terwilliger; Sergey Melnik; Philip A Bernstein,Abstract Developers need to access persistent XML data programmatically. Object-orientedaccess is often the preferred method. Translating XML data into objects or vice-versa is ahard problem due to the data model mismatch and the difficulty of query translation. Ourprototype addresses this problem by transforming object-based queries and updates intoqueries and updates on XML using declarative mappings between classes and XMLschema types. Our prototype extends the ADO .NET Entity Framework and leverages itsobject-relational mapping capabilities. We demonstrate how a developer can interact withstored relational and XML data using the Language Integrated Query (LINQ) feature of .NET.We show how LINQ queries are translated into a combination of SQL and XQuery. Finally;we illustrate how explicit mappings facilitate data independence upon database …,Proceedings of the VLDB Endowment,2008,14,19
Data Management Issues in Supporting Large-Scale Web Services.,Philip A Bernstein; Nishant Dani; Badriddine Khessib; Ramesh Manne; David Shutt,Abstract This paper discusses technical problems that arise in supporting large-scale 24× 7web services based on experience at MSN with Windows Live TM services. Issues coveredinclude multi-tier architecture; costs of commodity vs. premium servers; managing replicas;managing sessions; use of materialized views; and controlling checkpointing. We finish withsome possible research directions.,IEEE Data Eng. Bull.,2006,14,20
Establishing relationships between objects based on object interfaces,*,In an interface-based binary object system capable of supporting multiple interfaces intoobjects created by class templates; a relationship is defined as a pair of complementarycollections on two separate interfaces; each interface found on separate objects. A linkbetween objects is formed when an interface of one object lists an object supporting therelated interface included in the object and vice versa. The collections may be of objectssupporting the related interfaces or may be of specific relationship objects leading to objectssupporting the related interfaces. The collections are potentially multi-valued entities thatenable relationships to be established between objects according to one-to-one; many-to-one; and many-to-many architectures. By implementing a specific relationship object;behavior may be imparted to the relationship itself thereby providing more robust system …,*,2004,14,20
Comment on “Decomposition of a Data Base and the Theory of Boolean Switching Functions”[Letter to the Editor],Claude Delobel; Richard G.  Casey; Philip A.  Bernstein,Two of the authors of this letter have presented a theorem (Appendix C of [1]; hereinaftercalled “Theorem C”) relating Codd's third normal form for a data collection [2] to the minimumcover for an associated Boolean function. Actually this theorem is incorrect as stated. Thethird author (Bernstein) in his dissertation [3] has produced a counterexample to the theoremand has developed techniques for decomposing a data base into third normal form undergeneral conditions.,IBM Journal of Research and Development,1977,14,10
Concurrency control for confluent trees,*,Architecture that addresses the efficient detection of conflicts and the merging of datastructures such as trees; when possible. The process of detecting conflicts and merging thetrees is a meld operation. Confluent trees offer transactional consistency with some degreeof isolation; and scaling out a concurrent system based on confluent trees can beaccomplished where the meld operation is more efficient than the transaction computations.Transactions execute optimistically using lazily versioned “intention trees” that efficientlydescribe dependencies and effects using structure and content version information for eachintention subtree. The data structure is modified by melding the intention trees in sequence;which causes each transaction to either commit (producing an incremental new version ofthe data structure) or abort (identifying a conflict which prevents the intention tree from …,*,2013,13,0
Automated co-evolution of conceptual models; physical databases; and mappings,James F Terwilliger; Philip A Bernstein; Adi Unnithan,Abstract Schema evolution is an unavoidable consequence of the application developmentlifecycle. The two primary schemas in an application; the conceptual model and thepersistent database model; must co-evolve or risk quality; stability; and maintainabilityissues. We study application-driven scenarios; where the conceptual model changes andthe database and mapping must evolve in kind. We present a technique that; in most cases;allows those evolutions to progress automatically. We treat the mapping as data; and minethat data for patterns. Then; given an incremental change to the conceptual model; we canderive the proper store and mapping changes without user intervention. We characterize thesignificant subset of mappings for which automatic evolution is possible; and present ourtechniques for evolution propagation.,International Conference on Conceptual Modeling,2010,13,15
Relaxed currency constraints,*,The subject invention pertains to transaction processing systems and methodologies thatallows update transactions to read stale data copies and update a data store therewith. Eachtransactional operation; including a read; can carry or be associated with one or morefreshness constraints or tests that specify how fresh a data copy must be in order to be read.More specifically; the subject invention provides systems and methods that extendtransactions and serializability to account for out-of-date reads that are justified by freshnessrequirements.,*,2010,13,0
Atomic transactional execution in hardware: A new high performance abstraction for databases,Ravi Rajwar; Philip A Bernstein,Advances in hardware technology have deep implications on future database systemdesigns [1]. Increasing transistor densities; faster processors; larger memories; and low inter-chip communication latencies have enabled new hardware mechanisms such as processorssupporting speculative execution; large on-chip buffering; and aggressive multiprocessorsystem organizations with cache coherence. As a result; much of the support required toimplement hardware transactions is now either present in modern processors or theirimplementations are well understood. This paper discusses one such proposal. It is basedon a hardware mechanism called Transactional Lock Removal [2](TLR); which wasoriginally designed to support the atomic execution of critical sections by a lock-basedmultithreaded program in a lock-free manner. In this paper; we explain the mechanism …,Position paper for the 10th International Workshop on High Performance Transaction Systems,2003,13,19
A Formal Model of Concurrency Control Mechanisms for Database Systems.,Philip A Bernstein; David W Shipman,*,Berkeley Workshop,1978,13
A semantics for model management operators,Sergey Melnik; Philip A Bernstein; Alon Halevy; Erhard Rahm,Abstract Model management is an approach to simplify the programming of metadata-intensive applications. It offers developers powerful operators; such as Compose; Extract;and Merge; that are applied to models; such as database schemas or interfacespecifications; and to mappings between models. To be used in practice; these operatorsneed to be implemented for particular schema definition languages and mappinglanguages. To guide that implementation; we need a language-independent semantics thattells what the operators should do. In this paper we develop a state-based semantics of theoperators. That is; we express the effect of applying the operators to models in terms of whatthe operators do to instances of these models. We show that our semantics capturespreviouslyproposed desiderata for the operators. We study formal properties of the …,Microsoft Technical Report,2004,11,18
On matching schemas automatically,Philip A Bernstein; Erhard Rahm,*,Microsoft Research,2001,11
Inequality semijoins,PA Bernstein; N Goodman,*,forthcoming CCA report,1979,11
The SDD-1 redundant update algorithm (the general case),PA Bernstein; JB Rothnie; DW Shipman; N Goodman,*,Computer Corp. America; Cambridge; MA; Tech. Rep. CCA-77-09,1977,11
Mapping documents to a relational database table with a document position column,*,Architecture that maps document data (eg; XML-extended markup language) into columns ofone table; thereby avoiding schema normalization problems through special data storage.Moreover; an algorithm is described that can translate a query (eg; in XPath (XML pathlanguage); a query language for navigating through document elements and attributes of anXML document) into a relational algebra query of the document column representation.Based on the characteristics of the new mapping; query rewriting rules are provided thatoptimize the relational algebra query by minimizing the number of joins. The mapping ofXML documents to the table is based on a summary structure and a hierarchical labelingscheme (eg; ordpath) to enable a high-fidelity representation. Annotations are employed onthe summary structure nodes to assist in mapping XML elements and attributes to the …,*,2011,10,1
Reverse engineering models from databases to bootstrap application development,Ankit Malpani; Philip A Bernstein; Sergey Melnik; James F Terwilliger,Object-relational mapping systems have become often-used tools to provide applicationaccess to relational databases. In a database-first development scenario; the onus is on thedeveloper to construct a meaningful object layer for the application because shipping tools;as ORM tools only ship database reverse-engineering tools that generate objects with atrivial one-to-one mapping. We built a tool; EdmGen++; that combines pattern-finding rulesfrom conceptual modelling literature with configurable conditions that increase the likelihoodthat found patterns are semantically relevant. EdmGen++ produces a conceptual model withinheritance in Microsoft's Entity Data Model; which Microsoft's Entity Framework uses tosupport an executable object-to-relational mapping. The execution time of EdmGen++ oncustomer databases is reasonable for design-time.,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,10,10
Interactive schema translation with instance-level mapping,*,A system and method facilitating data access operations is provided. The system canfacilitate an executable; instance-level interaction between a source model (eg; schema)expressed in a first metamodel (eg; object-oriented metamodel) and a target modelexpressed in a second metamodel (eg; SQL metamodel). The system can produce instancemappings to round-trip the data between the source schema and the generated targetschema. Further; an abstraction component can be employed to translate the data accessoperations on the object model into SQL queries and updates.,*,2009,10,20
Model management engine for data integration with reverse-engineering support,Michael N Gubanov; Philip A Bernstein; Alexander Moshchuk,Model management is a high-level programming language designed to efficientlymanipulate schemas and mappings. It is comprised of robust operators that combined inshort programs can solve complex metadata-oriented problems in a compact way. Forinstance; countless enterprise data integration scenarios can be easily expressed in thishigh-level language thus saving hundreds of development man-hours. Here we present thefirst model management engine that has reverse-engineering support for data integration;which is one of the most pressing metadata-oriented problems. It merges two schemasbased on the mappings between them and allows user to correct the result keeping all themappings in sync automatically. For user it is much more convenient than determining whichmappings to correct in order to get desired result. In addition; the engine supports …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,10,0
Guest editorial: Special issue on meta-modelling and methodology engineering,Kalle Lyytinen; Richard Welke,*,*,1999,10
Middleware: An archictecture: for distributed system services,PA Bernstein,*,DEC Cambridge Research Lab report CRL,1993,10
Mapping XSD to OO schemas,Suad Alagić; Philip A Bernstein,Abstract This paper presents algorithms that make it possible to process XML data thatconforms to XML Schema (XSD) in a mainstream object-oriented programming language.These algorithms are based on our object-oriented view of the core of XSD. The novelty ofthis view is that it is intellectually manageable for object-oriented programmers while stillcapturing the complexity of the core structural properties of XSD. This paper develops twomappings based on this view. The first one is specified by a set of rules that map a sourceXSD schema into its object-oriented schema. The second one maps XML instances thatconform to an XSD schema to their representation as objects. In addition to mappingelements and attributes; these mappings reflect correctly the particle structures includingdifferent types of groups; and type derivation by restriction and extension. The structural …,International Conference on Object Databases,2009,9,20
Processing queries and merging schemas in support of data integration,Rachel Amanda Pottinger; Philip A Bernstein; Alon Y Halevy,In Chapter 1; we motivated the problem of answering queries using views as a method forreformulating queries asked in a Local-As-View (LAV) data integration system. In thischapter; we assume that a data integration system has been set up using LAV as themapping language between the mediated schema and the data sources; and focus on howto translate user queries into queries over the data sources using a technique calledanswering queries using views (aka rewriting queries using views). We defined answeringqueries using views in Chapter 2; both for finding equivalent rewritings (Definition 2.4) inquery optimization of physical data independence and for data integration where the goal isto find maximally-contained rewritings (Definition 2.8). While the problem is NP-Complete inthe number of subgoals of the query; the number of query subgoals is generally quite …,*,2004,9,20
PLoS Biology—we're open,Philip Bernstein; Barbara Cohen; Catriona MacCallum; Hemai Parthasarathy; Mark Patterson; Vivian Siegel,One could argue whether scientists need more journals; but we believe there is a global needfor greater access to scientific and medical information and that open-access journals can meetthis need by removing subscription barriers to the written scientific record. As professionaleditors; each of us entered the publishing world from the research community with the desireto promote the effective communication and dissemination of science. Offered the opportunityto help spark the transition to open-access publishing by creating an open-access journal thatwould compete successfully with the most prestigious existing journals; we jumped at thechance … What you see in this issue is the result of a collaborative effort among thefounders; the journal's editorial board; and its professional editors. A glance at the table of contentsand the list of outstanding scientists on our editorial board will give you a sense for the …,PLoS biology,2003,9,12
A survey of techniques for synchronization and recovery in decentralized computer systems,PA Bernstein; N Goodman,*,ACM Computing Surveys,1981,9
A Taxonomy of Partitioned Replicated Cloud-based Database Systems.,Divy Agrawal; Amr El Abbadi; Kenneth Salem,Abstract The advent of the cloud computing paradigm has given rise to many innovative andnovel proposals for managing large-scale; fault-tolerant and highly available datamanagement systems. This paper proposes a taxonomy of large scale partitioned replicatedtransactional databases with the goal of providing a principled understanding of the growingspace of scalable and highly available database systems. The taxonomy is based on therelationship between transaction management and replica management. We illustratespecific instances of the taxonomy using several recent partitioned replicated databasesystems.,IEEE Data Eng. Bull.,2015,8,10
Incremental compilation of object-to-relational mappings,*,Aspects of the subject matter described herein relate to incrementally modifying schemasand mappings. In aspects; an indication of a change to a client schema is received and acompilation directive is received. The compilation directive may indicate how one or moreentities or associations in the client schema are to be mapped to the store schema. Inresponse to receiving the indication of the change and the compilation directive; mappingdata and storage schema may be incrementally modified with incremental revalidation andincremental updating of query and update views.,*,2012,8,20
RRENCY CONTROL AND RECOVERY IN DATABASE SYSTEMS,Philip A Bernstein; Vassos Hadzilacos; Nathan Goodman,For over 20 years; businesses have been moving their data processing activities on-line.Many businesses; such as airlines and banks; are no longer able to function when their on-line computer systems are down. Their on-line databases must be up-to-date and correct atall times. In part; the requirement for correctness and reliability is the burden of theapplication programming staff. They write the application programs that perform thebusiness's basic functions: make a deposit or withdrawal; reserve a seat or purchase aticket; buy or sell a security; etc. Each of these programs is designed and tested to performits function correctly. However; even the most carefully implemented application program isvulnerable to certain errors that are beyond its control. These potential errors arise from twosources: concurrency and failures.,*,1987,8,20
Laying phantoms to rest,Philip A Bernstein; Nathan Goodman; Ming-Yee Lai,*,Proc. 5th IEEE International Computer Software and Application Conference,1981,8
Computational problems related to the design of normal form relational schemes,C Berri; PA Bernstein,*,ACM Trans. Database Syst,1979,8
zilakos and V. Goodman,PA Bernstein; V Ha,*,Concurrency Control and Recovery in Database Systems,*,8
Full-fidelity flexible object-oriented XML access,James F Terwilliger; Philip A Bernstein; Sergey Melnik,Abstract Developers need to programmatically access persistent XML data. Object-orientedaccess is often the preferred method. Translating XML data into objects or vice-versa is ahard problem due to the data model mismatch and the difficulty of query translation. Wepropose a framework that addresses this problem by transforming object-based queries andupdates into queries and updates on XML using flexible; declarative mappings betweenclasses and XML schema types. The same mappings are used to shred XML fragments fromquery results into client-side objects. Information in the XML store that is not mapped usingthe mapping language; such as comments and processing instructions; are also madeavailable in the object representation.,Proceedings of the VLDB Endowment,2009,7,0
Paper and proposal reviews: is the process flawed?,Henry F Korth; Philip A Bernstein; Mary Fernandez; Le Gruenwald; Phokion G Kolaitis; Kathryn McKinley; Tamer Ozsu,Abstract At the 2008 Computing Research Association Conference at Snowbird; the authorsparticipated in a panel addressing the issue of paper and proposal reviews. This short papersummarizes the panelists' presentations and audience commentary. It concludes with someobservations and suggestions on how we might address this issue in the near-term future.,ACM SIGMOD Record,2008,7,0
An apples-to-apples comparison of two database journals,Philip A Bernstein; Elisa Bertino; Andreas Heuer; Christian S Jensen; Holger Meyer; M Tamer Özsu; Richard T Snodgrass; Kyu-Young Whang,The editors of TODS and The VLDB Journal have col- laborated to generate historical data basedon common definitions of relevant metrics. The data reported here was first presented; in preliminaryform; at a VLDB panel [1]. This data has been updated in the intervening time to fix inconsistenciesand improve clarity. We found this to be a useful process; as the underly- ing data was cleanedand as we were able to observe some trends in metrics that had never before beencomputed. Additionally; we feel that such historical data is important for the community;authors; editors; and readers alike. The most recent data on manuscript processing times andrates is of interest to potential authors; some of the met- rics are of interest to readers in judgingthe timeliness of the material published by the journal; and the historical trends are of interestto the database community at large; as it helps us to understand how scientific publishing …,ACM SIGMOD Record,2005,7,1
Database publication practices,Philip A Bernstein; David DeWitt; Andreas Heuer; Zachary Ives; Christian S Jensen; Holger Meyer; M Tamer Özsu; Richard T Snodgrass; Kyu-Young Whang; Jennifer Widom,Abstract There has been a growing interest in improving the publication processes fordatabase research papers. This panel reports on recent changes in those processes andpresents an initial cut at historical data for the VLDB Journal and ACM Transactions onDatabase Systems.,Proceedings of the 31st international conference on Very large data bases,2005,7,15
Third-generation database system manifesto,Michael Stonebraker; Lawrence A Rowe; Bruce Lindsay; James Gray; Michael Carey; Michael Brodie; Philip Bernstein; David Beech,Google; Inc. (search). SIGN IN SIGN UP. Third-generation database system manifesto. Authors:Michael Stonebraker; Lawrence A. Rowe; Bruce Lindsay; James Gray;,Readings in database systems (2nd ed.),1994,7,14
Vassos Hadzilacos; and Nathan Goodman,Philip A Bernstein,*,Concurrency control and recovery in database systems,*,7
Automating evolution of schemas and mappings,*,Aspects of the subject matter described herein relate to automating evolution of schemasand mappings. In aspects; mappings between a conceptual model and a store model areupdated automatically in response to a change that occurs to the conceptual model. Forexample; when a change occurs to the conceptual model; a local scope of the change isdetermined. The local scope indicates mappings that are most similar to the type (s) affectedby the change. Based on the local scope; a pattern of mappings between the conceptualmodel and the store model is determined. Using this pattern and the nature of the change;the mappings are updated according to the pattern. In addition; the store model and datathereon may be updated in a manner to preserve existing data that is not to be deleted inresponse to the change.,*,2013,6,23
Discovering Structure in a Corpus of Schemas.,Alon Y Halevy; Jayant Madhavan; Philip A Bernstein,Abstract This paper describes a research program that exploits a large corpus of databaseschemas; possibly with associated data and meta-data; to build tools that facilitate thecreation; querying and sharing of structured data. The key insight is that given a largecorpus; we can discover patterns concerning how designers create structures forrepresenting domains. Given these patterns; we can more easily map between disparatestructures or propose structures that are appropriate for a given domain. We describe thefirst application of our approach to the problem of semi-automatic schema matching.,IEEE Data Eng. Bull.,2003,6,0
The Logic of a Data Manipulation Language,MA Casanova; PA Bernstein,*,Conference Record of the Sixth Annual ACM Symposium on Principles of Programming Languages (San Antonio; Texas); ACM; New York,1979,6
The Oregon Report Data-Base Systems,S Bing Yao; Stewart A Schuster; Philip A Bernstein; David W Shipman; Nathan Goodman; Diane CP Smith,Early in the history of computer systems; business recognized that computers could lowerthe cost and improve the accuracy of business data processing. The first attemptsatcomputerized data processing used sequential files stored on magnetic tapes. Butto'fullyexploit the potential of computers in data processing; it became necessary to accessdatadirectly; without following a predefined sequence. This was partly achieved by hardwareadvances-in particular; the development of disk technology-and partly by software'ad-vances; such as the development of indexing and other content-based access methods. Inthe 50's and 60's these software methods were incorporated into packages called filesystems. File systems serve as an interface between application programs and stored data;permitting data to be accessed without concern for device-related details. File …,Computer,1978,6,10
Comment on segment synthesis in logical data base design,Philip A Bernstein; CP Wang; HH Wedekind,Note: OCR errors may be found in this Reference List extracted from the full text article. ACMhas opted to expose the complete List rather than only correct and linked references … CPWang and HH Wedekind; "Segment Synthesis in Logical Data Base Design;" IBM J. Res.Develop. 19; 71 (1975) … EF Codd; "Further Normalization of the Data Base RelationalModel;" in Data Base Systems; Courant Computer Sciences Science Symposium 6;Prentice-Hall Publishing Co.; Inc.; Englewood Cliffs; NJ; 1972; pp. 33-64 … PA Bernstein; "Normalizationand Functional Dependencies in the Relational Data Base Model;" Technical Report No. 60;Computer Systems Research Group; Univ. of Toronto; Canada; October 1975.,IBM Journal of Research and Development,1976,6,0
Developing cloud services using the orleans virtual actor model,Philip A Bernstein; Sergey Bykov,Orleans provides a straightforward approach to building distributed interactive applicationsfor the Cloud; without having to learn complex programming patterns for handlingconcurrency; fault tolerance; and resource management. Orleans was made available asopen source in January 2015.,IEEE Internet Computing,2016,5,15
Scaling Optimistic Concurrency Control by Approximately Partitioning the Certifier and Log.,Philip A Bernstein; Sudipto Das,Abstract In optimistic concurrency control; a certifier algorithm processes a log of transactionoperations to determine whether each transaction satisfies a given isolation level andtherefore should commit or abort. This logging and certification of transactions is oftensequential and can become a bottleneck. To improve transaction throughput; it is beneficialto parallelize or scale out the certifier and the log. One common technique for suchparallelization is to partition the database. If the database is perfectly partitioned such thattransactions only access data from a single partition; then both the log and the certifier canbe parallelized such that each partition has its own independent log and certifier. However;for many applications; partitioning is only approximate; ie; a transaction can access multiplepartitions. Parallelization using such approximate partitioning requires synchronization …,IEEE Data Eng. Bull.,2015,5,10
Incremental mapping compilation in an object-to-relational mapping system,Philip A Bernstein; Marie Jacob; Jorge Pérez; Guillem Rull; James F Terwilliger,Abstract In an object-to-relational mapping system (ORM); mapping expressions explainhow to expose relational data as objects and how to store objects in tables. If mappings aresufficiently expressive; then it is possible to define lossy mappings. If a user updates anobject; stores it in the database based on a lossy mapping; and then retrieves the objectfrom the database; the user might get a different result than the updated state of the object;that is; the mapping might not" roundtrip." To avoid this; the ORM should validate that user-defined mappings roundtrip the data. However; this problem is NP-hard; so mappingvalidation can be very slow for large or complex mappings. We circumvent this problem bydeveloping an incremental compiler for OR mappings. Given a validated mapping; amodification to the object schema is compiled into incremental modifications of the …,proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,5,0
Full-fidelity representation of xml-represented objects,*,A data structure may exist in various representations; such as an object in an object-orientedsystem or a set of elements included in an extensible markup language (XML) documentstructured according to an XML type defined in an XML schema. While many aspects ofthese representations may correspond; some aspects of an XML document may not bespecified by the XML schema (such as developer comments; whitespace; and preprocessordirectives); and may be lost while translating an XML representation of the data structure toan object. These non-schematized aspects may be included in the object as a delta;specifying the location of an aspect with relation to an element defined by the XML schema.Preserving non-schematized aspects may promote the full representation of the datastructure as an object; and may facilitate a full-fidelity regeneration of the XML document …,*,2011,5,10
Technology and data-intensive science in the beginning of the 21st century,Philip A Bernstein; Dave Wecker; Ashok Krishnamurthy; Dinesh Manocha; Jeffrey Gardner; Natali Kolker; Chance Reschke; Jesse Stombaugh; Pamela Vagata; Elizabeth Stewart; Dean Welch; Eugene Kolker,Abstract This article is a summary of the technology issues and challenges of data-intensivescience and cloud computing as discussed in the Data-Intensive Science (DIS) workshop inSeattle; September 19–20; 2010.,Omics: a journal of integrative biology,2011,5,0
Schema Matching Using Clicklogs,*,Techniques described herein describe a schema and taxonomy matching process that usesclicklogs to map a schema for source data to a schema for target data. A search engine mayreceive source data that is structured using the source schema; and the search engine itselfmay contain target data structured using the target schema. Using query distributionsderived from the clicklogs; the source schema may be mapped to the target schema. Themapping can be used to integrate the source data into the target data and to index theintegrated data for a search engine.,*,2010,5,15
Sequoia: A fault-tolerant tightly-coupled computer for transaction processing,Philip A Bernstein,*,*,1985,5
The redundant update algorithm of SDD-1: A System for Distributed Databases (the fully redundant case),JB Rothnie; N Goodman; PA Bernstein,*,Phoc. lst Int. Conf Comput. Software and Applications (COMPSAC'77); IEEE Comput. Soc.; Chicago IL,1977,5
Object-oriented constraints for XML schema,Suad Alagić; Philip A Bernstein; Ruchi Jairath,Abstract This paper presents an object-oriented representation of the core structural andconstraint-related features of XML Schema. The structural features are represented withinthe limitations of object-oriented type systems including particles (elements and groups) andtype hierarchies (simple and complex types and type derivations). The applicability of thedeveloped representation is demonstrated through a collection of complex object-orientedqueries. The main novelty is that features of XML Schema that are not expressible in object-oriented type systems such as range constraints; keys and referential integrity; and typederivation by restriction are specified in an object-oriented assertion language Spec#. Anassertion language overcomes major problems in the object-oriented/XML mismatch. Itallows specification of schema integrity constraints and transactions that are required to …,International Conference on Object and Databases,2010,4,10
System and method for composition of mappings given by dependencies,*,A system that facilitates composition of schema mappings. A general algorithm is providedfor composing a broad class of mappings; where one or both mappings are not functions;such as constraints between two schemas and the inverse of functions. A compositioncomponent performs composition on schema mappings of disparate data sources; whichschema mappings can be expressed by at least one of full; embedded; and second-orderdependencies; wherein the second-order dependencies need not be in source-to-targetform. The algorithm for composition further includes a procedure that tests whether thecomposition algorithm will terminate.,*,2009,4,14
Associativity and commutativity in generic merge,Rachel Pottinger; Philip A Bernstein,Abstract A model is a formal description of a complex application artifact; such as a databaseschema; an application interface; a UML model; an ontology; or a message format. Theproblem of merging such models lies at the core of many meta data applications; such asview integration; mediated schema creation for data integration; and ontology merging. Thispaper examines the problem of merging two models given correspondences between them.In particular it concentrates on the associativity and commutativity of Merge; which arecrucial properties if Merge is to be composed with other operators.,*,2009,4,20
An object-oriented core for XML Schema,Suad Alagic; P Bernstein,*,*,2008,4
The many roles of meta data in data integration,Philip A Bernstein,1. USER'S VIEWPOINT From a database system engine viewpoint; data integration is the problemof processing queries against mediated schemas; where each mediated schema is mappedto a set of data sources. From a user's viewpoint; data integration problems focus more on thedevelopment and management of the mappings that feed the query processing view. Data integrationis a very large fraction of the work in information technology (IT) departments in largeenterprises. Based on anecdotal information from users and vendors; data integration appearsto comprise at least half of the work done by software engineers in IT departments today. Someof the main data integration activities are the following: • Data warehousing – developingextraction; transformation and loading (ETL) programs to load a data warehouse. • Lineage tracing– integrating ETL tools and data transforma- tion applications to show the sequence of …,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,4,20
Rethinking the conference reviewing process,Michael J Franklin; Jennifer Widom; Anastassia Ailamaki; Philip A Bernstein; David DeWitt; Alon Halevy; Zachary Ives; Gerhard Weikum,In recent years the database research community has endeavored to expand the scope ofthe field and attract a larger and more varied base of participants. We have also long workedat “educating” academic tenure committees and research management about theimportance of our major conferences. We may now be seeing some unintended effects ofour success. There is a growing dissatisfaction with conference reviewing from all sides ofthe process. Many now perceive the process to be" broken". A number of factors can beidentified as precipitating the discontent:• The number of submitted papers has spikeddramatically in recent years (see Figure 1).,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,4,0
Rondo: A Programming Platform for Generic Model Management,Philip A Bernstein; Sergey Melnik; Erhard Rahm,ABSTRACT Model management aims at reducing the amount of programming needed forthe development of metadata-intensive applications. We present a first complete prototype ofa generic modelmanagement system; in which high-level operators are used to manipulatemodels and mappings between models. We define the key conceptual structures: models;morphisms; and selectors; and describe their use and implementation. We specify thesemantics of the known model-management operators applied to these structures andsuggest several new generic operators. Also; we develop new algorithms for implementingthe individual operators. We examine the solutions for two model-management tasks thatinvolve manipulations of relational schemas; XML schemas; and SQL views.,Proceedings of the ACM SIGMOD International Conference on Management of Data; San Diego; California; USA,2003,4,3
V; Hadzilacos and N,PA Bernstein; A Philip,*,G oodm an. Concurrency Controland Recovery in D atabase System sA ddison-W esley,1987,4
Distributed database management,James B Rothnie,*,Proceedings of the fourth international conference on Very Large Data Bases-Volume 4,1978,4
A Preliminary Specification of TAXIS: A Language for Designing Interactive Information Systems,John Mylopoulos; Harry Kwing Tong Wong; Philip A Berstein,*,*,1978,4
Geo-distribution of actor-based services,Philip A Bernstein; Sebastian Burckhardt; Sergey Bykov; Natacha Crooks; Jose M Faleiro; Gabriel Kliot; Alok Kumbhare; Muntasir Raihan Rahman; Vivek Shah; Adriana Szekeres; Jorgen Thelin,Abstract Many service applications use actors as a programming model for the middle tier; tosimplify synchronization; fault-tolerance; and scalability. However; efficient operation of suchactors in multiple; geographically distant datacenters is challenging; due to the very highcommunication latency. Caching and replication are essential to hide latency and exploitlocality; but it is not a priori clear how to combine these techniques with the actorprogramming model. We present Geo; an open-source geo-distributed actor system thatimproves performance by caching actor states in one or more datacenters; yet guaranteesthe existence of a single latest version by virtue of a distributed cache coherence protocol.Geo's programming model supports both volatile and persistent actors; and supportsupdates with a choice of linearizable and eventual consistency. Our evaluation on several …,Proceedings of the ACM on Programming Languages,2017,3,0
Indexing in an Actor-Oriented Database.,Philip A Bernstein; Mohammad Dashti; Tim Kiefer; David Maier,ABSTRACT Many of today's interactive server applications are implemented using actor-oriented programming frameworks. Such applications treat actors as a distributed in-memoryobject-oriented database. However; actor programming frameworks offer few if anydatabase system features; leaving application developers to fend for themselves. It ischallenging to add such features because the design space is different than traditionaldatabase systems. The system must be scalable to a large number of servers; it must workwell with a variety of cloud storage services; and it must integrate smoothly with the actorprogramming model. We present the vision of an actor-oriented database. We then describeone component of such a system; to support indexed actors; focusing especially on details ofthe fault tolerance design. We implemented the indexing component in the Orleans …,CIDR,2017,3,0
Annotating database schemas to help enterprise search,Eli Cortez; Philip A Bernstein; Yeye He; Lev Novik,Abstract In large enterprises; data discovery is a common problem faced by users who needto find relevant information in relational databases. In this scenario; schema annotation is auseful tool to enrich a database schema with descriptive keywords. In this paper; wedemonstrate Barcelos; a system that automatically annotates corporate databases. Unlikeexisting annotation approaches that use Web oriented knowledge bases; Barcelos minesenterprise spreadsheets to find candidate annotations. Our experimental evaluation showsthat Barcelos produces high quality annotations; the top-5 have an average precision of87%.,Proceedings of the VLDB Endowment,2015,3,19
Partitioning optimistic concurrency control and logging,*,Parallel certification of transactions on shared data stored in database partitions included inan approximate database partitioning arrangement may be initiated; based on initiating aplurality of certification algorithm executions in parallel; and providing a sequential certifiereffect. Logging operations associated with a plurality of log partitions configured to storetransaction objects associated with each respective transaction may be initiated; eachrespective database partition included in the approximate database partitioning beingassociated with one or more of the log partitions. A scheduler may assign each of thetransactions to a selected one of the certification algorithm executions.,*,2013,3,20
Implementing an Append-Only Interface for Semiconductor Storage.,Colin W Reid; Philip A Bernstein,Abstract Solid-state disks are currently based on NAND flash and expose a standard diskinterface. To accommodate limitations of the medium; solid-state disk implementations avoidrewriting data in place; instead exposing a logical remapping of the physical storage. Wepresent an alternative way to use flash storage; where an append interface is exposeddirectly to software. We motivate how an append interface could be used by a databasesystem. We describe bit rot and space reclamation in direct-attached logstructured storageand give details of how to implement the interface in a custom controller. We then show howto make append operations idempotent; including how to create a fuzzy pointer to a pagethat has not yet been appended (and therefore whose address is not yet known); how todetect holes in the append sequence; and how to scale out read operations.,IEEE Data Eng. Bull.,2010,3,21
Brief announcement: Flash-log–a high throughput log,Mahesh Balakrishnan; Philip A Bernstein; Dahlia Malkhi; Vijayan Prabhakaran; Colin Reid,Introduction Modern storage solutions; such as non-volatile solid-state devices; offerunprecedented speed of access over high-bandwidth interconnects. An array of flashmemory chips attached directly to a 1-10 GB fiber switch can support up to 100K page writesper second. While no single host can drive such throughput; the combined power of a largegroup of clients; accessing the shared storage over a common interconnect; can utilize thesystem at full capacity.,International Symposium on Distributed Computing,2010,3,13
Distributed Systems,Abraham Bernstein,*,*,2009,3
Scaling out without partitioning,Phil Bernstein; CW Reid,Page 1. Scaling Out Without Partitioning Phil Bernstein & Colin Reid Microsoft Corporation A NovelTransactional Record Manager for Shared Raw Flash © 2009 Microsoft Corporation HPTS 2009October 26; 2009 Page 2. What is Hyder? 2 It's an incubation; ie research project. A software stackfor transactional record management • Stores [key; value] pairs; which are accessed withintransactions • It's a standard interface that underlies all database systems Functionality • Records:Stored [key; value] pairs • Record operations: Insert; Delete; Update; Get record where field =X; Get next • Transactions: Start; Commit; Abort Why build another one? • Make it easier to scaleout for large-scale web services • Exploit technology trends: flash memory; high-speed networksPage 3. Network Scaling Out with Partitioning 3 Internet Database Partition App $ Log Data WebServer App $ $ • Database is partitioned across …,13th Workshop on High Performance Transaction Systems; HPTS,2009,3,20
The lowell database research self-assessment meeting,Serge Abiteboul; R AGRAWAL; P BERNSTEIN,*,Communication of ACM: The Lowell Database Research Self-Assessment Meeting. New York: ACM Press,2005,3
Data management for peer-to-peer computing: A vision,Philip Bernstein Fausto; Philip A Bernstein; Fausto Giunchiglia; Anastasios Kementsietsidis; John Mylopoulos; Luciano Serafini; Ilya Zaihrayeu,Abstract We motivate special database problems introduced by peer-to-peer computing andpropose the Local Relational Model (LRM) to solve some of them. As well; we summarize aformalization of LRM; present an architecture for a prototype implementation; and discussopen research questions.,*,2002,3,10
Synchronizing Shared Memory in the SEQUOIA Fault-Tolerant Multiprocessor,Philip A.  Bernstein,*,IEEE Database Eng. Bull.,1986,3
Laying Phantoms to Rest (by Understanding the Interactions Between Schedulers and Translators in a Database System).,Harvard University. Center for Research in Computing Technology; PA Bernstein; N Goodman; M-Y Lai,*,*,1981,3
Errors in'process synchronization in database systems',Philip A Bernstein; Marco A Casanova; Nathan Goodman,Abstract This paper disproves several results pertaining to database concurrency controlthat are claimed in [8]. The results we disprove are• theorems 3.1; 3.2; 3.6--which claim apolynomial time algorithm for testing whether transaction schedules are serializable; and•theorems 4.2 and 4.7--which claim a necessary and sufficient mechanism for preserving the"weak consistency" of databases. In addition; we demonstrate that the notion of" weakconsistency" introduced in [8] admits database states that are strictly inconsistent.,ACM SIGMOD Record,1981,3,0
On the performance of balanced hashing functions when the keys are not equiprobable,Christos H Papadimitriou; Philip A Bernstein,Abstract The cost (expected number of accesses per retrieval) of hashing functions isexamined without the assumption that it is equally probable for all keys to be present in thetable. It is shown that the obvious strategy—trying to balance the sums of probabilities of thekeys mapped to any given address—may be suboptimal; however; the difference from theexactly optimal distribution cannot be large.,ACM Transactions on Programming Languages and Systems (TOPLAS),1980,3,20
Allocating storage in hierarchical data bases using traces,Philip A.  Bernstein; DC Tsichritzis,Abstract This paper describes a class of methods to allocate a hierarchical (ie treestructured) data base using traces. A trace is an n-tuple of indices;[x (1);…; x (n)]; whichdescribes the unique path from the root of the tree to the node being addressed. That is; onetakes the x (1)-th branch from the root; followed by the (2)-th branch from the next node; etc.until the path is completed. The last node on the path is the one being addressed. Given aset of traces that represent a set of nodes in a tree; the problem is to allocate them efficientlyon a file. We approach the problem by finding ways of mapping n-tuples (ie traces) ontonatural numbers (ie file indices). An allocation scheme is proposed which uses a 1: 1; ontotrace-to-address map and is designed to adapt to a changing distribution of nodes within thetree. The scheme is an attempt to solve the problem of efficiently allocating growing data …,Information Systems,1975,3,18
Allocating storage in hierarchical data bases,Philip A Bernstein; Dionysios C Tsichritzis,*,*,1974,3
Concurrency Control and Recovery in Database Systems. 1987,A Bernstain; V Hadzilacos; N Goodman,*,*,*,3
Getting consensus for data replication: Technical perspective,Philip A Bernstein,Data in a cloud computing system should be highly available. That is; whenever you connectto the system; the data you stored there should be ready to use. The standard mechanism toaccomplish this—data replication—involves maintaining multiple copies of each user'sdata.By itself; replicating data does not solve the problem; because the copy of data that isavailable might be stale. To see why; consider a system that maintains three copies of file x:x 1; x 2; and x 3. Suppose x 1 and x 2 are currently available and x 3 is down. If a programupdates x; the system writes the update to x 1 and x 2; but not to x 3 because it is down. Noproblem; since the system still has two correct copies. Next; suppose x 1 and x 2 fail; andthen x 3 recovers. Now there is a problem. If a user reads x; the best the system can do isreturn the value of x 3. But that copy is stale—it does not have the latest update.,Communications of the ACM,2014,2,10
Query containment in entity SQL,Guillem Rull; Philip A Bernstein; Ivo Garcia dos Santos; Yannis Katsis; Sergey Melnik; Ernest Teniente,Abstract We describe a software architecture we have developed for a constructivecontainment checker of Entity SQL queries defined over extended ER schemas expressed inMicrosoft's Entity Data Model. Our application of interest is compilation of object-to-relationalmappings for Microsoft's ADO .NET Entity Framework; which has been shipping since 2007.The supported language includes several features which have been individually addressedin the past but; to the best of our knowledge; they have not been addressed all at oncebefore. Moreover; when embarking on an implementation; we found no guidance in theliterature on how to modularize the software or apply published algorithms to a commercially-supported language. This paper reports on our experience in addressing these real-worldchallenges.,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,2,10
Incremental mapping compilation in an object-to-relational mapping system (extended version),Philip A Bernstein; Marie Jacob; Jorge Pérez; Guillem Rull; James F Terwilliger,ABSTRACT In an object-to-relational mapping system (ORM); mapping expressions explainhow to expose relational data as objects and how to store objects in tables. If mappings aresufficiently expressive; then it is possible to define lossy mappings. If a user updates anobject; stores it in the database based on a lossy mapping; and then retrieves the objectfrom the database; the user might get a different result than the updated state of the object;that is; the mapping might not “roundtrip." To avoid this; the ORM should validate that user-defined mappings roundtrip the data. However; this problem is NP-hard; so mappingvalidation can be very slow for large or complex mappings. We circumvent this problem bydeveloping an incremental compiler for OR mappings. Given a validated mapping; amodification to the object schema is compiled into incremental modifications of the …,*,2013,2,19
事务处理原理,Philip A Bernstein; Eric Newcomer,*,*,2011,2
Applying generic schema management to bioinformatics,Philip A Bernstein,Data translation—translating data from one format to another Schema evolution—copingwith applications that have revised data format requirements Cataloging—offering raw andprocessed data in a format that other scientists can understand Schema integration—offering database access through a common schema that is mapped to heterogeneousdatabases,OMICS A Journal of Integrative Biology,2003,2,20
E. newcomer 著; 大磯他訳 “トランザクション処理システム入門”,Philip Bernstein,*,*,1998,2
Decomposition of multilevel objects in an object-oriented database,PA Bernstein,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,Proc. European Symposium on research in computer security,1994,2,19
ACM forum,Albert D'Andrea; Carlo Zaniolo; Patrick J Brennan; Francois Bancihon; Philip A Bernstein; Michael Carey; David DeWitt; Ronald Fagin,In his" Forum" letter (Apr. 1992; pp. 16; 18) concerning the article;" Database Systems:Achievements and Opportunities"(Oct. 1991; p. 110); Henry Baker rightly asserts the well-known problems of relational database systems. Notwithstanding; Baker's amusing portrayalof the relational era as the" Dark Ages of commercial data processing" is simply not correct.In fact; future historians may well view relational technology as the primordial soup fromwhich a far superior class of database systems evolved.Despite Baker's failure to includethem with his rather manufacturing-centric views; the relational technology brought forthmany well-acknowledged benefits to the data-processing world at large. Clearly; relationaldatabase systems are being used today by a far wider audience of users than would haveever been possible with CODASYL and hierarchical database systems. And; as Ted …,Communications of the ACM,1992,2,3
Distributed Database Control and Allocation. Volume 1. Frameworks for Understanding Concurrency Control and Recovery Algorithms.,WK Lin; PA Bernstein; N Goodman; J Nolte,Abstract: This is the first of the three volumes of the final technical report for the projectDistributed Database Control and Allocation. This volume describes frameworks forunderstanding concurrency control and recovery algorithms for centralized and distributeddatabase systems. Descriptors:* Algorithms;* Data bases;* Distributed data processing;Control theory; Allocations; Multiple operation; Centralized; Test and evaluation; Reliability(Electronics); Recovery; Requirements; Mathematical analysis,*,1983,2,0
NEWS SECTION,PA Bernstein; C Beeri; J Minker; DJ Rosenkrantz; KC Sevcik; M Yannakakis; Ronald Fagin; Marc H Graham,*,*,1983,2
Distributed database control and allocation,Wente K Lin; Philip A Bernstein; N Goodman; J Nolie,*,Techn. rep./Rome air development center,1983,2
On the Construction of Database Schedulers Based on Conflict-preserving Serializability,Marco Antonio Casanova; Philip A Bernstein,*,*,1981,2
Comments on “Process synchronizaiton in databases systems”,Philip A Bernstein; Marco A Casanova; Nathan Goodman,In a recent paper [4]; Schlageter introduced a formal theory of database concurrency control.Theorems 3.1 and 3.2 of that paper imply that serializability of transaction schedules can betested in polynomial time; contradicting NP-completeness results in [2; 31. The followingcounterexample demonstrates that the results of [4] are in error.,ACM Transactions on Database Systems (TODS),1979,2,20
Tutorial; distributed data base management,Philip A Bernstein; James B Rothnie; David W Shipman,*,*,1978,2
Semantic networks and the design of interactive information systems,John Mylopoulos; H Wong; P Bernstein,*,Proc. of the 2nd National Conf. ofCSCSI,1975,2
The relational data base system OMEGA—August 1975 Progress Report,HA Schmid,*,*,*,2
Distributed components in computing clusters,*,The subject disclosure is directed towards components in different server clusters; eg;comprising software components such as components of a distributed computing system.Components are available for use by distributed computing system applications; yetmanaged by the distributed computing system runtime such that only a single instance canbe activated and exist within communicating (non-partitioned) clusters. Also described isrecovery from a situation in which no longer partitioned clusters each have created the samecomponent.,*,2016,1,6
Managing data with flexible schema,*,The subject matter described herein relates to managing data with flexible schema. Amethod; computer storage medium; and system are provided for managing data with flexibleschema. In one embodiment; the method comprises providing a logical view for logicaltables of a database; and managing mappings between the logical tables and a physicaltable according to predefined mapping constraints; each of the logical tables mapped as apart of the physical table. The mapping constraints at least specify that (i) a logical column inthe logical tables is mapped to at least one physical column in the physical table; and (ii)distinct logical columns in one of the logical tables are mapped to distinct physical columnsin the physical table. As a result; schema evolution may be done with minimized datamigration.,*,2015,1,15
Transactional Middleware Reconsidered.,Philip A Bernstein,Page 1. Transactional Middleware Reconsidered Phil Bernstein Sergey Bykov; Alan Geller;Gabriel Kliot; Jorgen Thelin Microsoft Corporation CIDR 2013; 1/7/13 Copyright © 2013Microsoft Corporation Page 2. Transactional Database Applications • Are hard to build • Havea highly regular structure 2 Page 3. 3 Transactional Application Structure An application systemmust coordinate the flow of requests between message sources and apps that run requestsas transactions. Web Server Request Controller Transaction Server Transaction Server intranetOther intranet systems Database System Database System Queues Other Internet Sites Page4. Application Server Architecture • Transactional middleware simplifies app development –Defines common app system structure – Adds missing platform features • 1970s – 1980s: RPC;multithreaded processes; session pooling …,CIDR,2013,1,19
A call for surveys,Philip A Bernstein; Christian S Jensen; Kian-Lee Tan,Abstract: The database field is experiencing an increasing need for survey papers. We callon more researchers to set aside time for this important writing activity. The database field isgrowing in population; scope of topics covered; and the number of papers published. Eachyear; thousands of new papers enter the database research literature. As a result; it hasbecome a daunting task to maintain a basic understanding of more than a few major areasof database technology. Even relatively narrow topics have dozens of papers; making it hardfor...,Sigmod Record,2012,1,20
How best to build web-scale data managers?,Philip A Bernstein; Daniel J Abadi; Michael J Cafarella; Joseph M Hellerstein; Donald Kossmann; Samuel Madden,1. PANEL OVERVIEW Many of the largest database-driven web sites use custom web- scaledata managers (WDMs). On the surface; these WDMs are being applied to problems that arewell-suited for relational database systems. Some examples are the following: • Map-Reduce[5]; Hadoop [7]; and Dryad [9] are used to process queries on large data sets using sequentialscan and aggregation. Hive [8] is a data warehouse built on Hadoop. • Google's Bigtable [3] isused to store a replicated table of rows of semi-structured data. • Amazon's Dynamo [6] is usedto store partitioned; replicated databases of key-value pairs. Cassandra [2] is similar. • Objectcaching systems are used instead of a persistent store; such as memcached [10]; Oracle'sCoherence; and Microsoft's Velocity project … These WDMs have challenging requirementsthat are not met by current relational database products. They need to scale out to …,Proceedings of the VLDB Endowment,2009,1,15
Principles of Transaction Processing; (The Morgan Kaufmann Series in Data Management Systems),Philip A Bernstein; Eric Newcomer,Kaufmann Series in Data Management Systems) principles of transaction processing themorgan kaufmann series in data management systems 2nd edition kindle edition principlesof transaction processing for the systems principles of transaction processing second editionthe morgan kaufmann series in data management Principles of Transaction Processing;Second Edition (The Morgan Kaufmann Series in Data Management Systems):,*,2009,1,20
Repository system engineering,Pillip A Bernstein,Repositories manage metadata. Metadata describes complex artifacts that are the subject offormal design activities; such as business processes; application interfaces; database (DB)schemas; engineering drawings; software configurations;; and document libraries; Demandfor them is growing; fueled by enterprise re-engineenng; integrated CASE; datawarehouse;< and management systems for networks; computer systems; informationresources; documents; web sites; etc. It's hard 10 measure product revenue; becauserepositories; are often embedded in other products; but it's arguably already a billion dollarper year business. It's likely to get a lot bigger. At the core of a repository system is arepository manager—a generic database application that manages metadata. It supportsfunctions for managing changes in the structure of objects: types; relationships; versions …,ACM SIGMOD Record,1996,1,0
Data Engineering,Divy Agrawal; Amr El Abbadi; Kenneth Salem; Manuel Bravo; Nuno Diegues; Jingna Zeng; Paolo Romano; Luıs Rodrigues; Philip A Bernstein; Sudipto Das; Justin Levandoski; Sudipta Sengupta; Ryan Stutsman; Rui Wang; Tudor-Ioan Salomie; Gustavo Alonso; Bettina Kemme; Ivan Brondino; José Pereira; Ricardo Vilaça; Francisco Cruz; Rui Oliveira; Yousuf Ahmad,Members of the Technical Committee on Data Engineering (TCDE) have voted for a newTCDE. The turnout for the election was higher than in past elections; which demonstrates; Ithink; two things. One; past TCDE Chair Kyu-Young Whang's initiative to enlargemembership has resulted in a larger overall TCDE membership; and hence a largerelectorate. Two; we had two strong candidates in Xiaofang Zhou and Erich Neuhold; whichgenerate more interest than in the past. The outcome is that Xiaofang Zhou is the new chairof the TCDE. I want to congratulate Xiaofang on his election victory. I am confident thatXiaofang will be a fine TCDE chair; and I look forward to working with him going forward.Xiaofang's letter as TC Chair appears on page 2 of the current issue. The TCDE Chair is theone empowered to appoint the TCDE Executive Committee. The new committee is shown …,*,1995,1,15
PC Database Systems-Present and Future,Philip A Bernstein,Successful PC DBMSs can fund a similar amount of engineering as traditional server-oriented DBMSs. Thus; PC DBMSs could evolve quickly into powerful; yet easyto-usechallengers to traditional DBMSs. Could a large number of PC DB servers compete withDBMSs designed for larger machines? In the medium-to-long term; what features willdistinguish highend DBMSs? What fraction of DBMS market revenue will they have? Withtens of thousands of DB users managing independent DBs;“heterogeneous distributed DB”takes on a new meaning. There will be Newton size PDAs to glass-house mainframes in thesame transaction. So it won't be a world of cooperating equals. Some DBMSs will be storageproviders. Others will have modest local stores; used mainly for personal files and temporarydata built during a transaction How will this affect transaction management and query …,VLDB,1994,1,15
Database theory: where has it been? where is it going?,Philip A Bernstein,Database theory is the application of mathematical techniques to the solution of problemsrelated to ths design; implementation; and use of database mangement systems. It is not atightly integrated mathematical theory. Rather; it is a'collection of. resul! ts on mult.ifarioustopics that are;; connected loosely or not at all. Some of these topics are data models;views; dependencies; power of query lenwages; dynamic&rage structures; quip opt@ i" xat(on; concurrency control; recover.+; security; and; semantic integrity. The field began'withCodd's insight that relations. a&prqdicate cal&ulus provide a; powerful and easy to useinterface to databases. Codd's application of a math&n+ ical'language and techniques todatabase mandgement are the most impor-'tant contributions to database theory. They gavethe mathematical framework for much of the field. Functional dependencies; also defined …,ACM SIGMOD Record,1983,1,1
Informationssysteme,Volker Burggräf,Sprungmarken. Zum Inhalt springen. Zur Hauptnavigation springen. Zur Unternavigationspringen Web-Impressum der Universität. Carl von Ossietzky Universität Oldenburg FakultätII - Informatik; Wirtschafts- und Rechtswissenschaften Department für Informatik: Stud.IPUni-Login Passwort. Suche/Search. Schnellzugriff: Informatikstartseite; Termine; Abteilungen;Mitarbeiterliste; Beauftragte; Gremien; Rechnerbetrieb (ARBI). Aktuelles: Übersicht; Termine;Aktuelles zum Studium; AbsolventInnenfeier; Stellenausschreibungen; Stipendien undPreise. Informationen für ... Übersicht; Schülerinnen und Schüler; Studieninteressierte;Internationale Studierende; Studierende. Studium & Lehre: Übersicht; Studium aktuell;Studiengänge; Studieren & Forschen; Studium …,*,2017,*,20
Concept expansion using tables,*,Concept expansion using tables; such as web tables; can return entities belonging to aconcept based on an input of the concept and at least one seed entity that belongs to theconcept. A concept expansion frontend can receive the concept and seed entity and providethem to a concept expansion framework. The concept expansion framework can expand thecoverage of entities for concepts; including tail concepts; using tables by leveraging richcontent signals corresponding to concept names. Such content signals can include contentmatching the concept that appear in captions; early headings; page titles; surrounding text;anchor text; and queries for which the page has been clicked. The concept expansionframework can use the structured entities in tables to infer exclusive tables. Such inferencediffers from previous label propagation methods and involves modeling a table-entity …,*,2016,*,0
Automated database schema annotation,*,Techniques and constructs that improve annotating target columns of a target database byperforming automated annotation of the target columns using sources. The techniquesinclude calculating a similarity score between a target column and columns extracted from atable that is included in a source. The similarity score is calculated based at least in part on asimilarity between a value in the target column of the target database and a column value ofthe extracted column from the table and on a similarity between an identity of the targetcolumn of the target database and column identities of the extracted columns from the table.In some examples; the techniques calculate similarity scores for one or more extractedcolumns and annotate the target column based on the similarity scores.,*,2016,*,14
Transactions for Distributed Actors in the Cloud,Tamer Eldeeb; Philip A Bernstein,Abstract—Many cloud-service applications have a middle tier organized as micro-servicesor actors. Such applications have small objects that are spread over many servers andcommunicate via message passing. Transactions in such an application are necessarilydistributed. However; distributed transactions usually perform poorly in this environment;primarily because locks must be held until after the forced-writes of two-phase commit; whichare slow in cloud storage systems. We present a new transaction protocol that avoids thisblocking by releasing all of a transaction's locks during phase one of two-phase commit; andby tracking commit dependencies to implement cascading abort. While a transaction T runsphase one; later conflicting transactions batch their updates. After T is prepared; the delayedbatch can prepare; enabling a distributed form of group commit. We describe how to …,*,2016,*,0
Sliding-window multi-class striping,*,A sequence of storage devices of a data store may include one or more stripesets for storingdata stripes of different lengths and of different types. Each data stripe may be stored in aprefix or other portion of a stripeset. Each data stripe may be identified by an array ofaddresses that identify each page of the data stripe on each included storage device. Whena first storage device of a stripeset becomes full; the stripeset may be shifted by removing thefull storage device from the stripeset; and adding a next storage device of the data store tothe stripeset. A class variable may be associated with storage devices of a stripeset toidentify the type of data that the stripeset can store. The class variable may be increased (orotherwise modified) when a computer stores data of a different class in the stripeset.,*,2016,*,0
Mapping and query translation between xml; objects; and relations,*,Described is programmatic access to persistent XML and relational data from applicationsbased upon explicit mappings between object classes; XML schema types; and relations.The mappings are used in data access; that is; they drive query and update processing. Aquery may be processed into a query for accessing the XML data and another query forsecond type for accessing the relational data. Mappings support strongly-typed classes andloosely-typed classes; and may be conditional upon other data; may decouple query andupdate translation performed at runtime from schema translation used at compile time;and/or may be compiled into transformations that produce objects from XML data andtransformations that produce XML data from objects. Mappings may be generatedautomatically or provided by the developer.,*,2016,*,23
Automating evolution of schemas and mappings,*,Aspects of the subject matter described herein relate to automating evolution of schemasand mappings. In aspects; mappings between a conceptual model and a store model areupdated automatically in response to a change that occurs to the conceptual model. Forexample; when a change occurs to the conceptual model; a local scope of the change isdetermined. The local scope indicates mappings that are most similar to the type (s) affectedby the change. Based on the local scope; a pattern of mappings between the conceptualmodel and the store model is determined. Using this pattern and the nature of the change;the mappings are updated according to the pattern. In addition; the store model and datathereon may be updated in a manner to preserve existing data that is not to be deleted inresponse to the change.,*,2015,*,3
2014 Index IEEE Transactions on Knowledge and Data Engineering Vol. 26,A Abboud; S Abraham; CC Aggarwal; A Ahmad; H Aksu; M Al Hasan; Alessia Albanese; Massimiliano Albanese; A Allue; K Amaral; Mehmet Fatih Amasyali; S Amer-Yahia; A An; W Aref; WG Aref; Ana Arruarte; A Arvanitis; N Asadi; L Atzori; Man Ho Au; U Avci; C Aykanat; Javad Azimi; A Badia; B Baesens; He Bai; Sumeet Bajaj; A Bannur; Alberto Bartoli; G Barua; S Barua; Sukarna Barua; D Ben-David; K Benabdeslem; F Benites; PA Bernstein; E Bertino; D Bhattacharjya; SS Bhowmick; MA Bhuiyan; Y Bi; C Bielza; B Biggio; F Bonchi; R Bordawekar; G Brown; J Bu; A Bulut; L Cagliero; Yi Cai; Yilun Cai; Z Cai; Inaki Calvo; M Canim; L Cao; Longbing Cao; V Carlan; P Carlin; J Carmona; C Castillo; Federico Cavalieri,This index covers all technical items-papers; correspondence; reviews; etc.-that appeared inthis periodical during the year; and items from previous years that were commented upon orcorrected in this year. Departments and other items may also be covered if they have beenjudged to have archival value. The Author Index contains the primary entry for each item;listed under the first author's name. The primary entry includes the co-authors' names; thetitle of the paper or other item; and its location; specified by the publication abbreviation;year; month; and inclusive pagination. The Subject Index contains entries describing theitem under all appropriate subject headings; plus the first author's name; the publicationabbreviation; month; and year; and inclusive pages. Note that the item title is found onlyunder the primary entry in the Author Index.,IEEE Transactions on Knowledge and Data Engineering,2015,*,20
Expansion of Tail Concept Using Web Tables,Chi Wang; Kaushik Chakrabarti; Yeye He; Kris Ganjam; Zhimin Chen; Philip A Bernstein,Abstract Human-curated knowledgebases like Freebase and DBPedia cover popularconcepts such as persons; organizations and locations; but many more specific concepts fallinto the long tail outside current knowledgebases; such as acidic fruits; HD video formatsand renewable resources. These concepts are found in conceptentity pairs automaticallyextracted from text documents; but they cover a limited number of entities per concept due toinsufficient mentions in text. In this paper; we propose to expand the coverage of entities fortail concepts using web tables. It is challenging to apply existing techniques because a tailconcept often overlaps many other concepts. Our solution is based on the fact that manyweb tables contain a set of entities all belonging to a fine grained concept. We leverage therich content signals and the structured entities in web tables to infer such exclusive tables …,*,2014,*,19
468 Performance Issues,Philip A Bernstein,Abstract Formal database semantics has concentrated on dependency constraints; such asfunctional and multivalued dependencies; and on normal forms for relations. Unfortunately;much of this work has been inaccessible to researchers outside this field; due to theunfamiliar formalism in which the work is couched. In addition; the lack of a single set ofdefinitions has confused the relationships among certain results. This paper is intended toserve the two-fold purpose of introducing the main issues and theorems of formal databasesemantics to the uninitiated; and to clarify the terminology of the field. l. INTRODUCTION l. 1Database Semantics,Readings in Artificial Intelligence and Databases,2014,*,20
Multiversion Concurrency Control; Theory and Algorithm,Waleed Abrar; PHILIP A BERNSTEIN; NATHAN GOODMAN Harvard,Page 1. Background Multiversion Concurrency Control;Theory and Algorithm Univesity ofKonstanz By Waleed Abrar PHILIP A. BERNSTEIN and NATHAN GOODMAN Harvard UniversityMay 6; 2014 PHILIP A. BERNSTEIN and NATHAN GOODMAN Harvard UniversityMultiversionConcurrency Control;Theory and Algorithm Page 2. Background Todays Agenda …,*,2014,*,10
Technical Perspective Getting Consensus for Data Replication,Philip A Bernstein,DATA IN A cloud computing system should be highly available. That is; whenever you connectto the system; the data you stored there should be ready to use. The standard mechanism toaccomplish this—data replication— involves maintaining multiple copies of each user's data.By itself; replicating data does not solve the problem; because the copy of data that is availablemight be stale. To see why; consider a system that maintains three copies of file x: x1; x2; andx3. Suppose x1 and x2 are currently available and x3 is down. If a program updates x; the systemwrites the update to x1 and x2; but not to x3 because it is down. No problem; since the systemstill has two correct copies. Next; suppose x1 and x2 fail; and then x3 recovers. Now there isa problem. If a user reads x; the best the system can do is return the value of x3. But that copyis stale—it does not have the latest update. An early solution …,Communications of the ACM,2014,*,10
A Renaissance for Analytic Approaches to Computer System Performance Optimization,Philip A Bernstein,*,*,2013,*
A FORMAL MODEL OF CONCURRENCY CONTROL MECfffiNISMS FOR DATABASE SYSTEMS·,Philip A Bernstein; David W Shipman,Abstract In a database system; an arbitrary interleaving of transactions can lead to aninconsistent database state. This spurious behavior can be prevented by a variety ofproposed synchronization mechanisms. To into these and one write operation pertransaction. We show why locking mechanisms lead to correct operation and show that twoproposed mechanisms are actually special cases of locking. We also examine conflict graphanalysis; the method used in the SDD-l distributed database system; we prove itscorrectness; and we show that it is not a locking mechanism.,NIA; K,2011,*,0
Data integration for data-intensive science,Philip A Bernstein,To perform analytic computation on data (scientific or otherwise); there are manypreliminary; time-consuming steps to identify and integrate the relevant inputs. A typicalsequence of steps is the following. Data discovery—Find the data sets that are relevant tothe question at hand. This may involve Web search and networking with other researchers;followed by deeper study to determine whether the data is really appropriate for the intendeduse. Obtain access to data—Determine how to access the data in a desired format. This mayinvolve retrieving the data or enabling the invocation of operations on the data in its homelocation. It may also involve legal issues; such as data ownership and privacy.,Omics: a journal of integrative biology,2011,*,0
PROCEEDINGS OF THE FIFTH BERKELEY WORKSHOP ON DISTRIBUTED DATA MANAGEMENT AND COMPUTER NETWORKS,RR Johnson,LEGAL NOTICE This book was prepared as an account of work sponsored by an agency of theUnited States Government. Neither the lTnited States Govcrn- ment nor any agency thereof; norany of their employees; makes any warranty; express or im- plied; or assumes any legal liabilityor responsibility for the accuracy; completeness; or usefulness of any information; apparatus;product; or process disclosed; or represents that its use would not infringe privately ownedrights. Reference herein to any specific commercial product; process; or service by tradename; trademark; manufacturer; or otherwise; does not necessarily constitute or imply itsendorsement; recommendation; or favor- ing by the United States Government or any agencythereof. The views and opinions of authors ex- pressed herein do not necessarily state or reflectthose of the United States Government or any agency thereof. Printed in the United …,*,2011,*,15
Mapping composition using algebraic operators,*,A general-purpose reusable algebraic-based composition algorithm for composingmappings between data schemas. The algorithm handles more expressive mappings;makes a best-effort to eliminate symbols when a perfect answer cannot be obtained;includes new heuristics; and is extensible. A relational algebraic language is providedwherein each mapping is expressed as a set of constraints; and each constraint is either acontainment or equality of two or more relational algebraic expressions. The compositionmechanism exploits monotonicity properties of algebraic operators in operator arguments;handles NULLs and bag semantics; operates to allow composition to produce a partial resultwhen a complete result is not possible; facilitates symbols elimination one symbol at a timeusing left composition; for example; as a way of isolating the symbols; supports making a …,*,2009,*,0
SQL Isolation Levels,Philip A Bernstein,The values in the relations of a relational database are elements of one or more underlyingsets called domains. In practical applications; a domain may be infinite; eg; the set of naturalnumbers. In this case; the value of a relational calculus query when applied to such adatabase may be infinite; eg;{njn! 10}. A query Q is called finite if the value of Q whenapplied to any database is finite. Even when the database domains are finite; all that isnormally known about them is that they are some finite superset of the values that occur inthe database. In this case; the value of a relational calculus query may depend on such anunknown domain; eg;{xj 8yR (x; y)}. A query Q is called domain independent if the value of Qwhen applied to any database is the same for any two domains containing the databasevalues or; equivalently; if the value of Q when applied to a database contains only values …,*,2009,*,15
HAMSTER: Human Assisted Mapping of Schema & Taxonomies to Enhance Relevance,Arnab Nandi; Philip A Bernstein,ABSTRACT We address the problem of unsupervised matching of schema information froma large number of data sources into the schema of a data warehouse. The matching processis the first step of a framework to integrate data feeds from thirdparty data providers into astructured-search engine's data warehouse. Our experiments show that traditionalschemabased and instance-based schema matching methods fall short. We propose a newtechnique based on the search engine's clicklogs. Two schema elements are matched if thedistribution of keyword queries that cause click-throughs on their instances are similar. Wepresent experiments on large commercial datasets that show the new technique has muchbetter accuracy than traditional techniques.,*,2009,*,20
Library of Congress Cataloging-in-Publication Data,Philip A Bernstein,Transaction processing has been an important software technology for 40 years. Largeenterprises in transportation; finance; retail; telecommunications; manufacturing;government; and the military are utterly dependent on transaction processing applicationsfor electronic reservations; banking; stock exchanges; order processing; music and videoservices; shipment tracking; government services; telephone switching; inventory control;and command and control. Many large hardware and software vendors receive much of theirrevenue from components of transaction processing systems; such as IBM; HP; Oracle;Microsoft; Dell; Red Hat; and EMC. The market for transaction processing products andservices is many tens of billions of dollars per year. As consumers; we all use thistechnology every day to withdraw cash; buy gas; rent movies; and make purchases on the …,*,2009,*,20
Translating Schemas and Data between Metamodels,Peter Mork; Philip A Bernstein; Sergey Melnik,ABSTRACT ModelGen is an operator that automatically translates a source modelexpressed in a source metamodel into an equivalent target model expressed in a differentmetamodel. For example; given an XML schema; ModelGen can automatically generate anequivalent relational schema or Java interface. This paper describes a new algorithm forModelGen with several novel properties. It automatically determines a series oftransformations to generate the target model. It generates forward-and reverse-views thattransform instances of the source model into instances of the target and back again. Itsupports rich mappings of inheritance hierarchies to flat relations. And it supportsincremental modification of a source-to-target mapping. We prove its correctness anddemonstrate its practicality in an implementation.,*,2007,*,20
Relaxed Currency Serializability for Middle-Tier Caching and Replication (extended version),Phil Bernstein; Alan Fekete; Hongfei Guo; Raghu Ramakrishnan; Pradeep Tamma,Abstract Many applications; such as e-commerce; routinely use copies of data that are not insync with the database due to heuristic caching strategies used to enhance performance.We study concurrency control for a transactional model that allows update transactions toread out-of-date copies. Each read operation carries a “freshness constraint” that specifieshow fresh a copy must be in order to be read. We offer a definition of correctness for thismodel and present algorithms to ensure several of the most interesting freshnessconstraints. We outline a serializability-theoretic correctness proof and present the results ofa detailed performance study. This is an extended version of a paper with the same title thatappeared in SIGMOD 2006.,*,2006,*,0
4th International and Interdisciplinary Conference on Modeling and Using Context (CONTEXT 2003),L Serafini; F Giunchiglia; J Mylopoulos; PA Bernstein,E' presente una richiesta di inserimento in ANCE di una nuova rivista; utilizza la funzione "Registracodice ANCE" per registrare il codice ricevuto dal servizio LoginMIUR o inviare una nuova richiestadi inserimento oppure cercare nuovamente la rivista. E' presente una richiesta di inserimentoin ANCE di una nuova serie; utilizza la funzione "Registra codice ANCE" per registrare il codicericevuto dal servizio LoginMIUR o inviare una nuova richiesta di inserimento oppure cercarenuovamente la serie … Segnalazioni con codici 20501/20503/20504: Alcuni dati obbligatoriper il sito CINECA non sono presenti o invalidi; oppure il sito CINECA non è riuscito ad individuareuna rivista con i dati forniti; è necessario controllare la correttezza dell'ISSN e/o EISSN doveapplicabili e il titolo della rivista … Segnalazioni con codici 20201/20202:La pubblicazionenon è stata trasferita SOLO per i docenti segnalati nel messaggio a causa di problemi …,*,2003,*,10
Very large data bases 2002: proceedings of the Twenty-eighth International Conference on Very Large Data Bases; Hong Kong SAR; China; 20-23 August 2002,International Conference on Very Large Data Bases; Philip A Bernstein,*,*,2002,*
Proceedings 2002 VLDB Conference,VLDB.; Philip A Bernstein; Yannis E Ioannidis,*,*,2002,*
Proceedings of the Twenty-eighth International Conference on Very Large Data Bases: Hong Kong SAR; China; 20-23 August 2002. Tutorial Notes,VLDB (28; 2002; Hong Kong); Philip A Bernstein,*,*,2002,*
Proceedings of Very Large Data Bases Conference (VLDB02),Philip Bernstein; Yannis Ioannidis; Raghu Ramakrishnan; Dimitris Papadias,Proceedings of Very Large Data Bases Conference (VLDB02).,*,2002,*,1
Proceedings of the 28th International Conference on Very Large Data Bases,Philip A Bernstein,*,*,2002,*
Topics to be covered,E Rahm; PA Bernstein,∎ Schema integration □ Developing global view over set of independently developed schemas∎ Data warehousing □ Transforming data from source format to warehouse format ∎ E-commerce/ B2B integration □ Transforming between message types and trading partner formats ∎ Semanticquery processing □ Mapping user-specified query concepts to database schema elements …∎ IN: 2 schemas S1 and S2 ∎ OUT: match result – mapping of elements in S1 and S2 … ∎Schema: set of elements connected by some structure … ∎ Mapping element: specification ofelements in S1 that map to elements in S2 and a mapping expression specifying how they arerelated... □ {elements in S1} ~= {elements in S2} : (mapping expression) … ∎ Schema-levelmatchers □ Consider schema information; not instance data □ Mapping expressions on schemaelement name; description; type; constraints; structure; etc. ∎ Instance-level matchers □ …,The VLDB Journal,2001,*,20
Report on the 2001 SIGMOD and PODS Awards,Philip A Bernstein,The Annual SIGMOD and PODS Awards honor important contributors to the database field.The awards are presented at the annual SIGMOD/PODS Conference. For those of you whomissed that presentation at the 2001 conference; this article reports on this year's winners.Congratulations to all of them for these significant achievements. The SIGMOD Innovationsaward is given “For innovative and highly significant contributions of enduring value to thedevelopment; understanding; or use of database systems and databases.” This year'swinner is Prof. Rudolf Bayer of the Technical University of Munich; for his invention of the B-Tree (with Edward McCreight); of B-Tree prefix compression; and of lock coupling (akacrabbing) for concurrent access to B-Trees (with Mario Schkolnick). All of these techniquesare widely used in commercial database products. Prof. Bayer has also made many other …,SIGMOD Record,2001,*,20
ACM SIGMOD Record Volume 29 Issue 2,Weidong Chen; Jeffrey Naughton; Philip A Bernstein,Google; Inc. (search). SIGN IN SIGN UP. ACM SIGMOD Record. Volume 29 Issue 2;June 2000 table of contents. Editors: Weidong Chen; Southern Methodist Univ.; Dallas;TX. Jeffrey Naughton; Univ. of Wisconsin-Madison; Madison.,*,2000,*,20
ISSAC 2000: 7-9 August 2000; University of St. Andrews; Scotland: Proceedings of the 2000 International Symposium on Symbolic and Algebraic Computation,Carlo Traverso; Weidong Chen; Jeffrey F Naughton; Philip A Bernstein,*,*,2000,*
Design Transactions and Serializability,Philip A Bernstein; Phil Bernstein,*,*,1997,*
Digital Equipment Corporation Cambridge Research Lab,Philip A Bernstein; Per O Gyllstrom; Tom Wimberg,STDL relies on standard C and COBOL for most application logic and all operations on SQLdatabases and files. All transactional features of STDL and new features outside standard Cand COBOL are isolated in procedures written in the STDL language. These procedures arecalled tasks. This isolation of transactional features is quite different than other persistentprogramming languages: one can use applications written in standard C or COBOL; and toimplement STDL; it is possible to map clauses of task language onto operations of most anydistributed TP monitor.,*,1993,*,14
MORE ON RELATIONAL DATABASE-SYSTEMS,F BANCILHON; PA BERNSTEIN; M CAREY; D DEWITT; R FAGIN; H GARCIAMOLINA; JN GRAY; D LOMET; A SILBERSCHATZ; JD ULLMAN; G WIEDERHOLD; M ZEMANKOVA,*,COMMUNICATIONS OF THE ACM,1992,*
ACM TODS Publication Policy,Don S.  Batory; Philip A.  Bernstein; Umeshwar Dayal; Laura M.  Haas; Theo Haerder; Won Kim; David Maier; Gerard Salton; Gio Wiederhold,*,SIGMOD Record,1989,*
468 Performance Issues,Catriel Beeri; Philip A Bernstein; Nathan Goodman,*,Readings in artificial intelligence and databases,1989,*
EUGENE WONG,PHILIP A BERNSTEIN; NATHAN GOODMAN,*,Tutorial; recent advances in distributed data base management,1984,*
Distributed Database Control and Allocation. Volume 3. Distributed Database System Designer's Handbook.,WK Lin; PA Bernstein; N Goodman; J Nolte,Abstract: This is the third of three volumes of the final technical report for the projectDistributed Database Control and Allocation. This volume attempts to provide a handbook ofinformation about a number of important concurrency control algorithms which can be usedin the design of a distributed data base management system. Descriptors:* Algorithms;* Databases;* Distributed data processing;* Systems engineering;* Handbooks; Control theory;Allocations; Multiple operation; Centralized,*,1983,*,19
Distributed Database Control and Allocation. Volume 2. Performance Analysis of Concurrency Control Algorithms.,WK Lin; PA Bernstein; N Goodman; J Nolte,Abstract: This is the second of three volumes of the final technical report for the projectDistributed Database Control and Allocation. This volume describes work on theperformance analysis of concurrency control algorithms. Descriptors:* Algorithms;* Databases;* Distributed data processing;* Reliability (Electronics);* Performance (Engineering);Control theory; Allocations; Multiple operation; Centralized; Requirements,*,1983,*,20
Distributed database control and allocation. Volume 3: Distributed database system designer's handbook[Final Technical Report; Jan. 1981- Jan. 1983],WK LIN; PA BERNSTEIN; N GOODMAN; J NOLTE,*,*,1983,*
Distributed database control and allocation. Volume 2: Performance analysis of concurrency control algorithms[Final Technical Report; Jan. 1981- Jan. 1983],WK LIN; PA BERNSTEIN; N GOODMAN; J NOLTE,*,*,1983,*
Fast Methods For Testing Quantified Relational Calculus Assertions; Rep. TR-24-82,Philip A Bernstein; Barbara T Blaustein,*,Information Systems,1983,*
Surveyor's Forum: Technical Transactions,Philip Bernstein; Nathan Goodman,The paper by Bernstein and Goodman (" Concurrency Control in Database Systems;"COMPUTING SURVEYS 13; 2 (June 1981); 185-221) considered algorithms that solved theproblems of concurrency control and replication simultaneously. If the problems are treatedseparately; then the basic 2PL algorithm the authors proposed for concurrency control canbe used to implement a host of replication algorithms directly. For example; primary copyand voting algorithms for replicated data can be implemented on top of basic 2PL.Separating the treatment of concurrency control from replication can lead to implementationand conceptual simplifications. The paper neither pointed out that the problems could beseparated; nor that such simplifications might result. In addition; Bernstein and Goodman'sassumptions limited their replication algorithms to a restricted subset of the interesting …,ACM Computing Surveys (CSUR),1982,*,1
Tfje Oregon; Report,SB Yao; Philip A Bernstein; Nathan Goodman; Stewart A Schuster; David W Shipman; Diane CP Smith,*,Tutorial--data base management in the 1980's,1981,*
Fundamental algorithms for concurrency control in distributed data base systems[Final Technical Report; Jul. 1979- Jan. 1980],Philip A Bernstein; Nathan Goodman,*,*,1980,*
On Optimization of Query Processing Strategies.,DM Chiu; YC Ho; PA Bernstein,Abstract: This report examines the formulation of the query processing problem as anoptimization problem. The real problem; which involves database states as parameters; isan intractable one. The problem can; however; be transformed into equivalent and simplifiedversions by making certain assumptions. In order to state these assumptions and theproblem transformation on a formal basis; the notion of characterization is introduced. Acharacterization is a mapping of the database state space into a simplified parameter space.Meaningful simplification of the original problem is possible only when suitablecharacterizations can be found. The problem formulations in several important papers arereviewed and a detailed example is represented to illustrate some ideas. Descriptors:*DATA PROCESSING;* INTERROGATION; DATA BASES; OPTIMIZATION; DATA …,*,1979,*,20
On optimization of query processing strategies[Interim Report],DM CHIU; YC HO; PA BERNSTEIN,*,*,1979,*
On Optimization of Query Processing Systems,DM Chiu; YC Ho; Philip A Bernstein,*,*,1979,*
Preceding page blank 189,Philip A Bernstein; David W Shipman,Abstract In a database system; an arbitrary interleaving of transactions can lead to aninconsistent database state. This spurious behavior can be prevented by a variety ofproposed synchronization mechanisms. To gain insight into these mechanisms; we analyzethem in a simple centralized system which permits one read operation and one writeoperation per transaction. We show why locking mechanisms lead to correct operation andshow that two proposed mechanisms are actually special cases of locking. We also examineconflict graph analysis; the method used in the SDD-1 distributed database system; weprove its correctness; and we show that it is not a locking mechanism. l. INTRODUCTION Ifseveral update requests are processed concurrently in a database system; an inconsistentdatabase state can result. This spurious behavior can be prevented by synchronizing …,Proceedings of the Third Berkeley Workshop on Distributed Data Management and Computer Networks; August 29-31; 1978; Lawrence Berkeley Laboratory; University of California; Prepared for the US Department of Energy,1978,*,15
Distributed data base management: tutorial initially presented at Compsac 78; Nov. 13-16; 1978; The Palmer House; Chicago; Ill.; The IEEE Computer Soc. Second I...,Philip A Bernstein,*,*,1978,*
S8. 2. RELATIONAL VIEWS,A Pirotte; AK Arora; CR Carlson; U Dayal; PA Bernstein,*,Very large data bases: Fourth International Conference on Very Large Data Bases; West Berlin; Germany; September 13-15; 1978,1978,*
A BLUEPRINT FOR DATABASE THEORY RESEARCH,Philip A Bernstein,*,The Oregon report: proceedings of the Conference on Computing in the 1980's; Portland; Oregon,1978,*
Session: formal topics,Philip A Bernstein,*,International Conference on Management of Data: Proceedings of the 1978 ACM SIGMOD international conference on management of data: Austin; Texas,1978,*
Operacionnye sistemy,Dionysios C Tsichritzis; Philip A Bernstein; Viktoriâ L'vovna Uškova; NB Fejgel'son; Igor Borisovič Zadyhajlo; Viktor Vladimirovič Martynûk,*,*,1977,*
Lecture Notes for CSC 468,Dionysios C Tsichritzis; Philip A Bernstein,*,*,1975,*
MODELS FOR DESCRIPTION OF COMPUTER SYSTEMS,PA Bernstein; D Tsichritzis,*,Proceedings of the... Annual Princeton Conference on Information Sciences and Systems,*,*
2010 IEEE 26th International Conference on Data Engineering (ICDE 2010),Ankit Malpani; Philip A Bernstein; Sergey Melnik; James F Terwilliger,Object-relational mapping systems have become often-used tools to provide applicationaccess to relational databases. In a database-first development scenario; the onus is on thedeveloper to construct a meaningful object layer for the application because shipping tools;as ORM tools only ship database reverse-engineering tools that generate objects with atrivial one-to-one mapping. We built a tool;...,*,*,*,21
26th International Conference on Data Engineering,MIrella Moro; Shahram Ghandeharlzadeh; Jayanf R Harltsa; Gerhard Wellolm; FabIo Casatl; Edward Chan,Shahram Ghandeharlzadeh; University of Southern california; Los Angeles; USA Jayanf R.Harltsa; Indian Institute of Science; Bangalore; India Gerhard Wellolm; Max-Planck Institute forInformatics; Saarbrlicken; Germany MIke carey; UC Irvine; USA FabIo Casatl; University ofTrento; Italy Edward Chan" Google; China loana Manolescu; INRIA; France SharadMehrotl'a; UC Urvine; USA Umeshwar Dayal; HP Labs; Palo Alto; california; USA V .... ". J.Tsotras; UC Riverside; california; USA,*,*,*,15
applications with a replicated architecture. International Conference on,PHILIP A BERNSTEIN; VASSOS HADZILACOS; NATHAN GOODMAN,BERLAGE; THOMAS; GENAU; ANDREAS. A framework for shared applications with a replicatedarchitecture. International Conference on Management of Data. Proceedings of the 1995 ACMSIGMOD international conference on Management of data. 1995 … BERNSTEIN; PHILIP A.;HADZILACOS; VASSOS; GOODMAN; NATHAN. Concurrency Control and Recovery in DatabaseSystems. Addison Wesley; Massachusetts; 1987; ISBN 0-201-10715-5 … BORA; SEBNEM;DIKENELLI; OGUZ. Applying Feedback Control in Adaptive Replication Mechanisms in FaultTolerant Multi-Agent Organization. International Conference on Software Engineering;Shanghai; China. 5-12 pages . ISBN:1-59593-395-6 2006 … BUSICHIA; GISELE.FERREIRA; JOÃO EDUARDO. Compartilhamento de Módulos de Bases de Dados Heterogêneasatravés de Objetos Integradores. SBBD; Brazilian Symposium of Databases. October …,*,*,*,20
Generic Schema Matching With Cupid Jayant Madhavan,Jayant Madhavan; Afshin Rostamizadeh; Warren Shen; Kenneth Wilder; Fei Wu; Philip A Bernstein; Erhard Rahm,Philip A. Bernstein; Jayant Madhavan; Erhard Rahm (Philip A. Generic Schema Matching WithCupid (Generic Schema Matching; Ten Years Later). 2010. matching; and its subtype schemamatching; are reviewed and compared. Cupid is a mapping tool that discovers mappings betweenschema elements (9) Jayant Madhavan; Philip A Bernstein; and Erhard Rahm. “Genericschema … List of computer science publications by Jayant Madhavan … Generic SchemaMatching; Ten Years Later. Generic … Jayant Madhavan; Afshin Rostamizadeh; WarrenShen; Kenneth Wilder; Fei Wu; Quality Impact of Value Matching and Scoring in Topk Entity AttributeExtraction. Managing Complex Databases in a Schema Management Framework. Applying GenericSchema Management to Bioinformatics. Jayant Madhavan; Philip A. Bernstein; ErhardRahm: Generic Schema Matching with Cupid … Generic Schema Matching With Cupid …,*,*,*,20
Metadata Management Engine for Data Integration with Reverse-Engineering Support,Michael N Gubanov; Philip A Bernstein; Alexander Moshchuk,Metadata management offers a set of generic operators to address a wide variety ofmetadata-centric problems [1] in an efficient way. The operators are functions that take andreturn schemas and mappings. The most popular are Match and Merge that compute amapping between two schemas and merge them based on that mapping [2]. Metadatamanagement operators combined in short programs offer a powerful abstraction to solvecomplex metadata problems quickly. One such problem is Enterprise Data Integrationwhose scenarios can be easily built on the top of the following short program and otherwisewould have required extensive development efforts: map12= Match (s1; s2)〈 s3;..〉= Merge(s1; s2; map12); where map12 is a mapping between schemas s1 and s2; s3 is a mergedschema. However; the following problems almost always arise in practice:• Schemas …,*,*,*,15
Generic Model Management,Erhard Rahm; Philip A Bernstein; Emeritus Gio Wiederhold,Abstract Many challenging problems facing information systems engineering involve themanipulation of complex metadata artifacts; or models; such as database schemas; interfacespecifications; or object diagrams; and mappings between models. The applications thatsolve metadata manipulation problems are complex and hard to build. The goal of genericmodel management is to reduce the amount of programming needed to develop suchapplications by providing a database infrastructure in which a set of high-level algebraicoperators; such as Match; Merge; and Compose; are applied to models and mappings as awhole rather than to their individual building blocks. This dissertation presents an initialstudy of the concepts and algorithms for generic model management. We describe the firstprototype of a generic model management system; introduce the algebraic operators that …,*,*,*,0
A FORMAL MODEL OF CONCURRENCY CONTROL MECHANISMS FOR,Philip A Bernstein; David W Shipman,Abstract In a database system; an arbitrary interleaving of transactions can lead to aninconsistent database state. This spurious behavior can be prevented by a variety ofproposed synchronization mechanisms. To gain insight into these mechanisms; we analyzethem in a simple" centralized system which permits one read operation and one writeoperation per transaction. We show why locking mechanisms lead to correct operation andshow that two proposed mechanisms are actually special cases of locking. We also examineconflict graph analysis; the method used in the SDD-1 distributed database system; weprove its correctness; and we show that it is not a locking mechanism.,BERKELEY WORKSHOP,*,*,12
With Great Freedom for Inconsistent Data Comes Great Scalability Responsibility,Yannis Katsis; Alin Deutsch; Yannis Papakonstantinou; Vasilis Vassalos,ABSTRACT Shared online databases; such as Google Fusion Tables or Quickbase; allowcommunity members to collaboratively maintain and browse data. While users may believein conflicting facts (due to conflicting sources; measurements or opinions); current onlinedatabases do not offer support for the management of data conflicts. Thus online databasescould clearly benefit from technology for uncertain/incomplete databases. However; priorworks on uncertain databases are of limited help when designing a conflict-aware onlinedatabase; for two reasons: First; their performance degrades rapidly as the number ofconflicting facts escalates; which can be the case in large user communities. Second; theywere built as storage models; resulting in data models that are either non-simple or non-compact and thus may require additional; often non-trivial processing before they appear …,*,*,*,0
Arora; RK; 359,C Batini; PA Bernstein; H Boral; ML Brodie; U Bussolati; CR Carison; F Cesarini; P De; C Devor; DJ De Witt; PS Fisher; R Gillner; E Grochla; CD Hafner; WD Haseman; C Holsapple; NK Jain; CI Johnston; CH Kriebel; M Lenzerini,*,*,*,*
Reports and theses,PA Bernstein; DW Shipman; JB Rothnie,*,*,*,*
ADVANCED INFORMATION SYSTEMS ENGINEERING,AM Salminen; Frank Wm Tompa; Kalle Lyytlnen; Richard Welke; Philip A Bernstein; Thomas Bergstraesser; Jason Carbon; Shankar Pal; Paul Sanders; David Shutt; Vincent Englebert; Jean-Luc Halnaut; Jos Van Hlllegersberg; Kuldeep Kumar; Hans W Nlssen; Matthfas Jarke; Dickson KW Chfu; Qfng Li; Kamalakar Karlapalem,*,*,*,*
Data Engineering,Serge Abiteboul; Sophie Cluet; Tova Milo; Pini Mogilevsky; Jerome Siméon; Sagit Zohar; Philip A Bernstein; Thomas Bergstraesser; Marco Carrer; Ashok Joshi; Paul Lin; Alok Srivastava; Laura Haas; Renee Miller; Bartholomew Niswonger; Mary Tork Roth; Peter Schwarz; Edward Wimmers,Membership in the TC on Data Engineering (http: www. is open to all current members of theIEEE Computer Society who are interested in database systems. The web page for the DataEngineering Bulletin is http://www. research. microsoft. com/research/db/debull. The webpage for the TC on Data Engineering is http://www. ccs. neu. edu/groups/IEEE/tcde/index.html.,*,*,*,10
VLDB Endowment Board of Trustees,Gerhard Weikum; Laura M Haas; Paolo Atzeni; Michael J Franklin; Amr El Abbadi; Gustavo Alonso; Peter MG Apers; Elisa Bertino; Peter Buneman; Johann Christoph Freytag; HV Jagadish; Christian S Jensen; Donald Kossmann; David Lomet; Renée J Miller; Shojiro Nishio; Beng Chin Ooi; Meral Ozsoyoglu; Krithi Ramamritham; Raghu Ramakrishnan; Stanley B Zdonik,The VLDB Endowment is a non-profit foundation whose objective is to promote scientific andeducational activities in the area of large-scale data; information; and knowledgemanagement. The Endowment serves as the steering committee for the VLDB conferenceseries. The Endowment also sponsors various scholarly activities. It has established aprogram that supports summer schools; tutorials; and other training activities of this kind; incountries that could otherwise not afford the expenses for such events. The Endowment isalso the main sponsor of the biennial Conference on Innovative Data Systems Research(CIDR); and it runs the VLDB Journal; one of the most successful journals in the databasearea. On various activities; the Endowment closely cooperates with ACM SIGMOD. TheVLDB Endowment has a board of 21 elected trustees; who are the legal guardians of the …,*,*,*,0
CASE Requirements for,Philip A Bernstein,A database system (DBMS) offers functions for storage managment; type management;associative access; and transaction management. State-of-the-art relational DBMSs providestorage management for small records; type management for simple record structures;associative access using relational algebraic operators; and transaction management forshort-duration transactions. These facilities are inadequate to support most engineeringdesign applications; such as mechanical design; electronic design; and software design 10;21; 22; 24; 31; 79).,Database eeri,*,*,0
Do we understand the wiring of our systems?,Sergey Melnik; Philip A Bernstein,Abstract Today's large-scale transaction systems are complex integrations of many mission-critical applications and databases; tied to external systems via messages and protocols.Thus; there are many schemas; views; method signatures; mappings; etc. that need to bewired together seamlessly. The correctness of this wiring is paramount. However; do wealways grasp the whole picture? Can we formally characterize the effects of optimizing theexisting wiring or introducing a new system into it? We claim that we do not have a good wayof addressing these questions. We illustrate our point using examples of schema evolutionand migration of legacy data. We highlight the challenges and suggest a way ofapproaching the problem.,*,*,*,20
Bulletin of the Technical Committee on,Serge Abiteboul; Sophie Cluet; Tova Milo; Pini Mogilevsky; Jerome Siméon; Sagit Zohar; Philip A Bernstein; Thomas Bergstraesser; Marco Carrer; Ashok Joshi; Paul Lin; Alok Srivastava; Laura Haas; Renee Miller; Bartholomew Niswonger; Mary Tork Roth; Peter Schwarz; Edward Wimmers,*,*,*,*
Shadow Editing: A Distributed Service for,Marc Shapiro; Marc Shapiro; Partha Dasgupta; R Ananthanarayanan; M Satyanarayanan; Peter A Alsberg; John D Day; Philip A Bernstein; Nathan Goodman; Eric C Cooper; Wen-Hann Wang; Jean-Loup Baer; Barton P Miller; Charles McDowell; Sean O'Malley; Larry L Peterson,From: nelly@corto.inria.fr. Received(Date): Fri; 17 Apr 92 16:05:31 +0200. Newsgroups:comp.os.research. Subject: OOOS bibliography update. Approved: comp-os-research@ftp.cse.ucsc.edu. This is an update of the "Object-Oriented and Operating Systems". bibliography file;maintained by the SOR project at INRIA. Rocquencourt (France); and provided to interested partiesas a. public service. It is created by applying "diff -b -c1" between the current. version and thelatest version which you have previously received. The "patch" program allows you to createthe new version by. automatically applying this diff to the old version. You may ftp the latest versionanonymously either from. ftp.cse.ucsc.edu (128.114.134.19); directory pub/bib; file. ooos.bib.Z(compressed) or from ftp.inria.fr (128.93.1.26);. directory INRIA/bib; file ooos.bib.Z (compressed) …,ieeetc,*,*,14
Corpus-based Schema Matching,Jay ant Madhavan; Philip Bernstein; Kuang Chen; Alon Halevy; Pradeep Shenoy,Abstract Schema matching is the problem of determining a set of correspondences thatidentify similar elements in two different schémas. In this paper we propose a novel methodfor matching schémas that leverages previous matching experiences by extractingknowledge from a corpus of known schémas and mappings; and applying this knowledge tomatch new schémas. We describe the Mapping Knowledge Base that captures theknowledge gleaned from the past; methods to apply the gleaned knowledge to newmatching tasks; and interesting tradeoffs in building such a system. Finally; we presentpreliminary experimental results that demonstrate that the use of past experience can resultin an improvement in the generated matches.,*,*,*,19
Hn VA D UNIVERSITY CENTER FOR RESEARCH IN COMPUTING TECHNOLOGY,PA Bernstein; N Goodman; M Casanova; U Dayal; EM Clarke Jr; L Liu; JH Reif; EO Ploedereder; GL Peterson,Abstract: This paper provides an update of the facilities added to the PREP2 text processingprogram since the documentation in RC 6948; January; 1978. In addition; a simplemechanical procedure is outlined for defining mnemonics and functions in PR_EP2; and it isillustrated with several detailed examples. Furthermore; we provide an elementaryintroduction to selected portions of Termtext/Format (T'I'/F); the underlying text processinglanguage used at IBM Research; and we present some advanced applications of PR_EP2.Finally; we include a set of text processing problems which should be useful in teachingcourses on PREP2.,*,*,*,10
How Best to Build Web-Scale Data Managers? A Panel Discussion,Philip A Bernstein; Daniel J Abadi; Michael J Cafarella; Joseph M Hellerstein; Donald Kossmann,Many of the largest database-driven web sites use custom webscale data managers(WDMs). On the surface; these WDMs are being applied to problems that are well-suited forrelational database systems. Some examples are the following:• Map-Reduce [5]; Hadoop[7]; and Dryad [9] are used to process queries on large data sets using sequential scan andaggregation. Hive [8] is a data warehouse built on Hadoop.• Google's Bigtable [3] is used tostore a replicated table of rows of semi-structured data.• Amazon's Dynamo [6] is used tostore partitioned; replicated databases of key-value pairs. Cassandra [2] is similar.• Objectcaching systems are used instead of a persistent store; such as memcached [10]; Oracle'sCoherence; and Microsoft's Velocity project. These WDMs have challenging requirementsthat are not met by current relational database products. They need to scale out to …,*,*,*,0
Data Engineering,Philip A Bernstein; Nishant Dani; Badriddine Khessib; Ramesh Manne; David Shutt; Jayant Madhavan; Alon Halevy; Shirley Cohen; Xin Luna Dong; Shawn R Jeffery; David Ko; Cong Yu; Varun Bhagwan; Mike Ching; Alex Cozzi; Raj Desai; Daniel Gruhl; Kevin Haas; Linda Kato; Jeff Kusnitz; Bryan Langston; Ferdy Nagy; Linda Nguyen; Jan Pieper; Savitha Srinivasan; Anthony Stuart; Renjie Tang,The Bulletin of the Technical Committee on Data Engineering is published quarterly and isdistributed to all TC members. Its scope includes the design; implementation; modelling;theory and application of database systems and their technology. Letters; conferenceinformation; and news should be sent to the Editor-in-Chief. Papers for each issue aresolicited by and should be sent to the Associate Editor responsible for the issue. Opinionsexpressed in contributions are those of the authors and do not necessarily reflect thepositions of the TC on Data Engineering; the IEEE Computer Society; or the authors'organizations. Membership in the TC on Data Engineering is open to all current members ofthe IEEE Computer Society who are interested in database systems. There are two DataEngineering Bulletin web sites: http://www. research. microsoft. com/research/db/debull …,*,*,*,20
