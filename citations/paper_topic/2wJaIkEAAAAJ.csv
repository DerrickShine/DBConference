Dbpedia: A nucleus for a web of open data,Sören Auer; Christian Bizer; Georgi Kobilarov; Jens Lehmann; Richard Cyganiak; Zachary Ives,Abstract DBpedia is a community effort to extract structured information from Wikipedia andto make this information available on the Web. DBpedia allows you to ask sophisticatedqueries against datasets derived from Wikipedia and to link other datasets on the Web toWikipedia data. We describe the extraction of the DBpedia datasets; and how the resultinginformation is published on the Web for human-and machine-consumption. We describesome emerging applications from the DBpedia community and show how website authorscan facilitate DBpedia content within their sites. Finally; we present the current status ofinterlinking DBpedia with other open datasets on the Web and outline how DBpedia couldserve as a nucleus for an emerging Web of open data.,*,2007,2935,7
An adaptive query execution system for data integration,Zachary G Ives; Daniela Florescu; Marc Friedman; Alon Levy; Daniel S Weld,Abstract Query processing in data integration occurs over network-bound; autonomous datasources. This requires extensions to traditional optimization and execution techniques forthree reasons: there is an absence of quality statistics about the data; data transfer rates areunpredictable and bursty; and slow or unavailable data sources can often be replaced byoverlapping or mirrored sources. This paper presents the Tukwila data integration system;designed to support adaptivity at its core using a two-pronged approach. Interleavedplanning and execution with partial optimization allows Tukwila to quickly recover fromdecisions based on inaccurate estimates. During execution; Tukwila uses adaptive queryoperators such as the double pipelined hash join; which produces answers quickly; and thedynamic collector; which robustly and efficiently computes unions across overlapping …,ACM SIGMOD Record,1999,590,7
Schema mediation in peer data management systems,Alon Y Halevy; Zachary G Ives; Dan Suciu; Igor Tatarinov,Intuitively; data management and data integration tools should be well-suited for exchanginginformation in a semantically meaningful way. Unfortunately; they suffer from two significantproblems: they typically require a comprehensive schema design before they can be used tostore or share information; and they are difficult to extend because schema evolution isheavyweight and may break backwards compatibility. As a result; many small-scale datasharing tasks are more easily facilitated by nondatabase-oriented tools that have littlesupport for semantics. The goal of the peer data management system (PDMS) is to addressthis need: we propose the use of a decentralized; easily extensible data managementarchitecture in which any user can contribute new data; schema information; or evenmappings between other peer's schemas. PDMSs represent a natural step beyond data …,Data Engineering; 2003. Proceedings. 19th International Conference on,2003,571,15
Piazza: data management infrastructure for semantic web applications,Alon Y Halevy; Zachary G Ives; Peter Mork; Igor Tatarinov,Abstract The Semantic Web envisions a World Wide Web in which data is described withrich semantics and applications can pose complex queries. To this point; researchers havedefined new languages for specifying meanings for concepts and developed techniques forreasoning about them; using RDF as the data model. To flourish; the Semantic Web needsto be able to accommodate the huge amounts of existing data and the applicationsoperating on them. To achieve this; we are faced with two problems. First; most of the world'sdata is available not in RDF but in XML; XML and the applications consuming it rely not onlyon the domain structure of the data; but also on its document structure. Hence; to provideinteroperability between such sources; we must map between both their domain structuresand their document structures. Second; data management practitioners often prefer to …,Proceedings of the 12th international conference on World Wide Web,2003,471,15
Updating xml,Igor Tatarinov; Zachary G Ives; Alon Y Halevy; Daniel S Weld,Abstract As XML has developed over the past few years; its role has expanded beyond itsoriginal domain as a semantics-preserving markup language for online documents; and it isnow also the de facto format for interchanging data between heterogeneous systems. Datasources expert XML “views” over their data; and other system can directly import or querythese views. As a result; there has been great interest in languages and systems forexpressing queries over XML data; whether the XML is stored in a repository or generatedas a view over some other data storage format. Clearly; in order to fully evolve XML into auniversal data representation and sharing format; we must allow users to specify updates toXML documents and must develop techniques to process them efficiently. Updatecapabilities are important not only for modifying XML documents; but also for propagating …,ACM SIGMOD Record,2001,441,4
What can database do for peer-to-peer?,Steven D Gribble; Alon Y Halevy; Zachary G Ives; Maya Rodrig; Dan Suciu,Abstract The Internet community has recently been focused on peer-to-peer systems likeNapster; Gnutella; and Freenet. The grand vision—a decentralized community of machinespooling their resources to benefit everyone—is compelling for many reasons: scalability;robustness; lack of need for administration; and even anonymity and resistance tocensorship. Existing peer-to-peer (P2P) systems have focused on specific applicationdomains (eg music files) or on providing filesystem-like capabilities; these systems ignorethe semantics of data. An important question for the database community is how datamanagement can be applied to P2P; and what we can learn from and contribute to the P2Parea. We address these questions; identify a number of potential research ideas in theoverlap between data management and P2P systems; present some preliminary …,WebDB,2001,355,15
Principles of data integration,AnHai Doan; Alon Halevy; Zachary Ives,Principles of Data Integration is the first comprehensive textbook of data integration;covering theoretical principles and implementation issues as well as current challengesraised by the semantic web and cloud computing. The book offers a range of dataintegration solutions enabling you to focus on what is most relevant to the problem at hand.Readers will also learn how to build their own algorithms and implement their own dataintegration application. Written by three of the most respected experts in the field; this bookprovides an extensive introduction to the theory and concepts underlying today's dataintegration techniques; with detailed; instruction for their application using concreteexamples throughout to explain the concepts. This text is an ideal resource for databasepractitioners in industry; including data warehouse engineers; database system …,*,2012,343,10
Adaptive query processing,Amol Deshpande; Zachary Ives; Vijayshankar Raman,Abstract As the data management field has diversified to consider settings in which queriesare increasingly complex; statistics are less available; or data is stored remotely; there hasbeen an acknowledgment that the traditional optimize-then-execute paradigm is insufficient.This has led to a plethora of new techniques; generally placed under the common banner ofadaptive query processing; that focus on using runtime feedback to modify query processingin a way that provides better response time or more efficient CPU utilization.,Foundations and Trends® in Databases,2007,323,4
The piazza peer data management system,Alon Y Halevy; Zachary G Ives; Jayant Madhavan; Peter Mork; Dan Suciu; Igor Tatarinov,Intuitively; data management and data integration tools are well-suited for exchanginginformation in a semantically meaningful way. Unfortunately; they suffer from two significantproblems: They typically require a comprehensive schema design before they can be usedto store or share information and they are difficult to extend because schema evolution isheavyweight and may break backward compatibility. As a result; many small-scale datasharing tasks are more easily facilitated by nondatabase-oriented tools that have littlesupport for semantics. The goal of the peer data management system (PDMS) is to addressthis need: We propose the use of a decentralized; easily extensible data managementarchitecture in which any user can contribute new data; schema information; or evenmappings between other peers' schemes. PDMSs represent a natural step beyond data …,IEEE Transactions on Knowledge and Data Engineering,2004,322,15
The Piazza peer data management project,Igor Tatarinov; Zachary Ives; Jayant Madhavan; Alon Halevy; Dan Suciu; Nilesh Dalvi; Xin Luna Dong; Yana Kadiyska; Gerome Miklau; Peter Mork,Abstract A major problem in today's information-driven world is that sharing heterogeneous;semantically rich data is incredibly difficult. Piazza is a peer data management system thatenables sharing heterogeneous data in a distributed and scalable way. Piazza assumes theparticipants to be interested in sharing data; and willing to define pairwise mappingsbetween their schemas. Then; users formulate queries over their preferred schema; and aquery answering system expands recursively any mappings relevant to the query; retrievingdata from other peers. In this paper; we provide a brief overview of the Piazza projectincluding our work on developing mapping languages and query reformulation algorithms;assisting the users in defining mappings; indexing; and enforcing access control overshared data.,ACM Sigmod Record,2003,263,7
XPERANTO: Publishing Object-Relational Data as XML.,Michael J Carey; Daniela Florescu; Zachary G Ives; Ying Lu; Jayavel Shanmugasundaram; Eugene J Shekita; Subbu N Subramanian,ABSTRACT Since its introduction; XML; the eXtended Markup Language; has quicklyemerged as the universal format for publishing and exchanging data in the World Wide Web.As a result; data sources; including object-relational databases; are now faced with a newclass of users: clients and customers who would like to deal directly with XML data ratherthan being forced to deal with the data source's particular (eg; object-relational) schema andquery language. The goal of the XPERANTO project at the IBM Almaden Research Center isto serve as a middleware layer that supports the publishing of XML data to this class ofusers. XPERANTO provides a uniform; XML-based query interface over an object-relationaldatabase that allows users to query and (re) structure the contents of the database as XMLdata; ignoring the underlying SQL tables and query language. In this paper; we give an …,WebDB (Informal Proceedings),2000,250,20
Update exchange with mappings and provenance,Todd J Green; Grigoris Karvounarakis; Zachary G Ives; Val Tannen,Abstract We consider systems for data sharing among heterogeneous peers related by anetwork of schema mappings. Each peer has a locally controlled and edited databaseinstance; but wants to ask queries over related data from other peers as well. To achievethis; every peer's updates propagate along the mappings to the other peers. However; thisupdate exchange is filtered by trust conditions---expressing what data and sources a peerjudges to be authoritative---which may cause a peer to reject another's updates. In order tosupport such filtering; updates carry provenance information. These systems target scientificdata sharing applications; and their general principles and architecture have beendescribed in [20]. In this paper we present methods for realizing such systems. Specifically;we extend techniques from data integration; data exchange; and incremental view …,Proceedings of the 33rd international conference on Very large data bases,2007,179,7
Querying data provenance,Grigoris Karvounarakis; Zachary G Ives; Val Tannen,Abstract Many advanced data management operations (eg; incremental maintenance; trustassessment; debugging schema mappings; keyword search over databases; or queryanswering in probabilistic databases); involve computations that look at how a tuple wasproduced; eg; to determine its score or existence. This requires answers to queries such as;"Is this data derivable from trusted tuples?";" What tuples are derived from this relation?"; or"What score should this answer receive; given initial scores of the base tuples?". Suchquestions can be answered by consulting the provenance of query results. In recent yearsthere has been significant progress on formal models for provenance. However; the issuesof provenance storage; maintenance; and querying have not yet been addressed in anapplication-independent way. In this paper; we adopt the most general formalism for tuple …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,159,15
An XML query engine for network-bound data,Zachary G Ives; Alon Y Halevy; Daniel S Weld,Abstract XML has become the lingua franca for data exchange and integration acrossadministrative and enterprise boundaries. Nearly all data providers are adding XML importor export capabilities; and standard XML Schemas and DTDs are being promoted for alltypes of data sharing. The ubiquity of XML has removed one of the major obstacles tointegrating data from widely disparate sources-namely; the heterogeneity of data formats.However; general-purpose integration of data across the wide are a also requires a queryprocessor that can query data sources on demand; receive streamed XML data from them;and combine and restructure the data into new XML output-while providing goodperformance for both batch-oriented and ad hoc; interactive queries. This is the goal of theTukwila data integration system; the first system that focuses on network-bound; dynamic …,The VLDB Journal—The International Journal on Very Large Data Bases,2002,158,10
Adapting to source properties in processing data integration queries,Zachary G Ives; Alon Y Halevy; Daniel S Weld,Abstract An effective query optimizer finds a query plan that exploits the characteristics of thesource data. In data integration; little is known in advance about sources' properties; whichnecessitates the use of adaptive query processing techniques to adjust query processing on-the-fly. Prior work in adaptive query processing has focused on compensating for delays andadjusting for mis-estimated cardinality or selectivity values. In this paper; we present ageneralized architecture for adaptive query processing and introduce a new technique;called adaptive data partitioning (ADP); which is based on the idea of dividing the sourcedata into regions; each executed by different; complementary plans. We show how thismodel can be applied in novel ways to not only correct for underestimated selectivity andcardinality values; but also to discover and exploit order in the source data; and to detect …,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,131,3
Crossing the Structure Chasm.,Alon Y Halevy; Oren Etzioni; AnHai Doan; Zachary G Ives; Jayant Madhavan; Luke K McDowell; Igor Tatarinov,Online information comes in two flavors: unstructured corpora of text on the one hand; andstructured data managed by databases and knowledge bases on the other. These twodifferent kinds of data lead to very different authoring; management and search paradigms.In the first; search is based on keywords and answers are ranked according to relevance. Inthe second; search is based on queries in a formal language (eg; SQL); and all the answersreturned for the query are correct according to the underlying semantics of the system. In theu-world of unstructured data; authoring data is straightforward. In contrast; in the s-world ofstructured data; authoring data is a conceptual effort that requires technical expertise andsubstantial up front effort; the author is required to provide a comprehensive structure (ie;schema) of the domain before entering data. This paper is focused on the profound …,CIDR,2003,116,7
Reconciling while tolerating disagreement in collaborative data sharing,Nicholas E Taylor; Zachary G Ives,Abstract In many data sharing settings; such as within the biological and biomedicalcommunities; global data consistency is not always attainable: different sites' data may bedirty; uncertain; or even controversial. Collaborators are willing to share their data; and inmany cases they also want to selectively import data from others---but must occasionallydiverge when they disagree about uncertain or controversial facts or values. For this reason;traditional data sharing and data integration approaches are not applicable; since theyrequire a globally consistent data instance. Additionally; many of these approaches do notallow participants to make updates; if they do; concurrency control algorithms orinconsistency repair techniques must be used to ensure a consistent view of the data for allusers. In this paper; we develop and present a fully decentralized model of collaborative …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,108,20
ORCHESTRA: Rapid; Collaborative Sharing of Dynamic Data.,Zachary G Ives; Nitin Khandelwal; Aneesh Kapur; Murat Cakir,Abstract Conventional data integration techniques employ a “top-down” design philosophy;starting by assessing requirements and defining a global schema; and then mapping datasources to that schema. This works well if the problem domain is well-understood andrelatively static; as with enterprise data. However; it is fundamentally mismatched with the“bottom-up” model of scientific data sharing; in which new data needs to be rapidlydeveloped; published; and then assessed; filtered; and revised by others.,CIDR,2005,104,2
Learning to create data-integrating queries,Partha Pratim Talukdar; Marie Jacob; Muhammad Salman Mehmood; Koby Crammer; Zachary G Ives; Fernando Pereira; Sudipto Guha,Abstract The number of potentially-related data resources available for querying---databases; data warehouses; virtual integrated schemas---continues to grow rapidly.Perhaps no area has seen this problem as acutely as the life sciences; where hundreds oflarge; complex; interlinked data resources are available on fields like proteomics; genomics;disease studies; and pharmacology. The schemas of individual databases are often large ontheir own; but users also need to pose queries across multiple sources; exploiting foreignkeys and schema mappings. Since the users are not experts; they typically rely on theexistence of pre-defined Web forms and associated query templates; developed byprogrammers to meet the particular scientists' needs. Unfortunately; such forms are scarcecommodities; often limited to a single database; and mismatched with biologists' …,Proceedings of the VLDB Endowment,2008,101,4
ORCHESTRA: facilitating collaborative data sharing,Todd J Green; Grigoris Karvounarakis; Nicholas E Taylor; Olivier Biton; Zachary G Ives; Val Tannen,One of the most elusive goals of structured data management has been sharing amonglarge; heterogeneous populations: while data integration [4; 10] and exchange [3] aregradually being adopted by corporations or small confederations; little progress has beenmade in integrating broader communities. Yet the need for large-scale sharing ofheterogeneous data is increasing: most of the sciences; particularly biology and astronomy;have become data-driven as they have attempted to tackle larger questions. The field ofbioinformatics; in particular; has seen a plethora of different databases emerge: each isfocused on a related but subtly different collection of organisms (eg; CryptoDB; TIGR;FlyNome); genes (GenBank; GeneDB); proteins (UniProt; RCSB Protein Databank);diseases (OMIM; GeneDis); and so on. Such communities have a pressing need to …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,96,7
The ORCHESTRA collaborative data sharing system,Zachary G Ives; Todd J Green; Grigoris Karvounarakis; Nicholas E Taylor; Val Tannen; Partha Pratim Talukdar; Marie Jacob; Fernando Pereira,Abstract Sharing structured data today requires standardizing upon a single schema; thenmapping and cleaning all of the data. This results in a single queriable mediated datainstance. However; for settings in which structured data is being collaboratively authored bya large community; eg; in the sciences; there is often a lack of consensus about how itshould be represented; what is correct; and which sources are authoritative. Moreover; suchdata is seldom static: it is frequently updated; cleaned; and annotated. The ORCHESTRAcollaborative data sharing system develops a new architecture and consistency model forsuch settings; based on the needs of data sharing in the life sciences. In this paper wedescribe the basic architecture and implementation of the ORCHESTRA system; andsummarize some of the open challenges that arise in this setting.,ACM Sigmod Record,2008,92,7
Adaptive query processing for internet applications,Zachary G Ives; Alon Y Levy; Daniel S Weld; Daniela Florescu; Marc Friedman,Abstract As the area of data management for the Internet has gained in popularity; recentwork has focused on effectively dealing with unpredictable; dynamic data volumes andtransfer rates using adaptive query processing techniques. Important requirements of theInternet domain include:(1) the ability to process XML data as it streams in from the network;in addition to working on locally stored data;(2) dynamic scheduling of operators to adjust toI/O delays and flow rates;(3) sharing and re-use of data across multiple queries; wherepossible;(4) the ability to output results and later update them. An equally importantconsideration is the high degree of variability in performance needs for different queryprocessing domains: perhaps an ad-hoc query application should optimize for display ofincomplete and partial incremental results; whereas a corporate data integration …,*,2000,92,12
Schema mediation for large-scale semantic data sharing,Y Halevy; G Ives; Dan Suciu; Igor Tatarinov,Abstract Intuitively; data management and data integration tools should be well suited forexchanging information in a semantically meaningful way. Unfortunately; they suffer fromtwo significant problems: they typically require a common and comprehensive schemadesign before they can be used to store or share information; and they are difficult to extendbecause schema evolution is heavyweight and may break backward compatibility. As aresult; many large-scale data sharing tasks are more easily facilitated by non-database-oriented tools that have little support for semantics. The goal of the peer data managementsystem (PDMS) is to address this need: we propose the use of a decentralized; easilyextensible data management architecture in which any user can contribute new data;schema information; or even mappings between other peers' schemas. PDMSs represent …,The VLDB Journal—The International Journal on Very Large Data Bases,2005,90,20
Piazza: mediation and integration infrastructure for semantic web data,Zachary G Ives; Alon Y Halevy; Peter Mork; Igor Tatarinov,Abstract The Semantic Web envisions a World Wide Web in which data is described withrich semantics and applications can pose complex queries. To this point; researchers havedefined new languages for specifying meanings for concepts and developed techniques forreasoning about them; using RDF as the data model. To flourish; the Semantic Web needsto provide interoperability—both between sites with different terminologies and with existingdata and the applications operating on them. To achieve this; we are faced with twoproblems. First; most of the world's data is available not in RDF but in XML; XML and theapplications consuming it rely not only on the domain structure of the data; but also on itsdocument structure. Hence; to provide interoperability between such sources; we must mapbetween both their domain structures and their document structures. Second; data …,Web Semantics: Science; Services and Agents on the World Wide Web,2004,72,1
Efficient evaluation of regular path expressions on streaming XML data,Zachary Ives; Alon Levy; D Weld,Abstract The adoption of XML promises to accelerate construction of systems that integratedistributed; heterogeneous data. Query languages for XML are typically based on regularpath expressions that traverse the logical XML graph structure; the efficient evaluation ofsuch path expressions is central to good query processing performance. Most existing XMLquery processing systems convert XML documents to an internal representation; generally aset of tables or objects; path expressions are evaluated using either index structures or joinoperations across the tables or objects. Unfortunately; the required index creation or joinoperations are often costly even with locally stored data; and they are especially expensivein the data integration domain; where the system reads data streamed from remote sourcesacross a network; and seldom reuses results for subsequent queries. This paper presents …,*,2000,67,15
Quantifying eavesdropping vulnerability in sensor networks,Madhukar Anand; Zachary Ives; Insup Lee,Abstract With respect to security; sensor networks have a number of considerations thatseparate them from traditional distributed systems. First; sensor devices are typicallyvulnerable to physical compromise. Second; they have significant power and processingconstraints. Third; the most critical security issue is protecting the (statistically derived)aggregate output of the system; even if individual nodes may be compromised. We suggestthat these considerations merit a rethinking of traditional security techniques: rather thandepending on the resilience of cryptographic techniques; in this paper we develop newtechniques to tolerate compromised nodes and to even mislead an adversary. We presentour initial work on probabilistically quantifying the security of sensor network protocols; withrespect to sensor data distributions and network topologies. Beginning with a taxonomy of …,Proceedings of the 2nd international workshop on Data management for sensor networks,2005,65,7
REX: recursive; delta-based data-centric computation,Svilen R Mihaylov; Zachary G Ives; Sudipto Guha,Abstract In today's Web and social network environments; query workloads include ad hocand OLAP queries; as well as iterative algorithms that analyze data relationships (eg; linkanalysis; clustering; learning). Modern DBMSs support ad hoc and OLAP queries; but mostare not robust enough to scale to large clusters. Conversely;" cloud" platforms likeMapReduce execute chains of batch tasks across clusters in a fault tolerant way; but havetoo much overhead to support ad hoc queries. Moreover; both classes of platform incursignificant overhead in executing iterative data analysis algorithms. Most such iterativealgorithms repeatedly refine portions of their answers; until some convergence criterion isreached. However; general cloud platforms typically must reprocess all data in each step.DBMSs that support recursive SQL are more efficient in that they propagate only the …,Proceedings of the VLDB Endowment,2012,60,15
Automatically incorporating new sources in keyword search-based data integration,Partha Pratim Talukdar; Zachary G Ives; Fernando Pereira,Abstract Scientific data offers some of the most interesting challenges in data integrationtoday. Scientific fields evolve rapidly and accumulate masses of observational andexperimental data that needs to be annotated; revised; interlinked; and made available toother scientists. From the perspective of the user; this can be a major headache as the datathey seek may initially be spread across many databases in need of integration. Worse;even if users are given a solution that integrates the current state of the source databases;new data sources appear with new data items of interest to the user. Here we build uponrecent ideas for creating integrated views over data sources using keyword searchtechniques; ranked answers; and user feedback [32] to investigate how to automaticallydiscover when a new data source has content relevant to a user's view-in essence …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,57,2
Efficient query processing for data integration,Zachary G Ives; Alon Halevy,The processing of queries written in a declarative language (eg; SQL or XQuery) has been asubject of intense study since the origins of the relational database system; with IBM'sSystem-R [SAC+ 79] and Berkeley's Ingres [SWKH76] projects from the 1970s. The standardapproach has been to take a declarative; user-supplied query and to try to select an order ofevaluation and the most appropriate algorithmic implementations for the operations in thequery—these are expressed within a query plan. The query plan is then executed; fetchingdata from source relations and combining it according to the operators to produce results.System-R established a standard approach to query processing that is still followed today.This approach is very similar to compilation and execution of traditional languages: a queryoptimizer statically compiles the query into a plan; attempting to pick the most efficient …,*,2002,57,10
Integrating network-bound XML data,Zachary G Ives; Alon Y Halevy; Daniel S Weld,Abstract Although XML was originally envisioned as a replacement for HTML on the web; tothis point it has instead been used primarily as a format for on-demand interchange of databetween applications and enterprises. The web is rather sparsely populated with static XMLdocuments; but nearly every data management application today can export XML data.There is great interest in integrating such exported data across applications andadministrative boundaries; and as a result; efficient techniques for integrating XML dataacross local-and wide-area networks are an important research focus.,Departmental Papers (CIS),2001,45,15
Recursive computation of regions and connectivity in networks,Mengmeng Liu; Nicholas E Taylor; Wenchao Zhou; Zachary G Ives; Boon Thau Loo,In recent years; the data management community has begun to consider situations in whichdata access is closely tied to network routing and distributed acquisition: examples include;sensor networks that execute queries about reachable nodes or contiguous regions;declarative networks that maintain information about shortest paths and reachableendpoints; and distributed and peer-to-peer stream systems that detect associations (eg;transitive relationships) among data at the distributed sources. In each case; thefundamental operation is to maintain a view over dynamic network state. This view istypically distributed; recursive; and may contain aggregation; eg; describing transitiveconnectivity; shortest paths; least costly paths; or region membership. Surprisingly; solutionsto computing such views are often domain-specific; expensive; and incomplete. In this …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,39,7
Reconcilable differences,Todd J Green; Zachary G Ives; Val Tannen,Abstract In this paper we study a problem motivated by the management of changes indatabases. It turns out that several such change scenarios; eg; the separately studiedproblems of view maintenance (propagation of data changes) and view adaptation(propagation of view definition changes) can be unified as instances of query reformulationusing views provided that support for the relational difference operator exists in the contextof query reformulation. Exact query reformulation using views in positive relationallanguages is well understood; and has a variety of applications in query optimization anddata sharing. Unfortunately; most questions about queries become undecidable in thepresence of difference (or negation); whether we use the foundational set semantics or themore practical bag semantics. We present a new way of managing this difficulty by …,Theory of Computing Systems,2011,37,3
Security challenges in next generation cyber physical systems,Madhukar Anand; Eric Cronin; Micah Sherr; Matt Blaze; Zachary Ives; Insup Lee,The advent of low-powered wireless networks of embedded sensors has spurred thedevelopment of new applications at the interface between the real world and its digitalmanifestation. Following this trend; the next generation Supervisory Control And DataAcquisition (SCADA) system is expected to replace traditional data gathering–a distributednetwork of Remote Terminal Units (RTU) or Programmable Logic Controllers (PLC); withdevices such as the wireless sensing devices. Before these intelligent systems can bedeployed in critical infrastructure such as emergency rooms and power plants; the securityproperties of sensors must be fully understood. Existing wisdom has been to apply thetraditional security models and techniques to sensor networks: as in conventional computingenvironments; the goal has been to protect physical entities: devices; packets; links; and …,Beyond SCADA: Networked Embedded Control for Cyber Physical Systems,2006,37,20
Adaptive query processing: why; how; when; what next?,Amol Deshpande; Zachary Ives; Vijayshankar Raman,Abstract Adaptive query processing has been the subject of a great deal of recent work;particularly in emerging data management environments such as data integration and datastreams. We provide an overview of the work in this area; identifying its common themes;laying out the space of query plans; and discussing open research problems. We discusswhy adaptive query processing is needed; how it is being implemented; where it is mostappropriately used; and finally; what next; ie; open research problems.,Proceedings of the 33rd international conference on Very large data bases,2007,36,15
Reliable storage and querying for collaborative data sharing systems,Nicholas E Taylor; Zachary G Ives,The sciences; business confederations; and medicine urgently need infrastructure forsharing data and updates among collaborators' constantly changing; heterogeneousdatabases. The ORCHESTRA system addresses these needs by providing datatransformation and exchange capabilities across DBMSs; combined with archived storage ofall database versions. ORCHESTRA adopts a peer-to-peer architecture in which individualcollaborators contribute data and compute resources; but where there may be no dedicatedserver or compute cluster.,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,35,15
Interactive data integration through smart copy & paste,Zachary Ives; Craig Knoblock; Steve Minton; Marie Jacob; Partha Talukdar; Rattapoom Tuchinda; Jose Luis Ambite; Maria Muslea; Cenk Gazen,Abstract: In many scenarios; such as emergency response or ad hoc collaboration; it iscritical to reduce the overhead in integrating data. Ideally; one could perform the entireprocess interactively under one unified interface: defining extractors and wrappers forsources; creating a mediated schema; and adding schema mappings? while seeing howthese impact the integrated view of the data; and refining the design accordingly. Wepropose a novel smart copy and paste (SCP) model and architecture for seamlesslycombining the design-time and run-time aspects of data integration; and we describe aninitial prototype; the CopyCat system. In CopyCat; the user does not need special tools forthe different stages of integration: instead; the system watches as the user copies data fromapplications (including the Web browser) and pastes them into CopyCat? s spreadsheet …,arXiv preprint arXiv:0909.1769,2009,34,7
Semantic Web In-Use Track-DBpedia: A Nucleus for a Web of Open Data,Soren Auer; Christian Bizer; Georgi Kobilarov; Jens Lehmann; Richard Cyganiak; Zachary Ives,*,Lecture Notes in Computer Science,2007,34
Distributed time-aware provenance,Wenchao Zhou; Suyog Mapara; Yiqing Ren; Yang Li; Andreas Haeberlen; Zachary Ives; Boon Thau Loo; Micah Sherr,Abstract The ability to reason about changes in a distributed system's state enables networkadministrators to better diagnose protocol misconfigurations; detect intrusions; and pinpointperformance bottlenecks. We propose a novel provenance model called Distributed Time-aware Provenance (DTaP) that aids forensics and debugging in distributed systems byexplicitly representing time; distributed state; and state changes. Using a distributed Datalogabstraction for modeling distributed protocols; we prove that the DTaP model provides asound and complete representation that correctly captures dependencies among events in adistributed system. We additionally introduce DistTape; an implementation of the DTaPmodel that uses novel distributed storage structures; query processing; and cost-basedoptimization techniques to efficiently query time-aware provenance in a distributed setting …,Proceedings of the VLDB Endowment,2012,32,4
Sensor Network Security: More Interesting Than You Think.,Madhukar Anand; Eric Cronin; Micah Sherr; Zachary G Ives; Insup Lee,Abstract With the advent of low-power wireless sensor networks; a wealth of newapplications at the interface of the real and digital worlds is emerging. A distributedcomputing platform that can measure properties of the real world; formulate intelligentinferences; and instrument responses; requires strong foundations in distributed computing;artificial intelligence; databases; control theory; and security. Before these intelligentsystems can be deployed in critical infrastructures such as emergency rooms andpowerplants; the security properties of sensors must be fully understood. Existing wisdomhas been to apply the traditional security models and techniques to sensor networks.However; sensor networks are not traditional computing devices; and as a result; existingsecurity models and methods are ill suited. In this position paper; we take the first steps …,HotSec,2006,32,7
Sideways information passing for push-style query processing,Zachary G Ives; Nicholas E Taylor,In many modern data management settings; data is queried from a central node or nodes;but is stored at remote sources. In such a setting it is common to perform" push-style" queryprocessing; using multithreaded pipelined hash joins and bushy query plans to computeparts of the query in parallel; to avoid idling; the CPU can switch between them as delaysare encountered. This works well for simple select-project-join queries; but increasingly;Web and integration applications require more complex queries with multiple joins and evennested subqueries. As we demonstrate in this paper; push-style execution of complexqueries can be improved substantially via sideways information passing; push-style queriesprovide many opportunities for information passing that have not been studied in the pastliterature. We present adaptive information passing; a general runtime decision-making …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,29,4
The nebula future internet architecture,Tom Anderson; Ken Birman; Robert Broberg; Matthew Caesar; Douglas Comer; Chase Cotton; Michael J Freedman; Andreas Haeberlen; Zachary G Ives; Arvind Krishnamurthy; William Lehr; Boon Thau Loo; David Mazières; Antonio Nicolosi; Jonathan M Smith; Ion Stoica; Robbert Van Renesse; Michael Walfish; Hakim Weatherspoon; Christopher S Yoo,Introduction The NEBULA Future Internet Architecture (FIA) project is focused on a futurenetwork that enables the vision of cloud computing [8; 12] to be realized. With computationand storage moving to data centers; networking to these data centers must be several ordersof magnitude more resilient for some applications to trust cloud computing and enable theirmove to the cloud.,The Future Internet Assembly,2013,28,4
MOSAIC: unified declarative platform for dynamic overlay composition,Yun Mao; Boon Thau Loo; Zachary Ives; Jonathan M Smith,Abstract Overlay networks create new networking services across nodes that communicateusing pre-existing networks. MOSAIC is a unified declarative platform for constructing newoverlay networks from multiple existing overlays; each possessing a subset of the desirednew network's characteristics. MOSAIC overlays are specified using Mozlog; a newdeclarative language for expressing overlay properties independently from their particularimplementation or underlying network. This paper focuses on the runtime aspects ofMOSAIC: composition and deployment of control and/or data plane functions of differentoverlay networks; dynamic compositions of overlay networks to meet changing applicationneeds and network conditions; and seamless support for legacy applications. MOSAIC isvalidated experimentally using compositions specified in Mozlog: we combine an …,Proceedings of the 2008 ACM CoNEXT Conference,2008,27,7
Smartcis: integrating digital and physical environments,Mengmeng Liu; Svilen R Mihaylov; Zhuowei Bao; Marie Jacob; Zachary G Ives; Boon Thau Loo; Sudipto Guha,Abstract With the increasing adoption of networked sensors; a new class of applications isemerging that combines data from the" digital world" with real-time sensor readings; in orderto intelligently manage physical environments and systems (eg;" smart" buildings; powergrids; data centers). This leads to new challenges in providing programmability;performance; extensibility; and multi-purpose heterogeneous data acquisition. The ASPENproject addresses these challenges by extending data integrationtechniques to thedistributed stream world; and adding new abstractions for physical phenomena. Wedescribe the architecture and implementation of our ASPEN system and its showcaseintelligent building application; SmartCIS; which was demonstrated at SIGMOD 2009. Wesummarize the new query processing algorithms we have developed for integrating …,ACM SIGMOD Record,2010,25,22
Maintaining recursive views of regions and connectivity in networks,Mengmeng Liu; Nicholas E Taylor; Wenchao Zhou; Zachary G Ives; Boon Thau Loo,The data management community has recently begun to consider declarative networkrouting and distributed acquisition: eg; sensor networks that execute queries aboutcontiguous regions; declarative networks that maintain shortest paths; and distributed andpeer-to-peer stream systems that detect transitive relationships among data at the distributedsources. In each case; the fundamental operation is to maintain a view over dynamicnetwork state. This view is typically distributed; recursive; and may contain aggregation; eg;describing shortest paths or least costly paths. Surprisingly; solutions to computing suchviews are often domain-specific; expensive; and incomplete. We recast the problem asincremental recursive view maintenance given distributed streams of updates to tuples: newstream data becomes insert operations and tuple expirations become deletions. We …,IEEE Transactions on Knowledge and Data Engineering,2010,25,1
Provenance in ORCHESTRA,Todd J Green; Grigoris Karvounarakis; Zachary G Ives; Val Tannen,Abstract Sharing structured data today requires agreeing on a standard schema; thenmapping and cleaning all of the data to achieve a single queriable mediated instance.However; for settings in which structured data is collaboratively authored by a largecommunity; such as in the sciences; there is seldom con-sensus about how the data shouldbe represented; what is correct; and which sources are authoritative. Moreover; such data isdynamic: it is frequently updated; cleaned; and annotated. The ORCHESTRA collaborativedata sharing system develops a new architecture and consistency model for such settings;based on the needs of data sharing in the life sciences. A key aspect of ORCHESTRA'sdesign is that the provenance of data is recorded at every step. In this paper we describeORCHESTRA's provenance model and architecture; emphasizing its integral use of …,*,2010,25,20
Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data,Zachary G Ives; Yannis Papakonstantinou; Alon Halevy,*,*,2003,25
Collaborative data sharing via update exchange and provenance,Grigoris Karvounarakis; Todd J Green; Zachary G Ives; Val Tannen,Abstract Recent work [Ives et al. 2005] proposed a new class of systems for supporting datasharing among scientific and other collaborations: this new collaborative data sharingsystem connects heterogeneous logical peers using a network of schema mappings. Eachpeer has a locally controlled and edited database instance; but wants to incorporate relateddata from other peers as well. To achieve this; every peer's data and updates propagatealong the mappings to the other peers. However; this operation; termed update exchange; isfiltered by trust conditions—expressing what data and sources a peer judges to beauthoritative—which may cause a peer to reject another's updates. In order to support suchfiltering; updates carry provenance information. This article develops methods for realizingsuch systems: we build upon techniques from data integration; data exchange …,ACM Transactions on Database Systems (TODS),2013,24,7
Caravan: Provisioning for What-If Analysis.,Daniel Deutch; Zachary G Ives; Tova Milo; Val Tannen,ABSTRACT Problems of what-if analysis (such as hypothetical deletions; insertions; andmodifications) over complex analysis queries are increasingly commonplace; eg; in forminga business strategy or looking for causal relationships in science. Here; data analysts aretypically interested only in task-specific views of the data; and they expect to be able tointeractively manipulate the data in a natural and seamless way—possibly on a phone ortablet; and possibly via a spreadsheet or similar interface without having to carry the fullmachinery of a DBMS. The Caravan system enables what-if analysis: fast; lightweight;interactive exploration of alternative answers; within views computed over large-scaledistributed data sources. Our novel approach is based on creating dedicated provisionedautonomous representations; or PARs. PARs are compiled out of the data; initial analysis …,CIDR,2013,24,4
Xml query languages in practice: an evaluation,Zachary G Ives; Ying Lu,Abstract The popularity of XML as a data representation format has led to significant interestin querying XML documents. Although a “universal” query language is still being designed;two language proposals; XQL and XML-QL; are being implemented and applied.Experience with these early implementations and applications has been instructive indetermining the requirements of an XML query language. In this paper; we discuss issues inattempting to query XML; analyze the strengths and weaknesses of current approaches; andpropose a number of extensions. We hope that this will be helpful both in forming theupcoming XML Query language standard and in supplementing existing languages.,International Conference on Web-Age Information Management,2000,24,20
Dynamic join optimization in multi-hop wireless sensor networks,Svilen R Mihaylov; Marie Jacob; Zachary G Ives; Sudipto Guha,Abstract To enable smart environments and self-tuning data centers; we are developing theAspen system for integrating physical sensor data; as well as stream data coming frommachine logical state; and database or Web data from the Internet. A key component of thissystem is a query processor optimized for limited-bandwidth; possibly battery-powereddevices with multiple hop wireless radio communications. This query processor is given aportion of a data integration query; possibly including joins among sensors; to execute.Several recent papers have developed techniques for computing joins in sensors; but thesetechniques are static and are only appropriate for specific join selectivity ratios. We considerthe problem of dynamic join optimization for sensor networks; developing solutions thatemploy cost modeling; as well as adaptive learning and self-tuning heuristics to choose …,Proceedings of the VLDB Endowment,2010,23,20
Nebula-a future internet that supports trustworthy cloud computing,Tom Anderson; Ken Birman; Robert Broberg; Matthew Caesar; Douglas Comer; Chase Cotton; Andreas Haeberlen; Zack Ives; Arvind Krishnamurthy; William Lehr; Boon Thau Loo; Antonio Nicolosi; Jonathan Smith; Ion Stoica; Robbert Van Renesse; Michael Walfish; Christopher Yoo,Abstract NEBULA is a future Internet architecture that is intrinsically more secure andaddresses threats to the emerging computer utility capabilities called cloud computing whilemeeting the challenges of flexibility; extensibility and economic viability. NEBULA'sarchitecture surrounds a highly-available and extensible core network interconnecting datacenters with new trustworthy transit and access networks that enable many new forms ofdistributed communication and computing. NEBULA mobile users will have quick; secure;24x7 access to services such as financial transactions and electronic medical services atany location. Local device software systems will evolve to select from a continuum ofdistributed computing and storage services provided by data centers accessible viaNEBULA. A major technical concern for such an architectural vision is trustworthiness; eg …,*,2010,23,11
A multimodal platform for cloud-based collaborative research,Joost B Wagenaar; Benjamin H Brinkmann; Zachary Ives; Gregory A Worrell; Brian Litt,The need for sharing and analyzing large-scale data sets in scientific research hasincreased significantly over the last decade. Despite multiple efforts; there is currently nosingle platform that is widely used to search for; share; and perform custom data analysisover large numbers of TB-scale datasets using cloud technologies. We present a cloud-based portal and data integration/access platform to fulfill this need. The IEEG-Portal isbeing developed as a means to share and collaborate on projects containing large EEGdatasets. It currently contains over 75 de-identified intracranial EEG datasets as well asimaging and associated meta-information; and a variety of datasets from animals. The IEEG-Portal is modular by design; which results in a highly extensible platform for neural dataanalysis on the cloud. In this paper; we highlight the current state of the portal …,Neural Engineering (NER); 2013 6th International IEEE/EMBS Conference on,2013,20,7
A substrate for in-network sensor data integration,Svilen R Mihaylov; Marie Jacob; Zachary G Ives; Sudipto Guha,Abstract With the ultimate goal of extending the data integration paradigm and queryprocessing capabilities to ad hoc wireless networks; sensors; and stream systems; weconsider how to support communication between sets of nodes performing distributed joinsin sensor networks. We develop a communication model that enables in-network join at avariety of locations; and which facilitates coordination among nodes in order to makeoptimization decisions. While we defer a discussion of the optimizer to future work; weexperimentally compare a variety of strategies; including at-base and in-network joins.Results show significant performance gains versus prior work; as well as opportunities foroptimization.,Proceedings of the 5th workshop on Data management for sensor networks,2008,20,4
MOSAIC: Unified platform for dynamic overlay selection and composition,Yun Mao; Boon Thau Loo; Zachary G Ives; Jonathan M Smith,Abstract MOSAIC constructs new overlay networks with desired characteristics bycomposing existing overlays with subsets of those attributes. Thus; MOSAIC overcomes theproblem of multiple network infrastructures that are partial solutions; while preservingdeployability. Composition of control and/or data planes is possible in the system. MOSAICoverlays are specified in Mozlog; a declarative language that specifies overlay propertieswithout binding them to a particular implementation or underlying network.,*,2008,20,20
Bidirectional Mappings for Data and Update Exchange.,Grigoris Karvounarakis; Zachary G Ives,ABSTRACT A key challenge in supporting information interchange is not only supportingqueries over integrated data; but also updates. Previous work on update exchange hasenabled update propagation over schema mappings in a unidirectional way—conceptuallysimilar to view maintenance; in that a derived instance gets updated based on changes to asource instance. In this paper; we consider how to support data and update propagationacross bidirectional mappings that enable different sites to mirror each other's data. Wedescribe how data and update exchange can be extended to support bidirectional updates;implement an algorithm to perform side effect-free update propagation in this model; andshow preliminary results suggesting our approach is feasible.,WebDB,2008,17,7
NetTrails: a declarative platform for maintaining and querying provenance in distributed systems,Wenchao Zhou; Qiong Fei; Shengzhi Sun; Tao Tao; Andreas Haeberlen; Zachary Ives; Boon Thau Loo; Micah Sherr,Abstract We demonstrate NetTrails; a declarative platform for maintaining and interactivelyquerying network provenance in a distributed system. Network provenance describes thehistory and derivations of network state that result from the execution of a distributedprotocol. It has broad applicability in the management; diagnosis; and security analysis ofnetworks. Our demonstration shows the use of NetTrails for maintaining and queryingnetwork provenance in a variety of distributed settings; ranging from declarative networks tounmodified legacy distributed systems. We conclude our demonstration with a discussion ofour ongoing research on enhancing the query language and security guarantees.,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,16,22
Provenance for Database Transforma+ ons,Val Tannen; JN Foster TJ Green G Karvounarakis; Z Ives,Page 1. Provenance for Database Transforma+ons 03/24/10 1 EDBT Keynote; Lausanne ValTannen University of Pennsylvania Joint work with JN Foster TJ Green G. Karvounarakis Z. IvesCornell UC Davis LogicBlox UPenn and ICS-‐FORTH Page 2. Data Provenance provenance;n. The fact of coming from some parficular source or quarter; origin; derivafion [Oxford EnglishDic4onary] • Data provenance [BunemanKhannaTan 01]: aims to explain how a par4cular result(in an experiment; simula4on; query; workflow; etc.) was derived. • Most science today isdata-‐intensive. Scien4sts; eg.; biologists; astronomers; worry about data provenance all the 4me.2 03/24/10 EDBT Keynote; Lausanne Page 3. Provenance? Lineage? Pedigree? • Cf. PeterBuneman: – Pedigree is for dogs – Lineage is for kings – Provenance is for art • For data; let'sbe ar4s4c (artsy?) 03/24/10 EDBT Keynote; Lausanne 3 Page 4 …,*,2010,16,20
Sharing work in keyword search over databases,Marie Jacob; Zachary Ives,Abstract An important means of allowing non-expert end-users to pose ad hoc querieswhether over single databases or data integration systems is through keyword search. Givena set of keywords; the query processor finds matches across different tuples and tables. Itcomputes and executes a set of relational sub-queries whose results are combined toproduce the k highest ranking answers. Work on keyword search primarily focuses on single-database; single-query settings: each query is answered in isolation; despite possibleoverlap between queries posed by different users or at different times; and the number ofrelevant tables is assumed to be small; meaning that sub-queries can be processed withoutusing cost-based methods to combine work. As we apply keyword search to support ad hocdata integration queries over scientific or other databases on the Web; we must reuse and …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,14,2
Self-organizing data sharing communities with SAGRES,Zachary Ives; Alon Levy; Jayant Madhavan; Rachel Pottinger; Stefan Saroiu; Igor Tatarinov; Shiori Betzler; Qiong Chen; Ewa Jaslikowska; Jing Su; Wai Tak Theodora Yeung,An increasing number of devices (eg; household appliances; PDAs; cell phones) havemicroprocessors and will soon be able to exhibit sophisticated behaviors and interactionswith other devices: a home heating system will monitor its residents' alarm clocks andschedules to set the temperature optimally; a car's GPS system will use local traffic reports tooptimize its driv er'sroute based on road conditions. The Sagres project at the University ofWashington addresses the key issues of data sharing and management in the realm ofinvisible computing. In the con text of invisible computing; data exchange and computationoccur in the background in response to cues from users. Devices are added and removedfrom the net w ork on a regular basis; and they must be able to interoperate with little humanintervention. The collection of devices that exist around a particular individual or in a …,ACM SIGMOD Record,2000,13,4
Actively soliciting feedback for query answers in keyword search-based data integration,Zhepeng Yan; Nan Zheng; Zachary G Ives; Partha Pratim Talukdar; Cong Yu,Abstract The problem of scaling up data integration; such that new sources can be quicklyutilized as they are discovered; remains elusive: global schemas for integrated data aredifficult to develop and expand; and schema and record matching techniques are limited bythe fact that data and metadata are often under-specified and must be disambiguated bydata experts. One promising approach is to avoid using a global schema; and instead todevelop keyword search-based data integration--where the system lazily discoversassociations enabling it to join together matches to keywords; and return ranked results. Theuser is expected to understand the data domain and provide feedback about answers'quality. The system generalizes such feedback to learn how to correctly integrate data. Amajor open challenge is that under this model; the user only sees and offers feedback on …,Proceedings of the VLDB Endowment,2013,12,7
TAP: Time-aware Provenance for Distributed Systems.,Wenchao Zhou; Ling Ding; Andreas Haeberlen; Zachary G Ives; Boon Thau Loo,Abstract In this paper; we explore the use of provenance for analyzing execution dynamicsin distributed systems. We argue that provenance could have significant practical benefits forsystem administrators; eg; for reasoning about changes in a system's state; diagnosingprotocol misconfigurations; detecting intrusions; and pinpointing performance bottlenecks.However; to realize this vision; we must revisit several aspects of provenance management.As a first step; we present time-aware provenance (TAP); an enhanced provenance modelthat explicitly represents time; distributed state; and state changes. We outline our researchagenda towards developing novel query processing; languages; and optimizationtechniques that can be used to efficiently and securely query time-aware provenance; evenin the presence of transient state or untrusted nodes.,TaPP,2011,12,15
StreamQRE: modular specification and efficient evaluation of quantitative queries over streaming data,Konstantinos Mamouras; Mukund Raghothaman; Rajeev Alur; Zachary G Ives; Sanjeev Khanna,Abstract Real-time decision making in emerging IoT applications typically relies oncomputing quantitative summaries of large data streams in an efficient and incrementalmanner. To simplify the task of programming the desired logic; we propose StreamQRE;which provides natural and high-level constructs for processing streaming data. Ourlanguage has a novel integration of linguistic constructs from two distinct programmingparadigms: streaming extensions of relational query languages and quantitative extensionsof regular expressions. The former allows the programmer to employ relational constructs topartition the input data by keys and to integrate data streams from different sources; whilethe latter can be used to exploit the logical hierarchy in the input stream for modularspecifications. We first present the core language with a small set of combinators; formal …,Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation,2017,11,10
Collaborating and sharing data in epilepsy research,Joost B Wagenaar; Gregory A Worrell; Zachary Ives; Matthias Dümpelmann; Brian Litt; Andreas Schulze-Bonhage,Abstract Technological advances are dramatically advancing translational research inEpilepsy. Neurophysiology; imaging and meta-data are now recorded digitally in mostcenters; enabling quantitative analysis. Basic and translational research opportunities to usethese data are exploding; but academic and funding cultures a preventing this potential frombeing realized. Research on epileptogenic networks; anti-epileptic devices and biomarkerscould progress rapidly; if collaborative efforts to digest this “big neuro data” could beorganized. Higher temporal and spatial resolution data are driving the need for novel multi-dimensional visualization and analysis tools. Crowd-sourced science; the same that drivesinnovation in computer science; could easily be mobilized for these tasks; were it not forcompetition for funding; attribution and lack of standard data formats and platforms. As …,Journal of clinical neurophysiology: official publication of the American Electroencephalographic Society,2015,11,7
A brief overview of the NEBULA future internet architecture,Tom Anderson; Ken Birman; Robert Broberg; Matthew Caesar; Douglas Comer; Chase Cotton; Michael J Freedman; Andreas Haeberlen; Zachary G Ives; Arvind Krishnamurthy; William Lehr; Boon Thau Loo; David Mazières; Antonio Nicolosi; Jonathan M Smith; Ion Stoica; Robbert Van Renesse; Michael Walfish; Hakim Weatherspoon; Christopher S Yoo,Abstract Nebula is a proposal for a Future Internet Architecture. It is based on theassumptions that:(1) cloud computing will comprise an increasing fraction of the applicationworkload offered to an Internet; and (2) that access to cloud computing resources willdemand new architectural features from a network. Features that we have identified includedependability; security; flexibility and extensibility; the entirety of which constitute resilience.Nebula provides resilient networking services using ultrareliable routers; an extensiblecontrol plane and use of multiple paths upon which arbitrary policies may be enforced. Wereport on a prototype system; Zodiac; that incorporates these latter two features.,ACM SIGCOMM Computer Communication Review,2014,11,7
What Can Peerto-Peer Do for Databases; and Vice Versa,Steven Gribble; Alon Halevy; Zachary Ives; Maya Rodrig; Dan Suciu,*,Proc. WebDB,2001,11
Principles of data integration,Alon Halevy; A Doan; Z Ives,*,Morgan Kaufmann,2012,10
Enabling incremental query re-optimization,Mengmeng Liu; Zachary G Ives; Boon Thau Loo,Abstract As declarative query processing techniques expand to the Web; data streams;network routers; and cloud platforms; there is an increasing need to re-plan execution in thepresence of unanticipated performance changes. New runtime information may affect whichquery plan we prefer to run. Adaptive techniques require innovation both in terms of thealgorithms used to estimate costs; and in terms of the search algorithm that finds the bestplan. We investigate how to build a cost-based optimizer that recomputes the optimal planincrementally given new cost information; much as a stream engine constantly updates itsoutputs given new data. Our implementation especially shows benefits for streamprocessing workloads. It lays the foundations upon which a variety of novel adaptiveoptimization algorithms can be built. We start by leveraging the recently proposed …,Proceedings of the 2016 International Conference on Management of Data,2016,9,7
Querying provenance for ranking and recommending,Zachary G Ives; Andreas Haeberlen; Tao Feng; Wolfgang Gatterbauer,Abstract As has been frequently observed in the literature; there is a strong connectionbetween a derived data item's provenance and its authoritativeness; utility; relevance; orprobability. A standard way of obtaining a score for a derived tuple is by first assigningscores to the “base” tuples from which it is derived—then using the semantics of the queryand the score measure to derive a value for the tuple. This “provenance-enabled” scoringhas led to a variety of scenarios where tuples' intrinsic value is based on their provenance;independent of whatever other tuples exist in the data set.,*,2012,9,7
Data integration and exchange for scientific collaboration,Zachary G Ives,Abstract As the sciences have become increasingly data driven; it is clear that informationintegration is critical to their advancement. By integrating diverse data; we can allowbiologists to discover big-picture patterns or behaviors; or to do comparative analysesamong different organisms or systems. By enabling collaborative editing and annotation ofintegrated data—incorporating contributions from parties with different viewpoints—we canfacilitate higher-quality; better-understood data. One of the open challenges; however; lies indeveloping the right architectures and models for supporting effective data integration andexchange in science.,International Workshop on Data Integration in the Life Sciences,2009,9,15
Integrating ontologies and relational data,Sören Auer; Zachary G Ives,Abstract In recent years; an increasing number of scientific and other domains haveattempted to standardize their terminology and provide reasoning capabilities throughontologies; in order to facilitate data exchange. This has spurred research into Web-basedlanguages; formalisms; and especially query systems based on ontologies.,Technical Reports (CIS),2007,9,10
MOSAIC: Declarative platform for dynamic overlay composition,Yun Mao; Boon Thau Loo; Zachary Ives; Jonathan M Smith,Abstract Overlay networks create new networking services using nodes that communicateusing pre-existing networks. They are often optimized for specific applications and targetedat niche vertical domains; but lack interoperability with which their functionalities can beshared. M osaic is a declarative platform for constructing new overlay networks from multipleexisting overlays; each possessing a subset of the desired new network's characteristics.This paper focuses on the design and implementation of M osaic: composition anddeployment of control and/or data plane functions of different overlay networks; dynamiccompositions of overlay networks to meet changing application needs and networkconditions; and seamless support for legacy applications. M osaic overlays are specifiedusing Mozlog; a new declarative language for expressing overlay properties …,Computer Networks,2012,8,7
Principles of data integration,Z Ives; A Halevy; A Doan,*,*,2012,8
Active learning in keyword search-based data integration,Zhepeng Yan; Nan Zheng; Zachary G Ives; Partha Pratim Talukdar; Cong Yu,Abstract The problem of scaling up data integration; such that new sources can be quicklyutilized as they are discovered; remains elusive: Global schemas for integrated data aredifficult to develop and expand; and schema and record matching techniques are limited bythe fact that data and metadata are often under-specified and must be disambiguated bydata experts. One promising approach is to avoid using a global schema; and instead todevelop keyword search-based data integration—where the system lazily discoversassociations enabling it to join together matches to keywords; and return ranked results. Theuser is expected to understand the data domain and provide feedback about answers'quality. The system generalizes such feedback to learn how to correctly integrate data. Amajor open challenge is that under this model; the user only sees and offers feedback on …,The VLDB Journal,2015,7,2
A wiki on the semantic web,Michel Buffa; F Gandon; G Erto,The wiki concept is more than 10 years old but has attained public success only recently;thanks to Wikipedia. However; in the intranet world; several studies have shown that theusage of wikis is subject to debate. Acceptance of such open; low-structured collaborativetools is not the rule. There are different reasons for explaining such low acceptance: socialreasons (corporate culture may not be adapted) but also usability reasons (the wiki is notstructured enough; it is hard to navigate and find relevant information; the wiki markuplanguage used by most wiki engine makes people reluctant to contribute to the wiki; etc.). Inthis chapter we present SweetWiki; a new wiki engine that relies on Semantic Webtechnologies and addresses most usability problems that have been reported in Buffa andGandon (2006); Chat and Nahaboo (2006); and Powers;(2005). SweetWiki is an example …,Emerging Technologies for Semantic Web Environments: Techniques; Methods and Applications; Fraunhofer Institute for Experimental Software Engineering (IESE); Germany (July 2007),2008,7,7
MOSAIC: Multiple Overlay Selection and Intelligent Composition,Yun Mao; Boon Thau Loo; Zachary G Ives; Jonathan M Smith,Abstract Today; the most effective mechanism for remedying shortcomings of the Internet; oraugmenting it with new networking capabilities; is to develop and deploy a new overlaynetwork. This leads to the problem of multiple networking infrastructures; each withindependent advantages; and each developed in isolation. A greatly preferable solution is tohave a single infrastructure under which new overlays can be developed; deployed;selected; and combined according to application and administrator needs.,Technical Reports (CIS),2007,7,7
Database publication practices,Philip A Bernstein; David DeWitt; Andreas Heuer; Zachary Ives; Christian S Jensen; Holger Meyer; M Tamer Özsu; Richard T Snodgrass; Kyu-Young Whang; Jennifer Widom,Abstract There has been a growing interest in improving the publication processes fordatabase research papers. This panel reports on recent changes in those processes andpresents an initial cut at historical data for the VLDB Journal and ACM Transactions onDatabase Systems.,Proceedings of the 31st international conference on Very large data bases,2005,7,15
Enabling an open data ecosystem for the Neurosciences,Martin Wiener; Friedrich T Sommer; Zachary G Ives; Russell A Poldrack; Brian Litt,As the pace and complexity of neuroscience data grow; an open data ecosystem mustdevelop and grow with it to allow neuroscientists the ability to reach for new heights ofdiscovery. However; the problems and complexities of neuroscience data sharing must firstbe addressed. Among the challenges facing data sharing in neuroscience; the problem ofincentives; discoverability; and sustainability may be the most pressing. We here describethese problems and provide potential future solutions to help cultivate an ecosystem for datasharing.,Neuron,2016,5,10
Crossing the structure chasm,Oren Etzioni; Alon Halevy; Anhai Doan; Zachary G Ives; Jayant Madhaven; Luke McDowell; Igor Tatarinov,Abstract It has frequently been observed that most of the world's data lies outside databasesystems. The reason is that database systems focus on structured data; leaving theunstructured realm to others. The world of unstructured data has several very appealingproperties; such as ease of authoring; querying and data sharing. In contrast; authoring;querying and sharing structured data require significant effort; albeit with the benefit of richquery languages and exact answers. We argue that in order to broaden the use of datamanagement tools; we need a concerted effort to cross this structure chasm; by importing theattractive properties of the unstructured world into the structured one. As an initial effort inthis direction; we introduce the REVERE System; which offers several mechanisms forcrossing the structure chasm; and considers as its first application the chasm on the …,*,2003,5,1
Recomputing materialized instances after changes to mappings and data,Todd J Green; Zachary G Ives,A major challenge faced by today's information systems is that of evolution as data usageevolves or new data resources become available. Modern organizations sometimesexchange data with one another via declarative mappings among their databases; as indata exchange and collaborative data sharing systems. Such mappings are frequentlyrevised and refined as new data becomes available; new cross-reference tables arecreated; and corrections are made. A fundamental question is how to handle changes tothese mapping definitions; when the organizations each materialize the results of applyingthe mappings to the available data. We consider how to incrementally recompute thesedatabase instances in this setting; reusing (if possible) previously computed instances tospeed up computation. We develop a principled solution that performs cost-based …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,4,20
The case for a unified extensible data-centric mobility infrastructure,Yun Mao; Zachary Ives; Boon Thau Loo; Jonathan M Smith,Abstract We present a unified; extensible data-centric mobility infrastructure based ondeclarative networks and composable distributed views over network; router; and host state.Declarative networks are a recent innovation for building extensible network architecturesusing declarative languages. The data-centric approach both improves flexibility overexisting solutions; and is extensible to meet the demands of future mobile applications andservices. We demonstrate the flexibility of distributed queries used in declarative networksby specifying and implementing mobile services; eg; overlay-based solutions for hostmobility; customizable routing; service discovery and composition; and location-basedservices. A prototype based on the P2 declarative networking system has beenimplemented; with which we evaluated two overlay-based mobility schemes (ROAM and …,Proceedings of 2nd ACM/IEEE international workshop on Mobility in the evolving internet architecture,2007,4,3
Rethinking the conference reviewing process,Michael J Franklin; Jennifer Widom; Anastassia Ailamaki; Philip A Bernstein; David DeWitt; Alon Halevy; Zachary Ives; Gerhard Weikum,In recent years the database research community has endeavored to expand the scope ofthe field and attract a larger and more varied base of participants. We have also long workedat “educating” academic tenure committees and research management about theimportance of our major conferences. We may now be seeing some unintended effects ofour success. There is a growing dissatisfaction with conference reviewing from all sides ofthe process. Many now perceive the process to be" broken". A number of factors can beidentified as precipitating the discontent:• The number of submitted papers has spikeddramatically in recent years (see Figure 1).,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,4,15
A quantitative evaluation of traffic-aware routing strategies,Eric J Anderson; Thomas E Anderson; Steven D Gribble; Anna R Karlin; Stefan Savage,Sunnnary In this research; we address a simple question: how much benefit can beachieved by traffic-aware routing of lntemet traffic? Efficient routing on packet-switchednetworks has attracted considerable~ h attention from the early days of the Interoet to thepresent day; yet current routing practice still relies on weighted shortest paths to route traffic;using algorithms that do not take the distribution of traffic demand into account. Compared totrafficaware routing; static muting potentially reduces Internet performance and/or increasesoperational and infrastructure costs; as networks must overprovision to avoid congestion.Efficiently mapping traffic demands onto a fixed and limited network topology-a practicecalled" traffic engineering"-poses several challenges: acquiring a traffic demand matrix;providing a mechanism (such as MPLS or adjustable edge weights) for mapping traffic to …,ACM SIGCOMM Computer Communication Review,2002,4,7
Looking at Everything in Context.,Zachary G Ives; Zhepeng Yan; Nan Zheng; Brian Litt; Joost B Wagenaar,ABSTRACT The database field has increasingly broadened past carefully controlled; closed-world data; to consider the much more complex space of data resources on the Web. In thisarea of “open” Web and contributed data; there are vast quantities of raw data—but there isa limited understanding about real or realistic usage scenarios and problems. In turn; thishas made it difficult to assess the effectiveness of data integration and structured searchtechniques. To take the next step; data integration researchers need to pool their resourcesaround a small number of cloud-hosted “hub” applications with real users; to gain access tothe sorts of workload-driven evaluations that are only possible in industry today. We presentour early work on the Habitat system; an extensible data hosting and management platformfor evaluating integration techniques in situ. We describe an initial deployment in a …,CIDR,2015,3,15
TrustForge: Flexible access control for collaborative crowd-sourced environment,Jian Chang; Peter Gebhard; Andreas Haeberlen; Zack Ives; Insup Lee; Oleg Sokolsky; Krishna K Venkatasubramanian,Observing the success of the open source software movement; the Adaptive Vehicle Make(AVM) is a program run by the Defense Advanced Project Agency (DARPA) with the goal ofapplying crowd-sourced and component-based engineering to the design of militaryvehicles. In this paper; we present a credentialing system called TrustForge; which enableseffective and flexible access control for the AVMcrowd-sourced repository. Credentialingsystems are essential in crowdsourcing to ensure quality; since it is potentially open tocontributions made by anyone. The open source software community has developedelaborate manual approaches of managing its contributor community; which are often verylabor-intensive and inefficient. Our aim with TrustForge is to improve the automation of thecredentialing and access control process in the context of component-based systems …,Privacy; Security and Trust (PST); 2013 Eleventh Annual International Conference on,2013,3,7
Adaptive stream processing,Zachary Ives,1. Software non-determinism: A software system is non-deterministic if; when re-executed; itresults in a different execution path than a prior execution. Non-determinism can arise when;for example; paths are determined by relative processor speed or the sequence of externalevents. Such software bugs have been called ''Heisenbugs''(hard failures being ''Bohrbugs'').2. Soft hardware failures: Hardware can also suffer from ''Heisenbugs.''For example; atransient hardware failure may be triggered by an environmental cause; such as a cosmicray changing a memory bit; etc. 3. Operator failures: Systems occasionally require operatorintervention. Operators; being human; make mistakes. An operator is unlikely to make thesame mistake at the same point in a subsequent execution.,*,2009,3,4
XPERANTO: Publishing Object-Relational Data as XML,Michael Carey Daniela; Michael Carey; Daniela Florescu; Zachary Ives; Ying Lu; Jayavel Shanmugasundaram; Eugene Shekita; Subbu Subramanian,Abstract Since its introduction; XML; the eXtended Markup Language; has quickly emergedas the universal format for publishing and exchanging data in the World Wide Web. As aresult; data sources; including object-relational databases; are now faced with a new classof users: clients and customers who would like to deal directly with XML data rather thanbeing forced to deal with the data source's particular (eg; object-relational) schema andquery language. The goal of the XPERANTO project at the IBM Almaden Research Center isto serve as a middleware layer that supports the publishing of XML data to this class ofusers. XPERANTO provides a uniform; XML-based query interface over an object-relationaldatabase that allows users to query and (re) structure the contents of the database as XMLdata; ignoring the underlying SQL tables and query language. In this paper; we give an …,In WebDB,2000,3,7
Center of excellence for mobile sensor data-to-knowledge (md2k),Santosh Kumar; Gregory Abowd; William T Abraham; Mustafa Al'Absi; Duen Horng Chau; Emre Ertin; Deborah Estrin; Deepak Ganesan; Timothy Hnat; Syed Monowar Hossain; Zachary Ives; Jacqueline Kerr; Benjamin M Marlin; Susan Murphy; James M Rehg; Inbal Nahum-Shani; Vivek Shetty; Ida Sim; Bonnie Spring; Mani Srivastava; Dave Wetter,EnablIng DIgItal bIobankS for mHEaltH Biomedical research studies archive biospecimens inbiobanks so that such specimens can later be reprocessed to capitalize on future technologicalimprovements; thereby supporting biomedical discoveries not possible at the time of datacollection. Conversely; mobile health (mHealth) studies usu- ally encode and retain derivativedigi- tal biomarkers (such as activity counts) that are specific to the computational models usedby respective vendors at the time of data collection; because the … Santosh Kumar; GregoryAbowd; William T. Abraham; Mustafa al'Absi; Duen Horng (Polo) Chau; Emre Ertin; DeborahEstrin; Deepak Ganesan; Timothy Hnat; Syed Monowar Hossain; Zachary Ives; JacquelineKerr; Benjamin M. Marlin; Susan Murphy; James M. Rehg; Inbal Nahum-Shani; Vivek Shetty;Ida Sim; Bonnie Spring; Mani Srivastava; and Dave Wetter … Sensors Several sensors …,IEEE pervasive computing,2017,2,7
A case study of tunnel instability in weakness zone containing swelling clay,Dawei Mao; Bjørn Nilsen; Shurong Feng; Haibin Zhao; Ming Lu,ABSTRACT Tunnelling in weakness zones containing swelling clay represent one of themost difficult conditions in hard rock tunnelling; which could result in large excavationproblems and in extreme cases even tunnel collapses. To enrich the engineeringexperience for such ground; the case of rock fall at the twin-tube Hanekleiv road tunnel isstudied in the paper. The rock fall occurred ten years after tunnel completion in thesouthbound tube; approximately 1.1 km from the northern entrance; in a fault zonecontaining swelling clay. Laboratory testing results indicate gouge material in the collapsezone was not very active on swelling and the content of swelling clay was low. Numericalsimulation has been carried out with focus on several selected mechanical states;particularly the one representing the long term loading on rock support. Both the detected …,*,2015,2,15
Parallelizing clique and quasi-clique detection over graph data,Qun Chen; C Fang,Abstract—In a wide variety of emerging data-intensive applications; such as social networkanalysis; Web document clustering; entity resolution; and detection of consistently co-expressed genes in systems biology; the detection of dense subgraphs (cliques andapproximate or quasi-cliques) is an essential component. Unfortunately; these problems areNP-Complete and thus computationally intensive at scale—hence there is a need to comeup with techniques for distributing the computation across multiple machines such that thecomputation; which is too time-consuming on a single machine; can be efficiently performedon a machine cluster given that it is large enough. In this paper; we first propose a newapproach for maximal clique and quasi-clique enumeration; which identifies densesubgraphs by recursive graph partitioning. Given a connected graph G=(V; E); it has a …,*,2014,2,7
When does cotraining work in real data? Knowledge and Data Engineering,J Du; C Ling; ZH Zhou,*,IEEE Transactions on,2011,2
Sharq guide: Finding relevant biological data and queries in a peer data management system,Sarah Cohen-Boulakia; Olivier Biton; Shirley Cohen; Zachary Ives; Val Tannen; Susan Davidson,Scientists are now faced with an explosion of information which must be rapidly analyzed toform hypotheses and create knowledge. A major challenge lies in how to effectively shareinformation among collaborating; yet autonomous; biological partners. These partners arepeers in the sense that they have a diversity of perspectives (and hence heterogeneous andcomplementary schemas); dynamic data; and the possibility of intermittent connectivity orparticipation. SHARQ (Sharing Heterogeneous and Autonomous Resources and Queries) isa collaborative project between the database group at the University of Pennsylvania (Penn)and two biological research groups from Penn Center for Bioinformatics and the Children'sHospital of Philadelphia. The goal of SHARQ is to develop generic tools and technologiesfor creating and maintaining confederations of peers whose purpose is distributed data …,Data Integration in the Life Sciences (Poster proceedings; selected for oral presentation),2006,2,15
Xperanto: Publishing object-relational data as xml,Zachary G Ives; Michael Carey; Eugene Shekita; Subbu Subramanian; Ying Lu,*,Third International Workshop on the Web and Databases,1999,2
Efficient Maximal Clique Enumeration Over Graph Data,Boyi Hou; Zhuo Wang; Qun Chen; Bo Suo; Chao Fang; Zhanhuai Li; Zachary G Ives,Abstract In a wide variety of emerging data-intensive applications; such as social networkanalysis; Web document clustering; entity resolution; and detection of consistently co-expressed genes in systems biology; the detection of dense subgraphs (cliques) is anessential component. Unfortunately; this problem is NP-Complete and thus computationallyintensive at scale—hence there is a need for efficient processing; as well as the techniquesfor distributing the computation across multiple machines such that the computation; which istoo time-consuming on a single machine; can be efficiently performed on a machine clustergiven that it is large enough. In this paper; we propose a new algorithm (called GP) formaximal clique enumeration. It identifies cliques by the operation of binary graphpartitioning; which iteratively divides a graph until each task is sufficiently small to be …,Data Science and Engineering,2016,1,2
Fine-grained provenance for linear algebra operators,Zhepeng Yan; Val Tannen; Zachary G Ives,Abstract Provenance is well-understood for relational query operators. Increasingly;however; data analytics is incorporating operations expressed through linear algebra:machine learning operations; network centrality measures; and so on. In this paper; westudy provenance information for matrix data and linear algebra operations. Our coretechnique builds upon provenance for aggregate queries and constructs a K− semialgebra.This approach tracks provenance by annotating matrix data and propagating theseannotations through linear algebra operations. We investigate applications in matrixinversion and graph analysis.,8th USENIX Workshop on the Theory and Practice of Provenance (TaPP 16),2016,1,8
Technical Perspective: k-Shape: Efficient and Accurate Clustering of Time Series,Zachary G Ives,Database research frequently cuts across many layers of abstraction (from formalfoundations to algorithms to languages to systems) and the software stack (from datastorage and distribution to runtime systems and query optimizers). It does this in a way that isspecialized to a particular class of data and workloads. Over the decades; we have seen thispattern applied to enterprise data; persistent objects; Web data; sensor data; data streams;and so on. Each time; the community has developed extensions to algebraic queryprimitives; specialized implementation techniques (index structures; pattern detectionalgorithms; update and consistency mechanisms; etc.); benchmarks; and new optimizationtechniques. Today; we are on the cusp of another class of data and applications becomingof broad interest. Time series data were once viewed as being the purview of specialized …,ACM SIGMOD Record,2016,1,5
Parallelizing maximal clique enumeration over graph data,Qun Chen; Chao Fang; Zhuo Wang; Bo Suo; Zhanhuai Li; Zachary G Ives,Abstract In a wide variety of emerging data-intensive applications; such as social networkanalysis; Web document clustering; entity resolution; and detection of consistently co-expressed genes in systems biology; the detection of dense subgraphs (cliques) is anessential component. Unfortunately; this problem is NP-Complete and thus computationallyintensive at scale—hence there is a need to come up with techniques for distributing thecomputation across multiple machines such that the computation; which is too time-consuming on a single machine; can be efficiently performed on a machine cluster giventhat it is large enough. In this paper; we first propose a new approach for maximal cliqueenumeration; which identifies cliques by recursive graph partitioning. Given a connectedgraph G=(V; E) G=(V; E); it has a space complexity of O (| E|) and a time complexity of O …,International Conference on Database Systems for Advanced Applications,2016,1,4
Database and XML Technologies: Third International XML Database Symposium; XSym 2005; Trondheim; Norway; August 28-29; 2005; Proceedings,Stéphane Bressan; Stefano Ceri; Ela Hunt; Zachary G Ives; Zohra Bellahsène; Michael Rys; Rainer Unland,This year marks an exciting time in the XML-database space: XQuery is moving closer tobecoming a full W3C Recommendation; and the “Big 3” database vendors (IBM; Oracle;Microsoft) are expected to release XQuery support in their relational DBMSs; joining anumber of existing open source and commercial products. Thus; we are very pleased tofeature an industrial paper (describing the XML-specific features of Microsoft SQL Server) aswell as 14 research papers. XSym's focus this year was on building XML repositories; andpapers discussed the following topics: indexing support for the evaluation of XPath andXQuery; benchmarks and algorithms for XQuery and XPath evaluation; algorithms forconstraint satisfaction checking; information extraction; and subtree matching; andapplications of XML in information systems. This year; XSym also coordinated its efforts …,*,2005,1,7
Interviewing in a tight job market,Zachary G Ives,When I was preparing to enter the academic interview circuit in Fall 2001; the processinitially seemed rather daunting; especially given the poor economic conditions—but I soonfound that my concerns were mostly unfounded. Fortunately; I had been given great advicethroughout my graduate studies at the University of Washington by my fellow graduatestudents and professors; and this helped immeasurably: early preparation for your futurecareer makes a tremendous difference. Also; you will quickly find the interview process to befun and exciting; rather than tense and stressful. In this article; I try to highlight some of thelessons I learned (either through others' or my own experience). My goal is not to provide acomprehensive guide to the job search process; but rather to complement the tips in articlesby Ugur Cetintemel (in the December 2001 issue of SIGMOD Record) and by Qiong Luo …,*,*,1,7
Research Challenges in Financial Data Modeling and Analysis,Lewis Alexander; Sanjiv R Das; Zachary Ives; HV Jagadish; Claire Monteleoni,Abstract Significant research challenges must be addressed in the cleaning; transformation;integration; modeling; and analytics of Big Data sources for finance. This article surveys theprogress made so far in this direction and obstacles yet to be overcome. These are issuesthat are of interest to data-driven financial institutions in both corporate finance andconsumer finance. These challenges are also of interest to the legal profession as well as toregulators. The discussion is relevant to technology firms that support the growing field ofFinTech.,Big data,2017,*,7
Parallelizing maximal clique and k-plex enumeration over graph data,Zhuo Wang; Qun Chen; Boyi Hou; Bo Suo; Zhanhuai Li; Wei Pan; Zachary G Ives,Abstract In a wide variety of emerging data-intensive applications; such as social networkanalysis; Web document clustering; entity resolution; and detection of consistently co-expressed genes in systems biology; the detection of dense subgraphs cliques and k-plex isan essential component. Unfortunately; these problems are NP-Complete and thuscomputationally intensive at scale—hence there is a need to come up with techniques fordistributing the computation across multiple machines such that the computation; which istoo time-consuming on a single machine; can be efficiently performed on a machine clustergiven that it is large enough. In this paper; we first propose a new approach for maximalclique and k-plex enumeration; which identifies dense subgraphs by binary graphpartitioning. Given a connected graph G=(V; E); it has a space complexity of O (| E|) and a …,Journal of Parallel and Distributed Computing,2017,*,7
Technical Perspective: Scaling Machine Learning via Compressed Linear Algebra,Zachary G Ives,Demand for more powerful “big data analytics” solutions has spurred a great deal of interestin the core programming models; abstractions; and platforms for next-generation systems.For these problems; a complete solution would address data wrangling and processing; andsupport analytics over data of any modality or scale. It would support a wide array ofmachine learning algorithms; but also provide primitives for building new ones. It should becustomizable; scale to vast volumes of data; and map to modern multicore; GPU; co-processor; and compute cluster hardware. In pursuit of these goals; novel techniques andsolutions are being developed by machine learning researchers (eg; high-performancelibraries like Theano [6]; runtime systems like GraphLab [5]); in the database and distributedsystems research communities (eg; distributed data analytics engines like Spark [7] and …,ACM SIGMOD Record,2017,*,7
Data-Trace Types for Distributed Stream Processing Systems,Konstantinos Mamouras; Caleb Stanford; Rajeev Alur; Zachary G Ives; Val Tannen,Abstract Distributed architectures for efficient processing of streaming data are increasinglycritical to modern information processing systems. The goal of this paper is to develop type-based programming abstractions that facilitate correct and efficient deployment of a logicalspecification of the desired computation on such architectures. In the proposed model; eachcommunication link has an associated type specifying tagged data items along with adependency relation over tags that captures the logical partial ordering constraints over dataitems. The semantics of a (distributed) stream processing system is then a function frominput data traces to output data traces; where a data trace is an equivalence class ofsequences of data items induced by the dependency relation. This data-trace transductionmodel generalizes both synchronous dataflow and relational query processors; and can …,Under submission,2017,*,12
Technical Perspective: Implicit Parallelism through Deep Language Embedding,Zachary G Ives,Modern “big data” analysis was motivated by the needs of the large Internet players; but itwas enabled by two main technical developments: parallel data processing technologiesthat support reliable and scalable computation over unreliable shared-nothing clusters ofcomputers; and continued advances in machine learning algorithms and techniques. Initialwork on these two areas happened largely independently: MapReduce was developed foraggregate computations over large multitudes of records; with minimal control flow and noevident goal of supporting machine learning. Conversely; many of the advances in machinelearning research targeted a single machine. However; many subsequent developments inparallel data processing have indeed been motivated by machine learning tasks.Additionally; many machine learning algorithms have been ported to parallel data …,ACM SIGMOD Record,2016,*,20
Collaborating and Sharing Data in Epilepsy Research (vol 32; pg 235; 2015),JB Wagenaar; GA Worrell; Z Ives; D Matthias; B Litt; A Schulze-Bonhage,*,JOURNAL OF CLINICAL NEUROPHYSIOLOGY,2016,*
connect with us,Zhichao Yan; Val Tannen; Zachary G Ives,Abstract: Provenance is well-understood for relational query operators. Increasingly;however; data analytics is incorporating operations expressed through linear algebra:machine learning operations; network centrality measures; and so on. In this paper; westudy provenance information for matrix data and linear algebra operations. Our coretechnique builds upon provenance for aggregate queries and constructs a K semialgebra.This approach tracks provenance by annotating matrix data and propagating theseannotations through linear algebra operations. We investigate applications in matrixinversion and graph analysis.,*,2016,*,15
Proceedings of the 15th International Workshop on the Web and Databases (WebDB),Z Ives; Y Velegrakis,IRIS è l'Anagrafe della ricerca dell'Università degli Studi di Trento; e ha lo scopo diraccogliere; documentare; diffondere e conservare le informazioni relative alla produzione scientificadegli autori afferenti all'Università degli Studi di Trento … Proceedings of the 15th InternationalWorkshop on the Web and Databases (WebDB) / Ives; Z.; Velegrakis; Y.. - (2012) … I dati visualizzatinon sono stati ancora sottoposti a validazione formale da parte dello Staff di IRIS; ma sono statiugualmente trasmessi al Sito Docente Cineca (Loginmiur).,*,2012,*,7
usenix conference policies,Zachary G Ives; Andreas Haeberlen; Tao Feng; Wolfgang Gatterbauer,Abstract: As has been frequently observed in the literature; there is a strong connectionbetween a derived data item's provenance and its authoritativeness; utility; relevance; orprobability. A standard way of obtaining a score for a derived tuple is by first assigningscores to the “base” tuples from which it is derived—then using the semantics of the queryand the score measure to derive a value for the tuple. This “provenance-enabled” scoringhas led to a variety of scenarios where tuples' intrinsic value is based on their provenance;independent of whatever other tuples exist in the data set.,*,2012,*,7
NetTrails: A Declarative Platform for Maintaining and Querying Provenance in Distributed Systems,Wenchao Zhuo; Qiong Fei; Shengzhi Sun; Tao Tao; Andreas Haeberlen; Zachary G Ives; Boon Thau Loo; Micah Sherr,Abstract We demonstrate NetTrails; a declarative platform for maintaining and interactivelyquerying network provenance in a distributed system. Network provenance describes thehistory and derivations of network state that result from the execution of a distributedprotocol. It has broad applicability in the management; diagnosis; and security analysis ofnetworks. Our demonstration shows the use of NetTrails for maintaining and queryingnetwork provenance in a variety of distributed settings; ranging from declarative networks tounmodified legacy distributed systems. We conclude our demonstration with a discussion ofour ongoing research on enhancing the query language and security guarantees.,*,2011,*,7
Time-aware Provenance for Distributed Systems,Wenchao Zhou; Ling Ding; Andreas Haeberlen; Zachary Ives; Boon Thau Loo,Page 1. Time-aware Provenance for Distributed Systems Wenchao Zhou; Ling Ding; AndreasHaeberlen; Zachary Ives; Boon Thau Loo University of Pennsylvania Page 2. Provenancefor Distributed Systems 2 Goal: Develop capability to answer diagnostic questions We needto tackle additional challenges… • Provenance in transient and inconsistent state • Explanationfor state changes • Security without trusted nodes • Nodes may be compromised by the attackerPage 3. Provenance in Dynamic Environments ∎ Reason - insertion of link(a;b;1) ∎ Provenancefor system state □ Not track dependency between changes □ Possible solution: differencingthe current provenance with a previous version. □ But; what about a deletion? No currentversion to compare… Why did node c's route to node a change? Page 4. Provenance inDynamic Environments ∎ Explicitly capture time …,In Proc. USENIX Workshop on Theory & Practice of Provenance (TaPP,2011,*,20
Faculty News,Andre DeHon; Steve Zdancewic; Matthew Blaze; Zachary G Ives; Milo MK Martin,Another interdisciplinary effort addresses software safety and security by preventingdangerous software practices; in particular the misuse of program pointers. Misuse ofpointers leads to many flawed software implementations. Some of these flaws can beexploited by worms; viruses; and other forms of malware; for example by attackers placingtheir code into memory with a buffer overflow. Through a series of projects called Hard-Bound; Softbound; and CETS; Professors Martin and Zdancewic have explored using bothhardware and software techniques to effectively prevent C programs from misusing pointers.A final project in this theme is SAFE; whose goal is to design new computer systems that arehighly resistant to cyber-attack; can adapt after a successful attack in order to continuerendering useful services; learn from previous attacks how to guard against and cope with …,Computer and Information Science,2011,*,15
Ronciling Differences,Todd J Green; Zachary G Ives; Val Tannen,Abstract In this paper we study a problem motivated by the management of changes indatabases. It turns out that several such change scenarios; eg; the separately studiedproblems of view maintenance (propagation of data changes) and view adaptation(propagation of view definition changes) can be unified as instances of query reformulationusing views provided that support for the relational difference operator exists in the contextof query reformulation. Exact query reformulation using views in positive relationallanguages is well understood; and has a variety of applications in query optimization anddata sharing. Unfortunately; most questions about queries become undecidable in thepresence of difference (or negation); whether we use the foundational set semantics or themore practical bag semantics. We present a new way of managing this difficulty by …,*,2011,*,20
Guest Editor's Introduction to the Special Section on the IEEE International Conference on Data Engineering,Yannis Ioannidis; Dik Lee; Raymond Ng,THE 25th IEEE International Conference on Data Engi- neering (ICDE 2009) was held inShanghai; China; on 29 March-2 April 2009. The conference call for papers attracted 545 submissionsin the research track. The eight papers in this special issue were selected from the 93 long paperspresented in Shanghai. Authors were invited to submit more complete and revised versions forthis issue for a round of careful refereeing. The paper titled “Projective Distribution of XQuerywith Updates;” by Ying Zhang; Nan Tang; and Peter Boncz; examines the problem of partitioningXQuery queries and executing each subquery on the nodes where its relevant data resides;while respecting XML node identity and preserving structural properties. It presents a sequenceof increasingly more refined semantics of parameter passing and associated techniques thatlead to minimization of the semantic difference between local execution of the original …,IEEE Transactions on Knowledge and Data Engineering,2010,*,15
Systems and Prototypes SmartCIS: Integrating Digital and Physical,Mengmeng Liu; Svilen R Mihaylov; Zhuowei Bao; Marie Jacob; Zachary G Ives; Boon Thau Loo; Sudipto Guha,*,SIGMOD record,2010,*
XML Publishing,Zachary Ives,XML access control refers to the practice of limiting access to (parts of) XML data to onlyauthorized users. Similar to access control over other types of data and resources; XMLaccess control is centered around two key problems:(i) the development of formal models forthe specification of access control policies over XML data; and (ii) techniques for efficientenforcement of access control policies over XML data.,*,2009,*,12
Updates and Transactions in Peer-to-Peer Systems,Zachary Ives,Uncertainty in events is uncertainty regarding either the occurrence of an event; oruncertainty regarding the data values associated with an event. This uncertainty is a result ofa gap between the actual occurrences of events in the real world; and the availability ofknowledge regarding the events.,*,2009,*,12
Orchestra: Sharing Inconsistent Data in a Consistent Way,Zachary Ives,One of the most pressing needs in business; government; and science is to bring togetherstructured data from a variety of systems; formats; and terminologies. For instance; theemerging field of systems biology seeks to unify biological data to get a big-picture view ofthe processes within living organisms. Many organizations have set up databases designedto be" clearing houses" for specific types of information: each is separately maintained;cleaned; and curated; and has its own schema and terminology. Updates are constantlymade as hypothesized relationships are confirmed or refuted; or new discoveries are made.The different databases contain complementary information that must be integrated to get acomplete picture-and each database may have data of different quality or relevance to adomain. However; there is often no consensus on what the definitive answers are-each …,Program Committee Workshop on Management of Uncertain Data,2008,*,7
Tom Crecelius 1480 Carlo A. Curino 761; 882 Emiran Curtmola 1408; 1448 D Harish D. 1124; 1325,Florian Daniel; David DeWitt; Amol Deshpande; AnHai Doan; Marcus Fontoura; Juliana Freire; Venkatesh Ganti; Hong Gao; Hector Garcia-Molina; Minos Garofalakis; Charles Garrod; Tingjian Ge; Lise Getoor; Phillip Gibbons; Lukasz Golab; Wojciech Golab; Yihong Gong; Albert Greenberg; Maxim Grinev; Peter Haas; Wook-Shin Han; Michael Hay; Monika Henzinger; Mauricio Hernandez; Mark Hill; Howard Ho; Allison Holloway; Mingsheng Hong; Chien-Yi Hou; Yanli Hu; Kien Hua; Jiansheng Huang; Ihab Francis Ilyas; Zachary G Ives; Marie Jacob; HV Jagadish; Magesh Jayapandian; David Jensen; Haifeng Jiang; Cheqing Jin; Ryan Johnson; Theodore Johnson; Vanja Josifovski,*,*,2008,*
Scalable; Peer-Based Mediation Across XML Schemas and Ontologies,Zachary G Ives; Alon Y Halevy; Peter Mork; Igor Tatarinov,Summary Research on the Semantic Web has focused on reasoning about data that issemantically annotated in the RDF data model; with concepts and properties specified inrich ontology languages such as OWL. However; to flourish; the Semantic Web needs toprovide interoperability both between sites with different ontologies and with existing; non-RDF data and the applications operating on them. To achieve this; we are faced with twoproblems. First; most of the world's data is available not in RDF but in XML; XML and theapplications consuming it rely not only on the domain structure of the data; but also on itsdocument structure. Hence; to provide interoperability between such sources; we must mapbetween both their domain structures and their document structures. Second; datamanagement practitioners often prefer to exchange data through local point-to-point data …,*,2006,*,7
1 Department of Computer and Information Science; University of Pennsylvania; Philadelphia; United States zives@ cis. upenn. edu 2 Department of Computer Scie...,Zachary G Ives; Alon Y Halevy; Peter Mork; Igor Tatarinov,Summary. Research on the Semantic Web has focused on reasoning about data that issemantically annotated in the RDF data model; with concepts and properties specified inrich ontology languages such as OWL. However; to flourish; the Semantic Web needs toprovide interoperability both between sites with different ontologies and with existing; non-RDF data and the applications operating on them. To achieve this; we are faced with twoproblems. First; most of the world's data is available not in RDF but in XML; XML and theapplications consuming it rely not only on the domain structure of the data; but also on itsdocument structure. Hence; to provide interoperability between such sources; we must mapbetween both their domain structures and their document structures. Second; datamanagement practitioners often prefer to exchange data through local point-to-point data …,Semantic Web and Peer-to-Peer: Decentralized Management and Exchange of Knowledge and Information,2005,*,7
Weather Market,Wesley Rosenblum; Brandon Rosenblum; Zachary Ives,Abstract Although there have been many advances over the past few decades in the field ofmeteorology; there still seems to be trouble consistently and accurately forecasting theeveryday weather conditions across the country. Inaccurate forecasts can have a negativeeffect on our daily quality of life and even have a large financial impact. There have beenestimates that if weather forecasts were just one degree more accurate; $1 billion inelectricity could be saved each year. The trend to solving this problem has so far been toinvest in larger and more powerful computers and supercomputers. Our idea is to harnessthe forecasting power of a community of individuals connected through the Internet. Ratherthan rely on the expertise of a single massive machine to make a forecast; our system relieson the expertise of thousands of people across the country. The way this is accomplished …,*,2005,*,7
Published online: 8 March 2005 M. Tamer Özsu: Coordinating Editor-in-Chief,Alon Y Halevy; Zachary G Ives; Dan Suciu; Igor Tatarinov; Avigdor Gal; Ateret Anaby-Tavor; Alberto Trombetta; Danilo Montesi; Dengfeng Gao; Christian S Jensen; Richard T Snodgrass; Michael D Soo; Yannis Tzitzikas; Nicolas Spyratos; Panos Constantopoulos,. One of the challenging problems that Web service technology faces is the ability toeffectively discover services based on their capabilities. We present an approach to tacklingthis problem in the context of description logics (DLs). We formalize service discovery as anew instance of the problem of rewriting concepts using terminologies. We call this newinstance the best covering problem. We...,The VLDB Journal,2005,*,10
Database and XML Technologies; Third International XML Database Symposium; XSym 2005,Zohra Bellahsène; Stéphane Bressan; Stefano Ceri; Z Ives; Michael Rys; Rainer Unland,Segnalazioni con codici 20501/20503/20504: Alcuni dati obbligatori per il sito CINECA nonsono presenti o invalidi; oppure il sito CINECA non è riuscito ad individuare una rivista con idati forniti; è necessario controllare la correttezza dell'ISSN e/o EISSN dove applicabili e iltitolo della rivista.Segnalazioni con codici 20201/20202: La pubblicazione non è statatrasferita SOLO per i docenti segnalati nel messaggio a causa di problemi nell'anagraficaCINECA e/o di Ateneo (pe i codici fiscali non sono gli stessi) oppure perché si tratta didocenti che; pur essendo abilitati all'inserimento nel sistema di Ateneo; non hanno facoltà disincronizzare le proprie pubblicazioni in CINECA. Tutti gli altri eventuali coautori senzasegnalazione troveranno la pubblicazione correttamente nel proprio spazio personaleCINECA.,*,2005,*,7
KNOWLEDGE AND DATA ENGINEERING,B Cui; BC Ooi; J Su; KL Tan; YK Woon; WK Ng; EP Lim; KL Tan; AY Halevy; ZG Ives; J Madhavan; P Mork; D Suciu; I Tatarinov; S Shah; K Ramamritham; P Shenoy; HT Shen; Y Shu; B Yu; E Bertino; E Ferrari; AC Squicciarini; L Xiong; L Liu; K Aberer; A Datta; M Hauswirth,CONCISE PAPERS Databases Main Memory Indexing: The Case for BD-Tree B. Cui; BCOoi; J. Su; and K.-L. Tan ................................................................................................................................ Data Mining A Support-Ordered Trie for Fast Frequency Itemset Discovery Y.-K. Woon;W.-K. Ng; and E.-P. Lim … SPECIAL SECTION ON PEER-TO-PEER-BASED DATA MANAGEMENTGuest Editors' Introduction: Special Section on Peer-to-Peer-Based Data Management BC Ooiand K.-L. Tan ...................................................................................................................................................... The Piazza Peer Data Management System AY Halevy; ZG Ives …,*,2004,*,7
IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING 1 The Piazza Peer Data Management System,Alon Y Halevy; Zachary G Ives; Jayant Madhavan; Peter Mork; Dan Suciu; Igor Tatarinov,Abstract Intuitively; data management and data integration tools should be well-suited forexchanging information in a semantically meaningful way. Unfortunately; they suffer fromtwo significant problems: they typically require a comprehensive schema design before theycan be used to store or share information; and they are difficult to extend because schemaevolution is heavyweight and may break backward compatibility. As a result; many small-scale data sharing tasks are more easily facilitated by nondatabase-oriented tools that havelittle support for semantics. The goal of the peer data management system (PDMS) is toaddress this need: we propose the use of a decentralized; easily extensible datamanagement architecture in which any user can contribute new data; schema information; oreven mappings between other peers' schemas. PDMSs represent a natural step beyond …,*,2004,*,2
Reminiscences on Influential Papers - Kenneth A. Ross,Zachary G.  Ives; Bertram Ludaescher; Ioana Manolescu,*,SIGMOD Record,2004,*
Abstracts of invited industrial track presentations,Zachary Ives,This talk will discuss what changes must take place in web services in the next three years inorder for web services to live up to their potential. It will discuss some hard problems thathave to be solved and others that industry is in the process of solving. It will discuss howweb services will lead to a pervasive change from pull to push computing and why. Finally itwill discuss the challenges web services are already putting on traditional databases.,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,*,15
Proceedings of the ACM SIGMOD International Conference on Management of Data: ACM SIGMOD 2003; June 9-12; 2003; San Diego; California,International Conference on Management of Data; Special Interest Group on Management of Data Association for Computing Machinery,*,*,2003,*
Interviewing during a tight job market,Zachary G Ives; Qiong Luo,Abstract The following collection of articles aims to provide a sequel to Ugur Cetintemel'sDecember 2001 interviewing advice article; with specific tips for times when the economy isin recession. The contributions are based on the personal experience of recent databasegraduates who were on the job market in the 2001-2002 season.,ACM SIGMOD Record,2002,*,15
The Convergence of Query and Object-Oriented Languages,Zachary Ives; Craig Wilcox,Abstract The area of custom database applications is a large and rapidly growing domain;as evidenced by the appearance of tools for developing web front-ends to databases (egMicrosoft Visual InterDev); the large number of commercial programming environments nowproviding\database wizards"(eg Symantec Visual Caf e; Microsoft Visual C++) and theemergence of database interconnectivity standards (eg JDBC; ODBC). Most sophisticateddatabase applications are a combination of code in a full objectoriented host language suchas C++ or Java and a series of queries written in a declarative language such as SQL orOQL. The combination of object-oriented and declarative languages; as well as of di erentunderlying data representations; creates an impedance mismatch {the two languages havedi erent data and execution models. This paper explores the compromises made by di …,*,1998,*,20
December 10; 1998,Zachary Ives; Craig Wilcox,*,*,1998,*
Friday; October 28; 2016 at 10: 45 am University of Michigan Law School; Hutchins Hall 100,HV Jagadish; Lewis Alexander; Sanjiv Das; Zachary Ives; Claire Monteleoni,In many fields of endeavor today; data provide the basis for informed decision-making. Thisis particularly true of macro-prudential analysis: determination of financial stability requirescleaning; integration; and analysis of multiple disparate large and complex sources of datain a timely way. In fact; the use of Big Data requires technical advances in multiple stages ofthe Big Data pipeline; as discussed by Jagadish et al (2014). These needs for data cleaning;integration; and analytics are universal; across many domains; and there is considerableexcellent research expanding the frontiers of what we are capable of doing in this regard.This panel will provide an overview of some of the successes we have had.,*,*,*,7
Abstract/Details,Madhusudhan Narayana; Ann Arbor; Allen Hanson; Erik G Learned-Miller; Aura Ganz; Rui Wang,Abstract (summary) Motion segmentation is the task of assigning a binary label to every pixelin an image sequence specifying whether it is a moving foreground object or stationarybackground. It is often an important task in many computer vision applications such asautomatic surveillance and tracking systems. Depending on whether the camera isstationary or moving; different approaches are possible for segmentation. Motionsegmentation when the camera is stationary is a well studied problem with many effectivealgorithms and systems in use today. In contrast; the problem of segmentation with a movingcamera is much more complex. In this thesis; we make contributions to the problem ofmotion segmentation in both camera settings. First for the stationary camera case; wedevelop a probabilistic model that intuitively combines the various aspects of the problem …,*,*,*,15
SmarterCIS: Integrating Digital and Physical Environments for Network Level Resource Management,Parijat Sarkar; Toon Sripatanaskul; Zachary Ives,ABSTRACT Previous work in the ASPEN project has resulted in extending data integrationtechniques to the distributed stream world; while adding new abstractions for physicalphenomena. The SmarterCIS project looks to extend the ASPEN project through thedevelopment of the SmarterCIS application. This application changes the scope of theSmartCIS monitoring system from a single node monitoring system to a cluster levelmonitoring one. Additionally; SmarterCIS has a manual control system which allows the userto effectively manage the resources in a cluster; in order to reduce power consumption withminimal comprise on performance. The primary contributions of this work are the integrationof the Xen virtual machine monitoring system and the Ganglia architecture into the ASPENruntime system; and also the provision of a new GUI to combine the monitoring and …,*,*,*,7
Abstract/Details,Svilen R Mihaylov; Ann Arbor; Zachary G Ives; Sudipto Guha; Carlos Guestrin; Andreas Haeberlen; Boon T Loo; Jonathan M Smith,*,*,*,*
Abstract/Details,Arun Raghavan; Ann Arbor; Milo MK Martin; David Brooks; Andre' DeHon; Zachary G Ives; Jonathan M Smith,The cultural and ethnic landscape of the United States is becoming increasingly diverse;with legal immigration rates as high as 400;000 individuals per year (Batalova & Terrezas;2011). Within this group of immigrants is a subset of refugees; many of whom are fleeingpersecution and torture and seeking safety in the United States (US). As this populationgrows within the US; mental health professionals are challenged to implement culturally andethically appropriate strategies to assess and treat individuals from diverse backgrounds(Okawa; 2006). Culture can exert a powerful and often misunderstood influence onpsychological assessment (Kirmayer; 1998); and few structured measures have beendemonstrated to have adequate cross-cultural validity for use with diverse and vulnerablepopulations such as survivors of torture (Campbell; 2007). This study examined the factor …,*,*,*,7
El-Khatib; K. 366,B Esfandiari; F Fankhauser; J Ferro; W Fokkink; L Fotia; A Francillon; J Garcia-Alfaro; P Gebhard; R Giustolisi; M Goldsmith; T Grechenig; T Gross; M Gruber; A Haeberlen; S Hammer; S Hauke; U Hengartner; B Henne; W Hong; A Iamnitchi; M Ingwar; J Isacenkova; Z Ives; R Jalili; CD Jensen; Z Jin; M Juarez; B Justus; C Kater; S Katzenbeisser; I Kayes; T Kohro; E Kurdjokova; K Lamberts; G Lax; I Lee; G Lenzini; Q Li; M Lin; B Liu; D Llewellyn-Jones; S Magin; M Makkes; L Malott; S Marsh,Cardoso Garcia; V. 111 Carlsson; N. 103 Castillo-Perez; S. 369 Ceolin; D. 325 Chabanne;H. 362 Chang; J. 291 Chaudhary; V. 195 Chellappan; S. 340 Chen; C. 177 Cheng; C. 177Cheng; L. 77 Chiasson; S. 267 Ciangaglini; V. 185 Cipiere; O. 362 Costin; A. 213 Crampton;J. 221 Creese; S. 333 Cuppens-Boulahia; N. 362 Cuppens; F. 362 … D'Arco; P. 11 de Laat;C. 257 De Santis; A. 11 Demchenko; Y. 257 Doerr; J. 169 Domingo-Ferrer; J. 27 dos SantosBrito; K. 111 … 2013 Eleventh Annual Conference on Privacy; Security and Trust (PST) …El-Khatib; K. 366 Esfandiari; B. 366 … Fankhauser; F. 205 Ferro; J. 119 Fokkink; W. 325Fotia; L. 36 Francillon; A. 213 … Garcia-Alfaro; J. 369 Gebhard; P. 291 Giustolisi; R. 309Goldsmith; M. 333 Grechenig; T. 205 Gross; T. 143 Gruber; M. 205 … Haeberlen; A. 291Hammer; S. 317 Hauke; S. 348 Hengartner; U. 69 Henne; B. 19 Hong; W. 177,*,*,*,4
The Case for a Unified Extensible The Case for a Unified Extensible Data-centric Mobility Infrastructure,Yun Mao Boon Thau Loo Yun; Boon Thau Loo Mao; Zachary Ives; Jonathan M Smith,Page 1. The Case for a Unified Extensible The Case for a Unified Extensible Data-centric MobilityInfrastructure Yun Mao Boon Thau Loo Yun Mao; Boon Thau Loo Zachary Ives; Jonathan M.Smith University of Pennsylvania A 27 2007 Aug 27; 2007 Mobiarch; Kyoto; Japan Project fundedby NSF NeTS-0721845 Page 2. Motivation • Mobile environment is the driving force of the gInternet architecture redesign – New environment; diversified wireless technologies – Newapplications and services New applications and services • Naming; location-aware; context-awareservices; etc • Current network architecture is not extensible to meet the demand – Slow adoptionof Mobile IP; IPv6 – Too many application specific overlay networks – Emerging networks: sensor;DTN • Problem: the architecture is tightly coupled with implementation 2 implementation Page3. Our approach: a declarative hiarctecture …,*,*,*,11
Mengmeng Liu,Zachary G Ives; Boon Thau Loo,• Enabled temporal entity fusion during the cleansing; resolution and integration of entitiesfrom multiple data sources (eg; Twitter; Facebook and SEC). Proposed declarativeapproaches to specify temporal conflict resolution and de-duplication in the high-levellanguages (HIL and Deer); and compiled them into JAQL scripts running over Hadoopframeworks.,*,*,*,7
Organization Committee,Denilson Barbosa; Rachel Pottinger; Grigoris Antoniou; ICS FORTH; Greece Smriti Bhagat; Vanessa Braganholo; Diego Calvanese; Paolo Cappellari; Roberto De Virgilio; Irini Fundulaki; Greece James Geller; Fausto Giunchiglia; Claudio Gutierrez; Andreas Harth; Zachary Ives; Solmaz Kolahi; Spyros Kotoulas; Carlos Eduardo Santos Pires; Kai-Uwe Sattler; Martin Theobald; Thanh Tran; Cong Yu; Francesco Guerra; Yannis Velegrakis,The Data Engineering Meets the Semantic Web (DESWEB) workshop series aims atbringing together researchers; developers and practitioners working in the intersectionbetween Databases and the Semantic Web. DESWEB welcomes work related to:(1) the useof Semantics in data management (eg; semanticaware schema matching; and he use ofsemantics in annotation; lineage and provenance of data);(2) Management of Semantic WebData (eg; languages; tools; and methodologies for representing and managing SemanticWeb data); and (3) Semantic Search and Linked Open Data (eg; Searching for and rankingontologies; Social Networking and the Semantic Web; and Semantic-aware searchengines). This third edition of DESWEB features a keynote presentation and four peer-reviewed articles (selected out of twelve submissions). In the keynote “Making the …,*,*,*,14
CSE-400 Senior Design Search Engine for XML Schemas,Val Tannen; Zachary Ives,Abstract XML; which stands for eXtensible Markup Language; has become important as adata storage and interchange format; because of its properties of being able to describestructured data; platform independence; human readable. DTD (Document Type Definition)and XML Schema (XSD)[1] are two ways to specify the structure of an XML document;therefore; search through XSD and DTD is an efficient and effective way to find XML data.This project is aiming to build a search engine for XSD in order to locate XML data. First;XSDs will be parsed and indexed by keywords. Then; XSD search engine will searchagainst the index database. XSD itself has XML format; and it is also structured data format.In addition to search by keywords; search by structure; which is the relations betweenkeywords; will make the search result more accurate and helpful. This project does not …,*,*,*,15
Database and XML technologies(Trondheim; 28-29 August 2005),Stéphane Bressan; Stefano Ceri; Ela Hunt; Zachary G Ives; Zohra Bellahsène; Michael Rys; Rainer Unland,*,Lecture notes in computer science,*,*
Workshop Officers,Laura Haas; Zachary Ives; Mukesh Mohania; Manish Bhide; Divy Agrawal; Phil Bernstein; Kevin Chang; Yi Chen; Alin Deutsch; AnHai Doan; Alon Halevy; Mizuho Iwaihara; Masaru Kitsuregawa; Craig Knoblock; Sergey Melnik; Ullas Nambiar; Felix Naumann; Evaggelia Pitoura; Prasan Roy; Michael Schrefl; Kohichi Takeda; Wang-Chiew Tan; Millist Vincent; Ji-Rong Wen,*,*,*,*
Query Optimization as a Datalog Program,Mengmeng Liu; Zachary G Ives; Boon Thau Loo,In recent years; there has been a resurgence of interest in using Datalog and declarativeprogramming techniques to capture a wide variety of problems: particularly those withnatural recursion in their computation; and those for which it might be desirable to allow forcustom modification by a sophisticated end user. One such problem is that of specifying thetransformation rules and search process of a query optimizer [1]. In certain emergingdomains it may be desirable to be able to customize query transformation rules; and Datalogis much more universally understood than the languages used in transformationaloptimizers like those generated by Volcano [2]. As part of the ASPEN project we envisionfuture query processing architectures targeted at widely distributed (cloud or cluster)deployments; where statistics and state monitoring information are acquired from across …,*,*,*,7
Orchestra: Facilitating Collaborative Data Sharing,Todd J Green Grigoris Karvounarakis Nicholas; E Taylor; Olivier Biton; Zachary G Ives; Val Tannen,*,*,*,*
Convergent Query Processing,Zachary G Ives; Alon Y Halevy; Daniel S Weld,Abstract The widely used paradigm of cost-based optimization divides query processing intoseparate optimization and execution stages. Performance is highly dependent on pre-existing statistics; and cumulative errors in the cost model rapidly increase with thecomplexity of the query. In response; researchers have investigated a variety of adaptivequery processing techniques—incorporating feedback into a system so it can adapt thequery plan being executed. While these techniques are effective in certain situations; mostare restricted to SPJ queries or limited in when they can trigger adaptive behavior; eachfocuses on a specific type of adaptivity; and there is no easy way to combine the techniquesto form a comprehensive solution. This paper presents convergent query processing; anovel form of adaptive query processing that subsumes previous approaches and …,*,*,*,4
Micropayments: A New Solution,Noah Ready-Campbell; Nate Conrad; Zachary Ives; Jonathan Smith,ABSTRACT Today; almost all web services rely on advertisements for revenue. Though thismodel has been successful; it can be intrusive to the user experience; and therefore is ill-suited to many services. One solution that has been put forth is micropayments; ie smallscale payments typically valued at less than one dollar. Such payments could be for itemssuch as digital content and premium web services. Though micropayments offer muchtheoretical promise; all attempts to-date have failed. However; due to recent social andtechnological developments; we believe that the situation is different now. Using anapproach with capacity to function in both the short term and the long term; we plan to createa viable method for micropayments to finally take root on the Internet. Such a creation wouldallow entirely new markets to emerge. The solution we propose to fill this void is …,*,*,*,7
A Scalable; Modular Product Recommendation System For Consumer Electronics Dept. of CIS-Senior Design 2010-2011,Edward Siegel; Vikas Shanbhogue; Bennett Blazei; Zachary Ives,ABSTRACT The consumer electronics market has a large number of novice shoppers whoare not familiar with industry jargon and do not have the knowledge required to makeinformed decisions about which products to purchase. There is significant demand for aservice that gathers data from consumers about their needs and preferences by askingsimple english-language questions; and recommends products that match these needs. Thecurrent alternatives to this are physically traveling to a store or examining jargon-filled onlinereviews; both of which are tedious; untrustworthy; and generally unattractive options. Manyexisting recommendation systems do not provide users with adequate descriptions of howrecommendations were computed. Others provide recommendations that are not sufficiently(a) trustworthy;(b) accurate; or (c) tailored to the individual customer. ElectricDeel is a …,*,*,*,7
FIND: Wireless Knowledge Infrastructure (WiKI),Boon Thau Loo; Zachary G Ives; Jonathan M Smith,We are witnessing a dramatic transition [24; 28] in the Internet; as it expands from a meansof connecting together desktop or portable PCs and servers to a ubiquitous; over-the-aircommunications medium interconnecting mobile personal devices; environmental sensors;and Web services. Metropolitan area networks are being deployed in a number of cities;including San Francisco (Feather); Philadelphia (the Wireless Philadelphia initiative; underpreliminary deployment) and even across the globe in city nations such as Singapore [85].Cellphone carriers such as Verizon; Sprint; and Cingular/AT&T have high speed datanetworks; conversely; there are a number of new cellular phones that can switch betweenthe cell carrier and WiFi using VOIP. The upcoming WiMAX standard is a major focus of Intel(planning to incorporate it into their next generation Centrino package) as well as other …,*,*,*,15
NeTS-NOSS: SNAPS: Sensor Network Abstraction and Programming System,Zachary Ives; Sudipto Guha; Insup Lee PI; Bill Hanson,*,*,*,*
Bulletin of the Technical Committee on,Sirish Chandrasekaran; Amol Deshpande; Kris Hildrum; Sam Madden; Vijayshankar Raman; Mehul A Shah; Zachary G Ives; Alon Y Levy; Daniel S Weld; Daniela Florescu; Marc Friedman,Bulletin of the Technical Committee on Ø Ò Ò Ö Ò June 2000 Vol. 23 No. 2 IEEE Computer SocietyLetters Letter from the Editor-in-Chief...................................................... David Lomet 1 Letter fromthe Special Issue Editor...................................................... Alon Levy 2 Special Issue on AdaptiveQuery Processing Dynamic Query Evaluation Plans: Some Course Corrections?.............................. Goetz Graefe 3 Adaptive … Editorial Board Editor-in-Chief David B. Lomet MicrosoftResearch One Microsoft Way; Bldg. 9 Redmond WA 98052-6399 lomet@ microsoft. com AssociateEditors Luis Gravano Computer Science Department Columbia University 1214 Amsterdam AvenueNew York; NY 10027 Alon Levy University of Washington Computer Science and EngineeringDept. Sieg Hall; Room 310 Seattle; WA 98195 Sunita Sarawagi School of Information TechnologyIndian Institute of Technology; Bombay Powai Street Mumbai; India 400076 Gerhard …,*,*,*,22
Ш Ъ ЦЬЧ Шй а з в Ч иЙЪ а и гв а и з ХФ,Zachary G Ives; Michael Carey; Eugene Shekita; Subbu Subramanian; Ying Lu,Abstract Since its introduction; XML; the eXtended Markup Language; has quickly emergedas the universal format for publishing and exchanging data. As a result; data sources;including object-relational databases; are now faced with a new class of users: clients andcustomers who would like to deal directly with XML data rather than being forced to deal withthe data source's particular (eg object-relational) schema and query language. The goal ofthe recently initiated XPERANTO project at the IBM Almaden Research Center is to serve asa middleware layer that supports the publishing of XML data to this class of users. Weprovide a uniform; XML-based query interface over an object-relational database that allowsusers to query and (re) structure XML data; ignoring the underlying SQL tables and querylanguage. In this paper; we present a model for XML query processing and describe the …,*,*,*,10
Scalable Reasoning and Querying for the Semantic Web,Sören Auer; Zachary Ives,ABSTRACT Ontologies; in the OWL language; form the basis of the Semantic Web: theydefine concepts and relationships; and are thus the fundamental model for encodinginformation. As the Semantic Web has been more widely adopted; extremely largeontologies have begun to emerge; particularly in the life sciences. Reasoning about suchontologies requires scalability beyond that of current Description Logic-based reasoningtools. We argue that in many practical settings; the solution to the scalability problem is toexploit relational database systems. Relational queries (views); like Description Logics; arebased on a subset of first-order logic. Many OWL class definitions can be cleanly convertedinto relational view definitions; which; when supplemented with an external operation thatrecomputes multiple views until fixpoint is achieved; can perform inference. We …,*,*,*,7
