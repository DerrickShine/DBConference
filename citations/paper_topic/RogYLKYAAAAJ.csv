Mars: a MapReduce framework on graphics processors,Bingsheng He; Wenbin Fang; Qiong Luo; Naga K Govindaraju; Tuyong Wang,Abstract We design and implement Mars; a MapReduce framework; on graphics processors(GPUs). MapReduce is a distributed programming framework originally proposed by Googlefor the ease of development of web search applications on a large number of commodityCPUs. Compared with CPUs; GPUs have an order of magnitude higher computation powerand memory bandwidth; but are harder to program since their architectures are designed asa special-purpose co-processor and their programming interfaces are typically for graphicsapplications. As the first attempt to harness GPU's power for MapReduce; we developedMars on an NVIDIA G80 GPU; which contains over one hundred processors; and evaluatedit in comparison with Phoenix; the state-of-the-art MapReduce framework on multi-coreCPUs. Mars hides the programming complexity of the GPU behind the simple and familiar …,Proceedings of the 17th international conference on Parallel architectures and compilation techniques,2008,815,12
Relational joins on graphics processors,Bingsheng He; Ke Yang; Rui Fang; Mian Lu; Naga Govindaraju; Qiong Luo; Pedro Sander,Abstract We present a novel design and implementation of relational join algorithms for new-generation graphics processing units (GPUs). The most recent GPU features include supportfor writing to random memory locations; efficient inter-processor communication; and aprogramming model for general-purpose computing. Taking advantage of these newfeatures; we design a set of data-parallel primitives such as split and sort; and use theseprimitives to implement indexed or non-indexed nested-loop; sort-merge and hash joins. Ouralgorithms utilize the high parallelism as well as the high memory bandwidth of the GPU;and use parallel computation and memory optimizations to effectively reduce memory stalls.We have implemented our algorithms on a PC with an NVIDIA G80 GPU and an Intel quad-core CPU. Our GPU-based join algorithms are able to achieve a performance …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,345,12
Relational query coprocessing on graphics processors,Bingsheng He; Mian Lu; Ke Yang; Rui Fang; Naga K Govindaraju; Qiong Luo; Pedro V Sander,Abstract Graphics processors (GPUs) have recently emerged as powerful coprocessors forgeneral purpose computation. Compared with commodity CPUs; GPUs have an order ofmagnitude higher computation power as well as memory bandwidth. Moreover; new-generation GPUs allow writes to random memory locations; provide efficient interprocessorcommunication through on-chip local memory; and support a general purpose parallelprogramming model. Nevertheless; many of the GPU features are specialized for graphicsprocessing; including the massively multithreaded architecture; the Single-Instruction-Multiple-Data processing style; and the execution model of a single application at a time.Additionally; GPUs rely on a bus of limited bandwidth to transfer data to and from the CPU;do not allow dynamic memory allocation from GPU kernels; and have little hardware …,ACM Transactions on Database Systems (TODS),2009,264,18
Leen: Locality/fairness-aware key partitioning for mapreduce in the cloud,Shadi Ibrahim; Hai Jin; Lu Lu; Song Wu; Bingsheng He; Li Qi,This paper investigates the problem of Partitioning Skew in MapReduce-based system. Ourstudies with Hadoop; a widely used MapReduce implementation; demonstrate that thepresence of partitioning skew causes a huge amount of data transfer during the shufflephase and leads to significant unfairness on the reduce input among different data nodes.As a result; the applications experience performance degradation due to the long datatransfer during the shuffle phase along with the computation skew; particularly in reducephase. We develop a novel algorithm named LEEN for locality-aware and fairness-awarekey partitioning in MapReduce. LEEN embraces an asynchronous map and reduce scheme.All buffered intermediate keys are partitioned according to their frequencies and the fairnessof the expected data distribution after the shuffle phase. We have integrated LEEN into …,Cloud Computing Technology and Science (CloudCom); 2010 IEEE Second International Conference on,2010,166,12
Distributed systems meet economics: Pricing in the cloud,Hongyi Wang; Qingfeng Jing; Rishan Chen; Bingsheng He; Zhengping Qian; Lidong Zhou,Abstract Cloud computing allows users to perform computation in a public cloud with apricing scheme typically based on incurred resource consumption. While cloud computing isoften considered as merely a new application for classic distributed systems; we argue that;by decoupling users from cloud providers with a pricing scheme as the bridge; cloudcomputing has fundamentally changed the landscape of system design and optimization.Our preliminary studies on Amazon EC2 cloud service and on a local cloud computingtestbed; have revealed an interesting interplay between distributed systems and economicsrelated to pricing. We believe that this new angle of looking at distributed systems potentiallyfosters new insights into cloud computing.,Proceedings of the 2nd USENIX conference on Hot topics in cloud computing,2010,165,18
Efficient gather and scatter operations on graphics processors,Bingsheng He; Naga K Govindaraju; Qiong Luo; Burton Smith,Abstract Gather and scatter are two fundamental data-parallel operations; where a largenumber of data items are read (gathered) from or are written (scattered) to given locations. Inthis paper; we study these two operations on graphics processing units (GPUs). Withsuperior computing power and high memory bandwidth; GPUs have become a commoditymultiprocessor platform for general-purpose high-performance computing. However; due tothe random access nature of gather and scatter; a naive implementation of the twooperations suffers from a low utilization of the memory bandwidth and consequently a long;unhidden memory latency. Additionally; the architectural details of the GPUs; in particular;the memory hierarchy design; are unclear to the programmers. Therefore; we design multi-pass gather and scatter operations to improve their data access locality; and develop a …,Proceedings of the 2007 ACM/IEEE conference on Supercomputing,2007,149,6
Mars: Accelerating mapreduce with graphics processors,Wenbin Fang; Bingsheng He; Qiong Luo; Naga K Govindaraju,We design and implement Mars; a MapReduce runtime system accelerated with graphicsprocessing units (GPUs). MapReduce is a simple and flexible parallel programmingparadigm originally proposed by Google; for the ease of large-scale data processing onthousands of CPUs. Compared with CPUs; GPUs have an order of magnitude highercomputation power and memory bandwidth. However; GPUs are designed as special-purpose coprocessors and their programming interfaces are less familiar than those on theCPUs to MapReduce programmers. To harness GPUs' power for MapReduce; wedeveloped Mars to run on NVIDIA GPUs; AMD GPUs as well as multicore CPUs.Furthermore; we integrated Mars into Hadoop; an open-source CPU-based MapReducesystem. Mars hides the programming complexity of GPUs behind the simple and familiar …,IEEE Transactions on Parallel and Distributed Systems,2011,139,15
Tree indexing on solid state drives,Yinan Li; Bingsheng He; Robin Jun Yang; Qiong Luo; Ke Yi,Abstract Large flash disks; or solid state drives (SSDs); have become an attractivealternative to magnetic hard disks; due to their high random read performance; low energyconsumption and other features. However; writes; especially small random writes; on flashdisks are inherently much slower than reads because of the erase-before-write mechanism.To address this asymmetry of read-write speeds in tree indexing on the flash disk; wepropose FD-tree; a tree index designed with the logarithmic method and fractionalcascading techniques. With the logarithmic method; an FD-tree consists of the head tree--asmall B+-tree on the top; and a few levels of sorted runs of increasing sizes at the bottom.This design is write-optimized for the flash disk; in particular; an index search will potentiallygo through more levels or visit more nodes; but random writes are limited to a small area …,Proceedings of the VLDB Endowment,2010,132,12
Medusa: Simplified graph processing on GPUs,Jianlong Zhong; Bingsheng He,Graphs are common data structures for many applications; and efficient graph processing isa must for application performance. Recently; the graphics processing unit (GPU) has beenadopted to accelerate various graph processing algorithms such as BFS and shortest paths.However; it is difficult to write correct and efficient GPU programs and even more difficult forgraph processing due to the irregularities of graph structures. To simplify graph processingon GPUs; we propose a programming framework called Medusa which enables developersto leverage the capabilities of GPUs by writing sequential C/C++ code. Medusa offers asmall set of user-defined APIs and embraces a runtime system to automatically executethose APIs in parallel on the GPU. We develop a series of graph-centric optimizations basedon the architecture features of GPUs for efficiency. Additionally; Medusa is extended to …,Parallel and Distributed Systems; IEEE Transactions on,2013,128,12
Database compression on graphics processors,Wenbin Fang; Bingsheng He; Qiong Luo,Abstract Query co-processing on graphics processors (GPUs) has become an effectivemeans to improve the performance of main memory databases. However; this co-processingrequires the data transfer between the main memory and the GPU memory via a low-bandwidth PCI-E bus. The overhead of such data transfer becomes an important factor; evena bottleneck; for query co-processing performance on the GPU. In this paper; we propose touse compression to alleviate this performance problem. Specifically; we implement ninelightweight compression schemes on the GPU and further study the combinations of theseschemes for a better compression ratio. We design a compression planner to find theoptimal combination. Our experiments demonstrate that the GPU-based compression anddecompression achieved a processing speed up to 45 and 56 GB/s respectively. Using …,Proceedings of the VLDB Endowment,2010,124,12
Comet: batched stream processing for data intensive distributed computing,Bingsheng He; Mao Yang; Zhenyu Guo; Rishan Chen; Bing Su; Wei Lin; Lidong Zhou,Abstract Batched stream processing is a new distributed data processing paradigm thatmodels recurring batch computations on incrementally bulk-appended data streams. Themodel is inspired by our empirical study on a trace from a large-scale production data-processing cluster; it allows a set of effective query optimizations that are not possible in atraditional batch processing model. We have developed a query processing system calledComet that embraces batched stream processing and integrates with DryadLINQ. We usedtwo complementary methods to evaluate the effectiveness of optimizations that Cometenables. First; a prototype system deployed on a 40-node cluster shows an I/O reduction ofover 40% using our benchmark. Second; when applied to a real production trace coveringover 19 million machine-hours; our simulator shows an estimated I/O saving of over 50%.,Proceedings of the 1st ACM symposium on Cloud computing,2010,121,12
Tree indexing on flash disks,Yinan Li; Bingsheng He; Qiong Luo; Ke Yi,Large flash disks have become an attractive alternative to magnetic hard disks; due to theirhigh random read performance; low energy consumption and other features. However;writes; especially random writes; on the flash disk are inherently much slower than readsbecause of the erase-before-write mechanism. To address this asymmetry of read-writespeeds in indexing on the flash disk; we propose the FD-tree; a tree index designed with thelogarithmic method and fractional cascading techniques. With the logarithmic method; an FD-tree consists of the head tree–a small B+-tree on the top; and a few levels of sorted runs ofincreasing sizes at the bottom. This design is write-optimized for the flash disk; in particular;an index search will potentially go through more levels or visit more nodes; but randomwrites are limited to the head tree and are subsequently transformed into sequential ones …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,120,12
Parallel data mining on graphics processors,Wenbin Fang; Ka Keung Lau; Mian Lu; Xiangye Xiao; Chi Kit Lam; Philip Yang Yang; Bingsheng He; Qiong Luo; Pedro V Sander; Ke Yang,ABSTRACT We introduce GPUMiner; a novel parallel data mining system that utilizes new-generation graphics processing units (GPUs). Our system relies on the massively multi-threaded SIMD (Single Instruction; Multiple-Data) architecture provided by GPUs. Asspecialpurpose co-processors; these processors are highly optimized for graphics renderingand rely on the CPU for data input/output as well as complex program control. Therefore; wedesign GPUMiner to consist of the following three components:(1) a CPU-based storage andbuffer manager to handle I/O and data transfer between the CPU and the GPU;(2) a GPU-CPU co-processing parallel mining module; and (3) a GPU-based mining visualizationmodule. We design the GPU-CPU co-processing scheme in mining depending on thecomplexity and inherent parallelism of individual mining algorithms. We provide the …,Hong Kong Univ. Sci. and Technology; Hong Kong; China; Tech. Rep. HKUST-CS08-07,2008,117,10
Frequent itemset mining on graphics processors,Wenbin Fang; Mian Lu; Xiangye Xiao; Bingsheng He; Qiong Luo,Abstract We present two efficient Apriori implementations of Frequent Itemset Mining (FIM)that utilize new-generation graphics processing units (GPUs). Our implementations takeadvantage of the GPU's massively multi-threaded SIMD (Single Instruction; Multiple Data)architecture. Both implementations employ a bitmap data structure to exploit the GPU's SIMDparallelism and to accelerate the frequency counting operation. One implementation runsentirely on the GPU and eliminates intermediate data transfer between the GPU memoryand the CPU memory. The other implementation employs both the GPU and the CPU forprocessing. It represents itemsets in a trie; and uses the CPU for trie traversing andincremental maintenance. Our preliminary results show that both implementations achieve aspeedup of up to two orders of magnitude over optimized CPU Apriori implementations …,Proceedings of the Fifth International Workshop on Data Management on New Hardware,2009,109,12
Towards Pay-As-You-Consume Cloud Computing,Shadi Ibrahim; Bingsheng He; Hai Jin,Cloud computing enables users to perform their computation tasks in the public virtualizedcloud using a pay-as-you-go style. Current pay-as-you-go pricing schemes typically chargeon the incurred virtual machine hours. Our case studies demonstrate significant variations inthe user costs; indicating significant unfairness among different users from the micro-economic perspective. Further studies reveal the reason for such variations is interferenceamong concurrent virtual machines. The amount of interference cost depends on variousfactors; including workload characteristics; the number of concurrent VMs; and scheduling inthe cloud. In this paper; we adopt the concept of pricing fairness from micro economics; andquantitatively analyze the impact of interference on the pricing fairness. To solve theunfairness caused by interference; we propose a pay-as-you-consume pricing scheme …,Services Computing (SCC); 2011 IEEE International Conference on,2011,97,12
Revisiting co-processing for hash joins on the coupled cpu-gpu architecture,Jiong He; Mian Lu; Bingsheng He,Abstract Query co-processing on graphics processors (GPUs) has become an effectivemeans to improve the performance of main memory databases. However; the relatively lowbandwidth and high latency of the PCI-e bus are usually bottleneck issues for co-processing.Recently; coupled CPU-GPU architectures have received a lot of attention; eg AMD APUswith the CPU and the GPU integrated into a single chip. That opens up new opportunities foroptimizing query co-processing. In this paper; we experimentally revisit hash joins; one ofthe most important join algorithms for main memory databases; on a coupled CPU-GPUarchitecture. Particularly; we study the fine-grained co-processing mechanisms on hashjoins with and without partitioning. The co-processing outlines an interesting design space.We extend existing cost models to automatically guide decisions on the design space …,Proceedings of the VLDB Endowment,2013,87,5
Large graph processing in the cloud,Rishan Chen; Xuetian Weng; Bingsheng He; Mao Yang,Abstract As the study of graphs; such as web and social graphs; becomes increasinglypopular; the requirements of efficiency and programming flexibility of large graph processingtasks challenge existing tools. We propose to demonstrate Surfer; a large graph processingengine designed to execute in the cloud. Surfer provides two basic primitives forprogrammers-MapReduce and propagation. MapReduce; originally developed by Google;processes different key-value pairs in parallel; and propagation is an iterative computationalpattern that transfers information along the edges from a vertex to its neighbors in the graph.These two primitives are complementary in graph processing. MapReduce is suitable forprocessing flat data structures; such as vertex-oriented tasks; and propagation is optimizedfor edge-oriented tasks on partitioned graphs. To further improve the programmability of …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,86,4
Improving large graph processing on partitioned graphs in the cloud,Rishan Chen; Mao Yang; Xuetian Weng; Byron Choi; Bingsheng He; Xiaoming Li,Abstract As the study of large graphs over hundreds of gigabytes becomes increasinglypopular for various data-intensive applications in cloud computing; developing large graphprocessing systems has become a hot and fruitful research area. Many of those existingsystems support a vertex-oriented execution model and allow users to develop customlogics on vertices. However; the inherently random access pattern on the vertex-orientedcomputation generates a significant amount of network traffic. While graph partitioning isknown to be effective to reduce network traffic in graph processing; there is little attentiongiven to how graph partitioning can be effectively integrated into large graph processing inthe cloud environment. In this paper; we develop a novel graph partitioning framework toimprove the network performance of graph partitioning itself; partitioned graph storage …,Proceedings of the Third ACM Symposium on Cloud Computing,2012,76,19
Maestro: Replica-aware map scheduling for mapreduce,Shadi Ibrahim; Hai Jin; Lu Lu; Bingsheng He; Gabriel Antoniu; Song Wu,Abstract MapReduce has emerged as a leading programming model for data-intensivecomputing. Many recent research efforts have focused on improving the performance of thedistributed frameworks supporting this model. Many optimizations are network-oriented andmost of them mainly address the data shuffling stage of MapReduce. Our studies withHadoop demonstrate that; apart from the shuffling phase; another source of excessivenetwork traffic is the high number of map task executions which process remote data. Thatleads to an excessive number of useless speculative executions of map tasks and to anunbalanced execution of map tasks across different machines. All these factors produce anoticeable performance degradation. We propose a novel scheduling algorithm for maptasks; named Maestro; to improve the overall performance of the MapReduce …,Proceedings of the 2012 12th ieee/acm international symposium on cluster; cloud and grid computing (ccgrid 2012),2012,73,19
NV-Tree: Reducing Consistency Cost for NVM-based Single Level Systems,Jun Yang; Qingsong Wei; Cheng Chen; Chundong Wang; Khai Leong Yong; Bingsheng He,Abstract The non-volatile memory (NVM) has DRAM-like performance and disk-likepersistency which make it possible to replace both disk and DRAM to build single levelsystems. To keep data consistency in such systems is non-trivial because memory writesmay be reordered by CPU and memory controller. In this paper; we study the consistencycost for an important and common data structure; B+Tree. Although the memory fence andCPU cacheline flush instructions can order memory writes to achieve data consistency; theyintroduce a significant overhead (more than 10X slower in performance). Based on ourquantitative analysis of consistency cost; we propose NV-Tree; a consistent and cache-optimized B+Tree variant with reduced CPU cacheline flush. We implement and evaluateNV-Tree and NV-Store; a key-value store based on NV-Tree; on an NVDIMM server. NV …,Proceedings of the 13th USENIX Conference on File and Storage Technologies,2015,71,10
High-throughput transaction executions on graphics processors,Bingsheng He; Jeffrey Xu Yu,Abstract OLTP (On-Line Transaction Processing) is an important business system sector invarious traditional and emerging online services. Due to the increasing number of users;OLTP systems require high throughput for executing tens of thousands of transactions in ashort time period. Encouraged by the recent success of GPGPU (General-Purposecomputation on Graphics Processors); we propose GPUTx; an OLTP engine performing high-throughput transaction executions on the GPU for in-memory databases. Compared withexisting GPGPU studies usually optimizing a single task; transaction executions requirehandling many small tasks concurrently. Specifically; we propose the bulk execution modelto group multiple transactions into a bulk and to execute the bulk on the GPU as a singletask. The transactions within the bulk are executed concurrently on the GPU. We study …,Proceedings of the VLDB Endowment,2011,69,12
GPUQP: query co-processing using graphics processors,Rui Fang; Bingsheng He; Mian Lu; Ke Yang; Naga K Govindaraju; Qiong Luo; Pedro V Sander,Abstract We present GPUQP; a relational query engine that employs both CPUs and GPUs(Graphics Processing Units) for in-memory query co-processing. GPUs are commodityprocessors traditionally designed for graphics applications. Recent research has shown thatthey can accelerate some database operations orders of magnitude over CPUs. So far; therehas been little work on how GPUs can be programmed for heavy-duty database constructs;such as tree indexes and joins; and how well a full-fledged GPU query co-processorperforms in comparison with their CPU counterparts. In this work; we explore the designdecisions in using GPUs for query co-processing using both a graphics API and a generalpurpose programming model. We then demonstrate the processing flows as well as theperformance results of our methods.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,63,3
Kernelet: High-throughput gpu kernel executions with dynamic slicing and scheduling,Jianlong Zhong; Bingsheng He,Graphics processors; or GPUs; have recently been widely used as accelerators in sharedenvironments such as clusters and clouds. In such shared environments; many kernels aresubmitted to GPUs from different users; and throughput is an important metric forperformance and total ownership cost. Despite recently improved runtime support forconcurrent GPU kernel executions; the GPU can be severely underutilized; resulting insuboptimal throughput. In this paper; we propose Kernelet; a runtime system to improve thethroughput of concurrent kernel executions on the GPU. Kernelet embraces transparentmemory management and PCI-e data transfer techniques; and dynamic slicing andscheduling techniques for kernel executions. With slicing; Kernelet divides a GPU kernel intomultiple sub-kernels (namely slices). Each slice has tunable occupancy to allow co …,IEEE Transactions on Parallel and Distributed Systems,2014,60,10
Transformation-based monetary costoptimizations for workflows in the cloud,Amelie Chi Zhou; Bingsheng He,Recently; performance and monetary cost optimizations for workflows from variousapplications in the cloud have become a hot research topic. However; we find that mostexisting studies adopt ad hoc optimization strategies; which fail to capture the keyoptimization opportunities for different workloads and cloud offerings (eg; virtual machineswith different prices). This paper proposes ToF; a general transformation-based optimizationframework for workflows in the cloud. Specifically; ToF formulates six basic workflowtransformation operations. An arbitrary performance and cost optimization process can berepresented as a transformation plan (ie; a sequence of basic transformation operations). Alltransformations form a huge optimization space. We further develop a cost model guidedplanner to efficiently find the optimized transformation for a predefined goal (eg …,IEEE Transactions on Cloud Computing,2014,60,18
Green-aware workload scheduling in geographically distributed data centers,Changbing Chen; Bingsheng He; Xueyan Tang,Renewable (or green) energy; such as solar or wind; has at least partially powered datacenters to reduce the environmental impact of traditional energy sources (brown energy withhigh carbon footprint). In this paper; we propose a holistic workload scheduling algorithm tominimize the brown energy consumption across multiple geographically distributed datacenters with renewable energy sources. While green energy supply for a single data centeris intermittent due to daily/seasonal effects; our workload scheduling algorithm is aware ofdifferent amounts of green energy supply and dynamically schedules the workload acrossdata centers. The scheduling decision adapts to workload and data center coolingdynamics. Our experiments with real workload traces demonstrate that our schedulingalgorithm greatly reduces brown energy consumption by up to 40% in comparison with …,Cloud Computing Technology and Science (CloudCom); 2012 IEEE 4th International Conference on,2012,57,12
Adaptive Disk I/O Scheduling for MapReduce in Virtualized Environment,Shadi Ibrahim; Hai Jin; Lu Lu; Bingsheng He; Song Wu,Virtual machine (VM) interference has long been a challenging problem for performancepredictability and system throughput for large-scale virtualized environments in the cloud.Such interferences are contributed by intertwined factors including the application's type; thenumber of con current VMs; and the VM scheduling algorithms used within the host. SinceMapReduce has become an important data processing platform in the cloud; we investigatethe impact of disk schedulers in Hadoop. Interestingly; our experimental results report anoticeable variation of the Hadoop performance between different applications whenapplying different disk pairs' schedulers in both the hypervisor and the virtual machines.Furthermore; a typical Hadoop application consists of different interleaving stages; eachrequiring different I/O workloads and patterns. As a result; the disk pairs' schedulers are …,Parallel Processing (ICPP); 2011 International Conference on,2011,55,18
Dynamicmr: A dynamic slot allocation optimization framework for mapreduce clusters,Shanjiang Tang; Bu-Sung Lee; Bingsheng He,MapReduce is a popular computing paradigm for large-scale data processing in cloudcomputing. However; the slot-based MapReduce system (eg; Hadoop MRv1) can suffer frompoor performance due to its unoptimized resource allocation. To address it; this paperidentifies and optimizes the resource allocation from three key aspects. First; due to the pre-configuration of distinct map slots and reduce slots which are not fungible; slots can beseverely under-utilized. Because map slots might be fully utilized while reduce slots areempty; and vice-versa. We propose an alternative technique called Dynamic HadoopSlotAllocation by keeping the slot-based model. It relaxes the slot allocation constraint toallow slots to be reallocated to either map or reduce tasks depending on their needs.Second; the speculative execution can tackle the straggler problem; which has shown to …,IEEE Transactions on Cloud Computing,2014,54,5
Optimizing the MapReduce Framework on Intel Xeon Phi Coprocessor,Mian Lu; Lei Zhang; Huynh Phung Huynh; Zhongliang Ong; Yun Liang; Bingsheng He; Rick Siow Mong Goh; Richard Huynh,MapReduce has become one of the most popular framework for building big-dataapplications. It was originally designed for distributed-computing; and has been extended tovarious hardware architectures; eg; multi-core CPUs; GPUs and FPGAs. In this work; wedevelop the first MapReduce framework on the recently released Intel Xeon Phicoprocessor. We utilize advanced features of the Xeon Phi to achieve high performance. Inorder to take advantage of the SIMD vector processing units; we propose a vectorizationfriendly technique to assist the auto-vectorization as well as develop SIMD hashcomputation algorithms. Furthermore; we utilize MIMD hyper-threading to pipeline the mapand reduce phases to improve the resource utilization. We also eliminate multiple localarrays but use low cost atomic operations on the global array for some applications …,arXiv preprint arXiv:1309.0215,2013,52,21
A survey of resource management in multi-tier web applications,Dong Huang; Bingsheng He; Chunyan Miao,Web applications are mostly designed with multiple tiers for flexibility and softwarereusability. It is difficult to model the behavior of multi-tier Web applications due to the factthat the workload is dynamic and unpredictable and the resource demand in each tier isdifferent. Those features also cause the task of resource allocation for multi-tier Webapplications very challenging. In order to meet service level agreements (SLAs) with minimalresource costs; Web service providers should dynamically allocate appropriate resources toeach tier. This is particularly important to minimize the monetary cost in the pay-as-you-gocloud computing environments. Recently; a number of rule and model based approacheshave been proposed for resource provisioning in cloud computing. In this survey; we identifychallenges of the resource allocation problem and conduct a comparative review on …,IEEE Communications Surveys & Tutorials,2014,48,12
Improving main memory hash joins on Intel Xeon Phi processors: An experimental approach,Saurabh Jha; Bingsheng He; Mian Lu; Xuntao Cheng; Huynh Phung Huynh,Abstract Modern processor technologies have driven new designs and implementations inmain-memory hash joins. Recently; Intel Many Integrated Core (MIC) co-processors(commonly known as Xeon Phi) embrace emerging x86 single-chip many-core techniques.Compared with contemporary multi-core CPUs; Xeon Phi has quite different architecturalfeatures: wider SIMD instructions; many cores and hardware contexts; as well as lower-frequency in-order cores. In this paper; we experimentally revisit the state-of-the-art hashjoin algorithms on Xeon Phi co-processors. In particular; we study two camps of hash joinalgorithms: hardware-conscious ones that advocate careful tailoring of the join algorithms tounderlying hardware architectures and hardware-oblivious ones that omit such carefultailoring. For each camp; we study the impact of architectural features and software …,Proceedings of the VLDB Endowment,2015,45,21
Supporting extended precision on graphics processors,Mian Lu; Bingsheng He; Qiong Luo,Abstract Scientific computing applications often require support for non-traditional datatypes; for example; numbers with a precision higher than 64-bit floats. As graphicsprocessors; or GPUs; have emerged as a powerful accelerator for scientific computing; wedesign and implement a GPU-based extended precision library to enable applications withhigh precision requirement to run on the GPU. Our library contains arithmetic operators;mathematical functions; and data-parallel primitives; each of which can operate at eithermulti-term or multi-digit precision. The multi-term precision maintains an accuracy of up to212 bits of signifcand whereas the multi-digit precision allows an accuracy of an arbitrarynumber of bits. Additionally; we have integrated the extended precision algorithms to a GPU-based query processing engine to support efficient query processing with extended …,Proceedings of the Sixth International Workshop on Data Management on New Hardware,2010,45,0
Vmbuddies: Coordinating live migration of multi-tier applications in cloud environments,Haikun Liu; Bingsheng He,Enabled by virtualization technologies; various multi-tier applications (such as webapplications) are hosted by virtual machines (VMs) in cloud data centers. Live migration ofmulti-tier applications across geographically distributed data centers is important for loadmanagement; power saving; routine server maintenance and quality-of-service. Differentfrom a single-VM migration; VMs in a multi-tier application are closely correlated; whichresults in a correlated VM migrations problem. Current live migration algorithms for single-VM cause significant application performance degradation because intermediate dataexchange between different VMs suffers relatively low bandwidth and high latency acrossdistributed data centers. In this paper; we design and implement a coordination systemcalled VMbuddies for correlated VM migrations in the cloud. Particularly; we propose an …,IEEE Transactions on Parallel and Distributed Systems,2015,44,21
In-cache query co-processing on coupled CPU-GPU architectures,Jiong He; Shuhao Zhang; Bingsheng He,Abstract Recently; there have been some emerging processor designs that the CPU and theGPU (Graphics Processing Unit) are integrated in a single chip and share Last Level Cache(LLC). However; the main memory bandwidth of such coupled CPU-GPU architectures canbe much lower than that of a discrete GPU. As a result; current GPU query co-processingparadigms can severely suffer from memory stalls. In this paper; we propose a novel in-cache query co-processing paradigm for main memory On-Line Analytical Processing(OLAP) databases on coupled CPU-GPU architectures. Specifically; we adapt CPU-assistedprefetching to minimize cache misses in GPU query co-processing and CPU-assisteddecompression to improve query execution performance. Furthermore; we develop a costmodel guided adaptation mechanism for distributing the workload of prefetching …,Proceedings of the VLDB Endowment,2014,44,18
Operation-aware buffer management in flash-based systems,Yanfei Lv; Bin Cui; Bingsheng He; Xuexuan Chen,Abstract The inherent asymmetry of read and write speeds of flash memory poses greatchallenges for buffer management design. Most of existing flash-based buffer managementpolicies adopt disk-oriented strategies by giving a specific priority to dirty pages; while notfully exploiting the characteristics of the flash memory. In this paper; we propose a novelbuffer replacement algorithm named FOR; which stands for Flash-based Operation-awarebuffer Replacement. The core idea of FOR is based on novel operation-aware page weightdetermination for buffer replacement. The weight metric not only measures the locality ofread/write operations on a page; but also takes the cost difference of read/write operationsinto account. We further develop an efficient implementation FOR+ with the time complexityof O (1) for each operation. Experiments on synthetic and benchmark traces demonstrate …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,41,21
Cache-oblivious databases: Limitations and opportunities,Bingsheng He; Qiong Luo,Abstract Cache-oblivious techniques; proposed in the theory community; have optimalasymptotic bounds on the amount of data transferred between any two adjacent levels of anarbitrary memory hierarchy. Moreover; this optimal performance is achieved without anyhardware platform specific tuning. These properties are highly attractive to autonomousdatabases; especially because the hardware architectures are becoming increasinglycomplex and diverse. In this article; we present our design; implementation; and evaluationof the first cache-oblivious in-memory query processor; EaseDB. Moreover; we discuss theinherent limitations of the cache-oblivious approach as well as the opportunities given by theupcoming hardware architectures. Specifically; a cache-oblivious technique usually requiressophisticated algorithm design to achieve a comparable performance to its cache …,ACM Transactions on Database Systems (TODS),2008,41,21
Omnidb: Towards portable and efficient query processing on parallel cpu/gpu architectures,Shuhao Zhang; Jiong He; Bingsheng He; Mian Lu,Abstract Driven by the rapid hardware development of parallel CPU/GPU architectures; wehave witnessed emerging relational query processing techniques and implementations onthose parallel architectures. However; most of those implementations are not portableacross different architectures; because they are usually developed from scratch and target ata specific architecture. This paper proposes a kernel-adapter based design (OmniDB); aportable yet efficient query processor on parallel CPU/GPU architectures. OmniDB attemptsto develop an extensible query processing kernel (qKernel) based on an abstract model forparallel architectures; and to leverage an architecture-specific layer (adapter) to makeqKernel be aware of the target architecture. The goal of OmniDB is to maximize the commonfunctionality in qKernel so that the development and maintenance efforts for adapters are …,Proceedings of the VLDB Endowment,2013,40,19
PCMLogging: reducing transaction logging overhead with PCM,Shen Gao; Jianliang Xu; Bingsheng He; Byron Choi; Haibo Hu,Abstract Phase Changing Memory (PCM); as one of the most promising next-generationmemory technologies; offers various attractive properties such as non-volatility; bit-alterability; and low idle energy consumption. In this paper; we present PCMLogging; anovel logging scheme that exploits PCM devices for both data buffering and transactionlogging in disk-based databases. Different from the traditional approach where bufferedupdates and transaction logs are completely separated; they are integrated in the newlogging scheme. Our preliminary experiments show an up to 40% improvement ofPCMLogging in disk I/O performance in comparison with a basic buffering and loggingscheme.,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,39,19
Network Performance Aware MPI Collective Communication Operations in the Cloud,Yifan Gong; Bingsheng He; Jianlong Zhong,This paper examines the performance of collective communication operations in messagepassing interfaces (MPI) in the cloud computing environment. The awareness of networktopology has been a key factor in performance optimizations for existing MPIimplementations. However; virtualization in the cloud environment not only hides thenetwork topology information from the users; but also causes traffic interference anddynamics to network performance. Existing topology-aware optimizations are no longerfeasible in the cloud environment. Therefore; we develop novel network performance awarealgorithms for a series of collective communication operations including broadcast; reduce;gather and scatter. We further implement two common applications; N-body and conjugategradient (CG). We have conducted our experiments with two complementary methods (on …,IEEE Transactions on Parallel and Distributed Systems,2013,34,1
Cache-conscious automata for XML filtering,Bingsheng He; Qiong Luo; Byron Choi,Hardware cache behavior is an important factor in the performance of memory-resident; data-intensive systems such as XML filtering engines. A key data structure in several recent XMLfilters is the automaton; which is used to represent the long-running XML queries in the mainmemory. In this paper; we study the cache performance of automaton-based XML filteringthrough analytical modeling and system measurement. Furthermore; we propose a cache-conscious automaton organization technique; called the hot buffer; to improve the locality ofautomaton state transitions. Our results show that 1) our cache performance model for XMLfiltering automata is highly accurate and 2) the hot buffer improves the cache performanceas well as the overall performance of automaton-based XML filtering,IEEE transactions on knowledge and data engineering,2006,33,12
A combined SDC-SDF architecture for normal I/O pipelined radix-2 FFT,Zeke Wang; Xue Liu; Bingsheng He; Feng Yu,We present an efficient combined single-path delay commutator-feedback (SDC-SDF) radix-2 pipelined fast Fourier transform architecture; which includes log 2 N-1 SDC stages; and 1SDF stage. The SDC processing engine is proposed to achieve 100% hardware resourceutilization by sharing the common arithmetic resource in the time-multiplexed approach;including both adders and multipliers. Thus; the required number of complex multipliers isreduced to log 4 N-0.5; compared with log 2 N-1 for the other radix-2 SDC/SDFarchitectures. In addition; the proposed architecture requires roughly minimum number ofcomplex adders log 2 N+ 1 and complex delay memory 2N+ 1.5 log 2 N-1.5.,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,2015,30,12
Reciprocal resource fairness: Towards cooperative multiple-resource fair sharing in iaas clouds,Haikun Liu; Bingsheng He,Abstract Resource sharing in virtualized environments have been demonstrated significantbenefits to improve application performance and resource/energy efficiency. However;resource sharing; especially for multiple resource types; poses several severe andchallenging problems in pay-as-you-use cloud environments; such as sharing incentive; free-riding; lying and economic fairness. To address those problems; we propose ReciprocalResource Fairness (RRF); a novel resource allocation mechanism to enable fair sharingmultiple types of resource among multiple tenants in new-generation cloud environments.RRF implements two complementary and hierarchical mechanisms for resource sharing:inter-tenant resource trading and intra-tenant weight adjustment. We show that RRF satisfiesseveral highly desirable properties to ensure fairness. Experimental results show that …,Proceedings of the International Conference for High Performance Computing; Networking; Storage and Analysis,2014,29,12
Handling partitioning skew in mapreduce using leen,Shadi Ibrahim; Hai Jin; Lu Lu; Bingsheng He; Gabriel Antoniu; Song Wu,Abstract MapReduce is emerging as a prominent tool for big data processing. Data locality isa key feature in MapReduce that is extensively leveraged in data-intensive cloud systems: itavoids network saturation when processing large amounts of data by co-allocatingcomputation and data storage; particularly for the map phase. However; our studies withHadoop; a widely used MapReduce implementation; demonstrate that the presence ofpartitioning skew (Partitioning skew refers to the case when a variation in either theintermediate keys' frequencies or their distributions or both among different data nodes)causes a huge amount of data transfer during the shuffle phase and leads to significantunfairness on the reduce input among different data nodes. As a result; the applicationssevere performance degradation due to the long data transfer during the shuffle phase …,Peer-to-Peer Networking and Applications,2013,29,13
Monetary Cost Optimizations for Hosting Workflow-as-a-Service in IaaS Clouds,Amelie Chi Zhou; Bingsheng He,Recently; we have witnessed workflows from science and other data-intensive applicationsemerging on Infrastructure-as-a-Service (IaaS) clouds; and many workflow service providersoffering workflow-as-a-service (WaaS). The major concern of WaaS providers is to minimizethe monetary cost of executing workflows in the IaaS clouds. The selection of virtualmachines (instances) types significantly affects the monetary cost and performance ofrunning a workflow. Moreover; IaaS cloud environment is dynamic; with high performancedynamics caused by the interference from concurrent executions and price dynamics likespot prices offered by Amazon EC2. Therefore; we argue that WaaS providers should havethe notion of offering probabilistic performance guarantees for individual workflows toexplicitly expose the performance and cost dynamics of IaaS clouds to users. We develop …,*,2015,27,12
Flag commit: Supporting efficient transaction recovery in flash-based dbmss,Sai Tung On; Jianliang Xu; Byron Choi; Haibo Hu; Bingsheng He,Owing to recent advances in semiconductor technologies; flash disks have been acompetitive alternative to traditional magnetic disks as external storage media. In this paper;we study how transaction recovery can be efficiently supported in database managementsystems (dbmss) running on slc flash disks. Inspired by the classical shadow-pagingapproach; we propose a new commit scheme; called flagcommit; to exploit the uniquecharacteristics of flash disks such as fast random read access; out-place updating; andpartial page programming. To minimize the need of writing log records; we embed thetransaction status into flash pages through a chain of commit flags. Based on flagcommit; wedevelop two recovery protocols; namely commit-based flag commit (cfc) and abort-basedflag commit (afc); to meet different performance needs. They are flexible to support no …,IEEE Transactions on Knowledge and Data Engineering,2012,26,10
Optimal sensor placement and measurement of wind for water quality studies in urban reservoirs,Wan Du; Zikun Xing; Mo Li; Bingsheng He; Lloyd Hock Chye Chua; Haiyan Miao,Abstract We collaborate with environmental scientists to study the hydrodynamics and waterquality in an urban district; where the surface wind distribution is an essential input butundergoes high spatial and temporal variations due to the complex urban landform createdby surrounding buildings. In this work; we study an optimal sensor placement scheme tomeasure the wind distribution over a large urban reservoir with a limited number of windsensors. Unlike existing sensor placement solutions that assume Gaussian process of targetphenomena; this study measures the wind which inherently exhibits strong non-Gaussianyearly distribution. By leveraging the local monsoon characteristics of wind; we segment ayear into different monsoon seasons which follow a unique distribution respectively. We alsouse computational fluid dynamics to learn the spatial correlation of wind in the presence …,Proceedings of the 13th international symposium on Information processing in sensor networks,2014,24,5
Long-term resource fairness: towards economic fairness on pay-as-you-use computing systems,Shanjiang Tang; Bu-sung Lee; Bingsheng He; Haikun Liu,Abstract Fair resource allocation is a key building block of any shared computing system.However; MemoryLess Resource Fairness (MLRF); widely used in many existingframeworks such as YARN; Mesos and Dryad; is not suitable for pay-as-you-use computing.To address this problem; this paper proposes Long-Term Resource Fairness (LTRF); anovel fair resource allocation mechanism. We show that LTRF satisfies several highlydesirable properties. First; LTRF incentivizes clients to share resources via group-buying byensuring that no client is better off in a computing system that she buys and usesindividually. Second; LTRF incentivizes clients to submit non-trivial workloads and be willingto yield unneeded resources to others. Third; LTRF has a resource-as-you-pay fairnessproperty; which ensures the amount of resources that each client should get according to …,Proceedings of the 28th ACM international conference on Supercomputing,2014,23,21
RAMZzz: Rank-aware DRAM power management with dynamic migrations and demotions,Donghong Wu; Bingsheng He; Xueyan Tang; Jianliang Xu; Minyi Guo,Main memory is a significant energy consumer which may contribute to over 40% of the totalsystem power; and will become more significant for server machines with more mainmemory. In this paper; we propose a novel memory system design named RAMZzz with rank-aware energy saving optimizations. Specifically; we rely on a memory controller to monitorthe memory access locality; and group the pages with similar access locality into the samerank. We further develop dynamic page migrations to adapt to data access patterns; and aprediction model to estimate the demotion time for accurate control on power statetransitions. We experimentally compare our algorithm with other energy saving policies withcycle-accurate simulation. Experiments with benchmark workloads show that RAMZzzachieves significant improvement on energy-delay2 and energy consumption over other …,High Performance Computing; Networking; Storage and Analysis (SC); 2012 International Conference for,2012,23,19
Cache-oblivious query processing,Bingsheng He; Qiong Luo,Abstract As CPU caches have become a performance bottleneck for main memorydatabases; optimizing the cache performance is essential for high-performance queryprocessing on relational databases. Cache-oblivious techniques; proposed by the theorycommunity; have optimal asymptotic bounds on the amount of data transferred between anytwo adjacent levels of an arbitrary memory hierarchy. Moreover; this optimal performance isachieved without any hardware platform specific tuning. These properties are highlyattractive to autonomous databases; especially because the hardware architectures arebecoming increasingly complex and diverse.,CIDR,2007,23,10
Mrphi: An optimized mapreduce framework on intel xeon phi coprocessors,Mian Lu; Yun Liang; Huynh Phung Huynh; Zhongliang Ong; Bingsheng He; Rick Siow Mong Goh,In this work; we develop MrPhi; an optimized MapReduce framework on a heterogeneouscomputing platform; particularly equipped with multiple Intel Xeon Phi coprocessors. To thebest of our knowledge; this is the first work to optimize the MapReduce framework on theXeon Phi. We first focus on employing advanced features of the Xeon Phi to achieve highperformance on a single coprocessor. We propose a vectorization friendly technique andSIMD hash computation algorithms to utilize the SIMD vectors. Then we pipeline the mapand reduce phases to improve the resource utilization. Furthermore; we eliminate multiplelocal arrays but use low cost atomic operations on the global array to improve the threadscalability. For a given application; our framework is able to automatically detect suitabletechniques to apply. Moreover; we extend our framework to a heterogeneous platform to …,IEEE Transactions on Parallel and Distributed Systems,2015,21,10
Dynamic job ordering and slot configurations for MapReduce workloads,Shanjiang Tang; Bu-Sung Lee; Bingsheng He,MapReduce is a popular parallel computing paradigm for large-scale data processing inclusters and data centers. A MapReduce workload generally contains a set of jobs; each ofwhich consists of multiple map tasks followed by multiple reduce tasks. Due to 1) that maptasks can only run in map slots and reduce tasks can only run in reduce slots; and 2) thegeneral execution constraints that map tasks are executed before reduce tasks; different jobexecution orders and map/reduce slot configurations for a MapReduce workload havesignificantly different performance and system utilization. This paper proposes two classes ofalgorithms to minimize the makespan and the total completion time for an offlineMapReduce workload. Our first class of algorithms focuses on the job ordering optimizationfor a MapReduce workload under a given map/reduce slot configuration. In contrast; our …,IEEE Transactions on Services Computing,2016,19,12
Dynamic slot allocation technique for MapReduce clusters,Shanjiang Tang; Bu-Sung Lee; Bingsheng He,MapReduce is a popular parallel computing paradigm for large-scale data processing inclusters and data centers. However; the slot utilization can be low; especially when HadoopFair Scheduler is used; due to the pre-allocation of slots among map and reduce tasks; andthe order that map tasks followed by reduce tasks in a typical MapReduce environment. Toaddress this problem; we propose to allow slots to be dynamically (re) allocated to eithermap or reduce tasks depending on their actual requirement. Specifically; we have proposedtwo types of Dynamic Hadoop Fair Scheduler (DHFS); for two different levels of fairness (ie;cluster and pool level). The experimental results show that the proposed DHFS can improvethe system performance significantly (by 32%~ 55% for a single job and 44%~ 68% formultiple jobs) while guaranteeing the fairness.,Cluster Computing (CLUSTER); 2013 IEEE International Conference on,2013,19,12
Cache-oblivious nested-loop joins,Bingsheng He; Qiong Luo,Abstract We propose to adapt the newly emerged cache-oblivious model to relational queryprocessing. Our goal is to automatically achieve an overall performance comparable to thatof fine-tuned algorithms on a multi-level memory hierarchy. This automaticity is becausecache-oblivious algorithms assume no knowledge about any specific parameter values;such as the capacity and block size of each level of the hierarchy. As a first step; we proposerecursive partitioning to implement cache-oblivious nested-loop joins (NLJs) withoutindexes; and recursive clustering and buffering to implement cache-oblivious NLJs withindexes. Our theoretical results and empirical evaluation on three different architecturesshow that our cache-oblivious NLJs match the performance of their manually optimized;cache-conscious counterparts.,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,18,10
A performance analysis framework for optimizing OpenCL applications on FPGAs,Zeke Wang; Bingsheng He; Wei Zhang; Shunning Jiang,Recently; FPGA vendors such as Altera and Xilinx have released OpenCL SDK forprogramming FPGAs. However; the architecture of FPGA is significantly different from that ofCPU/GPU; for which OpenCL is originally designed. Tuning the OpenCL code for goodperformance on FPGAs is still an open problem; since the existing OpenCL tools andmodels designed for CPUs/GPUs are not directly applicable to FPGAs. In the paper; wepresent an FPGA-based performance analysis framework that can shed light on theperformance bottleneck and thus guide the code tuning for OpenCL applications on FPGAs.Particularly; we leverage static and dynamic analysis to develop an analytical performancemodel; which has captured the key architectural features of FPGA abstractions underOpenCL. Then; we provide four programmer-interpretable metrics to quantify the …,High Performance Computer Architecture (HPCA); 2016 IEEE International Symposium on,2016,17,0
Hotplug or ballooning: A comparative study on dynamic memory management techniques for virtual machines,Haikun Liu; Hai Jin; Xiaofei Liao; Wei Deng; Bingsheng He; Cheng-zhong Xu,In virtualization environments; static memory allocation for virtual machines (VMs) can leadto severe service level agreement (SLA) violations or inefficient use of memory. Dynamicmemory allocation mechanisms such as ballooning and memory hotplug were proposed tohandle the dynamics of memory demands. However; these mechanisms so far have notbeen quantitatively or comparatively studied. In this paper; we first develop a runtime systemcalled U-tube; which provides a framework to adopt memory hotplug or ballooning fordynamic memory allocation. We then implement fine-grained memory hotplug in Xen. Wedemonstrate the effectiveness of U-tube for dynamic memory management through two casestudies: dynamic memory balancing and memory overcommitment. With these two casestudies; we make a quantitative comparison between memory hotplug and ballooning …,IEEE Transactions on Parallel and Distributed Systems,2015,17,3
Wave computing in the cloud,Bingsheng He; Mao Yang; Zhenyu Guo; Rishan Chen; Wei Lin; Bing Su; Hongyi Wang; Lidong Zhou,Abstract: We introduce the new Wave model for exposing the temporal relationship amongthe queries in data-intensive distributed computing. The model defines the notion of queryseries to capture the recurrent nature of batched computation on periodically updated inputstreams. This seemingly simple concept captures a significant portion of the queries weobserved in a production system. The recurring nature of the computation on the same inputstream opens up surprisingly significant opportunities for achieving better performance andhigher resource utilization.,Proceedings of the 12th conference on Hot topics in operating systems,2009,17,12
A study of data partitioning on OpenCL-based FPGAs,Zeke Wang; Bingsheng He; Wei Zhang,A lot of research efforts have been devoted to accelerating relational database applicationson FPGAs; due to their high energy efficiency and high throughput. Most of the existingstudies are based on hardware description languages (HDLs). Recently; FPGA vendorshave started to develop OpenCL SDKs for much better programmability. In this paper; weinvestigate the performance of relational database applications on OpenCL-based FPGAs.As a start; we study the performance of data partitioning; a core operation widely used inrelational databases. Due to random memory accesses; data partitioning is time-consumingand can become a major bottleneck for database operators such as hash join. We start withthe state-of-the-art OpenCL implementation which was originally designed for CPUs/GPUs;and find that it suffers from lock overheads and memory bandwidth overheads. To reduce …,Field Programmable Logic and Applications (FPL); 2015 25th International Conference on,2015,16,16
Real-time in-memory checkpointing for future hybrid memory systems,Shen Gao; Bingsheng He; Jianliang Xu,Abstract In this paper; we study real-time in-memory checkpointing as an effective means toimprove the reliability of future large-scale parallel processing systems. Under this context;the checkpoint overhead can become a significant performance bottleneck. Novel memorysystem designs with upcoming non-volatile random access memory (NVRAM) technologiesare emerging to address this performance issue. However; we find that those designs canstill have prohibitively high checkpoint overhead and system downtime; especially whencheckpoints are taken frequently to implement a reliable system. In this paper; we propose anovel in-memory checkpointing system; named Mona; for reducing the checkpoint overheadof hybrid memory systems with NVRAM and DRAM. To minimize the in-memory checkpointoverhead; Mona dynamically writes partial checkpoints from DRAM to NVRAM during …,Proceedings of the 29th ACM on International Conference on Supercomputing,2015,16,12
In-memory grid files on graphics processors,Ke Yang; Bingsheng He; Rui Fang; Mian Lu; Naga Govindaraju; Qiong Luo; Pedro Sander; Jiaoying Shi,Abstract Recently; graphics processing units; or GPUs; have become a viable alternative ascommodity; parallel hardware for general-purpose computing; due to their massive data-parallelism; high memory bandwidth; and improved general-purpose programminginterface. In this paper; we explore the use of GPU on the grid file; a traditionalmultidimensional access method. Considering the hardware characteristics of GPUs; wedesign a massively multi-threaded GPU-based grid file for static; memory-residentmultidimensional point data. Moreover; we propose a hierarchical grid file variant to handledata skews efficiently. Our implementations on the NVIDIA G80 GTX graphics card are ableto achieve two to eight times' higher performance than their CPU counterparts on a singlePC.,Proceedings of the 3rd international workshop on Data management on new hardware,2007,16,18
Towards GPU-Accelerated Large-Scale Graph Processing in the Cloud,Jianlong Zhong; Bingsheng He,Recently; we have witnessed that cloud providers start to offer heterogeneous computingenvironments. There have been wide interests in both clusters and cloud of adoptinggraphics processors (GPUs) as accelerators for various applications. On the other hand;large-scale graph processing is important for many data-intensive applications in the cloud.In this paper; we propose to leverage GPUs to accelerate large-scale graph processing inthe cloud. Specifically; we develop an in-memory graph processing engine G2 with threenon-trivial GPU-specific optimizations. Firstly; we adopt fine-grained APIs to take advantageof the massive thread parallelism of the GPU. Secondly; G2 embraces a graph partitionbased approach for load balancing on heterogeneous CPU/GPU architectures. Thirdly; aruntime system is developed to perform transparent memory management on the GPU …,Cloud Computing Technology and Science (CloudCom); 2013 IEEE 5th International Conference on,2013,15,12
Green Databases Through Integration of Renewable Energy,Cheng Chen; Bingsheng He; Xueyan Tang; Changbing Chen; Yubao Liu,ABSTRACT Recently; a lot of energy efficient techniques have been developed to reducethe usage of the carbon intensive energy (brown energy) of databases. There is a newopportunity to reduce the brown energy usage: renewable energy (green energy) has beenused to at least partially power computer systems. The key challenge of exploiting greenenergy sources is that they are variable and intermittent. So far; there has been little work onintegrating renewable energy into a database system. This paper attempts to bridge this gapwith ReinDB (Renewable Energy Integrated Database). The design goal of ReinDB is tominimize the brown energy consumption on a database server with both green and brownenergy supplies. Specifically; we develop the green supply driven execution paradigm andadaptive power management techniques to adapt to green energy supply. We further …,Proc of CIDR,2013,15,8
Optimization of asynchronous graph processing on GPU with hybrid coloring model,Xuanhua Shi; Junling Liang; Sheng Di; Bingsheng He; Hai Jin; Lu Lu; Zhixiang Wang; Xuan Luo; Jianlong Zhong,Abstract Modern GPUs have been widely used to accelerate the graph processing forcomplicated computational problems regarding graph theory. Many parallel graphalgorithms adopt the asynchronous computing model to accelerate the iterativeconvergence. Unfortunately; the consistent asynchronous computing requires locking or theatomic operations; leading to significant penalties/overheads when implemented on GPUs.To this end; coloring algorithm is adopted to separate the vertices with potential updatingconflicts; guaranteeing the consistency/correctness of the parallel processing. We propose alight-weight asynchronous processing framework called Frog with a hybrid coloring model.We find that majority of vertices (about 80%) are colored with only a few colors; such thatthey can be read and updated in a very high degree of parallelism without violating the …,Proceedings of the 20th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming,2015,14,5
Parallel graph processing on graphics processors made easy,Jianlong Zhong; Bingsheng He,Abstract This paper demonstrates Medusa; a programming framework for parallel graphprocessing on graphics processors (GPUs). Medusa enables developers to leverage themassive parallelism and other hardware features of GPUs by writing sequential C/C++ codefor a small set of APIs. This simplifies the implementation of parallel graph processing on theGPU. The runtime system of Medusa automatically executes the user-defined APIs inparallel on the GPU; with a series of graph-centric optimizations based on the architecturefeatures of GPUs. We will demonstrate the steps of developing GPU-based graphprocessing algorithms with Medusa; and the superior performance of Medusa with both real-world and synthetic datasets.,Proceedings of the VLDB Endowment,2013,14,18
Melia: A MapReduce Framwork on OpenCL-based FPGAs,Zekewang; Shuhao Zhang; Bingsheng He; Wei Zhang,*,IEEE TPDS,2016,13
Willow: saving data center network energy for network-limited flows,Dan Li; Yirong Yu; Wu He; Kai Zheng; Bingsheng He,Today's giant data centers are power hungry. Data center energy saving not only helpscontrol the operational cost; but also benefits the sustainable growth of cloud services. Dueto the adoption of much more switches in modern data centers as well as the mature server-side power management techniques; energy saving for the data center network is becomingincreasingly important. Most previous works on saving data center network energy focus onaggregating flows to as few switches as possible. However; in this paper we argue that thismethod may not work for network-limited flows; the throughputs of which are elastic basedon the competing flows. To save the network energy consumed by this kind of elastic flows;we propose a flow scheduling approach called Willow; which takes both the number ofswitches involved and their active working durations into consideration. We formulate this …,IEEE Transactions on Parallel and Distributed Systems,2015,13,4
F2C: Enabling Fair and Fine-grained Resource Sharing in Multi-tenant IaaS Clouds,Haikun Liu; Bingsheng He,This paper presents F2C; a cooperative resource management system for Infrastructure-as-a-Service (IaaS) clouds. Inspired by group-buying mechanisms in real product and servicemarkets; F2C advocates a group of cloud tenants (called tenant coalition) to buy resourcecapacity in bulk and share the resource pool in the form of virtual machines (VMs). Tenantcoalitions leads to vast opportunities for fine-grained resource sharing among multipletenants. However; resource sharing; especially for multiple resource types; poses severalchallenging problems in pay-as-you-use cloud environments; such as sharing incentive; free-riding; lying and economic fairness. To address those problems; we propose ReciprocalResource Fairness (RRF); a novel resource allocation mechanism to enable fair sharing onmultiple resource types within a tenant coalition. RRF is implemented in two …,IEEE Transactions on Parallel & Distributed Systems,2015,13,3
FD-buffer: a buffer manager for databases on flash disks,Sai Tung On; Yinan Li; Bingsheng He; Ming Wu; Qiong Luo; Jianliang Xu,Abstract We design and implement FD-Buffer; a buffer manager for database systemsrunning on flash-based disks. Unlike magnetic disks; flash media has an inherent read-writeasymmetry: writes involve expensive erase operations and as a result are usually muchslower than reads. Therefore; we address this asymmetry in FD-Buffer. Specifically; we usethe average I/O cost per page access as opposed to the traditional miss rate as theperformance metric for a buffer. We develop a new replacement policy in which we separateclean and dirty pages into two pools. The size ratio of the two pools is automatically adaptedto the read-write asymmetry and the runtime workload. We evaluate FD-Buffer with trace-driven experiments on real flash disks. Our evaluation results show that our algorithmachieves up to 33% improvement on the overall performance on commodity flash disks; in …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,13,21
Accurate emulation of wireless sensor networks,Hejun Wu; Qiong Luo; Pei Zheng; Bingsheng He; Lionel M Ni,Abstract Wireless sensor networks (WSNs) have a wide range of useful; data-centricapplications; and major techniques involved in these applications include in-network queryprocessing and query-informed routing. Both techniques require realistic environments anddetailed system feedback for development and evaluation. Unfortunately; neither real sensornetworks nor existing simulators/emulators are suitable for this requirement. In this designpaper; we propose a distributed sensor network emulator; a Virtual Mote Network (VMNet);to meet this requirement. We describe the system architecture; the synchronization of thenodes and the virtual time emulation with a focus on mechanisms that are effective foraccurate emulation.,IFIP International Conference on Network and Parallel Computing,2004,13,12
Accurate emulation of wireless sensor networks,Hejun Wu; Qiong Luo; Pei Zheng; Bingsheng He; Lionel M Ni,Abstract Wireless sensor networks (WSNs) have a wide range of useful; data-centricapplications; and major techniques involved in these applications include in-network queryprocessing and query-informed routing. Both techniques require realistic environments anddetailed system feedback for development and evaluation. Unfortunately; neither real sensornetworks nor existing simulators/emulators are suitable for this requirement. In this designpaper; we propose a distributed sensor network emulator; a Virtual Mote Network (VMNet);to meet this requirement. We describe the system architecture; the synchronization of thenodes and the virtual time emulation with a focus on mechanisms that are effective foraccurate emulation.,IFIP International Conference on Network and Parallel Computing,2004,13,6
GPL: A GPU-based Pipelined Query Processing Engine,Johns Paul; Jiong He; Bingsheng He,Abstract Graphics Processing Units (GPUs) have evolved as a powerful query co-processorfor main memory On-Line Analytical Processing (OLAP) databases. However; existing GPU-based query processors adopt a kernel-based execution approach which optimizesindividual kernels for resource utilization and executes the GPU kernels involved in thequery plan one by one. Such a kernel-based approach cannot utilize all GPU resourcesefficiently due to the resource underutilization of individual kernels and memory ping-pongacross kernel executions. In this paper; we propose GPL; a novel pipelined query executionengine to improve the resource utilization of query co-processing on the GPU. Different fromthe existing kernel-based execution; GPL takes advantage of hardware features of new-generation GPUs including concurrent kernel execution and efficient data communication …,ACM SIGMOD,2016,12,10
Sensor placement and measurement of wind for water quality studies in urban reservoirs,Wan Du; Zikun Xing; Mo Li; Bingsheng He; Lloyd Hock Chye Chua; Haiyan Miao,Abstract We study the water quality in an urban district; where the surface wind distribution isan essential input but undergoes high spatial and temporal variations due to the impact ofsurrounding buildings. In this work; we develop an optimal sensor placement scheme tomeasure the wind distribution over a large urban reservoir using a limited number of windsensors. Unlike existing solutions that assume Gaussian process of target phenomena; thisstudy measures the wind that inherently exhibits strong non-Gaussian yearly distribution. Byleveraging the local monsoon characteristics of wind; we segment a year into differentmonsoon seasons that follow a unique distribution respectively. We also use computationalfluid dynamics to learn the spatial correlation of wind. The output of sensor placement is aset of the most informative locations to deploy the wind sensors; based on the readings of …,ACM Transactions on Sensor Networks (TOSN),2015,12,6
A uniform framework for ad-hoc indexes to answer reachability queries on large graphs,Linhong Zhu; Byron Choi; Bingsheng He; Jeffrey Xu Yu; Wee Keong Ng,Abstract Graph-structured databases and related problems such as reachability queryprocessing have been increasingly relevant to many applications such as XML databases;biological databases; social network analysis and the Semantic Web. To efficiently evaluatereachability queries on large graph-structured databases; there has been a host of recentresearch on graph indexing. To date; reachability indexes are generally applied to the entiregraph. This can often be suboptimal if the graph is large or/and its subgraphs are diverse instructure. In this paper; we propose a uniform framework to support existing reachabilityindexing for subgraphs of a given graph. This in turn supports fast reachability queryprocessing in large graph-structured databases. The contributions of our uniform frameworkare as follows:(1) We formally define a graph framework that facilitates indexing …,International Conference on Database Systems for Advanced Applications,2009,12,21
Stack-based parallel recursion on graphics processors,Ke Yang; Bingsheng He; Qiong Luo; Pedro V Sander; Jiaoying Shi,Abstract Recent research has shown promising results on using graphics processing units(GPUs) to accelerate general-purpose computation. However; today's GPUs do not supportrecursive functions. As a result; for inherently recursive algorithms such as tree traversal;GPU programmers need to explicitly use stacks to emulate the recursion. Parallelizing suchstack-based implementation on the GPU increases the programming difficulty; moreover; it isunclear how to improve the efficiency of such parallel implementations. As a first step toaddress both ease of programming and efficiency issues; we propose three parallel stackimplementation alternatives that differ in the granularity of stack sharing. Taking treetraversals as an example; we study the performance tradeoffs between these alternativesand analyze their behaviors in various situations. Our results could be useful to both GPU …,ACM Sigplan Notices,2009,12,12
PCMLogging: Optimizing Transaction Logging and Recovery Performance with PCM,Shen Gao; Jianliang Xu; Theo Härder; Bingsheng He; Byron Choi; Haibo Hu,Phase-change memory (PCM); as one of the most promising next-generation memorytechnologies; offers various attractive properties such as non-volatility; byte addressability;bit alterability; and low idle energy consumption. Recently; PCM has drawn much attentionfrom the database community for optimizing query and transaction performance. As acomplement to existing work; we present PCMLogging; a novel logging scheme that exploitsPCM for both data caching and transaction logging to minimize I/O accesses in disk-baseddatabases. Specifically; PCMLogging caches dirty pages/records in PCM and furthermaintains an implicit log in the cached updates to support database recovery. By integratinglog and cached updates; PCMLogging enables simplified recovery and prolongs PCMlifetime. Furthermore; using PCMLogging; we develop a wear-leveling algorithm; that …,IEEE Transactions on Knowledge and Data Engineering,2015,11,21
MROrder: Flexible job ordering optimization for online MapReduce workloads,Shanjiang Tang; Bu-Sung Lee; Bingsheng He,Abstract MapReduce has become a widely used computing model for large-scale dataprocessing in clusters and data centers. A MapReduce workload generally contains multiplejobs. Due to the general execution constraints that map tasks are executed before reducetasks; different job execution orders in a MapReduce workload can have significantlydifferent performance and system utilization. This paper proposes a prototype system calledMROrder to dynamically optimize the job order for online MapReduce workloads. Moreover;MROrder is designed to be flexible for different optimization metrics; eg; makespan and totalcompletion time. The experimental results show that MROrder is able to improve the systemperformance by up to 31% for makespan and 176% for total completion time.,European Conference on Parallel Processing,2013,11,21
A Map-Reduce Based Framework for Heterogeneous Processing Element Cluster Environments,Yu Shyang Tan; Bu-Sung Lee; Bingsheng He; Roy H Campbell,In this paper; we present our design of a Processing Element (PE) Aware MapReduce baseframework; Pamar. Pamar is designed for supporting distributed computing on clusterswhere node PE configurations are asymmetric on different nodes. Pamar's main goal is toallow users to seamlessly utilize different kinds of processing elements (eg; CPUs or GPUs)collaboratively for large scale data processing. To show proof of concept; we haveincorporated our designs into the Hadoop framework and tested it on cluster environmentshaving asymmetric node PE configurations. We demonstrate Pamar's ability to identify PEsavailable on each node and match-make user jobs with nodes; base on job PErequirements. Pamar allows users to easily parallelize applications across large datasetsand at the same time utilizes different PEs for processing different classes of functions …,2012 12th IEEE/ACM International Symposium on Cluster; Cloud and Grid Computing,2012,11,12
An overview of CMPI: network performance aware MPI in the cloud,Yifan Gong; Bingsheng He; Jianlong Zhong,Abstract Cloud computing enables users to perform distributed computing tasks on manyvirtual machines; without owning a physical cluster. Recently; various distributed computingtasks such as scientific applications are being moved from supercomputers and privateclusters to public clouds. Message passing interface (MPI) is a key and common componentin distributed computing tasks. The virtualized computing environment of the public cloudhides the network topology information from the users; and existing topology-awareoptimizations for MPI are no longer feasible in the cloud environment. We propose a networkperformance aware MPI library named CMPI. CMPI embraces a new model for capturing thenetwork performance among different virtual machines in the cloud. Based on the networkperformance model; we develop novel network performance aware algorithms for …,Proceedings of the 17th ACM SIGPLAN symposium on Principles and Practice of Parallel Programming,2012,11,21
On the Efficiency and Programmability of Large Graph Processing in the Cloud,Rishan Chen; Xuetian Weng; Bingsheng He; Mao Yang; Byron Choi; Xiaoming Li,ABSTRACT As the study of large graphs over hundreds of gigabytes becomes increasinglypopular in cloud computing; efficiency and programmability of large graph processing taskschallenge existing tools. The inherent random access pattern on the graph generatessignificant amount of network traffic. Moreover; implementing custom logics on theunstructured data in a distributed manner is often a pain for graph analysts. To addressthese challenges; we develop Surfer; a large graph processing engine in the cloud. Surferresolves the bottleneck of network traffic with graph partitioning; which is specificallyadapted to the network environment of the cloud. To improve the programmability; Surferprovides two basic primitives as building blocks for high-level applications–MapReduce andpropagation. Surfer implements both primitives with automatic optimizations on the …,*,2010,11,12
A quantitative summary of XML structures,Zi Lin; Bingsheng He; Byron Choi,Abstract Statistical summaries in relational databases mainly focus on the distribution of datavalues and have been found useful for various applications; such as query evaluation anddata storage. As xml has been widely used; eg for online data exchange; the need for(corresponding) statistical summaries in xml has been evident. While relational techniquesmay be applicable to the data values in xml documents; novel techniques are requried forsummarizing the structures of xml documents. In this paper; we propose metrics for majorstructural properties; in particular; nestings of entities and one-to-many relationships; of XMLdocuments. Our technique is different from the existing ones in that we generate aquantitative summary of an xml structure. By using our approach; we illustrate that somepopular real-world and synthetic xml benchmark datasets are indeed highly skewed and …,International Conference on Conceptual Modeling,2006,11,19
Benchmarking in-network sensor query processing,Qiong Luo; Hejun Wu; Wenwei Xue; Bingsheng He,Abstract In-network sensor query processing systems are used for power-efficient sensorydata acquisition and aggregation in wireless sensor networks. Due to the cross-layer designof these systems and the resource-limited and noisy nature of WSNs; it is challenging tostudy the end-to-end performance of these systems in a realistic setting. In this paper; wedesign and implement a benchmark; Bisque; for this purpose. We identify the components ofan SUT (System Under Test); set the network topology; database schema and population;select nine queries; as well as fix the performance metrics and scaling factors for thebenchmark. We apply Bisque to TinyDB and its variations with different network routingprotocols and aggregation techniques on a WSN emulation platform. Our initial results showboth the strengths and the limitations of current-generation WSN query processing …,The Hong Kong University of Science and Technology; Tech. Rep. HKUST-CS05-09,2005,11,5
Fast Subgraph Matching on Large Graphs using Graphics Processors,Ha-Nguyen Tran; Jung-jae Kim; Bingsheng He,Abstract Subgraph matching is the task of finding all matches of a query graph in a largedata graph; which is known as an NP-complete problem. Many algorithms are proposed tosolve this problem using CPUs. In recent years; Graphics Processing Units (GPUs) havebeen adopted to accelerate fundamental graph operations such as breadth-first search andshortest path; owing to their parallelism and high data throughput. The existing subgraphmatching algorithms; however; face challenges in mapping backtracking problems to theGPU architectures. Moreover; the previous GPU-based graph algorithms are not designed tohandle intermediate and final outputs. In this paper; we present a simple and GPU-friendlymethod for subgraph matching; called GpSM; which is designed for massively parallelarchitectures. We show that GpSM outperforms the state-of-the-art algorithms and …,*,2015,10,12
HPC Simulations of Information Propagation Over Social Networks,Jiangming Jin; Stephen John Turner; Bu-Sung Lee; Jianlong Zhong; Bingsheng He,Abstract Simulations provide a flexible and valuable method to study the behaviors ofinformation propagation over complex social networks. High Performance Computing (HPC)is a technology that allows the implementation of efficient algorithms on powerful newhardware resources. With the increased computing resource usage in large-scale networkbased simulations; it is therefore attractive to apply the emerging HPC techniques to improvethe simulation performance. This paper describes optimized simulation strategies based onalgorithmic adaptation at runtime; which can facilitate the performance improvement ofexecution. In addition; the proposed optimization method is demonstrated on HPCarchitectures such as Multicore CPU and General Purpose GPU (GPGPU). Such a highperformance simulation approach is evaluated by a range of experiments on different …,Procedia Computer Science,2012,10,0
MEADOWS: modeling; emulation; and analysis of data of wireless sensor networks,Qiong Luo; Lionel M Ni; Bingsheng He; Hejun Wu; Wenwei Xue,Abstract In this position paper; we present MEADOWS; a software framework that we arebuilding at HKUST for modeling; emulation; and analysis of data of wireless sensornetworks. This project is motivated by the unique need of intertwining modeling; emulation;and data analysis in studying sensor databases. We describe our design of basic dataanalysis tools along with an initial case study on HKUST campus. We also report ourprogress on modeling power consumption for sensor databases and on wireless sensornetwork emulation for query processing. Additionally; we outline our future directions onMEADOWS for discussion and feedback at the workshop.,Proceeedings of the 1st international workshop on Data management for sensor networks: in conjunction with VLDB 2004,2004,10,12
QoS-Aware Resource Allocation for Video Transcoding in Clouds,Lei Wei; Jianfei Cai; Chuan Heng Foh; Bingsheng He,As the biggest big data; video data streaming in the network contributes the largest portion ofglobal traffic nowadays and in the future. Due to heterogeneous mobile devices; networks;and user preferences; the demands of transcoding source videos into different versionshave increased significantly. However; video transcoding is a time-consuming task; and howto guarantee quality-of-service (QoS) for large video data is very challenging; particularly forthose real-time applications that hold strict delay requirement such as live TV. In this paper;we propose a cloud-based online video transcoding (COVT) system aiming to offereconomical and QoS guaranteed solution for online large-volume video transcoding. COVTutilizes the performance profiling technique to obtain the different performances oftranscoding tasks in different infrastructures. Based on the profiles; we model the cloud …,IEEE Transactions on Circuits and Systems for Video Technology,2017,9,12
Fair resource allocation for data-intensive computing in the cloud,Shanjiang Tang; Bu-Sung Lee; Bingsheng He,To address the computing challenge of'big data'; a number of data-intensive computingframeworks (eg; MapReduce; Dryad; Storm and Spark) have emerged and become popular.YARN is a de facto resource management platform that enables these frameworks runningtogether in a shared system. However; we observe that; in cloud computing environment; thefair resource allocation policy implemented in YARN is not suitable because of itsmemoryless resource allocation fashion leading to violations of a number of good propertiesin shared computing systems. This paper attempts to address these problems for YARN.Both singlelevel and hierarchical resource allocations are considered. For single-levelresource allocation; we propose a novel fair resource allocation mechanism called Long-Term Resource Fairness (LTRF) for such computing. For hierarchical resource allocation …,IEEE Transactions on Services Computing,2016,9,15
On performance debugging of unnecessary lock contentions on multicore processors: a replay-based approach,Long Zheng; Xiaofei Liao; Bingsheng He; Song Wu; Hai Jin,Abstract Locks have been widely used as an effective synchronization mechanism amongprocesses and threads. However; we observe that a large number of false inter-threaddependencies (ie; unnecessary lock contentions) exist during the program execution onmulticore processors; thereby incurring significant performance overhead. This paperpresents a performance debugging framework; PERFPLAY; to facilitate a comprehensiveand in-depth understanding of the performance impact of unnecessary lock contentions. Thecore technique of our debugging framework is trace replay. Specifically; PERFPLAY recordsthe program execution trace; on the basis of which the unnecessary lock contentions can beidentified through trace analysis. We then propose a novel technique of trace transformationto transform these identified unnecessary lock contentions in the original trace into the …,Proceedings of the 13th Annual IEEE/ACM International Symposium on Code Generation and Optimization,2015,9,11
An overview of Medusa: simplified graph processing on GPUs,Jianlong Zhong; Bingsheng He,Abstract Graphs are the de facto data structures for many applications; and efficient graphprocessing is a must for the application performance. GPUs have an order of magnitudehigher computational power and memory bandwidth compared to CPUs and have beenadopted to accelerate several common graph algorithms. However; it is difficult to writecorrect and efficient GPU programs and even more difficult for graph processing due to theirregularities of graph structures. To address those difficulties; we propose a programmingframework named Medusa to simplify graph processing on GPUs. Medusa offers a small setof APIs; based on which developers can define their application logics by writing sequentialcode without awareness of GPU architectures. The Medusa runtime system automaticallyexecutes the developer defined APIs in parallel on the GPU; with a series of graph-centric …,Proceedings of the 17th ACM SIGPLAN symposium on Principles and Practice of Parallel Programming,2012,9,8
EaseDB: a cache-oblivious in-memory query processor,Bingsheng He; Yinan Li; Qiong Luo; Dongqing Yang,Abstract We propose to demonstrate EaseDB; the first cache-oblivious queryprocessor for in-memory relational query processing. The cache-oblivious notion from the theory communityrefers to the property that no parameters in an algorithm or a data structure need to be tunedfor a specific memory hierarchy for optimality. As a result; EaseDB automatically optimizesthe cache performance as well as the overall performance of query processing on anymemory hierarchy. We have developed a visualization interface to show the detailedperformance of EaseDB in comparison with its cache-conscious counterpart; with both theparameters in the cache-conscious algorithms and the hardware platforms varied.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,9,12
A Declarative Optimization Engine for Resource Provisioning of Scientific Workflows in IaaS Clouds,Amelie Chi Zhou; Bingsheng He; Xuntao Cheng; Chiew Tong Lau,Abstract Resource provisioning for scientific workflows in Infrastructure-as-a-service (IaaS)clouds is an important and complicated problem for budget and performance optimizationsof workflows. Scientists are facing the complexities resulting from severe cloud performancedynamics and various user requirements on performance and cost. To address thosecomplexity issues; we propose a declarative optimization engine named Deco for resourceprovisioning of scientific workflows in IaaS clouds. Deco allows users to specify theirworkflow optimization goals and constraints of specific problems with an extendeddeclarative language. We propose a novel probabilistic optimization approach for evaluatingthe declarative optimization goals and constraints in dynamic clouds. To accelerate thesolution finding; Deco leverages the available power of GPUs to find the solution in a fast …,*,2015,8,12
Medusa: A Parallel Graph Processing System on Graphics Processors,Jianlong Zhong; Bingsheng He,Abstract Medusa is a parallel graph processing system on graphics processors (GPUs). Thecore design of Medusa is to enable developers to leverage the massive parallelism andother hardware features of GPUs by writing sequential C/C++ code for a small set of APIs.This simplifies the implementation of parallel graph processing on the GPU. The runtimesystem of Medusa automatically executes the user-defined APIs in parallel on the GPU; witha series of optimizations based on the architecture features of GPUs and characteristics ofgraph applications. In this paper; we present an overview of the Medusa system and a casestudy of adopting Medusa to a research project on social network simulations. With Medusa;users without GPU programming experiencecan quickly implement their graph operationson the GPU; which accelerates the discovery and findings of domain-specific applications.,ACM SIGMOD Record,2014,8,5
Probabilistic Scheduling of Scientific Workflows in Dynamic Cloud Environments,Amelie Chi Zhou; Bingsheng He; Cheng Liu,*,CoRR,2013,8
Not All Joules are Equal: Towards Energy-Efficient and Green-Aware Data Processing Frameworks,Zhaojie Niu*; Bingsheng He; Fangming Liu,Interests have been growing in integrating renewable energy into data centers; whichattracts many research efforts in developing green-aware algorithms and systems. However;little attention was paid to the efficiency of each joule consumed by data center workloads. Infact; not all joules are equal in the sense that the amount of work that can be done by a joulecan vary significantly in data centers. Ignoring this fact leads to significant energy waste (by25% of the total energy consumption in Hadoop YARN on a Facebook production traceaccording to our study). In this paper; we investigate how to exploit such joule efficiency tomaximize the benefits of renewable energy for MapReduce framework. We develop job/taskscheduling algorithms with a particular focus on the factors on joule efficiency in the datacenter; including the energy efficiency of MapReduce workloads; renewable energy …,IEEE IC2E,2016,7,19
Monetary cost optimizations for mpi-based hpc applications on amazon clouds: Checkpoints and replicated execution,Yifan Gong; Bingsheng He; Amelie Chi Zhou,In this paper; we propose monetary cost optimizations for MPI-based applications withdeadline constraints on Amazon EC2. Particularly; we consider to utilize two kinds ofAmazon EC2 instances (on-demand and spot instances). As a spot instance can fail at anytime due to out-of-bid events; fault tolerant executions are necessary. Through detailedstudies; we have found that two common fault tolerant mechanisms; ie; checkpoints andreplicated executions; are complementary for cost-effective MPI executions on spotinstances. We formulate the optimization problem and propose a novel cost model tominimize the expected monetary cost. The experimental results with NPB benchmarks onAmazon EC2 demonstrate that 1) it is feasible to run MPI applications with performanceconstraints on spot instances; 2) our proposal achieves significant monetary cost …,High Performance Computing; Networking; Storage and Analysis; 2015 SC-International Conference for,2015,7,8
Improving update-intensive workloads on flash disks through exploiting multi-chip parallelism,Bingsheng He; Jeffrey Xu Yu; Amelie Chi Zhou,Solid state drives (SSDs); or flash disks have been considered as ideal storage for variousdata-intensive workloads; because of the low random access latency and the intra-disk multi-chip parallelism. However; due to inherent nature of flash memories; update-intensiveworkloads cause the flash disk fragmented; and trigger costly internal activities such ascleaning and wear leveling. We use database transaction processing as a motivating update-intensive workload. Our studies based on a flash disk simulator as well as flash disks showthat; these activities result in significant overhead to the I/O response time and systemthroughput. To resolve the impact of internal activities; we propose dynamic pagereplications to exploit the multi-chip parallelism on the flash disk. Specifically; we replicatethe frequently blocked data pages to improve the data availability even when internal …,IEEE Transactions on Parallel and Distributed Systems,2015,7,5
Simplified resource provisioning for workflows in iaas clouds,Amelie Chi Zhou; Bingsheng He,Resource provisioning is an important and complicated problem for scientific workflows inInfrastructure-as-a-service (IaaS) clouds. Scientists are facing the complexities resulting fromthe diverse cloud offerings; complex workflow structures and characteristics as well asvarious user requirements on budget and performance. In this paper; we review the relatedwork on the cost-aware optimizations of workflows in IaaS clouds and summarize theunderlying research issues. Existing studies are not effective enough on finding goodsolutions to workflow optimization problems due to the complexity of workflows and thecloud dynamics. The heuristics proposed in the existing work are specifically designed forcertain applications or certain budget and performance requirements. To address thoseissues; we propose a flexible and effective optimization system to simplify the resource …,Cloud Computing Technology and Science (CloudCom); 2014 IEEE 6th International Conference on,2014,7,12
Finding constant from change: Revisiting network performance aware optimizations on iaas clouds,Yifan Gong; Bingsheng He; Dan Li,Network performance aware optimizations have long been an effective approach tooptimizing distributed applications on traditional network environments. However; theassumptions of network topology or direct use of several measurements of pair-wise networkperformance for optimizations are no longer valid on IaaS clouds. Virtualization hidesnetwork topology from users; and direct use of network performance measurements may notrepresent long-term performance. To enable existing network performance awareoptimizations on IaaS clouds; we propose to decouple constant component from dynamicnetwork performance while minimizing the difference by a mathematical method calledRPCA (Robust Principal Component Analysis). We use the constant component to guidenetwork performance aware optimizations and demonstrate the efficiency of our approach …,High Performance Computing; Networking; Storage and Analysis; SC14: International Conference for,2014,7,10
Towards Economic Fairness for Big Data Processing in Pay-as-you-go Cloud Computing,Shanjiang Tang; Bu-Sung Lee; and Bingsheng He,Recent trends indicate that the pay-as-you-go Infrastructure-as-a-Service (IaaS) cloudcomputing has become a popular platform for big data processing applications; due to itsmerits of accessibility; elasticity and flexibility. However; the resource demands ofprocessing workloads are often varying over time for individual users; implying that it is hardfor a user to keep the high resource utilization for cost efficiency all the time. Resourcesharing is a classic and effective approach to improve the resource utilization viaconsolidating multiple users' workloads. However; we show that; current existing fair policiessuch as max-min fairness; widely adopted and implemented in many popular big dataprocessing systems including YARN; Spark; Mesos; and Dryad; are not suitable for pay-as-you-go cloud computing. We show that it is because of their memory less allocation …,IEEE CloudCom,2014,7,21
FD-Buffer: A Cost-Based Adaptive Buffer Replacement Algorithm for Flash Memory Devices,Sai Tung On; Shen Gao; Bingsheng He; Ming Wu; Qiong Luo; Jianliang Xu,In this paper; we present a design and implementation of FD-Buffer; a cost-based adaptivebuffer manager for flash memory devices. Due to flash memory's unique hardware features;it has an inherent read-write asymmetry: writes involve expensive erase operations; whichusually makes them much slower than reads. To address this read-write asymmetry; werevisit buffer management and consider the average I/O cost per page access as the maincost metric; as opposed to the traditional miss rate. While there have been a number ofbuffer management algorithms that take the read-write asymmetry into consideration; mostalgorithms fail to effectively adapt to the runtime workload or different degrees of asymmetry.In this paper; we develop a new replacement algorithm in which we separate clean and dirtypages into two pools. The size ratio of the two pools is automatically adapted based on …,IEEE Transactions on Computers,2013,7,15
Speedup for Multi-Level Parallel Computing,Shanjiang Tang; Bu-Sung Lee; Bingsheng He,This paper studies the speedup for multi-level parallel computing. Two models of parallelspeedup are considered; namely; fixed-size speedup and fixed-time speedup. Based onthese two models; we start with the speedup formulation that takes into account unevenallocation and communication latency; and gives an accurate estimation. Next; we proposea high-level abstract case with providing a global view of possible performanceenhancement; namely E-Amdahl's Law for fixed-size speedup and E-Gustafson's Law forfixed-time speedup. These two laws demonstrate seemingly opposing views about thespeedup of multi-level parallel computing. Our study illustrates that they are not contradictorybut unified and complementary. The results lead to a better understanding in theperformance and scalability of multi-level parallel computing. The experimental results …,Parallel and Distributed Processing Symposium Workshops & PhD Forum (IPDPSW); 2012 IEEE 26th International,2012,7,19
Cache-Oblivious hash joins,Bingsheng He; Qiong Luo,Abstract Partitioning has been used to improve the performance of the hash join in the mainmemory; however; cache-conscious partitioning requires the knowledge about the cacheparameters; such as the capacity and unit size; of a chosen level of the CPU caches; eg; theL2 cache. Obtaining this knowledge and subsequently tuning the algorithm may beinconvenient; and sometimes infeasible; for complex systems. As evidence; our experimentson three different hardware platforms show that; on each platform; the best partitioninggranularity was none of the cache parameters. Therefore; we propose a cache-obliviousapproach to partitioned hash joins; in which the algorithm is aware of the existence of thememory hierarchy but requires no knowledge about the parameter values. In specific; weperform binary partitioning on a join relation recursively until the base case is reached. To …,*,2006,7,12
Frog: Asynchronous graph processing on GPU with hybrid coloring model,Xuanhua Shi; Xuan Luo; Junling Liang; Peng Zhao; Sheng Di; Bingsheng He; Hai Jin,GPUs have been increasingly used to accelerate graph processing for complicatedcomputational problems regarding graph theory. Many parallel graph algorithms adopt theasynchronous computing model to accelerate the iterative convergence. Unfortunately; theconsistent asynchronous computing requires locking or atomic operations; leading tosignificant penalties/overheads when implemented on GPUs. As such; the coloringalgorithm is adopted to separate the vertices with potential updating conflicts; guaranteeingthe consistency/correctness of the parallel processing. Common coloring algorithms;however; may suffer from low parallelism because of a large number of colors generallyrequired for processing a large-scale graph with billions of vertices. We propose a light-weight asynchronous processing framework called Frog with a preprocessing/hybrid …,IEEE Transactions on Knowledge and Data Engineering,2017,6,21
FinePar: irregularity-aware fine-grained workload partitioning on integrated architectures,Feng Zhang; Bo Wu; Jidong Zhai; Bingsheng He; Wenguang Chen,The integrated architecture that features both CPU and GPU on the same die is an emergingand promising architecture for fine-grained CPU-GPU collaboration. However; theintegration also brings forward several programming and system optimization challenges;especially for irregular applications. The complex interplay between heterogeneity andirregularity leads to very low processor utilization of running irregular applications onintegrated architectures. Furthermore; fine-grained co-processing on the CPU and GPU isstill an open problem. Particularly; in this paper; we show that the previous workloadpartitioning for CPU-GPU co-processing is far from ideal in terms of resource utilization andperformance. To solve this problem; we propose a system software named FinePar; whichconsiders architectural differences of the CPU and GPU and leverages finegrained …,Proceedings of the 2017 International Symposium on Code Generation and Optimization,2017,6,0
Relational query processing on OpenCL-based FPGAs,Zeke Wang; Johns Paul; Hui Yan Cheah; Bingsheng He; Wei Zhang,The release of OpenCL support for FPGAs represents a significant improvement inextending database applications to the reconfigurable domain. Taking advantage of theprogrammability offered by the OpenCL HLS tool; an OpenCL database can be easily portedand re-designed for FPGAs. A single SQL query in these database systems usually consistsof multiple operators; and each one of these operators in turn consists of multiple OpenCLkernels. Due to the specific properties of FPGAs; each OpenCL kernel can have differentFPGA-specific optimization combinations; in terms of CU (compute unit) and SIMD (kernelvectorization); which are critical to the overall performance of query processing. Due to theresource limitation of an FPGA image; our query plan also considers the possibility of usingmultiple FPGA images. In this paper; we propose an FPGA-specific cost model to …,Field Programmable Logic and Applications (FPL); 2016 26th International Conference on,2016,6,0
Thermal-aware task scheduling for 3D-network-on-chip: A Bottom-to-Top scheme,Yingnan Cui; Wei Zhang; Vivek Chaturvedi; Weichen Liu; Bingsheng He,Three-dimensional network-on-chip (3D-NoC) emerges as a potential multi-corearchitecture delivering high performance; high energy efficiency and great scalability.However; 3D-NoC suffers from severe thermal problems due to its high power density. Tosolve this problem; thermal-aware scheduling is an effective solution. However; the highcomplexity of the thermal model of 3D-NoC becomes a major hurdle for developing efficientthermal-aware scheduling algorithms for 3D-NoC. In this paper; we propose a novel thermal-aware task scheduling scheme named as the Bottom-to-Top (B2T) approach to address thischallenge. This heuristic-based method performs task allocation on processing units toefficiently minimize the peak temperature and improve the execution time of the tasks withlow complexity. The algorithm is first designed for two-layer 3D-NoC and then extended to …,Integrated Circuits (ISIC); 2014 14th International Symposium on,2014,6,18
Thermal-aware task scheduling for 3D-network-on-chip: A Bottom-to-Top scheme,Yingnan Cui; Wei Zhang; Vivek Chaturvedi; Weichen Liu; Bingsheng He,Three-dimensional network-on-chip (3D-NoC) emerges as a potential multi-corearchitecture delivering high performance; high energy efficiency and great scalability.However; 3D-NoC suffers from severe thermal problems due to its high power density. Tosolve this problem; thermal-aware scheduling is an effective solution. However; the highcomplexity of the thermal model of 3D-NoC becomes a major hurdle for developing efficientthermal-aware scheduling algorithms for 3D-NoC. In this paper; we propose a novel thermal-aware task scheduling scheme named as the Bottom-to-Top (B2T) approach to address thischallenge. This heuristic-based method performs task allocation on processing units toefficiently minimize the peak temperature and improve the execution time of the tasks withlow complexity. The algorithm is first designed for two-layer 3D-NoC and then extended to …,Integrated Circuits (ISIC); 2014 14th International Symposium on,2014,6,12
Pipelined Compaction for the LSM-Tree,Zigang Zhang; Yinliang Yue; Bingsheng He; Jin Xiong; Mingyu Chen; Lixin Zhang; Ninghui Sun,Write-optimized data structures like Log-Structured Merge-tree (LSM-tree) and its variantsare widely used in key-value storage systems like Big Table and Cassandra. Due to deferraland batching; the LSM-tree based storage systems need background compactions to mergekey-value entries and keep them sorted for future queries and scans. Backgroundcompactions play a key role on the performance of the LSM-tree based storage systems.Existing studies about the background compaction focus on decreasing the compactionfrequency; reducing I/Os or confining compactions on hot data key-ranges. They do not paymuch attention to the computation time in background compactions. However; thecomputation time is no longer negligible; and even the computation takes more than 60% ofthe total compaction time in storage systems using flash based SSDs. Therefore; an …,Proceedings of the 2014 IEEE 28th International Parallel and Distributed Processing Symposium,2014,6,18
Towards efficient resource allocation for heterogeneous workloads in IaaS clouds,Lei Wei; Chuan Heng Foh; Bingsheng He; Jianfei Cai,Infrastructure-as-a-service (IaaS) cloud technology has attracted much attention from userswho have demands on large amounts of computing resources. Current IaaS cloudsprovision resources in terms of virtual machines (VMs) with homogeneous resourceconfigurations where different types of resources in VMs have similar share of the capacity ina physical machine (PM). However; most user jobs demand different amounts for differentresources. For instance; high-performance-computing jobs require more CPU cores whilebig data processing applications require more memory. The existing homogeneousresource allocation mechanisms cause resource starvation where dominant resources arestarved while non-dominant resources are wasted. To overcome this issue; we propose aheterogeneous resource allocation approach; called skewness-avoidance multi-resource …,IEEE Transactions on Cloud Computing,2015,5,19
Towards multi-resource physical machine provisioning for IaaS clouds,Lei Wei; Bingsheng He; Chuan Heng Foh,Virtualization has been an enabling technology for IaaS (Infrastructure as a Service) Clouds.Physical machine (PM) provisioning is a key problem for IaaS cloud providers on theirresource utilization and quality of service to users. Proper provisioning is able to ensure theservice quality while conserving unnecessary power consumption from over-provisionedPMs. However; the effectiveness of PM provisioning in current IaaS providers such asAmazon and Rackspace is severely limited by that they offer virtual machines withproportional resource provisioning on different resource types (including CPU; memory anddisk etc). Such a rigid offering cannot satisfy diversified user applications in the cloud; andcan cause significant over-provision on PMs in order to satisfy users' requirement on allresource types. This paper argues a more flexible approach that IaaS providers should …,Communications (ICC); 2014 IEEE International Conference on,2014,5,12
When data management systems meet approximate hardware: challenges and opportunities,Bingsheng He,Abstract Recently; approximate hardware designs have got many research interests in thecomputer architecture community. The essential idea of approximate hardware is that thehardware components such as CPU; memory and storage can trade off the accuracy ofresults for increased performance; reduced energy consumption; or both. We propose aDBMS ApproxiDB with its design; implementation and optimization aware of the underlyingapproximate hardware. ApproxiDB will run on a hybrid machine consisting of bothapproximate hardware and precise hardware (ie; the conventional hardware withoutsacrificing the accuracy). With approximate hardware; ApproxiDB can efficiently support theconcept of approximate query processing; without the overhead of pre-computed synopsesor sampling techniques. More importantly; ApproxiDB is also beneficial to precise query …,Proceedings of the VLDB Endowment,2014,5,12
GPGPU for Real-Time Data Analytics,Bingsheng He; Huynh Phung Huynh; Rick Goh Siow Mong,The demand for real-time data analytics (RTDA) has been on the rise in the past decadesand is ever-growing with the proliferation of different data collection devices. GPGPU(General-Purpose computation on Graphics Processing Units) is an emerging research areain HPC (high performance computing). With the massive computation power and highmemory bandwidth; GPUs have become a sharp weapon to address the performancerequirement of RTDA. Designed as co-processors; GPUs pose a number of technicalchallenges for RTDA in terms of efficiency and programmability. On the one hand; while newgeneration GPUs can have over an order of magnitude higher memory bandwidth andhigher computation power (in terms of GFLOPS) than CPUs; novel GPGPU algorithmicdesign and implementation are a must to unleash the hardware power. On the other hand …,Parallel and Distributed Systems (ICPADS); 2012 IEEE 18th International Conference on,2012,5,12
On Achieving Efficient Data Transfer for Graph Processing in Geo-Distributed Datacenters,Amelie Zhou; Shadi Ibrahim; Bingsheng He,Graph partitioning is important for optimizing the performance and communication cost oflarge graph processing jobs. Recently; many graph applications such as social networksstore their data on geo-distributed datacenters (DCs) to provide services worldwide with lowlatency. This raises new challenges to existing graph partitioning methods; due to the costlyWide Area Network (WAN) usage and the multi-levels of network heterogeneities in geo-distributed DCs. In this paper; we propose a geo-aware graph partitioning method named G-Cut; which aims at minimizing the inter-DC data transfer time of graph processing jobs ingeo-distributed DCs while satisfying the WAN usage budget. G-Cut adopts two noveloptimization phases which address the two challenges in WAN usage and networkheterogeneities separately. G-Cut can be also applied to partition dynamic graphs thanks …,ICDCS'17-The 37th IEEE International Conference on Distributed Computing Systems (ICDCS 2017),2017,4,12
NV-Tree: A Consistent and Workload-Adaptive Tree Structure for Non-Volatile Memory,Jun Yang; Qingsong Wei; Chundong Wang; Cheng Chen; Khai Leong Yong; Bingsheng He,The non-volatile memory (NVM) which can provide DRAM-like performance and disk-likepersistency has the potential to build single-level systems by replacing both DRAM and disk.Keeping data consistency in such systems is non-trivial because memory writes may bereordered by CPU. Although ordered memory writes for achieving data consistency can beimplemented using the memory fence and the CPU cache line flush instructions; theyintroduce a significant overhead (more than 10X slower in performance). In this paper; wefocus on an important and common data structure; B $^+ $ Tree. Based on our quantitativeanalysis for consistent tree structures; we propose NV-Tree; a consistent; cache-optimizedand workload-adaptive B $^+ $ Tree variant with significantly reduced consistency cost (upto 96 percent reduction in CPU cache line flush). To further optimize NV-Tree under …,IEEE Transactions on Computers,2016,4,11
NV-Tree: A Consistent and Workload-Adaptive Tree Structure for Non-Volatile Memory,Jun Yang; Qingsong Wei; Chundong Wang; Cheng Chen; Khai Leong Yong; Bingsheng He,The non-volatile memory (NVM) which can provide DRAM-like performance and disk-likepersistency has the potential to build single-level systems by replacing both DRAM and disk.Keeping data consistency in such systems is non-trivial because memory writes may bereordered by CPU. Although ordered memory writes for achieving data consistency can beimplemented using the memory fence and the CPU cache line flush instructions; theyintroduce a significant overhead (more than 10X slower in performance). In this paper; wefocus on an important and common data structure; B $^+ $ Tree. Based on our quantitativeanalysis for consistent tree structures; we propose NV-Tree; a consistent; cache-optimizedand workload-adaptive B $^+ $ Tree variant with significantly reduced consistency cost (upto 96 percent reduction in CPU cache line flush). To further optimize NV-Tree under …,IEEE Transactions on Computers,2016,4,5
gScale: scaling up GPU virtualization with dynamic sharing of graphics memory space,Mochi Xue; Kun Tian; Yaozu Dong; Jiacheng Ma; Jiajun Wang; Zhengwei Qi; Bingsheng He; Haibing Guan,Abstract With increasing GPU-intensive workloads deployed on cloud; the cloud serviceproviders are seeking for practical and efficient GPU virtualization solutions. However; thecutting-edge GPU virtualization techniques such as gVirt still suffer from the restriction ofscalability; which constrains the number of guest virtual GPU instances. This paperintroduces gScale; a scalable GPU virtualization solution. By taking advantage of the GPUprogramming model; gScale presents a dynamic sharing mechanism which combinespartition and sharing together to break the hardware limitation of global graphics memoryspace. Particularly; we propose three approaches for gScale:(1) the private shadowgraphics translation table; which enables global graphics memory space sharing amongvirtual GPU instances;(2) ladder mapping and fence memory space pool; which allows …,2016 USENIX Annual Technical Conference (USENIX ATC 16),2016,4,6
Rank-aware dynamic migrations and adaptive demotions for DRAM power management,Yanchao Lu; Donghong Wu; Bingsheng He; Xueyan Tang; Jianliang Xu; Minyi Guo,Modern DRAM architectures allow a number of low-power states on individual memoryranks for advanced power management. Many previous studies have taken advantage ofdemotions on low-power states for energy saving. However; most of the demotion schemesare statically performed on a limited number of pre-selected low-power states; and aresuboptimal for different workloads and memory architectures. Even worse; the idle periodsare often too short for effective power state transitions; especially for memory intensiveapplications. Wrong decisions on power state transition incur significant energy and delaypenalties. In this paper; we propose a novel memory system design named RAMZzz withrank-aware energy saving optimizations including dynamic page migrations and adaptivedemotions. Specifically; we group the pages with similar access locality into the same …,IEEE Transactions on Computers,2016,4,9
Gemini: An adaptive performance-fairness scheduler for data-intensive cluster computing,Zhaojie Niu; Shanjiang Tang; Bingsheng He,In data-intensive cluster computing platforms such as Hadoop YARN; performance andfairness are two important factors for system design and optimizations. Many previousstudies are either for performance or for fairness solely; without considering the tradeoffbetween performance and fairness. Recent studies observe that there is a tradeoff betweenperformance and fairness because of resource contention between users/jobs. However;their scheduling algorithms for bi-criteria optimization between performance and fairness arestatic; without considering the impact of different workload characteristics on the tradeoffbetween performance and fairness. In this paper; we propose an adaptive scheduler calledGemini for Hadoop YARN. We first develop a model with the regression approach toestimate the performance improvement and the fairness loss under the sharing …,Cloud Computing Technology and Science (CloudCom); 2015 IEEE 7th International Conference on,2015,4,10
Thermal-Aware Task Scheduling for 3D-Network-on-Chip: A Bottom to Top Scheme,Yingnan Cui; Wei Zhang; Vivek Chaturvedi; Weichen Liu; Bingsheng He,Three-dimensional network-on-chip (3D-NoC) emerges as a potential multi-corearchitecture delivering high performance; high energy efficiency and great scalability.However; 3D-NoC suffers from severe thermal problems due to its high power density. Tosolve this problem; thermal-aware scheduling is an effective solution. However; the highcomplexity of the thermal model of 3D-NoC becomes a major hurdle for developing efficientthermal-aware scheduling algorithms for 3D-NoC. In this paper; we propose a novel thermal-aware task scheduling scheme named as the Bottom-to-Top (B2T) approach to address thischallenge. This heuristic-based method performs task allocation on processing units toefficiently minimize the peak temperature and improve the execution time of the tasks withlow complexity. The algorithm is first designed for two-layer 3D-NoC and then extended to …,Journal of Circuits; Systems and Computers,2015,4,12
To Co-Run; or Not To Co-Run: A Performance Study on Integrated Architectures,Feng Zhang; Jidong Zhai; Wenguang Chen; Bingsheng He; Shuhao Zhang,Architecture designers tend to integrate both CPU and GPU on the same chip to deliverenergy-efficient designs. To effectively leverage the power of both CPUs and GPUs onintegrated architectures; researchers have recently put substantial efforts into co-running asingle application on both the CPU and the GPU of such architectures. However; few studieshave been performed to analyze a wide range of parallel computation patterns on sucharchitectures. In this paper; we port all programs in Rodinia benchmark suite and co-runthese programs on the integrated architecture. We find that co-running results are not alwaysbetter than running the application on the CPU only or the GPU only. Among the 20programs; 3 programs can benefit from co-running; 12 programs using GPU only and 2programs using CPU only achieve the best performance. The remaining 3 programs …,Modeling; Analysis and Simulation of Computer and Telecommunication Systems (MASCOTS); 2015 IEEE 23rd International Symposium on,2015,4,10
Energy-Efficient Query Processing on Embedded CPU-GPU Architectures,Xuntao Cheng; Bingsheng He; Chiew Tong Lau,Abstract Energy efficiency is a major design and optimization factor for query co-processingof databases in embedded devices. Recently; GPUs of new-generation embedded deviceshave evolved with the programmability and computational capability for general-purposeapplications. Such CPU-GPU architectures offer us opportunities to revisit GPU query co-processing in embedded environments for energy efficiency. In this paper; weexperimentally evaluate and analyze the performance and energy consumption of a GPUquery co-processor on such hybrid embedded architectures. Specifically; we study fourmajor database operators as micro-benchmarks and evaluate TPC-H queries on CARMA;which has a quad-core ARM Cortex-A9 CPU and a NVIDIA Quadro 1000M GPU. Weobserve that the CPU delivers both better performance and lower energy consumption …,Proceedings of the 11th International Workshop on Data Management on New Hardware,2015,4,19
Multi-Resource Fair Allocation in Pay-as-you-go Cloud Computing,Shanjiang Tang; Zhaojie Niu; Bu-sung Lee; Bingsheng He,*,*,2014,4
A framework for analyzing monetary cost of database systems in the cloud,Changbing Chen; Bingsheng He,Abstract In this paper; we propose to develop a framework to analyze the monetary cost ofrunning database systems in the public cloud. The framework offers guidelines andmethodologies in analyzing and estimating monetary cost of database systems. It consists ofmultiple components including categorizing database performance tuning knobs;benchmarking the price/performance of computation resources offered by the cloudprovider; and building a monetary cost model. As a case study of our proposed framework;we conduct an in-depth study on two popular open-source database systems with respect totwo cloud providers. We find that evaluating a query spans a wide range of monetary costs(with a difference up to 91%); and the experimental results demonstrate the accuracy of ourmonetary cost estimation.,International Conference on Web-Age Information Management,2013,4,12
Understanding co-running behaviors on integrated CPU/GPU architectures,Feng Zhang; Jidong Zhai; Bingsheng He; Shuhao Zhang; Wenguang Chen,Architecture designers tend to integrate both CPUs and GPUs on the same chip to deliverenergy-efficient designs. It is still an open problem to effectively leverage the advantages ofboth CPUs and GPUs on integrated architectures. In this work; we port 42 programs inRodinia; Parboil; and Polybench benchmark suites and analyze the co-running behaviors ofthese programs on both AMD and Intel integrated architectures. We find that co-runningperformance is not always better than running the program only with CPUs or GPUs. Amongthese programs; only eight programs can benefit from the co-running; while 24 programsonly using GPUs and seven programs only using CPUs achieve the best performance. Theremaining three programs show little performance preference for different devices. Throughextensive workload characterization analysis; we find that architecture differences …,IEEE Transactions on Parallel and Distributed Systems,2017,3,3
Efficient Query Processing on Many-core Architectures: A Case Study with Intel Xeon Phi Processor,Xuntao Cheng; Bingsheng He; Mian Lu; Chiew Tong Lau; Huynh Phung Huynh; Rick Siow Mong Goh,Abstract Recently; Intel Xeon Phi is emerging as a many-core processor with up to 61 x86cores. In this demonstration; we present PhiDB; an OLAP query processor with simultaneousmulti-threading (SMT) capabilities on Xeon Phi as a case study for parallel databaseperformance on future many-core processors. With the trend towards many-corearchitectures; query operator optimizations; and efficient query scheduling on such many-core architectures remain as challenging issues. This motivates us to redesign and evaluatequery processors. In PhiDB; we apply Xeon Phi aware optimizations on query operators toexploit hardware features of Xeon Phi; and design a heuristic algorithm to schedule theconcurrent execution of query operators for better performance; to demonstrate theperformance impact of Xeon Phi aware optimizations. We have also developed a user …,Proceedings of the 2016 International Conference on Management of Data,2016,3,12
Modular placement for interposer based multi-FPGA systems,Fubing Mao; Wei Zhang; Bo Feng; Bingsheng He; Yuchun Ma,Novel device with multiple FPGAs on-chip based on interposer interconnection hasemerged to resolve the IOs limit and improve the inter-FPGA communication delay.However; new challenges arise for the placement on such architecture. Firstly; existing workdoes not consider the detailed models for the path wirelength and delay estimation forinterposer; which may significantly affect the placement quality. Secondly; previous work ismostly based on traditional tile-based placement which is slow for the placement of largedesign on multiple FPGAs. In this paper; we propose a new fast two-stage modularplacement flow for interposer based multiple FPGAs aiming for delay optimization with theincorporation of a detailed interposer routing model for wirelength and delay estimation.Firstly; we adopt the force-directed method for its global property to get an efficient …,Great Lakes Symposium on VLSI; 2016 International,2016,3,12
Rotated Logging Storage Architectures for Data Centers: Models and Optimizations,Yinliang Yue; Bingsheng He; Lei Tian; Hong Jiang; Fang Wang; Dan Feng,We propose Rotated Logging (RoLo); a new logging architecture for parallel disk-basedmirrored storage systems for enhanced energy efficiency; which is one of the key concernsin modern data centers. By spreading destaging I/O activities among short idle time slots andproactively reclaiming the stale logging space; RoLo rotates loggers among a logicallogging space pool formed collectively from the free storage space available amongmirrored disks. We develop three flavors of RoLo; that is; RoLo-P/R/E; to emphasizeperformance; reliability; and energy efficiency respectively. Without the extra dedicated logdisks and the corresponding centralized destaging; RoLo eliminates the additionalhardware and energy costs; potential single point of failure and performance bottleneck.Furthermore; RoLo-P/R/E; applied to specific scenes correctly; can prolong the lifecycle of …,IEEE Transactions on Computers,2016,3,5
Synergy of dynamic frequency scaling and demotion on dram power management: Models and optimizations,Yanchao Lu; Bingsheng He; Xueyan Tang; Minyi Guo,Main memory (or DRAM) is one of the most significant components to the computer system'sperformance and energy consumption. Dynamic frequency scaling (DFS) and DRAM low-power states (Demotion) are two main-stream techniques for DRAM power management.DFS reduces the operation frequency of memory channels and DRAM devices when thememory bandwidth is under-utilized; whereas demotion transits individual memory ranks tolow-power states during long idle periods. Despite that there have been fruitful researchwork for DFS and demotion separately; little attention has been paid to the synergy betweenthese two techniques. To bridge this gap; this paper conducts a comprehensive study on thesynergy between DFS and demotion. In particular; we leverage queuing theory to developanalytical models for the energy consumption and performance of DRAM systems with …,IEEE Transactions on Computers,2015,3,21
Improving Data Partitioning Performance on OpenCL-Based FPGAs,Zeke Wang; Bingsheng He; Wei Zhang,We investigate the performance of relational database applications on recent OpenCL-based FPGAs. As a start; we study the performance of data partitioning; a core operationwidely used in relational databases. Due to the random memory accesses; data partitioningis time-consuming and can become a major bottleneck for database operators such as hashjoins. We start with the state-of-the-art OpenCL implementation which was originallydesigned for the CPU/GPU; and find that such an implementation suffers from lock overheadand memory stalls. To resolve those overheads; we develop a simple yet efficient multi-kernel approach to leverage two emerging features in Alter a OpenCL SDK; namely taskkernel and channel. We evaluate the proposed design on a recent Alter a Stratix V GXFPGA. Our results demonstrate that our proposed approach can achieve roughly 10.7 X …,Field-Programmable Custom Computing Machines (FCCM); 2015 IEEE 23rd Annual International Symposium on,2015,3,12
Understanding the Behavior of Solid State Disk,Qingchao Cai; Rajesh Vellore Arumugam; Quanqing Xu; Bingsheng He,Abstract In this paper; we develop a family of methods to characterize the behavior of new-generation Solid State Disks (SSDs). We first study how writes are handled inside the SSDby varying request size of writes and detecting the placement of requested pages. We furtherexamine how this SSD performs garbage collection and flushes write buffer. The resultshows that the clustered pages must be written and erased simultaneously; otherwisesignificant storage waste will arise if such clustered pages are partially written. We thenconduct two case studies to analyze the storage efficiency when an SSD is used for serverstorage and the cache layer of a hybrid storage system. In the first case; we find that amoderate storage waste exists; whereas in the second case; the number of written pagescaused by a write request can be as much as 4.2 times that of pages requested; implying …,*,2015,3,21
Monetary cost optimizations for HPC applications on Amazon clouds: Checkpoints and replicated execution,Yifan Gong; Amelie Chi Zhou; Bingsheng He,I. MOTIVATION Recently; we have witnessed that many emerging high performancecomputing (HPC) or scientific computing applications are developed and hosted in thecloud. As those applications are usually long running jobs and are costly in the cloud;monetary cost [11];[7] and performance [3];[2] are important optimization factors. MessagePassing Interface (MPI) is the key programming paradigm for developing HPC and scientificapplications. That motivates us to investigate whether and how we can reduce the monetarycost for MPI-based applications with performance constraint in the cloud. Cloud has evolvedinto an economic market. Besides ondemand instances that charges users at a fixed rate;Amazon EC2 provides spot instances; whose prices are mainly determined by the supplyand demand in the market. Table I shows the statistics of the price history of four types of …,SC’14 (Poster),2014,3,19
Simulation of information propagation over complex networks: Performance studies on multi-GPU,Jiangming Jin; Stephen John Turner; Bu-Sung Lee; Jianlong Zhong; Bingsheng He,Abstract General Purpose Graphics Processing Units (GPGPU) have been used in highperformance computing platforms to accelerate the performance of scientific applicationssuch as simulations. With the increased computing resources required for large-scalenetwork simulation; one GPU device may not have enough memory and computationcapacities. It is therefore necessary to enhance the system scalability by introducing multipleGPU devices. It is also attractive to investigate the performance scalability of Multi-GPUsimulations. This paper describes the simulation of information propagation on multiple GPUdevices; including the optimized network simulation algorithms; the network partitioning andreplication strategy; and the data synchronization scheme. The experimental results forscalable random networks show that the number of simulation steps; computation time …,Proceedings of the 2013 IEEE/ACM 17th International Symposium on Distributed Simulation and Real Time Applications,2013,3,10
Crystal: The Power of Structure Against Corruptions,Hongyi Wang; Bingsheng He; Vijayan Prabhakaran; Lidong Zhou,*,The 5th Workshop on Hot Topics in System Dependability (HotDep’09),2009,3
Adaptive index utilization in memory-resident structural joins,Bingsheng He; Qiong Luo; Byron Choi,We consider adaptive index utilization as a fine-grained problem in autonomic databases inwhich an existing index is dynamically determined to be used or not in query processing. Asa special case; we study this problem for structural joins; the core operator in XML queryprocessing; in the main memory. We find that index utilization is beneficial for structural joinsonly under certain join selectivity and distribution of matching elements. Therefore; wepropose adaptive algorithms to decide whether to use an index probe or a data scan foreach step of matching during the processing of a structural join operator. Our adaptivealgorithms are based on the history; the look-ahead information; or both. We havedeveloped a cost model to facilitate this adaptation and have conducted experiments withboth synthetic and real-world data sets. Our results show that adaptively utilizing indexes …,Knowledge and Data Engineering; IEEE Transactions on,2007,3,9
Revisiting the design of data stream processing systems on multi-core processors,Shuhao Zhang; Bingsheng He; Daniel Dahlmeier; Amelie Chi Zhou; Thomas Heinze,Driven by the rapidly increasing demand for handling real-time data streams; many datastream processing (DSP) systems have been proposed. Regardless of the differentarchitectures of those DSP systems; they are mostly aiming at scaling out using a cluster ofcommodity machines and built around a number of key design aspects: a) pipelinedprocessing with message passing; b) on-demand data parallelism; and c) JVM basedimplementation. However; there lacks a study on those key design aspects on modern scale-up architectures; where more CPU cores are being put on the same die; and the onchipcache hierarchies are getting larger; deeper; and complex. Multiple sockets bring non-uniform memory access (NUMA) effort. In this paper; we revisit the aforementioned designaspects on a modern scale-up server. Specifically; we use a series of applications as …,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,2,12
DIDO: Dynamic Pipelines for In-Memory Key-Value Stores on Coupled CPU-GPU Architectures,Kai Zhang; Jiayu Hu; Bingsheng He; Bei Hua,As an emerging hardware; the coupled CPU-GPU architecture integrates a CPU and a GPUinto a single chip; where the two processors share the same memory space. This specialproperty opens up new opportunities for building in-memory keyvalue store systems; as iteliminates the data transfer costs on PCI-e bus; and enables fine-grained cooperationbetween the CPU and the GPU. In this paper; we propose DIDO; an in-memory key-valuestore system with dynamic pipeline executions on the coupled CPU-GPU architecture; toaddress the limitations and drawbacks of state-of-the-art system designs. DIDO is capable ofadapting to different workloads through dynamically adjusting the pipeline with fine-grainedtask assignment to the CPU and the GPU at runtime. By exploiting the hardware features ofcoupled CPU-GPU architectures; DIDO achieves this goal with a set of techniques …,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,2,12
Building an Efficient Put-Intensive Key-Value Store with Skip-Tree,Yinliang Yue; Bingsheng He; Yuzhe Li; Weiping Wang,Multi-component based Log-Structured Merge-tree (LSM-tree) has been becoming one ofthe mainstream indexes. LSM-tree adopts component-by-component KV item flowing downmechanism to push each KV item from one smaller component to the adjacent largercomponent during compaction procedures until the KV items reach the largest component.This process incurs significant write amplification and limits the write throughput. In thispaper; we propose one multi-component Skip-tree to aggressively push the KV items to thenon-adjacent larger components via skipping some components and then make the KVitems' top-down move more efficient. We develop adaptive and reliable KV item movementsamong components. By reducing the number of steps during the flowing process frommemory-resident component to the disk-resident largest component; Skip-tree can …,IEEE Transactions on Parallel and Distributed Systems,2017,2,10
A Declarative Optimization Engine for Resource Provisioning of Scientific Workflows in Geo-Distributed Clouds,Amelie Chi Zhou; Bingsheng He; Xuntao Cheng; Chiew Tong Lau,Geo-distributed clouds are becoming increasingly popular for cloud providers; and datacenters with different regions often offer different prices; even for the same type of virtualmachines. Resource provisioning in geo-distributed clouds is an important and complicatedproblem for budget and performance optimizations of scientific workflows. Scientists arefacing the complexities resulted from various cloud offerings in the geo-distributed settings;severe cloud performance dynamics and evolving user requirements on performance andcost. To address those complexities; we propose a declarative optimization engine namedGeco for resource provisioning of scientific workflows in geo-distributed clouds. Geco allowsusers to specify their workflow optimization goals and constraints of specific problems withan extended declarative language. We propose a novel probabilistic optimization …,IEEE Transactions on Parallel and Distributed Systems,2017,2,5
Elastic multi-resource fairness: balancing fairness and efficiency in coupled CPU-GPU architectures,Shanjiang Tang; BingSheng He; Shuhao Zhang; Zhaojie Niu,Abstract Fairness and efficiency are two important concerns for users in a shared computersystem; and there tends to be a tradeoff between them. Heterogeneous computing posesnew challenging issues on the fair allocation of computational resources among users dueto the availability of different kinds of computing devices (eg; CPU and GPU). Prior workeither considers the fair resource allocation separately for each computing device or isunable to balance flexibly the tradeoff between the fairness and system utilization. In thiswork; we consider an emerging heterogeneous computing system with coupled CPU andGPU into a single chip. We first show that it is essential to have a new fair policy for coupledCPU-GPU architectures that is capable of considering both the CPU and the GPU as awhole in fair resource allocation and being aware of the system utilization maximization …,High Performance Computing; Networking; Storage and Analysis; SC16: International Conference for,2016,2,21
A Performance Debugging Framework for Unnecessary Lock Contentions with Record/Replay Techniques,Xiaofei Liao; Long Zheng; Bingsheng He; Song Wu; Hai Jin,Locks have been widely used as an effective synchronization mechanism among processesand threads. However; we observe that; a large number of false inter-thread dependencies(ie; unnecessary lock contentions) exist during the program execution on multicoreprocessors; incurring significant performance overhead. This paper presents a performancedebugging framework; PERFPLAY; to facilitate the identification of unnecessary lockcontentions and to guide programmers to improve the program performance by eliminatingthe unnecessary lock contentions. Since the performance debugging of unnecessary lockcontentions is input-sensitive; we first identify the representative inputs for performancedebugging. Next; PERFPLAY quantifies the performance impact of unnecessary lockcontention code regions for each candidate input. Taking into account conflicting attribute …,IEEE Transactions on Parallel and Distributed Systems,2016,2,19
Decentralized Thermal-Aware Task Scheduling for Large-Scale Many-Core Systems,Yingnan Cui; Wei Zhang; Vivek Chaturvedi; Bingsheng He,Technology scaling has enabled fast increase in the number of cores integrated in many-core systems. However; feature size shrinking also makes large-scale many-core systemsvulnerable to thermal failures. Thermal-aware task scheduling is an efficient technique toreduce the run-time temperatures of many-core processors. Most existing thermal-awaretask scheduling algorithms leverage centralized scheduling schemes to gather the overallinformation and generate the task schedule at a center scheduler. Although that scheme canachieve the optimal temperature reduction; however; it faces severe computation bottleneckand communication congestion when the many-core processors evolve to large-scale withhundreds or thousands of cores. In this paper; we propose a decentralized thermal-awarescheduling algorithm to address this problem in large-scale systems. Experiment results …,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,2016,2,21
VColor: A practical vertex-cut based approach for coloring large graphs,Yun Peng; Byron Choi; Bingsheng He; Shuigeng Zhou; Ruzhi Xu; Xiaohui Yu,Graph coloring is a fundamental NP-hard problem in graph theory. It has a wide range ofreal applications; such as Operations Research; Communication Network; ComputationalBiology and Compiler Optimization. Notable efforts have been spent on designing itsapproximation algorithms. Halldrsson proposed the algorithm (denoted as SampleIS) withthe current best known approximation ratio. However; its time complexity is O (| G| 3); where|G| is the number of vertices of a graph G. It is clear that SampleIS is not practical for largegraphs. In this paper; we propose a practical vertex-cut based coloring technique (VColor)for coloring large graphs. First; we partition G into k connected components (CCs) of a smallsize s by removing a vertex-cut component (VCC). For each CC; we apply our novel coloringalgorithm; based on maximal independent set enumeration. The approximation ratio and …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,2,20
A Study of Big Data Computing Platforms: Fairness and Energy Consumption,Zhaojie Niu; Bingsheng He,Improving the performance is the common sense on those large-scale data processingframeworks and fruitful studies are proposed in this direction. In contrast; the fairness andenergy consumption of those frameworks need further exploration and how theperformance; fairness and energy consumption interact each other on big data computingframeworks is not well addressed. In our research; we study the fairness and the energyconsumption of those big data computing systems. We find that there are tradeoff betweenthese factors. We conduct detailed studies on the factors which impact the tradeoff betweendifferent factors. Based on the observations in our study; we propose workload aware;energy-efficient and green-aware optimizations and implement them into Hadoop YARN.Particularly; in this thesis proposal; we propose to explore the following research …,Cloud Engineering Workshop (IC2EW); 2016 IEEE International Conference on,2016,2,6
A Taxonomy and Survey on eScience as a Service in the Cloud,Amelie Chi Zhou; Bingsheng He; Shadi Ibrahim,Abstract: Cloud computing has recently evolved as a popular computing infrastructure formany applications. Scientific computing; which was mainly hosted in private clusters andgrids; has started to migrate development and deployment to the public cloud environment.eScience as a service becomes an emerging and promising direction for science computing.We review recent efforts in developing and deploying scientific computing applications in thecloud. In particular; we introduce a taxonomy specifically designed for scientific computing inthe cloud; and further review the taxonomy with four major kinds of science applications;including life sciences; physics sciences; social and humanities sciences; and climate andearth sciences. Our major finding is that; despite existing efforts in developing cloud-basedeScience; eScience still has a long way to go to fully unlock the power of cloud computing …,arXiv preprint arXiv:1407.7360,2014,2,16
Simulation studies of viral advertisement diffusion on multi-GPU,Jiangming Jin; Stephen John Turner; Bu-Sung Lee; Jianlong Zhong; Bingsheng He,Abstract Simulation has become an important method that is widely used in studying thepropagation behaviors during the process of viral advertisement diffusion. With theincreased computing and memory resources required for large-scale network processing;General Purpose Graphics Processing Units (GPGPUs) have been used in highperformance computing platforms to accelerate simulation performance. In this paper; weshow optimized simulation strategies of viral advertisement diffusion on a Multi-GPU system.Using our proposed simulation strategies; we examine the spread of viral advertisementsover a realistic social network with different tolerance thresholds. We also investigate theeffect of different initial nodes selection policies in maximizing the performance ofadvertisement diffusion. According to our simulation studies of viral advertisement …,Simulation Conference (WSC); 2013 Winter,2013,2,5
Cloud assisted water quality management in singapore,Cheng Liu; Zikun Xing; Lloyd HC Chua; Bingsheng He; Mo Li; Eikaas Hans,Liu; Cheng; Xing; Zikun; Chua; Lloyd HC; He; Bingsheng; Li; Mo and Hans; Eikaas 2012; Cloudassisted water quality management in Singapore; in SIWW 2012 : Notes from the SingaporeInternational Water Week; [The Conference]; Singapore; pp. 1-1 … Unless expressly statedotherwise; the copyright for items in DRO is owned by the author; with all rights reserved …Every reasonable effort has been made to ensure that permission has been obtained for itemsincluded in DRO. If you believe that your rights have been infringed by this repository; pleasecontact drosupport@deakin.edu.au.,SIWW 2012: Notes from the Singapore International Water Week,2012,2,4
GViewer: GPU-accelerated graph visualization and mining,Jianlong Zhong; Bingsheng He,Abstract Visualization is an effective way of identifying the patterns of interests (such ascommunities) in graphs including social networks and Web [8; 6]. There have been anumber of tools developed for graph visualizations; eg; Tulip; Gephi and GMine [8]. All ofthese tools use the CPU as the main power to calculate the graph layouts for visualization;such as force-directed layout [2]. However; the layout calculation is usually computationintensive; for example; the force-directed layout has the complexity of O (N 3); where N is thenumber of vertexes in the graph. In our experiments; the CPU-based solution takes morethan half one hours on the CPU to layout a graph with 14.5 thousand vertexes.,International Conference on Social Informatics,2011,2,12
Medusa: A unified framework for graph computation and visualization on graphics processors,Jianlong Zhong; Bingsheng He; Gao Cong,*,*,2011,2
The HKUST Frog Pond–A Case Study of Sensory Data Analysis,Wenwei Xue; Bingsheng He; Hejun Wu; Qiong Luo,Abstract Many sensor network applications are data-centric; and data analysis plays animportant role in these applications. However; it is a challenging task to find out what specificproblems and requirements sensory data analysis will face; because these applications aretightly embedded in the physical world and the sensory data reflect the physical phenomenabeing monitored. In this paper; we propose to use field studies as an alternative foridentifying these problems and requirements. Specifically; we deployed an experimentalsensor network for monitoring the frog pond in our university and analyzed the collectedsensory data. We present our methodology of sensory data collection and analysis. We alsodiscuss preliminary analytical results from the collected sensory data; together with ourgeneralization for similar sensor network applications. We find that this case study helped …,IFIP International Conference on Network and Parallel Computing,2004,2,12
The HKUST Frog Pond–A Case Study of Sensory Data Analysis,Wenwei Xue; Bingsheng He; Hejun Wu; Qiong Luo,Abstract Many sensor network applications are data-centric; and data analysis plays animportant role in these applications. However; it is a challenging task to find out what specificproblems and requirements sensory data analysis will face; because these applications aretightly embedded in the physical world and the sensory data reflect the physical phenomenabeing monitored. In this paper; we propose to use field studies as an alternative foridentifying these problems and requirements. Specifically; we deployed an experimentalsensor network for monitoring the frog pond in our university and analyzed the collectedsensory data. We present our methodology of sensory data collection and analysis. We alsodiscuss preliminary analytical results from the collected sensory data; together with ourgeneralization for similar sensor network applications. We find that this case study helped …,IFIP International Conference on Network and Parallel Computing,2004,2,12
A study of main-memory hash joins on many-core processor: A case with intel knights landing architecture,Xuntao Cheng; Bingsheng He; Xiaoli Du; Chiew Tong Lau,Abstract Advanced processor architectures have been driving new designs;implementations and optimizations of main-memory hash join algorithms recently. Thenewly released Intel Xeon Phi many-core processor of the Knights Landing architecture(KNL) embraces interesting hardware features such as many low-frequency out-of-ordercores connected on a 2D mesh; and high-bandwidth multi-channel memory (MCDRAM). Inthis paper; we experimentally revisit the state-of-the-art main-memory hash join algorithms tostudy how the new hardware features of KNL affect the algorithmic design and tuning as wellas to identify the opportunities for further performance improvement on KNL. Ourexperiments show that; although many existing optimizations are still valid on KNL withproper tuning; even the state-of-the-art algorithms have severely underutilized the …,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,2017,1,18
Technical Report: Accelerating Dynamic Graph Analytics on GPUs,Mo Sha; Yuchen Li; Bingsheng He; Kian-Lee Tan,Abstract: As graph analytics often involves compute-intensive operations; GPUs have beenextensively used to accelerate the processing. However; in many applications such as socialnetworks; cyber security; and fraud detection; their representative graphs evolve frequentlyand one has to perform a rebuild of the graph structure on GPUs to incorporate the updates.Hence; rebuilding the graphs becomes the bottleneck of processing high-speed graphstreams. In this paper; we propose a GPU-based dynamic graph storage scheme to supportexisting graph algorithms easily. Furthermore; we propose parallel update algorithms tosupport efficient stream updates so that the maintained graph is immediately available forhigh-speed analytic processing on GPUs. Our extensive experiments with three streamingapplications on large-scale real and synthetic datasets demonstrate the superior …,arXiv preprint arXiv:1709.05061,2017,1,12
Towards Declarative and Data-centric Virtual Machine Image Management in IaaS Clouds,Haikun Liu; Bingsheng He; Xiaofei Liao; Hai Jin,Virtual machine image (VMI) management has become one of the key infrastructurecomponents in IaaS (Infrastructure as a Service) cloud systems. Any “good” VMImanagement system should support flexible and efficient VMI services to cloud users; andoffer scalable; easy-to-maintain and efficient VMI management for cloud providers. Whilethere have been a number of systems and optimizations for VMI management; this paperinvestigates a declarative and data-centric approach to VMI management for both cloudusers and providers. Specifically; by viewing VMI management as a data-intensiveapplication; we propose Hemera; a novel VMI management system prototype based onrelational database systems. Hemera adopts a data-centric approach to VMI managementsystem design; where a VMI is modeled as structured data. With the data-centric …,IEEE Transactions on Cloud Computing,2017,1,12
Multikernel Data Partitioning With Channel on OpenCL-Based FPGAs,Zeke Wang; Johns Paul; Bingsheng He; Wei Zhang,Recently; field-programmable gate array (FPGA) vendors (such as Altera) have started toaddress the programmability issues of FPGAs via OpenCL SDKs. In this paper; we analyzethe performance of relational database applications on FPGAs using OpenCL. In particular;we study how to improve the performance of data partitioning; which is a very importantbuilding block in relational database. Since the data partitioning causes random memoryaccesses; it is time-consuming; and then; it has been the major bottleneck for databaseoperators; such as partitioned hash join. In particular; we import the state-of-the-art OpenCLimplementation of data partitioning from OmniDB; which was originally designed andoptimized for CPUs/GPUs; and we find that this implementation suffers from both lockoverhead and memory bandwidth overhead. Accordingly; we present a multikernel …,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,2017,1,16
An Adaptive Efficiency-Fairness Meta-scheduler for Data-Intensive Computing,Zhaojie Niu; Shanjiang Tang; Bingsheng He,In data-intensive cluster computing platforms such as Hadoop YARN; efficiency and fairnessare two important factors for system design and optimizations. Previous studies are either forefficiency or for fairness solely; without considering the tradeoff between efficiency andfairness. Recent studies observe that there is a tradeoff between efficiency and fairnessbecause of resource contention between users/jobs. By leveraging the existing schedulers;a meta-scheduler is able to dynamically choose one of them for job/task scheduling atruntime. In this paper; we propose a meta-scheduler called FLEX to realize the tradeoffbetween system efficiency and fairness in Hadoop YARN. FLEX combines multiple existingschedulers into a single aggregated view without any modification on the originalschedulers. Equipped with these candidate schedulers; FLEX utilizes machine learning …,IEEE Transactions on Services Computing,2017,1,19
AdaStorm: Resource Efficient Storm with Adaptive Configuration,Zujian Weng; Qi Guo; Chunkai Wang; Xiaofeng Meng; Bingsheng He,Storm is a popular real-time processing system. However; our earlier experiment shows thatthe fixed configuration of Storm would lead to either significant resource waste or limitedprocessing throughput. In this demonstration; we present AdaStorm; a system to dynamicallyadjust the Storm configuration according to current data stream properties. AdaStorm isdesigned to minimize the resource usage while still ensuring the same or even better real-time response. We will demonstrate that AdaStorm can achieve resource efficiency as wellas data rate tolerance; compared to Storm system with fixed configuration. Video:https://youtu. be/YFPBFNdMbXM.,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,1,21
JouleMR: Towards Cost-Effective and Green-Aware Data Processing Frameworks,Zhaojie Niu; Bingsheng He; Fangming Liu,Interests have been growing in energy management of the cluster effectively in order toreduce the energy consumption as well as the electricity cost. Renewable energy anddynamic pricing schemes in smart grids are two major emerging trends in energy markets.However; current data processing frameworks are not aware of the efficiency of each jouleconsumed by the data center workloads in the context of these two major trends. In fact; notall joules are equal in the sense that the amount of work that can be done by a joule canvary significantly in data centers. Ignoring this fact leads to significant energy waste (by 25%of the total energy consumption in Hadoop YARN on a Facebook production trace accordingto our study). In this paper; we propose JouleMR; a cost-effective and green-aware dataprocessing framework. Specifically; we investigate how to exploit such joule efficiency to …,IEEE Transactions on Big Data,2017,1,4
Accelerating dynamic graph analytics on gpus,Mo SHAN; Yuchen Li; Bingsheng He; Kian-Lee Tan,Abstract As graph analytics often involves compute-intensive operations; GPUs have beenextensively used to accelerate theprocessing. However; in many applications such associalnetworks; cyber security; and fraud detection; their representativegraphs evolvefrequently and one has to perform arebuild of the graph structure on GPUs to incorporatetheupdates. Hence; rebuilding the graphs becomes the bottleneckof processing high-speedgraph streams. In this paper; we propose a GPU-based dynamic graph storage schemetosupport existing graph algorithms easily. Furthermore; we propose parallel updatealgorithms to support ecientstream updates so that the maintained graph isimmediatelyavailable for high-speed analytic processing on GPUs. Ourextensiveexperiments with three streaming applications onlarge-scale real and synthetic datasets …,*,2017,1,10
A Hybrid Logic Block Architecture in FPGA for Holistic Efficiency,Tao Luo; Hao Liang; Wei Zhang; Bingsheng He; Douglas Maskell,This brief presents a hybrid design of a configurable logic block (CLB) composed of look-uptables (LUTs) and universal logic gates (ULGs). A ULG is designed to realize holisticefficiency compared with the corresponding LUT. Previous designs with ULGs are eitherbased on pure ULG or LUT-ULG complementary architecture; which incur a longer delay ordouble the area compared to the LUT-based design. In contrast; we propose a hybrid CLBthat contains a mixture of LUTs and ULGs to address the generality problem as well as toachieve the holistic benefits including the area; performance; and power. To exploit theadvantage of ULGs thoroughly while not causing negative side effects; the ratio of LUTs andULGs in one CLB is explored by experiments. Experimental results show that; compared topure LUT design; our proposed architecture design can save up to 17.1% logic power as …,IEEE Transactions on Circuits and Systems II: Express Briefs,2017,1,13
Fairness-Efficiency Allocation of CPU-GPU Heterogeneous Resources,Qiumin Lu; Jianguo Yao; Zhengwei Qi; Bingsheng He,Considering the performance improvement the cloud technology provides by processingworkloads in parallel; applications and services are now migrating to online clouds. In acloud platform; workloads can be executed in a virtualized environment to have a greatimprovement of the resource utilization. However; there is a new challenge in the allocationproblem; which is quantifying and optimizing the fairness and efficiency of heterogeneousresources (CPUs and GPUs) required by applications such as cloud gaming. The solvingapproach needs scalarization methods of the requirement vector; relevant functions forfairness metrics; and an acceptable algorithm to solve that; where the difficulties mainlylocate. We design an iterative; dynamic-adaptive heuristic solving algorithm Fairness-Efficiency Allocation (FEA) and optimize the implementation on a virtualized platform …,IEEE Transactions on Services Computing,2016,1,19
A Study of Sorting Algorithms on Approximate Memory,Shuang Chen; Shunning Jiang; Bingsheng He; Xueyan Tang,Abstract Hardware evolution has been one of the driving factors for the redesign of databasesystems. Recently; approximate storage emerges in the area of computer architecture. Ittrades off precision for better performance and/or energy consumption. Previous studieshave demonstrated the benefits of approximate storage for applications that are tolerant toimprecision such as image processing. However; it is still an open question whether andhow approximate storage can be used for applications that do not expose such intrinsictolerance. In this paper; we study one of the most basic operations in database--sorting on ahybrid storage system with both precise storage and approximate storage. Particularly; westart with a study of three common sorting algorithms on approximate storage. Experimentalresults show that a 95% sorted sequence can be obtained with up to 40% reduction in …,Proceedings of the 2016 International Conference on Management of Data,2016,1,21
A Taxonomy and Survey of Scientific Computing in the Cloud,Amelie Chi Zhou; Bingsheng He; Shadi Ibrahim,Cloud computing has evolved as a popular computing infrastructure for many applications.With (big) data acquiring a crucial role in eScience; efforts have been made recentlyexploring how to efficiently develop and deploy scientific applications on theunprecedentedly scalable cloud infrastructures. We review recent efforts in developing anddeploying scientific computing applications in the cloud. In particular; we introduce ataxonomy specifically designed for scientific computing in the cloud; and further review thetaxonomy with four major kinds of science applications; including life sciences; physicssciences; social and humanities sciences; and climate and earth sciences. Due to the largedata size in most scientific applications; the performance of I/O operations can greatly affectthe overall performance of the applications. We notice that; the dynamic I/O performance …,*,2016,1,12
Library-Based Placement and Routing in FPGAs with Support of Partial Reconfiguration,Fubing Mao; Yi-Chung Chen; Wei Zhang; Hai Helen Li; Bingsheng He,Abstract While traditional Field-Programmable Gate Array design flow usually employs fine-grained tile-based placement; modular placement is increasingly required to speed up thelarge-scale placement and save the synthesis time. Moreover; the commonly used modulescan be pre-synthesized and stored in the library for design reuse to significantly save thedesign; verification time; and development cost. Previous work mainly focuses on modularfloorplanning without module placement information. In this article; we propose a library-based placement and routing flow that best utilizes the pre-placed and routed modules fromthe library to significantly save the execution time while achieving the minimal area-delayproduct. The flow supports the static and reconfigurable modules at the same time. Themodular information is represented in the B*-Tree structure; and the B*-Tree operations …,ACM Transactions on Design Automation of Electronic Systems (TODAES),2016,1,8
A discrete thermal controller for chip-multiprocessors,Yingnan Cui; Wei Zhang; Bingsheng He,Abstract As the power density of modern processors keeps increasing; thermal managementremains a challenging problem for processor designers. Among various solutions; closed-loop automatic thermal controllers have the benefits of fast response speed and high controlaccuracy. However; as a processor is a discrete system by nature; controllers designed byclassic control theories fail to consider the system features related to the discreteness andthus cannot achieve optimal result. In this work; we propose a discrete thermal controllerwith the form of the digital filter with special concern about the frequency field responseaffected by the sampling process. We optimize the sampling period and the response time ofthe controller. Experimental results show up to 50% sampling frequency reduction and up to25% improvement in the performance of CMP systems with thermal constraints when …,Proceedings of the 2016 Conference on Design; Automation & Test in Europe,2016,1,12
Accelerating Database Query Processing on OpenCL-based FPGAs,Zeke Wang; Huiyan Cheah; Johns Paul; Bingsheng He; Wei Zhang,Abstract The release of OpenCL support for FPGAs represents a significant improvement inextending database applications to the reconfigurable domain. Taking advantage of theprogrammability offered by the OpenCL HLS tool; an OpenCL database can be easily portedand re-designed for FPGAs. A single SQL query in these database systems usually consistsof multiple operators; and each one of these operators in turn consists of multiple OpenCLkernels. Due to the specific properties of FPGAs; each OpenCL kernel can have differentoptimization combinations (in terms of CU and SIMD) which is critical to the overallperformance of query processing. In this paper; we propose an efficient method toimplement database operators on OpenCL-based FPGAs. We use a cost model todetermine the optimum query plan for an input query. Our cost model has two …,Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays,2016,1,4
A racetrack memory based in-memory booth multiplier for cryptography application,Tao Luo; Wei Zhang; Bingsheng He; Douglas Maskell,Security is an important concern in cloud computing nowadays. RSA is one of the mostpopular asymmetric encryption algorithms that are widely used in internet basedapplications for its public key strategy advantage over symmetric encryption algorithms.However; RSA encryption algorithm is very compute intensive; which would affect the speedand power efficiency of the encountered applications. Racetrack Memory (RM) is a newlyintroduced promising technology in future storage and memory system; which is perfect tobe used in memory intensive scenarios because of its high data density. However; noveldesigns should be applied to exploit the advantages of RM while avoiding the adverseimpact of its sequential access mechanism. In this paper; we present an in-memory Boothmultiplier based on racetrack memory to alleviate this problem. As the building block of …,Design Automation Conference (ASP-DAC); 2016 21st Asia and South Pacific,2016,1,18
Demo abstract: Wind measurements for water quality studies in urban reservoirs,Wan Du; Mo Li; Zikun Xing; Bingsheng He; Lloyd Hock Chye Chua; Zhenjiang Li; Yuanqiang Zheng; Pengfei Zhou,Water quality monitoring and prediction are critical for ensuring the sustainability of waterresources which are essential for social security; especially for countries with limited landlike Singapore. For example; the Singapore government identified water as a new growthsector and committed in 2006 to invest S $330 million over the following five years for waterresearch and development [1]. To investigate the water quality evolution numerically; somekey water quality parameters at several discrete locations in the reservoir (eg; dissolvedoxygen; chlorophyll; and temperature) and some environmental parameters (eg; the winddistribution above water surface; air temperature and precipitation) are used as inputs to athree-dimensional hydrodynamics-ecological model; Estuary Lake and Coastal OceanModel-Computational Aquatic Ecosystem Dynamics Model (ELCOM-CAEDYM)[2]. Based …,Sensing; Communication; and Networking (SECON); 2014 Eleventh Annual IEEE International Conference on,2014,1,9
Network performance aware graph partitioning for large graph processing systems in the cloud,Rishan Chen; Xuetian Weng; Bingsheng He; Byron Choi; Mao Yang,A wide variety of recent applications model their data in graphs/networks such as socialnetworks; web graphs; and protein–protein interaction networks. Efficient processing forlarge graph data poses new challenges for almost all components of state-of-the-art datamanagement systems. To list a few examples:(i) graph data are complex structures andcannot be efficiently stored as relational tables;(ii) the access patterns of large graphprocessing are complex; which results in inefficient disk accesses or networkcommunications; and (iii) last but not least; to tackle scalability issues; graph processingmust be efficiently distributed in a networked environment. Researchers have been activelyproposing many innovative solutions to address the new challenges of large graphprocessing. In particular; a notable number of techniques have recently been proposed to …,*,2014,1,10
Debugging performance impact of unnecessary lock contentions via replay technique,Long Zheng; Xiaofei Liao; Bingsheng He; Song Wu; Hai Jin,Abstract Locks have been widely used as an effective synchronization mechanism amongprocesses and threads. However; we observe that; a large number of false inter-threaddependencies (ie; unnecessary lock contention) exist during the execution on multicoreprocessors; which incurs significant performance overhead. This paper; therefore; presentsa performance debugging framework; PERFPLAY; to facilitate a comprehensive and in-depth understanding of the performance impact of unnecessary lock contentions. The coretechnique of our debugging framework is trace replay. Specifically; PERFPLAY records theprogram execution trace; on the basis of which we can detect all unnecessary lockcontentions through trace replay techniques. We propose a novel technique of tracetransformation to transform these unnecessary lock contentions in the original trace into …,*,2014,1,12
GPU-Accelerated Cloud Computing for Data-Intensive Applications,Baoxue Zhao; Jianlong Zhong; Bingsheng He; Qiong Luo; Wenbin Fang; Naga K Govindaraju,Abstract Recently; many large-scale data-intensive applications have emerged from theInternet and science domains. They pose significant challenges on the performance;scalability and programmability of existing data management systems. The challenges areeven greater when these data management systems run on emerging parallel anddistributed hardware and software platforms. In this chapter; we study the use of the GPU(Graphics Processing Units) in MapReduce and general graph processing in the Cloud forthese data-intensive applications. In particular; we report our experiences in developingsystem prototypes; and discuss the open problems in the interplay between data-intensiveapplications and system platforms.,*,2014,1,1
Brief announcement: on minimum interaction time for continuous distributed interactive computing,Lu Zhang; Xueyan Tang; Bingsheng He,Abstract In this paper; we study the interaction times of continuous distributed interactivecomputing in which the application states change due to not only user-initiated operationsbut also time passing. We formulate the Minimum Interaction Time problem as acombinatorial problem of how the clients are assigned to the servers and the simulation timesettings of the servers. We also outline two approaches to approximate the problem.,Proceedings of the 2013 ACM symposium on Principles of distributed computing,2013,1,5
Spectral decomposition for optimal graph index prediction,Liyan Song; Yun Peng; Byron Choi; Jianliang Xu; Bingsheng He,Abstract There is an ample body of recent research on indexing for structural graph queries.However; as verified by our experiments with a large number of random and scale-freegraphs; there may be a great variation in the performances of indexes of graph queries.Unfortunately; the structures of graph indexes are often complex and ad-hoc; so deriving anaccurate performance model is a daunting task. As a result; database practitioners mayencounter difficulties in choosing the optimal index for their data graphs. In this paper; weaddress this problem by proposing a spectral decomposition method for predicting therelative performances of graph indexes. Specifically; given a graph; we compute itsspectrum. We then propose a similarity function to compare the spectrums of graphs. Weadopt a classification algorithm to build a model and a voting algorithm for predicting the …,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2013,1,12
GPU-Assisted Buffer Management,Jianlong Zhong; Bingsheng He,Abstract Cloud computing has become an emerging virtualization-based computingparadigm for various applications such as scientific computing and databases. Buffermanagement is an important factor for the I/O performance of the virtualized platform. In thisstudy; we propose to leverage the memory and the computation power of the graphicsprocessors (GPUs) to improve the effectiveness of buffer management. GPUs have recentlybeen modeled as manycore processors for general-purpose computation. Designed as co-processors; they have an order of magnitude higher computation power than CPUs; andhave a large amount of GPU memory; connected to the main memory with the PCI-e bus. Inparticular; we present two approaches of GPU-assisted buffer management; namely GRAMand DEDU. GRAM utilizes the GPU memory as additional buffer space and models the …,Procedia Computer Science,2011,1,18
A general framework for improving query processing performance on multi-level memory hierarchies,Bingsheng He; Yinan Li; Qiong Luo; Dongqing Yang,Abstract We propose a general framework for improving the query processing performanceon multi-level memory hierarchies. Our motivation is that (1) the memory hierarchy is animportant performance factor for query processing;(2) both the memory hierarchy anddatabase systems are becoming increasingly complex and diverse; and (3) increasing theamount of tuning does not always improve the performance. Therefore; we categorizemultiple levels of memory performance tuning and quantify their performance impacts. As acase study; we use this framework to improve the in-memory performance of storagemodels; B+-trees; nested-loop joins and hash joins. Our empirical evaluation verifies theusefulness of the proposed framework.,Proceedings of the 3rd international workshop on Data management on new hardware,2007,1,12
G-NET: Effective {GPU} Sharing in {NFV} Systems,Kai Zhang; Bingsheng He; Jiayu Hu; Zeke Wang; Bei Hua; Jiayi Meng; Lishan Yang,Abstract: Network Function Virtualization (NFV) virtualizes software network functions to offerflexibility in their design; management and deployment. Although GPUs have demonstratedtheir power in significantly accelerating network functions; they have not been effectivelyintegrated into NFV systems for the following reasons. First; GPUs are severely underutilizedin NFV systems with existing GPU virtualization approaches. Second; data isolation in theGPU memory is not guaranteed. Third; building an efficient network function on CPU-GPUarchitectures demands huge development efforts.,15th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 18),2018,*,12
vS ensor: leveraging fixed-workload snippets of programs for performance variance detection,Xiongchao Tang; Jidong Zhai; Xuehai Qian; Bingsheng He; Wei Xue; Wenguang Chen,Abstract Performance variance becomes increasingly challenging on current large-scaleHPC systems. Even using a fixed number of computing nodes; the execution time of severalruns can vary significantly. Many parallel programs executing on supercomputers suffer fromsuch variance. Performance variance not only causes unpredictable performancerequirement violations; but also makes it unintuitive to understand the program behavior.Despite prior efforts; efficient on-line detection of performance variance remains an openproblem. In this paper; we propose vS ensor; a novel approach for light-weight and on-lineperformance variance detection. The key insight is that; instead of solely relying on anexternal detector; the source code of a program itself could reveal the runtime performancecharacteristics. Specifically; many parallel programs contain code snippets that are …,Proceedings of the 23rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming,2018,*,12
Scalable GPU Virtualization with Dynamic Sharing of Graphics Memory Space,Mochi Xue; Jiacheng Ma; Wentai Li; Kun Tian; Yaozu Dong; Jinyu Wu; Zhengwei Qi; Bingsheng He; Haibing Guan,With increasing GPU-intensive workloads deployed on cloud; cloud service providers areseeking for practical and efficient GPU virtualization solutions. However; the cutting-edgeGPU virtualization techniques such as gVirt still suffer from the restriction of scalability; whichconstrains the number of guest virtual GPU instances. This paper presents gScale; ascalable and practical open source GPU virtualization solution based on gVirt. gScalepresents a sharing mechanism which combines partition and sharing together to break thehardware limitation of global graphics memory space. Particularly; we propose twoapproaches for gScale:(1) the private shadow graphics translation table (GTT); whichenables global graphics memory space sharing among virtual GPUs;(2) ladder mappingand fence memory space pool; which allows CPU access host physical memory space …,IEEE Transactions on Parallel and Distributed Systems,2018,*,3
Efficient Support Vector Machine Training Algorithm on GPUs,Jiashuai Shi; Zeyi Wen; Bingsheng He; Jian Chen,Abstract Support Vector Machines (SVMs) are popular for many machine learning tasks.With rapid growth of dataset size; the high cost of training limits the wide use of SVMs.Several SVM implementations on GPUs have been proposed to accelerate SVMs. However;they support only classification (SVC) or regression (SVR). In this work; we propose a simpleand effective SVM training algorithm on GPUs which can be used for SVC; SVR and one-class SVM. Initial experiments show that our implementation outperforms existing ones. Weare in the process of encapsulating our algorithm into an easy-to-use library which hasPython; R and MATLAB interfaces.,*,2018,*,12
Long-Term Multi-Resource Fairness for Pay-as-you Use Computing Systems,Shanjiang Tang; Zhaojie Niu; Bingsheng He; Bu-Sung Lee; Ce Yu,Abstract—Many current computing systems such as clouds and supercomputers chargeusers for their resource usages. A user's demand is often changing over time; indicating thatit is difficult to keep the high resource utilization all the time for cost efficiency. Resourcesharing is a classical and effective approach for high resource utilization. In view of theheterogeneous resource demands of users' workloads; multi-resource allocation fairness isa must for resource sharing in such pay-as-you-use computing systems. However; we findthat; existing multi-resource fair policies such as Dominant Resource Fairness (DRF);implemented in currently popular resource management systems such as Apache YARN [4]and Mesos [23]; are not suitable for the pay-as-you-use computing systems. We show thatthis is because of their memoryless characteristic that can cause the following problems …,IEEE Transactions on Parallel and Distributed Systems,2018,*,16
Many-core needs fine-grained scheduling: A case study of query processing on Intel Xeon Phi processors,Xuntao Cheng; Bingsheng He; Mian Lu; Chiew Tong Lau,Abstract Emerging many-core processors feature very high memory bandwidth andcomputational power. For example; Intel Xeon Phi many-core processors of the KnightsCorner (KNC) and Knights Landing (KNL) architectures embrace 60 to 64 x86-based CPUcores with 512-bit SIMD capabilities and high-bandwidth memories like the GDDR5 on KNCand on-package DRAMs on KNL. In this paper; we study the performance main-memorydatabase operators and online analytical processing (OLAP) on such many-corearchitectures. We find that even the state-of-the-art database operators suffer severely frommemory stalls and resource underutilization on those many-core processors. We argue thata software approach decomposing a coarse-grained operator into fine-grained phases andexecuting two independent phases with complementary resource requirements …,Journal of Parallel and Distributed Computing,2017,*,3
Efficient Disk-based Directed Graph Processing: A Strongly Connected Component Approach,Yu Zhang; Xiaofei Liao; Xiang Shi; Hai Jin; Bingsheng He,Recently; there have been many disk-based systems proposed for iterative graphprocessing. In the popular vertex/edge-centric systems; an iterative directed graph algorithmneeds to reprocess many partitions so as to update their vertices states according to othernon-convergent vertices for the unawareness of their dependencies. As a result; it induceshigh data access cost and a long time to converge. To tackle this problem; we propose anovel system for iterative directed graph processing with taking advantage of the stronglyconnected component (SCC) structure. With this system; each SCC is able to reachconvergence in order and needs to be loaded into the main memory for exactly once; gettingmuch lower data access cost and faster convergence. Besides; the vertices of each SCCneed less updates for convergence. We further develop a lightweight approach to …,IEEE Transactions on Parallel and Distributed Systems,2017,*,12
COMBA: A comprehensive model-based analysis framework for high level synthesis of real applications,Jieru Zhao; Liang Feng; Sharad Sinha; Wei Zhang; Yun Liang; Bingsheng He,High Level Synthesis (HLS) relies on the use of synthesis pragmas to generate digitaldesigns meeting a set of specifications. However; the selection of a set of pragmas dependslargely on designer experience and knowledge of the target architecture and digital design.Existing automated methods of pragma selection are very limited in scope and capability toanalyze complex design descriptions in high-level languages to be synthesized using HLS.In this paper; we propose COMBA; a comprehensive model-based analysis frameworkcapable of analyzing the effects of a multitude of pragmas related to functions; loops andarrays in the design description using pluggable analytical models; a recursive datacollector (RDC) and a metric-guided design space exploration algorithm (MGDSE). Whencompared with HLS tools like Vivado HLS; COMBA reports an average error of around 1 …,Computer-Aided Design (ICCAD); 2017 IEEE/ACM International Conference on,2017,*,12
Efficient process mapping in geo-distributed cloud data centers,Amelie Chi Zhou; Yifan Gong; Bingsheng He; Jidong Zhai,Abstract Recently; various applications including data analytics and machine learning havebeen developed for geo-distributed cloud data centers. For those applications; the ways tomap parallel processes to physical nodes (ie;" process mapping") could significantly impactthe performance of the applications because of non-uniform communication cost in such geo-distributed environments. While process mapping has been widely studied in grid/clusterenvironments; few of the existing studies have considered the problem in geo-distributedcloud environments. In this paper; we propose a novel model to formulate the geo-distributed process mapping problem and develop a new method to efficiently find the nearoptimal solution. Our algorithm considers both the network communication performance ofgeo-distributed data centers as well as the communication matrix of the target application …,Proceedings of the International Conference for High Performance Computing; Networking; Storage and Analysis,2017,*,10
A distributed in-memory key-value store system on heterogeneous CPU–GPU cluster,Kai Zhang; Kaibo Wang; Yuan Yuan; Lei Guo; Rubao Li; Xiaodong Zhang; Bingsheng He; Jiayu Hu; Bei Hua,Abstract In-memory key-value stores play a critical role in many data-intensive applicationsto provide high-throughput and low latency data accesses. In-memory key-value stores haveseveral unique properties that include (1) data-intensive operations demanding highmemory bandwidth for fast data accesses;(2) high data parallelism and simple computingoperations demanding many slim parallel computing units; and (3) a large working set.However; our experiments show that homogeneous multicore CPU systems are increasinglymismatched to the special properties of key-value stores because they do not providemassive data parallelism and high memory bandwidth; the powerful but the limited numberof computing cores does not satisfy the demand of the unique data processing task; and thecache hierarchy may not well benefit to the large working set. In this paper; we present …,The VLDB Journal,2017,*,20
Dynamic module partitioning for library based placement on heterogeneous FPGAs,Fubing Mao; Wei Zhang; Bingsheng He; Siew-Kei Lam,Library based design and IP reuse have been previously proposed to speed up thesynthesis for large-scale FPGA designs. However; previous library based design flow facesseveral unresolved challenges. Firstly; they may result in large waste area between themodules due to the difference in module sizes. While utilizing multiple ratio modules canhelp to reduce the waste area; pre-synthesis each module for different ratios is timeconsuming and would require a large library. Secondly; when the targeting FPGAarchitecture changes; a new library is needed to best fit the targeting architecture. Re-synthesizing the library for different architectures is not feasible. To address thesechallenges; in this paper; we propose a dynamic module partitioning approach for the librarybased design flow to dynamically generate the appropriate shape of modules based on …,Embedded and Real-Time Computing Systems and Applications (RTCSA); 2017 IEEE 23rd International Conference on,2017,*,12
Hardware/software cooperative caching for hybrid DRAM/NVM memory architectures,Haikun Liu; Yujie Chen; Xiaofei Liao; Hai Jin; Bingsheng He; Long Zheng; Rentong Guo,Abstract Non-Volatile Memory (NVM) has recently emerged for its nonvolatility; high densityand energy efficiency. Hybrid memory systems composed of DRAM and NVM have the bestof both worlds; because NVM can offer larger capacity and have near-zero standby powerconsumption while DRAM provides higher performance. Many studies have advocated touse DRAM as a cache to NVM. However; it is still an open problem on how to manage theDRAM cache effectively and efficiently. In this paper; we propose a novelHardware/Software Cooperative Caching (HSCC) mechanism that organizes NVM andDRAM in a flat address space while logically supporting a cache/memory hierarchy. HSCCmaintains the NVM-to-DRAM address mapping and tracks the access counts of NVM pagesthrough a moderate extension to page tables and TLBs. It significantly simplifies the …,Proceedings of the International Conference on Supercomputing,2017,*,3
Multi-Query Optimization for Complex Event Processing in SAP ESP,Shuhao Zhang; Hoang Tam Vo; Daniel Dahlmeier; Bingsheng He,SAP Event Stream Processor (ESP) platform aims at delivering real-time stream processingand analytics in many time-critical areas such as Capital Markets; Internet of Things (IoT)and Data Center Intelligence. SAP ESP allows users to realize complex event processing(CEP) in the form of pattern queries. In this paper; we present MOTTO–a multi-queryoptimizer in SAP ESP in order to improve the performance of many concurrent patternqueries. This is motivated by the observations that many real-world applications usuallyhave concurrent pattern queries working on the same data streams; leading to tremendoussharing opportunities among queries. In MOTTO; we leverage three major sharingtechniques; namely merge; decomposition and operator transformation sharing; to reduceredundant computation among pattern queries. In addition; MOTTO supports nested …,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,*,6
Data Management Systems on Future Hardware: Challenges and Opportunities,Bingsheng He,Hardware development is a major driver for the development of data management systems.For example; due to the increased capacity and low cost of main memory; data managementsystems have shifted from disk-based to in-memory systems [1]. Recently; databases onemerging hardware have gained a lot of attractions in both academia and industry. Asignificant amount of research has been devoted to the design and implementation of high-performance hardwareconscious systems. We can summarize them into three main lines ofresearch; mainly according to processor architectures.,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,*,3
Network Performance Aware Optimizations on IaaS Clouds,Yifan Gong; Bingsheng He; Dan Li,Network performance aware optimizations have long been a hot research topic to optimizedistributed applications on traditional network environments. However; those optimizationtechniques rely on a few measurements on pair-wise network performance; and such directuse of network measurements is no longer valid on Infrastructure-as-a-service (IaaS) clouds.First; the direct calibration is ineffective. Network performance measurements may notrepresent the long-term performance (informally the stable component inside networkperformance) because of virtualization and network performance interference in the cloud.Second; the direct calibration is inefficient because the measurement overhead of all pair-wise link performance in a cluster becomes prohibitively high as the number of instancesincreases. To effectively and efficiently utilize existing network performance aware …,IEEE Transactions on Computers,2017,*,12
Multi-query optimizer for complex event processing,*,Disclosed herein are technologies for facilitating optimization of pattern queries. Inaccordance with one aspect; jumbo query plans are generated by applying at least onesharing technique and combining at least two of the pattern queries. Costs of the jumboquery plans may then be estimated and used to search for an optimal query plan. Theoptimal query plan may then be executed on an input data stream to generate an outputdata stream.,*,2017,*,3
Dynamic Partitioning for Library based Placement on Heterogeneous FPGAs,Fubing Mao; Wei Zhang; Bingsheng He; SiewKei Lam,Abstract Library based design and IP reuses have been previously proposed to speed upthe synthesis of large-scale FPGA designs. However; existing methods result in large areawastage due to the module size difference and the waste area inside each module. In thispaper; we propose an efficient and dynamic module partitioning approach for the librarybased design flow that minimizes the area wastage. Our proposed approach efficientlyutilizes the pre-placement module information such as relative positions of blocks includingCLBs; DSPs and RAMs; and the module sizes (width; height) for placing these blocks. Weintroduce a B*-tree representation to enable a fast modular placement. Simulated annealingalgorithm is adopted to direct each round of the placement and to search for theoptimization. We develop a set of efficient rules to guide the module selection and …,Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays,2017,*,12
A Variation-Aware Adaptive Fuzzy Control System for Thermal Management of Microprocessors,Yingnan Cui; Wei Zhang; Bingsheng He,Thermal failures pose severe threats to reliability and performance of modernmicroprocessors; which calls for thermal management solutions to effectively control thetemperature within a processor. Among various thermal management techniques; closed-loop thermal controllers have the advantages of high control accuracy and high responsespeed. However; it is challenging for closed-loop thermal controllers to deal with static anddynamic thermal model uncertainties; which significantly affect the control quality of thecontroller. In this paper; we propose an adaptive fuzzy controller for thermal management ofmicroprocessors with adaptability to thermal model variations. The experiments withmicrobenchmarks and the SPEC CPU2006 benchmarks demonstrate that our adaptive fuzzycontroller maintains the control quality when faced with severe variations of the thermal …,IEEE Transactions on Very Large Scale Integration (VLSI) Systems,2017,*,5
Analysis of Minimum Interaction Time for Continuous Distributed Interactive Computing,Lu Zhang; Xueyan Tang; Bingsheng He,Distributed interactive computing allows participants at different locations to interact witheach other in real time. In this paper; we study the interaction times of continuous DistributedInteractive Applications (DIAs) in which the application states change due to not only user-initiated operations but also time passing. Given the clients and servers of a continuous DIA;its interaction time is directly affected by how the clients are assigned to the servers as wellas the simulation time settings of the servers. We formulate the Minimum Interaction Time(MIT) problem as a combinatorial problem of these two tuning knobs and prove that it is NP-hard. We then approximate the problem by fixing the client assignment or the simulation timeoffsets among the servers. When the client assignment is fixed; we show that finding theminimum achievable interaction time can be reduced to a weighted bipartite matching …,IEEE Transactions on Parallel and Distributed Systems,2017,*,5
FD-Buffer: A Buffer Manager for Databases on Flash Disks,Qiong Luo; Available From Qiong Luo; Sai Tung On; Yinan Li; Bingsheng He; Ming Wu; Jianliang Xu,CiteSeerX - Document Details (Isaac Councill; Lee Giles; Pradeep Teregowda):FD-buffer: a buffer manager for databases on flash disks.,*,2016,*,12
eScience and Big Data Workflows in Clouds: A Taxonomy and Survey,AC Zhou; B He; S Ibrahim,The development of computer science and technology widens our view to the world. As aresult; the amount of data observed from the world to be stored and processed has becomelarger. Analysis of such large-scale data with traditional technologies is usually time-consuming and requires a large-scale system infrastructure; and therefore can hinder thedevelopment of scientific discoveries and theories. eScience offers scientists the scope tostore; interpret; analyze and distribute their data to other research groups with state-of-the-art computing technologies. eScience plays a significant role in every aspect of scientificresearch; starting from the initial theory-based research through simulations; systematictesting and verification; to the organized collecting; processing and interpretation of scientificdata. Recently; cloud computing has become a popular computing infrastructure for …,*,2016,*,20
9 Resource Management in Big Data Processing Systems,Shanjiang Tang; Bingsheng He; Haikun Liu; Bu-Sung Lee,In many application domains such as social networks and bioinformatics; data is beinggathered at unprecedented scale. Efficient processing for Big Data analysis poses newchallenges for almost all aspects of state-of-the-art data processing and managementsystems. For example; there are a few challenges as follows:(i) the data can be arbitrarilycomplex structures (eg; graph data) and cannot be efficiently stored in relationaldatabase;(ii) the data access of large-scale data processing are frequent and complex;resulting in inefficient disk I/O accesses or network communications; and (iii) last but notleast; a variety of unpredictable failure problems must be tackled in the distributedenvironment; so the data processing system must have a fault tolerance mechanism torecovery the task computation automatically. Cloud computing has emerged as an …,*,2016,*,21
Efficient Query Processing on Many-core Architectures: A Case Study with Intel Xeon Phi Processor,Rick Siow Mong Goh Xuntao Cheng*; Bingsheng He; Mian Lu; Chiew Tong Lau; Huynh Phung Huynh,*,ACM SIGMOD DEMO,2016,*
Access Control in Cloud Computing,Qianqian Zhao; Maode Ma; Yuqing Zhang; Bingsheng He,Abstract Data sharing as one of the most popular service applications in cloud computinghas received wide attention; which makes the consumers achieve the shared contentswhenever and wherever possible. However; the new paradigm of data sharing will alsointroduce some security issues while it provides much convenience. The data confidentiality;the privacy security; the user key accountability; and the efficiency are hindering its rapidexpansion. An effective and secure access control mechanism is becoming one way to dealwith this dilemma. In this chapter; the authors focus on presenting a detailed review on theexisting access control mechanisms. Then; they explore some potential research issues forthe further development of more comprehensive and secure access control schemes.Finally; the authors expect that the topic of access control in cloud computing will attract …,*,2016,*,18
Hierarchical Library Based Power Estimator for Versatile FPGAs,Hao Liang; Yi-Chung Chen; Tao Luo; Wei Zhang; Hai Li; Bingsheng He,FPGA is a promising hardware accelerator in modern high-performance computing systems;eg cloud computing; big-data processing; etc. In such a system; power is a key factor of thedesign requiring thermal and energy-saving considerations. Modern power estimators forFPGA either support specific hardware provided by vendors or contain power models forcertain types of conventional FPGA architectures. However; with technology advancement;novel FPGA of versatile architectures are introduced to further augment current FPGAarchitecture at various aspects; such as emerging FPGA with non-volatile memory; nanowireinterconnection of reconfigurable array; etc. To evaluate the power consumption of variousFPGA designs; the power estimator has to be made more flexible and extendable forsupporting new devices and architectures. We introduce in this paper a novel power …,Embedded Multicore/Many-core Systems-on-Chip (MCSoC); 2015 IEEE 9th International Symposium on,2015,*,0
Guest Editors' Introduction: Special Issue on Economics and Market Mechanisms for Cloud Computing,Bharadwaj Veeravalli; Bingsheng He,Acloud is an emerging computing market where cloud providers and users are the players.Those players share; trade and consume computing resources in the cloud. On the otherhand; economic mechanisms (such as auctions and tiered pricing) have been designed forshaping cloud computing into a diversifying pay-as-you-go paradigm. The next generationrevolution in this domain; whose developments and realizations started to manifest already;is referred to as Cloud of Clouds wherein the computational and data infrastructure forhandling scientific; business and enterprise applications span across multiple clouds andData-Centers (DCs). Since its inception; cloud computing research has provided a range ofservices (PaaS; SaaS; IaaS) to cloud users and building cloud applications. The cloudparadigm is also increasingly being used to support more traditional high-performance …,IEEE Transactions on Cloud Computing,2015,*,5
In-Memory Data Analytics on Coupled CPU-GPU Architectures,Jiong He; Bingsheng He; Mian Lu; Shuhao Zhang,Abstract In the big data era; in-memory data analytics is an effective means of achieving highperformance data processing and realizing the value of data in a timely manner. Efforts inthis direction have been spent on various aspects; including in-memory algorithmic designsand system optimizations. In this paper; we propose to develop the next-generation in-memory relational database processing techniques on coupled CPU-GPU architectures.Particularly; we demonstrate novel design and implementations of query processingparadigms to utilize the strengths of coupled CPU-GPU architectures such as shared mainmemory and cache hierarchy. We propose a fine-grained method to distribute workload ontoavailable processors; since the CPU and the GPU share the same main memory space.Besides; we propose an in-cache paradigm for query processing to take advantage of …,*,2015,*,12
Towards automatic partial reconfiguration in FPGAs,Fubing Mao; Wei Zhang; Bingsheng He,Partial Reconfiguration (PR) is an advanced reconfigurable characteristic for FPGAs and ithas the capability to reconfigure specific regions of FPGAs while the other parts are stillactive or are inactive in a shutdown mode after its initial configuration. It provides manybenefits for industry; eg sharing the same hardware resource for different applications.,Field-Programmable Technology (FPT); 2014 International Conference on,2014,*,21
A novel authenticated multi-party key agreement for private cloud,Tuo He; Maode Ma; Wenping Ma; Bingsheng He,Cloud computing technology is an emerging technology for various types of vast informationto be processed in the data centers to overcome the serious shortage of resource such asspace; power and cost; etc. Along with the development of cloud computing; security ofcloud computing is becoming more and more critical. In this paper; we aim to propose a setof secure and efficient authenticated multi-party key agreement protocols based on thehierarchical identity-based cryptography (HIBC) for private cloud. For different scenarios; wedesign loop-level and cascade-level authentication protocols among users in a private cloudof hierarchical structure; respectively. The new multi-party protocols are supposed to bemore efficient and secure than the other existing solutions.,Communications (ICC); 2014 IEEE International Conference on,2014,*,18
SilverWisdom: Towards a Knowledge Base for Elderly People,Xuntao Cheng; Zhaojie Niu; Bingsheng He,*,International Journal of Information Technology,2013,*
Improving run time in three-dimensional reservoir hydrodynamics and water quality modeling,Zikun Xing; Cheng Liu; Lloyd HC Chua; Bingsheng He; Hans S Eikaas,Kranji Reservoir (1 25'N; 103 43'E) is a small and shallow tropical reservoir (surface area ofabout 300 hectares and mean depth of about 5 m; see Fig. 1A) located in Singapore whichexperiences episodes of eutrophication. As part of management efforts for the reservoir; wehave applied the Estuary Lake and Coastal Ocean Model-Computational Aquatic EcosystemDynamics Model (ELCOM-CAEDYM) which is an integrated three-dimensionalhydrodynamic-ecological model developed by the Centre for Water Research; University ofWestern Australia (Hodges et al.; 2000; Romero et al.; 2004). An ELCOM-CAEDYM modelwas set up to model water quality in Kranji reservoir; specifically studying dissolved oxygen(DO); major nutrients and total chlorophyll-a concentrations. ELCOM-CAEDYM is a complexmodel and proper model calibration and validation is not a trivial task. Furthermore …,ICHE 2012: Proceedings of the 10th International Conference on Hydroscience & Engineering,2012,*,12
Supplemental Material: Long-Term Multi-Resource Fairness for Pay-as-you Use Computing Systems,Shanjiang Tang; Zhaojie Niu; Bingsheng He; Bu-Sung Lee; Ce Yu,Abstract—Many current computing systems such as clouds and supercomputers chargeusers for their resource usages. A user's demand is often changing over time; indicating thatit is difficult to keep the high resource utilization all the time for cost efficiency. Resourcesharing is a classical and effective approach for high resource utilization. In view of theheterogeneous resource demands of users' workloads; multi-resource allocation fairness isa must for resource sharing in such pay-as-you-use computing systems. However; we findthat; existing multi-resource fair policies such as Dominant Resource Fairness (DRF);implemented in currently popular resource management systems such as Apache YARN [4]and Mesos [23]; are not suitable for the pay-as-you-use computing systems. We show thatthis is because of their memoryless characteristic that can cause the following problems …,*,*,*,12
ThunderSVM: A Fast SVM Library on GPUs and CPUs,Zeyi Wen; Jiashuai Shi; Bingsheng He; Qinbin Li; Jian Chen,Abstract Support Vector Machines (SVMs) are classic supervised learning models forclassification; regression and distribution estimation. A survey conducted by Kaggle in 2017shows that 26% of the data mining and machine learning practitioners are users of SVMs.However; SVM training and prediction are very expensive computationally for large andcomplex problems. This paper presents an efficient and open source SVM software toolkitcalled ThunderSVM which exploits the high-performance of Graphics Processing Units(GPUs) and multi-core CPUs. ThunderSVM supports all the functionalities—includingclassification (SVC); regression (SVR) and one-class SVMs—of LibSVM and uses identicalcommand line options; such that existing LibSVM users can easily apply our toolkit.ThunderSVM can be used through multiple language interfaces including C/C++; Python …,*,*,*,0
Multi-kernel Data Partitioning with Channel on OpenCL-based FPGAs (Technical Report),Zeke Wang; Johns Paul; Bingsheng He; Wei Zhang,Abstract—FPGAs have been widely used to accelerate relational database applications; dueto their high throughput and high energy efficiency. However; hardware programmer needsto leverage hardware description languages (HDLs) to program FPGAs. Since HDL is cycle-sensitive and error-prone; deep knowledge about hardware design and hands-onexperiences are required to guarantee a successful design on FPGA; impeding a morewidespread adoption of FPGAs. Fortunately; FPGA vendors (such as Altera) have started toaddress the programmability issues of FPGAs via OpenCL SDKs. In this paper; we analyzethe performance of relational database applications on FPGAs using OpenCL. In particular;we study how to improve the performance of data partitioning; which is a very importantbuilding block in relational database. Since the data partitioning casuses random memory …,Work,*,*,11
Supplemental Material: Fair Resource Allocation for Data-Intensive Computing in the Cloud,Shanjiang Tang; Bu-Sung Lee; Bingsheng He,Abstract—To address the computing challenge of'big data'; a number of data-intensivecomputing frameworks (eg; MapReduce; Dryad; Storm and Spark) have emerged andbecome popular. YARN is a de facto resource management platform that enables theseframeworks running together in a shared system. However; we observe that; in cloudcomputing environment; the fair resource allocation policy implemented in YARN is notsuitable because of its memoryless resource allocation fashion leading to violations of anumber of good properties in shared computing systems. This paper attempts to addressthese problems for YARN. Both singlelevel and hierarchical resource allocations areconsidered. For single-level resource allocation; we propose a novel fair resource allocationmechanism called Long-Term Resource Fairness (LTRF) for such computing. For …,*,*,*,12
Bridging Reconfigurable Computing and HPC: An OpenCL-based MapReduce Framework on FPGA,Bingsheng He; Zeke Wang; Shuhao Zhang; Wei Zhang,*,*,*,*
Accelerating Database Query Processing on OpenCL-based FPGAs,Zeke Wang Johns Paul Huiyan Cheah; Bingsheng He; Wei Zhang,Abstract—The release of OpenCL support for FPGAs represents a significant improvementin extending database applications to the reconfigurable domain. Taking advantage of theprogrammability offered by the OpenCL HLS tool; an OpenCL database can be easily portedand re-designed for FPGAs. A single SQL query in these database systems usually consistsof multiple operators; and each one of these operators in turn consists of multiple OpenCLkernels. Due to the specific properties of FPGAs; each OpenCL kernel can have differentFPGA-specific optimization combinations (in terms of CU (Compute Units) and SIMD (Kernelvectorization)) which are critical to the overall performance of query processing. Due to theresource limitation of an FPGA image; our query plan also considers the possibility of usingmultiple FPGA images. In this paper; we propose an FPGA-specific cost model to …,*,*,*,0
Economic Fairness for Resource Sharing in Pay-as-you-use Cloud Computing,Shanjiang Tang; Bu-Sung Lee; Bingsheng He,*,*,*,*
Supplemental Material: DynamicMR: A Dynamic Slot Allocation Optimization Framework for MapReduce Clusters,Shanjiang Tang; Bu-Sung Lee; Bingsheng He,Abstract—MapReduce is a popular computing paradigm for large-scale data processing incloud computing. However; the slot-based MapReduce system (eg; Hadoop MRv1) cansuffer from poor performance due to its unoptimized resource allocation. To address it; thispaper identifies and optimizes the resource allocation from three key aspects. First; due tothe pre-configuration of distinct map slots and reduce slots which are not fungible; slots canbe severely under-utilized. Because map slots might be fully utilized while reduce slots areempty; and vice-versa. We proposes an alternative technique called Dynamic Hadoop SlotAllocation by keeping the slot-based model. It relaxes the slot allocation constraint to allowslots to be reallocated to either map or reduce tasks depending on their needs. Second; thespeculative execution can tackle the straggler problem; which has shown to improve the …,*,*,*,18
APSCC 2014,Xiang Bai; Yungang Bao; Jiajun Bu; Yi Cai; Buqing Cao; Jian Cao; Duanbing Chen; Fu Chen; Haibo Chen; Hao Chen; Liang Chen; Shiping Chen; Shizhan Chen; Yueguo Chen; Yunji Chen; Bin Cheng; Bo Cheng; Rui Chu; Hongning Dai; Shuiguang Deng; Sheng Di; Zhijun Ding; Tadashi Dohi; Dezun Dong; Wei Dong; Weisheng Dong; Zaiwen Feng; Xiaofeng Gao; Andrzej Goscinski; Bin Guo; Deke Guo; Jinsong Han; Yahong Han; Bingsheng He; Daojing He; Qiang He; Yuan He; Chunming Hu; Yu Hua; Hongyu Huang; Jeff Huang; Rongrong Ji; Hai Jiang; Hongbo Jiang,Xiang Bai; Huazhong University of Science and Technology; China Yungang Bao; Chinese Academyof Sciences; China Jiajun Bu; Zhejiang University; China Yi Cai; South China University ofTechnology; China Buqing Cao; Hunan University of Science and Technology; China JianCao; Shanghai Jiao Tong University; China Le Chang; Huawei Technologies; Co.; Ltd; ChinaDuanbing Chen; University of Electronic Science and Technology of China; China Fu Chen;Beijing Foreign Studies University; China Haibo Chen; Shanghai Jiao Tong University; ChinaHao Chen; Hunan University; China Liang Chen; Zhejiang University; China Shiping Chen; CSIROICT; Australia Shizhan Chen; Tianjin University; China Yueguo Chen; Renmin University ofChina; China Yunji Chen; Chinese Academy of Sciences; China Bin Cheng; NEC LaboratoriesEurope; German Bo Cheng; Beijing University of Posts and Telecommunications; China …,*,*,*,2
Synergy of Dynamic Frequency Scaling and Demotion on DRAM Power Management: Models and Optimizations (Supplementary File),Yanchao Lu; Bingsheng He; Xueyan Tang; Minyi Guo,In this section; we evaluate the impact of Hybrid on fullsystem energy consumption andperformance. We start by performing back-of-envelop calculations; following previousstudies [1];[2]. We assume that the average power consumption of memory system accountsfor 40% of the total system power in the baseline policy (ie; BASE); and calculate a fixedaverage power estimate (ie; the remaining 60%) for all other components. Thus; the energyconsumption of all other components (ie; non-memory system energy consumption) isproportional to the program execution time; which is usually consistent with the real-worldcase [1];[2]. This ratio (40%) has been chosen as the current contribution of memory systemto entire system power consumption [1];[2];[3];[4];[5]. We also study the impact of varying thisratio in this evaluation. Architectural characteristics and experimental parameters are the …,*,*,*,0
GPGPU for Big Data Analytics,Bingsheng He,*,*,*,*
DynamicMR: A Dynamic Slot Allocation and Scheduling Framework for MapReduce Clusters,Shanjiang Tang; Bu-Sung Lee; Bingsheng He,*,*,*,*
Network Performance Aware MPI Collective Communication Operations in the Cloud (Supplementary File),Yifan Gong; Bingsheng He; Jianlong Zhong,*,*,*,*
Battery Matters: Rightsizing Energy Storage for Green Datacenters,Wei Deng; Fangming Liu; Hai Jin; Chuan Wu; Xue Liu; Bingsheng He,Abstract—Modern cloud datacenters are equipped with mul-tiple energy sources includingsmart grids; battery and on-site renewable energy. The battery places an important role instoring renewable energy and power purchased from the grid markets; for green and cost-effective energy consumption. There is a lack of study in the existing literature on quantifyingthe role and cost tradeoff of rightsizing the battery for energy store in a cloud datacenter. Inthis paper; our goal is to obtain a thorough understanding on the tradeoffs between battery'scontribution in energy storage and its provisioning cost; in order to gain useful insights forbattery rightsizing in cloud datacenters with arbitrary energy demand and time-varyingrenewable energy generation. We further consider different pricing schemes of the smartgrids; including constant pricing; dynamic real-time pricing and two-timescale pricing …,*,*,*,10
Medusa: Simplified Graph Processing on GPUs (Supplementary File),Jianlong Zhong; Bingsheng He,*,*,*,*
Report on the Second International Workshop on Flash-Based Database Systems (FlashDB 2012),Xiaofeng Meng; Bingsheng He; Wei Cao; Jianliang Xu,Nowadays; as OLTP and OLAP applications' data volume grows into “big data” scale;requirements such as high performance; low latency; high availability; and low powerconsumption etc. become more and more critical and challenging. This trend gives rise tothe advent of new types of storage media and storage devices; such as flash-based SolidState Drives and Phase Change Memory; which are competitive rivals of traditionalmagnetic disks and main memory. Being the pioneers in the storage innovation market; flash-based devices have prevailed in consumer electronics because of non-volatility; low-cost;small size; shock resistance; and low-power consumption. But features like out-placeupdates; asymmetric read/write/erasure latencies; and limited life span and capacity etc.pose challenges in directly using flash-based devices as data storage devices. Storage …,*,*,*,12
