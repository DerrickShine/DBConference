A measure of similarity between graph vertices: Applications to synonym extraction and web searching,Vincent D Blondel; Anahí Gajardo; Maureen Heymans; Pierre Senellart; Paul Van Dooren,We introduce a concept of {similarity} between vertices of directed graphs. Let GA and GBbetwo directed graphs with; respectively; n A and n B vertices. We define an n B\times n Asimilarity matrix S whose real entry sij expresses how similar vertex j (in GA) is to vertex i (inGB): we say that sij is their similarity score. The similarity matrix can be obtained as the limitof the normalized even iterates of S k+ 1= BS kAT+ BTSkA; where A and B are adjacencymatrices of the graphs and S 0 is a matrix whose entries are all equal to 1. In the specialcase where GA= GB= G; the matrix S is square and the score sij is the similarity scorebetween the vertices i and j of G. We point out that Kleinberg's" hub and authority" method toidentify web-pages relevant to a given query can be viewed as a special case of ourdefinition in the case where one of the graphs has two vertices and a unique directed …,Siam Review,2004,421
Corroborating information from disagreeing views,Alban Galland; Serge Abiteboul; Amélie Marian; Pierre Senellart,Abstract We consider a set of views stating possibly conflicting facts. Negative facts in theviews may come; eg; from functional dependencies in the underlying database schema. Wewant to predict the truth values of the facts. Beyond simple methods such as voting (typicallyrather accurate); we explore techniques based on" corroboration"; ie; taking into accounttrust in the views. We introduce three fixpoint algorithms corresponding to different levels ofcomplexity of an underlying probabilistic model. They all estimate both truth values of factsand trust in the views. We present experimental studies on synthetic and real-world data.This analysis illustrates how and in which context these methods improve corroborationresults over baseline methods. We believe that corroboration can serve in a wide range ofapplications such as source selection in the semantic Web; data quality assessment or …,Proceedings of the third ACM international conference on Web search and data mining,2010,241
PARIS: Probabilistic alignment of relations; instances; and schema,Fabian M Suchanek; Serge Abiteboul; Pierre Senellart,Abstract One of the main challenges that the Semantic Web faces is the integration of agrowing number of independently designed ontologies. In this work; we present paris; anapproach for the automatic alignment of ontologies. paris aligns not only instances; but alsorelations and classes. Alignments at the instance level cross-fertilize with alignments at theschema level. Thereby; our system provides a truly holistic solution to the problem ofontology alignment. The heart of the approach is probabilistic; ie; we measure degrees ofmatchings based on probability estimates. This allows paris to run without any parametertuning. We demonstrate the efficiency of the algorithm and its precision through extensiveexperiments. In particular; we obtain a precision of around 90% in experiments with some ofthe world's largest ontologies.,Proceedings of the VLDB Endowment,2011,216
Web data management,Serge Abiteboul; Ioana Manolescu; Philippe Rigaux; Marie-Christine Rousset; Pierre Senellart,The Internet and World Wide Web have revolutionized access to information. Users nowstore information across multiple platforms from personal computers to smartphones andwebsites. As a consequence; data management concepts; methods and techniques areincreasingly focused on distribution concerns. Now that information largely resides in thenetwork; so do the tools that process this information. This book explains the foundations ofXML with a focus on data distribution. It covers the many facets of distributed datamanagement on the Web; such as description logics; that are already emerging in today'sdata integration applications and herald tomorrow's semantic Web. It also introduces themachinery used to manipulate the unprecedented amount of data collected on the Web.Several'Putting into Practice'chapters describe detailed practical applications of the …,*,2011,118
Querying and updating probabilistic information in XML,Serge Abiteboul; Pierre Senellart,Abstract We present in this paper a new model for representing probabilistic information in asemi-structured (XML) database; based on the use of probabilistic event variables. This workis motivated by the need of keeping track of both confidence and lineage of the informationstored in a semi-structured warehouse. For instance; the modules of a (Hidden Web) contentwarehouse may derive information concerning the semantics of discovered Web servicesthat is by nature not certain. Our model; namely the fuzzy tree model; supports both querying(tree pattern queries with join) and updating (transactions containing an arbitrary set ofinsertions and deletions) over probabilistic tree data. We highlight its expressive power anddiscuss implementation issues.,International Conference on Extending Database Technology,2006,117
On the complexity of managing probabilistic XML data,Pierre Senellart; Serge Abiteboul,Abstract In [3]; we introduced a framework for querying and updating probabilisticinformation over unordered labeled trees; the probabilistic tree model. The data model isbased on trees where nodes are annotated with conjunctions of probabilistic eventvariables. We briefly described an implementation and scenarios of usage. We develop herea mathematical foundation for this model. In particular; we present complexity results. Weidentify a very large class of queries for which simple variations of querying and updatingalgorithms from [3] compute the correct answer. A main contribution is a full complexityanalysis of queries and updates. We also exhibit a decision procedure for the equivalence ofprobabilistic trees and prove it is in co-RP. Furthermore; we study the issue of removing lessprobable possible worlds; and that of validating a probabilistic tree against a DTD. We …,Proceedings of the twenty-sixth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2007,104
On the expressiveness of probabilistic XML models,Serge Abiteboul; Benny Kimelfeld; Yehoshua Sagiv; Pierre Senellart,Abstract Various known models of probabilistic XML can be represented as instantiations ofthe abstract notion of p-documents. In addition to ordinary nodes; p-documents havedistributional nodes that specify the possible worlds and their probabilistic distribution.Particular families of p-documents are determined by the types of distributional nodes thatcan be used as well as by the structural constraints on the placement of those nodes in a p-document. Some of the resulting families provide natural extensions and combinations ofpreviously studied probabilistic XML models. The focus of the paper is on the expressivepower of families of p-documents. In particular; two main issues are studied. The first is theability to (efficiently) translate a given p-document of one family into another family. Thesecond is closure under updates; namely; the ability to (efficiently) represent the result of …,The VLDB Journal,2009,92
Automatic Discovery of Similar Words,Pierre Senellart; Vincent D Blondel,The purpose of this chapter is to review some methods used for automatic extraction ofsimilar words from different kinds of sources: large corpora of documents; the World WideWeb; and monolingual dictionaries. The underlying goal of these methods is in general theautomatic discovery of synonyms. This goal; however; is most of the time too difficult toachieve since it is often hard to distinguish in an automatic way among synonyms;antonyms; and; more generally; words that are semantically close to each others. Mostmethods provide words that are “similar” to each other; with some vague notion of semanticsimilarity. We mainly describe two kinds of methods: techniques that; upon input of a word;automatically compile a list of good synonyms or near-synonyms; and techniques thatgenerate a thesaurus (from some source; they build a complete lexicon of related words) …,Survey of Text Mining II,2008,89
Crowd mining,Yael Amsterdamer; Yael Grossman; Tova Milo; Pierre Senellart,Abstract Harnessing a crowd of Web users for data collection has recently become a wide-spread phenomenon. A key challenge is that the human knowledge forms an open worldand it is thus difficult to know what kind of information we should be looking for. Classicdatabases have addressed this problem by data mining techniques that identify interestingdata patterns. These techniques; however; are not suitable for the crowd. This is mainly dueto properties of the human memory; such as the tendency to remember simple trends andsummaries rather than exact details. Following these observations; we develop here for thefirst time the foundations of crowd mining. We first define the formal settings. Based on these;we design a framework of generic components; used for choosing the best questions to askthe crowd and mining significant patterns from the answers. We suggest general …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,75
Automatic extraction of synonyms in a dictionary,Vincent D Blondel; Pierre P Senellart,Abstract We propose a method for automatic synonym extraction in a dictionary. Our methodis based on an algorithm that computes similarity measures between vertices in graphs. Thisalgorithm can be thought of as a generalization of Kleinberg's web search algorithm tostructure graphs that are more general than the hub-authority graph used by Kleinberg. Weuse the 1913 Webster's Dictionary and apply our method on four synonym queries. Theresults obtained are analyzed and compared to those obtained with two other methods.,Text Mining Workshop,2002,67
Finding related pages using Green measures: An illustration with Wikipedia,Yann Ollivier; Pierre Senellart,Abstract We introduce a new method for finding nodes semantically related to a given nodein a hyperlinked graph: the Green method; based on a classical Markov chain tool. It isgeneric; adjustment-free and easy to implement. We test it in the case of the hyperlinkstructure of the English version of Wikipedia; the on-line encyclopedia. We present anextensive comparative study of the performance of our method versus several other classicalmethods in the case of Wikipedia. The Green method is found to have both the best averageresults and the best robustness.,AAAI,2007,62
Automatic wrapper induction from hidden-web sources with domain knowledge,Pierre Senellart; Avin Mittal; Daniel Muschick; Rémi Gilleron; Marc Tommasi,Abstract We present an original approach to the automatic induction of wrappers for sourcesof the hidden Web that does not need any human supervision. Our approach only needsdomain knowledge expressed as a set of concept names and concept instances. There aretwo parts in extracting valuable data from hidden-Web sources: understanding the structureof a given HTML form and relating its fields to concepts of the domain; and understandinghow resulting records are represented in an HTML result page. For the former problem; weuse a combination of heuristics and of probing with domain instances; for the latter; we use asupervised machine learning technique adapted to tree-like information on an automatic;imperfect; and imprecise; annotation using the domain knowledge. We show experimentsthat demonstrate the validity and potential of the approach.,Proceeding of the 10th ACM workshop on Web information and data management,2008,61
Probabilistic XML: Models and complexity,Benny Kimelfeld; Pierre Senellart,Abstract Uncertainty in data naturally arises in various applications; such as data integrationand Web information extraction. Probabilistic XML is one of the concepts that have beenproposed to model and manage various kinds of uncertain data. In essence; a probabilisticXML document is a compact representation of a probability distribution over ordinary XMLdocuments. Various models of probabilistic XML provide different languages; with variousdegrees of expressiveness; for such compact representations. Beyond representation;probabilistic XML systems are expected to support data management in a way that properlyreflects the uncertainty. For instance; query evaluation entails probabilistic inference; andupdate operations need to properly change the entire probability space. Efficiently andeffectively accomplishing data-management tasks in that manner is a major technical …,*,2013,54
Schema mapping discovery from data instances,Georg Gottlob; Pierre Senellart,Abstract We introduce a theoretical framework for discovering relationships between twodatabase instances over distinct and unknown schemata. This framework is grounded in thecontext of data exchange. We formalize the problem of understanding the relationshipbetween two instances as that of obtaining a schema mapping so that a minimum repair ofthis mapping provides a perfect description of the target instance given the source instance.We show that this definition yields “intuitive” results when applied on database instancesderived from each other by basic operations. We study the complexity of decision problemsrelated to this optimality notion in the context of different logical languages and show that;even in very restricted cases; the problem is of high complexity.,Journal of the ACM (JACM),2010,50
Online influence maximization,Siyu Lei; Silviu Maniu; Luyi Mo; Reynold Cheng; Pierre Senellart,Abstract Social networks are commonly used for marketing purposes. For example; freesamples of a product can be given to a few influential social network users (or seed nodes);with the hope that they will convince their friends to buy it. One way to formalize thisobjective is through the problem of influence maximization (or IM); whose goal is to find thebest seed nodes to activate under a fixed budget; so that the number of people who getinfluenced in the end is maximized. Solutions to IM rely on the influence probability that auser influences another one. However; this probability information may be unavailable orincomplete. In this paper; we study IM in the absence of complete information on influenceprobability. We call this problem Online Influence Maximization (OIM); since we learninfluence probabilities at the same time we run influence campaigns. To solve OIM; we …,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2015,47
Aggregate queries for discrete and continuous probabilistic XML,Serge Abiteboul; T-H Hubert Chan; Evgeny Kharlamov; Werner Nutt; Pierre Senellart,Abstract Sources of data uncertainty and imprecision are numerous. A way to handle thisuncertainty is to associate probabilistic annotations to data. Many such probabilisticdatabase models have been proposed; both in the relational and in the semi-structuredsetting. The latter is particularly well adapted to the management of uncertain data comingfrom a variety of automatic processes. An important problem; in the context of probabilisticXML databases; is that of answering aggregate queries (count; sum; avg; etc.); which hasreceived limited attention so far. In a model unifying the various (discrete) semi-structuredprobabilistic models studied up to now; we present algorithms to compute the distribution ofthe aggregation values (exploiting some regularity properties of the aggregate functions)and probabilistic moments (especially; expectation and variance) of this distribution. We …,Proceedings of the 13th international conference on database theory,2010,46
Data quality in web archiving,Marc Spaniol; Dimitar Denev; Arturas Mazeika; Gerhard Weikum; Pierre Senellart,Abstract Web archives preserve the history of Web sites and have high long-term value formedia and business analysts. Such archives are maintained by periodically re-crawlingentire Web sites of interest. From an archivist's point of view; the ideal case to ensure highestpossible data quality of the archive would be to" freeze" the complete contents of an entireWeb site during the time span of crawling and capturing the site. Of course; this is practicallyinfeasible. To comply with the politeness specification of a Web site; the crawler needs topause between subsequent http requests in order to avoid unduly high load on the site's httpserver. As a consequence; capturing a large Web site may span hours or even days; whichincreases the risk that contents collected so far are incoherent with the parts that are still tobe crawled. This paper introduces a model for identifying coherent sections of an archive …,Proceedings of the 3rd workshop on Information credibility on the web,2009,45
The repeatability experiment of SIGMOD 2008,Ioana Manolescu; Loredana Afanasiev; Andrei Arion; Jens Dittrich; Stefan Manegold; Neoklis Polyzotis; Karl Schnaitter; Pierre Senellart; Spyros Zoupanos; Dennis Shasha,Abstract SIGMOD 2008 was the first database conference that offered to test submitters'programs against their data to verify the experiments published. This paper discusses therationale for this effort; the community's reaction; our experiences; and advice for futuresimilar efforts.,ACM SIGMOD Record,2008,38
Discovering meta-paths in large heterogeneous information networks,Changping Meng; Reynold Cheng; Silviu Maniu; Pierre Senellart; Wangda Zhang,Abstract The Heterogeneous Information Network (HIN) is a graph data model in whichnodes and edges are annotated with class and relationship labels. Large and complexdatasets; such as Yago or DBLP; can be modeled as HINs. Recent work has studied how tomake use of these rich information sources. In particular; meta-paths; which representsequences of node classes and edge types between two nodes in a HIN; have beenproposed for such tasks as information retrieval; decision making; and productrecommendation. Current methods assume meta-paths are found by domain experts.However; in a large and complex HIN; retrieving meta-paths manually can be tedious anddifficult. We thus study how to discover meta-paths automatically. Specifically; users areasked to provide example pairs of nodes that exhibit high proximity. We then investigate …,Proceedings of the 24th International Conference on World Wide Web,2015,34
Provenance circuits for trees and treelike instances,Antoine Amarilli; Pierre Bourhis; Pierre Senellart,Abstract Query evaluation in monadic second-order logic (MSO) is tractable on trees andtreelike instances; even though it is hard for arbitrary instances. This tractability result hasbeen extended to several tasks related to query evaluation; such as counting query results[2] or performing query evaluation on probabilistic trees [8]. These are two examples of themore general problem of computing augmented query output; that is referred to asprovenance. This article presents a provenance framework for trees and treelike instances;by describing a linear-time construction of a circuit provenance representation for MSOqueries. We show how this provenance can be connected to the usual definitions ofsemiring provenance on relational instances [17]; even though we compute it in an unusualway; using tree automata; we do so via intrinsic definitions of provenance for general …,International Colloquium on Automata; Languages; and Programming,2015,29
Monadic datalog containment,Michael Benedikt; Pierre Bourhis; Pierre Senellart,Abstract We reconsider the problem of containment of monadic datalog (MDL) queries inunions of conjunctive queries (UCQs). Prior work has dealt with special cases; but has leftthe precise complexity characterization open. We begin by establishing a 2EXPTIME lowerbound on the MDL/UCQ containment problem; resolving an open problem from the early90's. We then present a general approach for getting tighter bounds on the complexity;based on analysis of the number of mappings of queries into tree-like instances. We use themachinery to present an important case of the MDL/UCQ containment problem that is in co-NEXPTIME; and a case that is in EXPTIME. We then show that the technique can be used toget a new tight upper bound for containment of tree automata in UCQs. We show that thenew MDL/UCQ upper bounds are tight.,International Colloquium on Automata; Languages; and Programming,2012,28
Probabilistic XML via Markov chains,Michael Benedikt; Evgeny Kharlamov; Dan Olteanu; Pierre Senellart,Abstract We show how Recursive Markov Chains (RMCs) and their restrictions can defineprobabilistic distributions over XML documents; and study tractability of querying over suchmodels. We show that RMCs subsume several existing probabilistic XML models. In contrastto the latter; RMC models (i) capture probabilistic versions of XML schema languages suchas DTDs;(ii) can be exponentially more succinct; and (iii) do not restrict the domain ofprobability distributions to be finite. We investigate RMC models for which tractability can beachieved; and identify several tractable fragments that subsume known tractableprobabilistic XML models. We then look at the space of models between existingprobabilistic XML formalisms and RMCs; giving results on the expressiveness andsuccinctness of RMC subclasses; both with each other and with prior formalisms.,Proceedings of the VLDB Endowment,2010,28
Determining relevance of accesses at runtime,Michael Benedikt; Georg Gottlob; Pierre Senellart,Abstract Consider the situation where a query is to be answered using Web sources thatrestrict the accesses that can be made on backend relational data by requiring someattributes to be given as input of the service. The accesses provide lookups on the collectionof attributes values that match the binding. They can differ in whether or not they requirearguments to be generated from prior accesses. Prior work has focused on the question ofwhether a query can be answered using a set of data sources; and in developing staticaccess plans (eg; Datalog programs) that implement query answering. We are interested indynamic aspects of the query answering problem: given partial information about the data;which accesses could provide relevant data for answering a given query? We considerimmediate and long-term notions of" relevant accesses"; and ascertain the complexity of …,Proceedings of the 30th symposium on Principles of database systems of data,2011,23
Deriving dynamics of web pages: A survey,Marilena Oita; Pierre Senellart,The World Wide Web is dynamic by nature: content is continuously added; deleted; orchanged; which makes it challenging for Web crawlers to keep up-to-date with the currentversion of a Web page; all the more so since not all apparent changes are significant ones.We review major approaches to change detection in Web pages and extraction of temporalproperties (especially; timestamps) of Web pages. We focus our attention on techniques andsystems that have been proposed in the last ten years and we analyze them to get someinsight into the practical solutions and best practices available. We aim at providing ananalytical view of the range of methods that can be used; distinguishing them on severaldimensions; especially; their static or dynamic nature; the modeling of Web pages; or; fordynamic methods relying on comparison of successive versions of a page; the similarity …,TWAW (Temporal Workshop on Web Archiving),2011,22
Intelligent and adaptive crawling of web applications for web archiving,Muhammad Faheem; Pierre Senellart,Abstract Web sites are dynamic in nature with content and structure changing overtime.Many pages on the Web are produced by content management systems (CMSs) such asWordPress; vBulletin; or phpBB. Tools currently used by Web archivists to preserve thecontent of the Web blindly crawl and store Web pages; disregarding the CMS the site isbased on (leading to suboptimal crawling strategies) and whatever structured content iscontained in Web pages (resulting in page-level archives whose content is hard to exploit).We present in this paper an application-aware helper (AAH) that fits into an archiving crawlprocessing chain to perform intelligent and adaptive crawling of Web applications (eg; thepages served by a CMS). Because the AAH is aware of the Web application currentlycrawled; it is able to refine the list of URLs to process and to extend the archive with …,International Conference on Web Engineering,2013,21
Archiving data objects using web feeds,Marilena Oita; Pierre Senellart,Web feeds; either in RSS or Atom XML-based formats; are evolving descriptive documentsthat characterize a dynamic hub of a Web site and help subscribers keep up with what is themost recent Web content of interest. In this paper; we show how Web feeds can be usefulinstruments for information extraction and Web page change detection. Web pagesreferenced by feed items are usually blog posts or news articles; data with a dynamic (thenephemeral) nature and which is clustered topically in a feed channel. We monitor Webchannels and extract from the associated Web pages the text and references correspondingto Web articles. The result is enriched with the timestamp and additional metadata minedfrom the feed; and encapsulated in a'data object'. The data object will be in particularinformation devoided of all the template elements or advertisements. These irrelevant …,IWAW,2010,21
Updating probabilistic XML,Evgeny Kharlamov; Werner Nutt; Pierre Senellart,Abstract We investigate the complexity of performing updates on probabilistic XML data forvarious classes of probabilistic XML documents of different succinctness. We consider twoelementary kinds of updates; insertions and deletions; that are defined with the help of alocator query that specifies the nodes where the update is to be performed. For insertions;two semantics are considered; depending on whether a node is to be inserted once or forevery match of the query. We first discuss deterministic updates over probabilistic XML; andthen extend the algorithms and complexity bounds to probabilistic updates. In addition to anumber of intractability results; our main result is an efficient algorithm for insertions definedwith branching-free queries over probabilistic models with local dependencies. Finally; wediscuss the problem of updating probabilistic XML databases with continuous probability …,Proceedings of the 2010 EDBT/ICDT Workshops,2010,21
Uncertain version control in open collaborative editing of tree-structured documents,M Lamine Ba; Talel Abdessalem; Pierre Senellart,Abstract In order to ease content enrichment; exchange; and sharing; web-scalecollaborative platforms such as Wikipedia or Google Docs enable unbounded interactionsbetween a large number of contributors; without prior knowledge of their level of expertiseand reliability. Version control is then essential for keeping track of the evolution of theshared content and its provenance. In such environments; uncertainty is ubiquitous due tothe unreliability of the sources; the incompleteness and imprecision of the contributions; thepossibility of malicious editing and vandalism acts; etc. To handle this uncertainty; we use aprobabilistic XML model as a basic component of our version control framework. Eachversion of a shared document is represented by an XML tree and the whole document;together with its different versions; is modeled as a probabilistic XML document …,Proceedings of the 2013 ACM symposium on Document engineering,2013,20
Tractable lineages on treelike instances: Limits and extensions,Antoine Amarilli; Pierre Bourhis; Pierre Senellart,Abstract Query evaluation on probabilistic databases is generally intractable (# P-hard).Existing dichotomy results have identified which queries are tractable (or safe); andconnected them to tractable lineages. In our previous work; using different tools; we showedthat query evaluation is linear-time on probabilistic databases for arbitrary monadic second-order queries; if we bound the treewidth of the instance. In this paper; we study limitationsand extensions of this result. First; for probabilistic query evaluation; we show that MSOtractability cannot extend beyond bounded treewidth: there are even FO queries that arehard on any efficiently constructible unbounded-treewidth class of graphs. This dichotomyrelies on recent polynomial bounds on the extraction of planar graphs as minors; andimplies lower bounds in non-probabilistic settings; for query evaluation and match …,Proceedings of the 35th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,2016,18
Exploiting the social and semantic web for guided web archiving,Thomas Risse; Stefan Dietze; Wim Peters; Katerina Doka; Yannis Stavrakas; Pierre Senellart,Abstract The constantly growing amount of Web content and the success of the Social Weblead to increasing needs for Web archiving. These needs go beyond the pure preservationof Web pages. Web archives are turning into “community memories” that aim at building abetter understanding of the public view on; eg; celebrities; court decisions; and other events.In this paper we present the ARCOMEM architecture that uses semantic information such asentities; topics; and events complemented with information from the social Web to guide anovel Web crawler. The resulting archives are automatically enriched with semantic meta-information to ease the access and allow retrieval based on conditions that involve high-level concepts.,International Conference on Theory and Practice of Digital Libraries,2012,18
Extraction of information in large graphs. Automatic search for synonyms,Pierre P Senellart,Page 1. Extraction of information in large graphs Automatic search for synonyms Pierre Senellart;under the direction of Prof. Vincent Blondel June 5th 2001 - August 3rd 2001 Page 2. The dictionarygraph Computation (n.) The act or process of computing; calculation; reckon- ing. Computation(n.) The result of computation; the amount computed. Computed (imp. & pp) of Compute Computing(p. pr. & vb. n.) of Compute Compute (vt) To determine calculation; to reckon; to count. Compute(n.) Computation. Computer (n.) One who computes. Page 3. Computer Compute ComputingComputation Computed Rest of the graph Page 4. Extraction of the graph • Multiwords (eg All Saints';Surinam toad) • Prefixes and suffixes (eg un-; -ous) • Different meanings of a word • Derived forms(eg daisies; sought) • Accentuated characters (eg proven/al; cr/che) • Misspelled words 112;169vertices - 1;398;424 arcs. Page 5. Lexical units …,Rapport de stage; Université Catholique de Louvain,2001,18
CrowdMiner: Mining association rules from the crowd,Yael Amsterdamer; Yael Grossman; Tova Milo; Pierre Senellart,Abstract This demo presents CrowdMiner; a system enabling the mining of interesting datapatterns from the crowd. While traditional data mining techniques have been usedextensively for finding patterns in classic databases; they are not always suitable for thecrowd; mainly because humans tend to remember only simple trends and summaries ratherthan exact details. To address this; CrowdMiner employs a novel crowd-mining algorithm;designed specifically for this context. The algorithm iteratively chooses appropriatequestions to ask the crowd; while aiming to maximize the knowledge gain at each step. Wedemonstrate CrowdMiner through a Well-Being portal; constructed interactively by miningthe crowd; and in particular the conference participants; for common health related practicesand trends.,Proceedings of the VLDB Endowment,2013,16
Repeatability & workability evaluation of SIGMOD 2009,Stefan Manegold; Ioana Manolescu; Loredana Afanasiev; Jianlin Feng; Gang Gou; Marios Hadjieleftheriou; Stavros Harizopoulos; Panos Kalnis; Konstantinos Karanasos; Dominique Laurent; Mihai Lupu; Nicola Onose; Christopher Ré; Virginie Sans; Pierre Senellart; Tianyi Wu; Dennis Shasha,Abstract SIGMOD 2008 was the first database conference that offered to test submitters'programs against their data to verify the repeatability of the experiments published [1]. Giventhe positive feedback concerning the SIGMOD 2008 repeatability initiative; SIGMOD 2009modified and expanded the initiative with a workability assessment.,ACM SIGMOD Record,2010,16
Comprendre le Web caché. Understanding the Hidden Web,Pierre Senellart,Résumé Le Web caché (également appelé Web profond ou Web invisible); c'est-à-dire lapartie du Web qui n'est pas directement accessible par des hyperliens; mais à travers desformulaires HTML ou des services Web; est d'une grande valeur; mais difficile à exploiter.Nous présentons un processus pour la découverte; l'analyse syntaxique et sémantique; etl'interrogation des services du Web caché; le tout de manière entièrement automatique.Nous proposons une architecture générale se basant sur un entrepôt semi-structuré decontenu imprécis (probabiliste). Nous fournissons une analyse détaillée de la complexité dumodèle d'arbre probabiliste sous-jacent. Nous décrivons comment une combinaisond'heuristiques et de sondages du Web peut être utilisée pour comprendre la structure d'unformulaire HTML. Nous présentons une utilisation originale des champs aléatoires …,*,2007,15
On the connections between relational and XML probabilistic data models,Antoine Amarilli; Pierre Senellart,Abstract A number of uncertain data models have been proposed; based on the notion ofcompact representations of probability distributions over possible worlds. In probabilisticrelational models; tuples are annotated with probabilities or formulae over Boolean randomvariables. In probabilistic XML models; XML trees are augmented with nodes that specifyprobability distributions over their children. Both kinds of models have been extensivelystudied; with respect to their expressive power; compactness; and query efficiency; amongother things. Probabilistic database systems have also been implemented; in both relationaland XML settings. However; these studies have mostly been carried out independently andthe translations between relational and XML models; as well as the impact for probabilisticrelational databases of results about query complexity in probabilistic XML and vice versa …,BNCOD,2013,14
Optimal top-k generation of attribute combinations based on ranked lists,Jiaheng Lu; Pierre Senellart; Chunbin Lin; Xiaoyong Du; Shan Wang; Xinxing Chen,Abstract In this work; we study a novel query type; called top-k; m queries. Suppose we aregiven a set of groups and each group contains a set of attributes; each of which isassociated with a ranked list of tuples; with ID and score. All lists are ranked in decreasingorder of the scores of tuples. We are interested in finding the best combinations of attributes;each combination involving one attribute from each group. More specifically; we want the top-k combinations of attributes according to the corresponding top-m tuples with matching IDs.This problem has a wide range of applications from databases to search engines ontraditional and non-traditional types of data (relational data; XML; text; etc.). We show that astraightforward extension of an optimal top-k algorithm; the Threshold Algorithm (TA); hasshortcomings in solving the km problem; as it needs to compute a large number of …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,14
The hidden web; XML and the Semantic Web: scientific data management perspectives,Fabian M Suchanek; Aparna S Varde; Richi Nayak; Pierre Senellart,Abstract The World Wide Web no longer consists just of HTML pages. Our work sheds lighton a number of trends on the Internet that go beyond simple Web pages. The hidden Webprovides a wealth of data in semi-structured form; accessible through Web forms and Webservices. These services; as well as numerous other applications on the Web; commonlyuse XML; the eXtensible Markup Language. XML has become the lingua franca of theInternet that allows customized markups to be defined for specific domains. On top of XML;the Semantic Web grows as a common structured data source. In this work; we first explaineach of these developments in detail. Using real-world examples from scientific domains ofgreat interest today; we then demonstrate how these new developments can assist themanaging; harvesting; and organization of data on the Web. On the way; we also illustrate …,Proceedings of the 14th International Conference on Extending Database Technology,2011,14
Capturing Continuous Data and Answering Aggregate Queries in Probabilistic XML,SERGE ABITEBOUL; T-H HUBERT CHAN; EVGENY KHARLAMOV; WERNER NUTT; PIERRE SENELLART,Abstract Sources of data uncertainty and imprecision are numerous. A way to handle thisuncertainty is to associate probabilistic annotations to data. Many such probabilisticdatabase models have been proposed; both in the relational and in the semi-structuredsetting. The latter is particularly well adapted to the management of uncertain data comingfrom a variety of automatic processes. An important problem; in the context of probabilisticXML databases; is that of answering aggregate queries (count; sum; avg; etc.); which hasreceived limited attention so far. In a model unifying the various (discrete) semi-structuredprobabilistic models studied up to now; we present algorithms to compute the distribution ofthe aggregation values (exploiting some regularity properties of the aggregate functions)and probabilistic moments (especially expectation and variance) of this distribution. We …,ACM Transactions on Database Systems,2011,14
ProbTree: A query-efficient representation of probabilistic graphs,Silviu Maniu; Reynold Cheng; Pierre Senellart,Information in many applications; such as mobile wireless systems; social networks; androad networks; is captured by graphs; in many cases uncertain. We study the problem ofquerying a probabilistic graph; in particular; we examine source-to-target'queries; such ascomputing the shortest path between two vertices. Evaluating ST-queries over probabilisticgraphs is# P-hard; as it requires examining an exponential number of possible worlds'.Existing solutions to the ST-query problem; which sample possible worlds; have twodownsides:(i) many samples are needed for reasonable accuracy; and (ii) a possible worldcan be very large. To tackle these issues; we study the ProbTree; a data structure that storesa succinct representation of the probabilistic graph. Existing ST-query solutions areexecuted on top of this structure; with the number of samples and possible world sizes …,1st International Workshop on Big Uncertain Data; BUDA 2014,2014,13
A probabilistic XML merging tool,Talel Abdessalem; M Lamine Ba; Pierre Senellart,Abstract This demonstration paper presents a probabilistic XML data merging tool; thatrepresents the outcome of semi-structured document integration as a probabilistic tree. Thesystem is fully automated and integrates methods to evaluate the uncertainty (modeled asprobability values) of the result of the merge. It is based on the two-way tree-mergetechnique and an uncertain data model defined using probabilistic event variables. Theresulting probabilistic repository can be queried using a subset of the XPath querylanguage. The demonstration application is based on revisions of the Wikipediaencyclopedia: a Wikipedia article is no longer considered as the latest valid revision but asthe merge of all possible revisions; some of which are uncertain.,Proceedings of the 14th International Conference on Extending Database Technology,2011,13
Scalable; generic; and adaptive systems for focused crawling,Georges Gouriten; Silviu Maniu; Pierre Senellart,Abstract Focused crawling is the process of exploring a graph iteratively; focusing on parts ofthe graph relevant to a given topic. It occurs in many situations such as a company collectingdata on competition; a journalist surfing the Web to investigate a political scandal; or anarchivist recording the activity of influential Twitter users during a presidential election. In allthese applications; users explore a graph (eg; the Web or a social network); nodes arediscovered one by one; the total number of exploration steps is constrained; some nodes aremore valuable than others; and the objective is to maximize the total value of the crawledsubgraph. In this article; we introduce scalable; generic; and adaptive systems for focusedcrawling. Our first effort is to define an abstraction of focused crawling applicable to a largedomain of real-world scenarios. We then propose a generic algorithm; which allows us to …,Proceedings of the 25th ACM conference on Hypertext and social media,2014,12
Cross-Fertilizing Deep Web Analysis and Ontology Enrichment.,Marilena Oita; Antoine Amarilli; Pierre Senellart,*,VLDS,2012,12
On the complexity of deriving schema mappings from database instances,Pierre Senellart; Georg Gottlob,Abstract We introduce a theoretical framework for discovering relationships between twodatabase instances over distinct and unknown schemata. This framework is grounded in thecontext of data exchange. We formalize the problem of understanding the relationshipbetween two instances as that of obtaining a schema mapping so that a minimum repair ofthis mapping provides a perfect description of the target instance given the source instance.We show that this definition yields" intuitive" results when applied on database instancesderived from each other by basic operations. We study the complexity of decision problemsrelated to this optimality notion in the context of different logical languages and show that;even in very restricted cases; the problem is of high complexity.,Proceedings of the twenty-seventh ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2008,12
Web page rank prediction with Markov models,Michalis Vazirgiannis; Dimitris Drosos; Pierre Senellart; Akrivi Vlachou,Abstract In this paper we propose a method for predicting the ranking position of a Webpage. Assuming a set of successive past top-k rankings; we study the evolution of Webpages in terms of ranking trend sequences used for Markov Models training; which are inturn used to predict future rankings. The predictions are highly accurate for all experimentalsetups and similarity measures.,Proceedings of the 17th international conference on World Wide Web,2008,11
SYSTRAN translation stylesheets: machine translation driven by XSLT,Pierre Senellart; Jean Senellart,Page 1. SYSTRAN Translation Stylesheets: Machine Translation driven by XSLT PierreSenellart1;2 Jean Senellart1 1 2 XML Conference 2005 November 17th; 2005 Senellart;Senellart (SYSTRAN & INRIA) STS: Machine Translation driven by XSLT XML Conf. 2005;2005/11/17 1 / 43 Page 2. Introduction SYSTRAN SYSTRAN: A Leading Machine TranslationCompany Machine Translation of Natural Language Senellart; Senellart (SYSTRAN & INRIA)STS: Machine Translation driven by XSLT XML Conf. 2005; 2005/11/17 2 / 43 Page 3.Introduction SYSTRAN SYSTRAN: A Leading Machine Translation Company MachineTranslation of Natural Language 20+ different languages Senellart; Senellart (SYSTRAN &INRIA) STS: Machine Translation driven by XSLT XML Conf. 2005; 2005/11/17 2 / 43 Page4. Introduction SYSTRAN SYSTRAN: A Leading Machine Translation Company …,Proceedings of XML Conference 2005,2005,11
Discovering interesting information with advances in Web technology,Richi Nayak; Pierre Senellart; Fabian M Suchanek; Aparna S Varde,Abstract The Web is a steadily evolving resource comprising much more than mere HTMLpages. With its ever-growing data sources in a variety of formats; it provides great potentialfor knowledge discovery. In this article; we shed light on some interesting phenomena of theWeb: the deep Web; which surfaces database records as Web pages; the Semantic Web;which defines meaningful data exchange formats; XML; which has established itself as alingua franca for Web data exchange; and domain-specific markup languages; which aredesigned based on XML syntax with the goal of preserving semantics in targeted domains.We detail these four developments in Web technology; and explain how they can be usedfor data mining. Our goal is to show that all these areas can be as useful for knowledgediscovery as the HTML-based part of the Web.,ACM SIGKDD Explorations Newsletter,2013,10
Optimizing approximations of DNF query lineage in probabilistic XML,Asma Souihli; Pierre Senellart,Probabilistic XML is a probabilistic model for uncertain tree-structured data; with applicationsto data integration; information extraction; or uncertain version control. We explore in thiswork efficient algorithms for evaluating tree-pattern queries with joins over probabilistic XMLor; more specifically; for listing the answers to a query along with their computed orapproximated probability. The approach relies on; first; producing the lineage query byevaluating it over the probabilistic XML document; and; second; looking for an optimalstrategy to compute the probability of the lineage formula. This latter part relies on a query-optimizer-like approach: exploring different evaluation plans for different parts of the formulaand estimating the cost of each plan; using a cost model for the various evaluationalgorithms. We demonstrate the efficiency of this approach on datasets used in previous …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,10
API Blender: A uniform interface to social platform APIs,Georges Gouriten; Pierre Senellart,Abstract: With the growing success of the social Web; most Web developers have to interactwith at least one social Web platform; which implies studying the related API specifications.These are often only informally described; may contain errors; lack harmonization; andgenerally speaking make the developer's work difficult. Most attempts to solve this problem;proposing formal description languages for Web service APIs; have had limited successoutside of B2B applications; we believe it is due to their top-down nature. In addition; aprogrammer dealing with one or several of these APIs has to deal with a number of relatedtasks such as data integration; requests chaining; or policy management; that arecumbersome to implement. Inspired by the SPORE project; we present API Blender; an open-source solution to describe; interact with; and integrate the most common social Web APIs …,arXiv preprint arXiv:1301.2086,2013,10
ProApproX: a lightweight approximation query processor over probabilistic trees,Pierre Senellart; Asma Souihli,Abstract We demonstrate a system for querying probabilistic XML documents with simpleXPath queries. A user chooses between a variety of query answering techniques; both exactand approximate; and observes the running behavior; pros; and cons; of each method; interms of efficiency; precision of the result; and data model and query language supported.,SIGMOD,2011,10
Modeling; Querying; and Mining Uncertain XML Data,Evgeny Kharlamov; Pierre Senellart,ABSTRACT This chapter deals with data mining in uncertain XML data models; whoseuncertainty typically comes from imprecise automatic processes. We first review the literatureon modeling uncertain data; starting with well-studied relational models and moving then totheir semistructured counterparts. We focus on a specific probabilistic XML model; whichallows representing arbitrary finite distributions of XML documents; and has been extendedto also allow continuous distributions of data values. We summarize previous work onquerying this uncertain data model and show how to apply the corresponding techniques toseveral data mining tasks; exemplified through use cases on two running examples.,XML Data Mining: Models; Methods; and Applications. IGI Global,2011,10
Get a sample for a discount,Ruiming Tang; Antoine Amarilli; Pierre Senellart; Stéphane Bressan,Abstract While price and data quality should define the major trade-off for consumers in datamarkets; prices are usually prescribed by vendors and data quality is not negotiable. In thispaper we study a model where data quality can be traded for a discount. We focus on thecase of XML documents and consider completeness as the quality dimension. In our setting;the data provider offers an XML document; and sets both the price of the document and aweight to each node of the document; depending on its potential worth. The data consumerproposes a price. If the proposed price is lower than that of the entire document; then thedata consumer receives a sample; ie; a random rooted subtree of the document whoseselection depends on the discounted price and the weight of nodes. By requesting severalsamples; the data consumer can iteratively explore the data in the document. We show …,International Conference on Database and Expert Systems Applications,2014,9
Finding optimal probabilistic generators for XML collections,Serge Abiteboul; Yael Amsterdamer; Daniel Deutch; Tova Milo; Pierre Senellart,Abstract We study the problem of; given a corpus of XML documents and its schema; findingan optimal (generative) probabilistic model; where optimality here means maximizing thelikelihood of the particular corpus to be generated. Focusing first on the structure ofdocuments; we present an efficient algorithm for finding the best generative probabilisticmodel; in the absence of constraints. We further study the problem in the presence ofintegrity constraints; namely key; inclusion; and domain constraints. We study in this casetwo different kinds of generators. First; we consider a continuation-test generator thatperforms; while generating documents; tests of schema satisfiability; these tests prevent fromgenerating a document violating the constraints but; as we will see; they are computationallyexpensive. We also study a restart generator that may generate an invalid document and …,Proceedings of the 15th International Conference on Database Theory,2012,9
Combined tractability of query evaluation via tree automata and cycluits,Antoine Amarilli; Pierre Bourhis; Mikaël Monet; Pierre Senellart,We investigate parameterizations of both database instances and queries that make queryevaluation fixed-parameter tractable in combined complexity. We introduce a new Datalogfragment with stratified negation; intensional-clique-guarded Datalog (ICG-Datalog); withlinear-time evaluation on structures of bounded treewidth for programs of bounded rule size.Such programs capture in particular conjunctive queries with simplicial decompositions ofbounded width; guarded negation fragment queries of bounded CQ-rank; or two-way regularpath queries. Our result is shown by compiling to alternating two-way automata; whosesemantics is defined via cyclic provenance circuits (cycluits) that can be tractably evaluated.Last; we prove that probabilistic query evaluation remains intractable in combinedcomplexity under this parameterization.,ICDT 2017-International Conference on Database Theory,2017,8
Hup-me: inferring and reconciling a timeline of user activity from rich smartphone data,David Montoya; Serge Abiteboul; Pierre Senellart,Abstract We designed a system to infer multimodal itineraries traveled by a user from acombination of smartphone sensor data (eg; GPS; Wi-Fi; accelerometer) and knowledge ofthe transport network infrastructure (eg; road and rail maps; public transportation timetables).The system uses a Transportation network that captures the set of possible paths of thisnetwork for the modes; eg; foot; bicycle; road_vehicle; and rail. This Transportation networkis constructed from OpenStreetMap data and public transportation routes published onlineby transportation agencies in GTFS format. The system infers itineraries from a sequence ofsmartphone observations in two phases. The first phase uses a dynamic Bayesian networkthat models the probabilistic relationship between paths in Transportation network andsensor data. The second phase attempts to match portions recognized as road_vehicle or …,Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems,2015,8
Merging Uncertain Multi-Version XML Documents.,Mouhamadou Lamine Ba; Talel Abdessalem; Pierre Senellart,Page 1. Merging Uncertain Multi-Version XML Documents M. Lamine BA; Talel Abdessalem &Pierre Senellart ACM DocEng 2013 - 1st International Workshop on Document Changes (Florence;Italy) September 10th ; 2013 ML Ba; T. Abdessalem & P. Senellart ACM DocEng 2013 – DchangesSeptember 10th ; 2013 1 / 1 Page 2. Merging feature: a need in open environments Merging feature:a need in open environments ▶ Merging documents related to the same topic or sharing a largecommon part; eg; Wikipedia articles ML Ba; T. Abdessalem & P. Senellart ACM DocEng 2013 –Dchanges September 10th ; 2013 2 / 1 Page 3. Merging feature: a need in open environmentsMerging feature: a need in open environments ▶ Merging documents related to the same topicor sharing a large common part; eg; Wikipedia articles ▶ Recommend the outcome of the mergingof contributions of the most trustworthy contributors …,DChanges,2013,7
Value joins are expensive over (probabilistic) XML,Evgeny Kharlamov; Werner Nutt; Pierre Senellart,Abstract We address the cost of adding value joins to tree-pattern queries and monadicsecond-order queries over trees in terms of the tractability of query evaluation over two datamodels: XML and probabilistic XML. Our results show that the data complexity rises fromlinear; for join-free queries; to intractable; for queries with value joins; while combinedcomplexity remains essentially the same. For tree-pattern queries with joins (TPJ) thecomplexity jump is only on probabilistic XML; while for monadic second-order logic overtrees with joins (TMSOJ) it already appears for deterministic XML documents. Moreover; forTPJ queries that have a single join; we show a dichotomy: every query is either essentiallyjoin-free; and in this case it is tractable over probabilistic XML; or it is intractable. In this lightwe study the problem of deciding whether a query with joins is essentially join-free. For …,Proceedings of the 4th International Workshop on Logic in Databases,2011,7
Knowledge discovery over the deep web; semantic web and XML,Aparna Varde; Fabian Suchanek; Richi Nayak; Pierre Senellart,Abstract In this tutorial we provide an insight into Web Mining; ie; discovering knowledgefrom the World Wide Web; especially with reference to the latest developments in Webtechnology. The topics covered are: the Deep Web; also known as the Hidden Web orInvisible Web; the Semantic Web including standards such as RDFS and OWL; theeXtensible Markup Language XML; a widespread communication medium for the Web; anddomain-specific markup languages defined within the context of XML We explain how eachof these developments support knowledge discovery from data stored over the Web; therebyassisting several real-world applications.,International Conference on Database Systems for Advanced Applications,2009,7
Towards a version control model with uncertain data,Mouhamadou Lamine Ba; Talel Abdessalem; Pierre Senellart,Abstract Content-based online collaborative platforms and office applications are widelyused for collaborating and exchanging data; in particular in the form of XML-basedelectronic documents. Usually; a version control system is built-in in these applications tosupport collaboration and to properly manage document evolution. However; most versioncontrol models require error-prone and time-consuming manual management of conflictsand uncertainties; thus heavily affecting collaborative work. Since in collaborative contextsconflicts are of a more semantic nature; ie; due to uncertainty on what is really true; we focuson a version control model that deals with uncertain data. We introduce an XML versioncontrol model to assess uncertainty in data and to automatically resolve conflicts. Officedocuments and those of content-based online collaborative platforms are described in …,Proceedings of the 4th workshop on Workshop for Ph. D. students in information & knowledge management,2011,6
La diversité culturelle dans l'industrie de la musique enregistrée en France (2003-2008),Marc Bourreau; François Moreau; Pierre Senellart,Résumé L'industrie musicale française est en crise depuis le milieu des années 2000. Lesventes ont chuté alors même que le processus de numérisation des contenus sedéveloppait. Comment apprécier l'incidence sur la diversité culturelle de la production et dela consommation d'une filière en crise? Fondée sur l'approche d'Andrew Stirling; la mesurede la diversité culturelle est analysée selon trois dimensions: la variété produite etconsommée; l'équilibre des ventes entre les différents titres et la disparité des albums et desartistes écoutés. L'analyse révèle la baisse du poids des majors au profit des petits et grosproducteurs indépendants; elle apporte des éléments de réponse sur l'effet de levier desventes en ligne (hypothèse de la longue traîne) et sur l'appréciation de la diversité dans lapart des ventes réalisées en grandes surfaces spécialisées.,Culture études,2011,6
The SIGMOD 2010 programming contest a distributed query engine,Clément Genzmer; Volker Hudlet; Hyunjung Park; Daniel Schall; Pierre Senellart,Abstract We report on the second annual ACM SIGMOD programming contest; whichconsisted in building an efficient distributed query engine on top of an in-memory index. Thisarticle is co-authored by the organizers of the competition (Clément Genzmer; PierreSenellart) and the students who built the two leading implementations (Volker Hudlet;Hyunjung Park; Daniel Schall).,ACM SIGMOD Record,2010,6
XML warehousing meets sociology,François-Xavier Dudouet; Ioana Manolescu; Benjamin Nguyen; Pierre Senellart,ABSTRACT In this article; we describe a novel application of XML and Web basedtechnologies: a sociological study of the W3C standardization process. We propose a newmethodology and tools; to be used by sociologists to study the standardization process;illustrated by the W3C XQuery Working Group. The novelty of our approach has many facets.Information Technology (IT) has received little attention from sociologists; yet thestandardization of the Web is a crucial issue; both economical and political; based on theuse of a semi-structured content warehouse. We introduce a modeling and queryingapproach of an XML content warehouse; and show it produces high added-valueinformation. This information is used to conduct a preliminary sociological analysis of theXQuery standardization process.,Proceedings of the IADIS International Conference on the Web and Internet,2005,6
Possible and certain answers for queries over order-incomplete data,Antoine Amarilli; Mouhamadou Lamine Ba; Daniel Deutch; Pierre Senellart,Abstract: To combine and query ordered data from multiple sources; one needs to handleuncertainty about the possible orderings. Examples of such" order-incomplete" data includeintegrated event sequences such as log entries; lists of properties (eg; hotels andrestaurants) ranked by an unknown function reflecting relevance or customer ratings; anddocuments edited concurrently with an uncertain order on edits. This paper introduces aquery language for order-incomplete data; based on the positive relational algebra withorder-aware accumulation. We use partial orders to represent order-incomplete data; andstudy possible and certain answers for queries in this context. We show that these problemsare respectively NP-complete and coNP-complete; but identify many tractable casesdepending on the query operators or input partial orders. Comments: 55 pages; 5 figures …,arXiv preprint arXiv:1707.07222,2017,5
An Indexing Framework for Queries on Probabilistic Graphs,Silviu Maniu; Reynold Cheng; Pierre Senellart,Abstract Information in many applications; such as mobile wireless systems; social networks;and road networks; is captured by graphs. In many cases; such information is uncertain. Westudy the problem of querying a probabilistic graph; in which vertices are connected to eachother probabilistically. In particular; we examine “source-to-target” queries (ST-queries);such as computing the shortest path between two vertices. The major difference with thedeterministic setting is that query answers are enriched with probabilistic annotations.Evaluating ST-queries over probabilistic graphs is &num; P-hard; as it requires examiningan exponential number of “possible worlds”—database instances generated from theprobabilistic graph. Existing solutions to the ST-query problem; which sample possibleworlds; have two downsides:(i) a possible world can be very large and (ii) many samples …,ACM Transactions on Database Systems (TODS),2017,5
The ARCOMEM architecture for social-and semantic-driven web archiving,Thomas Risse; Elena Demidova; Stefan Dietze; Wim Peters; Nikolaos Papailiou; Katerina Doka; Yannis Stavrakas; Vassilis Plachouras; Pierre Senellart; Florent Carpentier; Amin Mantrach; Bogdan Cautis; Patrick Siehndel; Dimitris Spiliotopoulos,Abstract The constantly growing amount ofWeb content and the success of the SocialWeblead to increasing needs for Web archiving. These needs go beyond the pure preservationoof Web pages. Web archives are turning into “community memories” that aim at building abetter understanding of the public view on; eg; celebrities; court decisions and other events.Due to the size of the Web; the traditional “collect-all” strategy is in many cases not the bestmethod to build Web archives. In this paper; we present the ARCOMEM (From FutureInternet 2014; 6 689 Collect-All Archives to Community Memories) architecture andimplementation that uses semantic information; such as entities; topics and events;complemented with information from the Social Web to guide a novel Web crawler. Theresulting archives are automatically enriched with semantic meta-information to ease the …,Future Internet,2014,5
ARCOMEM crawling architecture,Vassilis Plachouras; Florent Carpentier; Muhammad Faheem; Julien Masanès; Thomas Risse; Pierre Senellart; Patrick Siehndel; Yannis Stavrakas,Abstract: The World Wide Web is the largest information repository available today.However; this information is very volatile and Web archiving is essential to preserve it for thefuture. Existing approaches to Web archiving are based on simple definitions of the scope ofWeb pages to crawl and are limited to basic interactions with Web servers. The aim of theARCOMEM project is to overcome these limitations and to provide flexible; adaptive andintelligent content acquisition; relying on social media to create topical Web archives. In thisarticle; we focus on ARCOMEM's crawling architecture. We introduce the overall architectureand we describe its modules; such as the online analysis module; which computes a priorityfor the Web pages to be crawled; and the Application-Aware Helper which takes intoaccount the type of Web sites and applications to extract structure from crawled content …,future internet,2014,5
Documenting Contemporary Society by Preserving Relevant Information from Twitter,Thomas Risse; Wim Peters; Pierre Senellart; Diana Maynard,In recent years; Twitter has changed from a medium for posting personal updates or statusinformation to a channel for sharing and distributing information of all kinds. Its increasinglypervasive nature is encouraging more and more people to give insights into their daily lifeand to stay in contact with friends. This also attracts many companies and media agencies;attempting to establish a more or less constant flow of information to their customers. Thelimitation to 140 characters reduces efforts and focuses the tweet on the core information.The ease of use of Twitter and its availability on every smartphone also encourages peopleto act as citizen journalists and immediately report the events they witness. Twitter can thusbe seen as the foremost channel for “breaking news;” where information about eventsappears before being distributed via traditional channels. Followup messages on Twitter …,*,2013,5
Archivage du contenu éphémère du Web à l’aide des flux Web,Marilena Oita; Pierre Senellart,Résumé Cette proposition de démonstration concerne une application d'archivage ducontenu du Web à l'aide des flux Web. A partir de la spécification d'un domaine parl'utilisateur; des services spécialisés sont utilisés pour acquérir des flux pertinents. Pourchacun de ces flux; on exploite les indices sémantiques attachés à un objet dynamique pourextraire; à partir de la page Web associée; les données qui correspondent à la description.On ajoute à cet objet des méta-données supplémentaires et l'estampille temporelle; onextrait le template de la page; et on garde ces composants indépendamment pour être prêtsà répondre à des requêtes temporelles et sémantiques et; à la demande; reconstruire lapage Web référencée par le flux. Les méthodes pour détecter le changement de la pageWeb sont également utiles dans le cadre d'un crawl incrémental des versions du même …,Proc. BDA; Toulouse; France; 2010a. Conference without formal proceedings.(Demonstration),*,5
Top-k querying of unknown values under order constraints,Antoine Amarilli; Yael Amsterdamer; Tova Milo; Pierre Senellart,Abstract Many practical scenarios make it necessary to evaluate top-k queries over dataitems with partially unknown values. This paper considers a setting where the values aretaken from a numerical domain; and where some partial order constraints are given overknown and unknown values: under these constraints; we assume that all possible worldsare equally likely. Our work is the first to propose a principled scheme to derive the valuedistributions and expected values of unknown items in this setting; with the goal ofcomputing estimated top-k results by interpolating the unknown values from the known ones.We study the complexity of this general task; and show tight complexity bounds; proving thatthe problem is intractable; but can be tractably approximated. We then consider the case oftree-shaped partial orders; where we show a constructive PTIME solution. We also …,LIPIcs-Leibniz International Proceedings in Informatics,2017,4
Cost-model oblivious database tuning with reinforcement learning,Debabrota Basu; Qian Lin; Weidong Chen; Hoang Tam Vo; Zihong Yuan; Pierre Senellart; Stéphane Bressan,Abstract In this paper; we propose a learning approach to adaptive performance tuning ofdatabase applications. The objective is to validate the opportunity to devise a tuning strategythat does not need prior knowledge of a cost model. Instead; the cost model is learnedthrough reinforcement learning. We instantiate our approach to the use case of index tuning.We model the execution of queries and updates as a Markov decision process whose statesare database configurations; actions are configuration changes; and rewards are functionsof the cost of configuration change and query and update evaluation. During thereinforcement learning process; we face two important challenges: not only the unavailabilityof a cost model; but also the size of the state space. To address the latter; we devisestrategies to prune the state space; both in the general case and for the use case of index …,International Conference on Database and Expert Systems Applications,2015,4
Truth Finding with Attribute Partitioning,M Lamine Ba; Roxana Horincar; Pierre Senellart; Huayu Wu,Abstract Truth finding is the problem of determining which of the statements made bycontradictory sources is correct; in the absence of prior information on the trustworthiness ofthe sources. A number of approaches to truth finding have been proposed; from simplemajority voting to elaborate iterative algorithms that estimate the quality of sources bycorroborating their statements. In this paper; we consider the case where there is aninherent structure in the statements made by sources about real-world objects; that implydifferent quality levels of a given source on different groups of attributes of an object. We donot assume this structuring given; but instead find it automatically; by exploring andweighting the partitions of the sets of attributes of an object; and applying a reference truthfinding algorithm on each subset of the optimal partition. Our experimental results on …,Proceedings of the 18th International Workshop on Web and Databases,2015,4
FOREST: Focused object retrieval by exploiting significant tag paths,Marilena Oita; Pierre Senellart,Abstract Content-intensive websites; eg; of blogs or news; present pages that contain Webarticles automatically generated by content management systems. Identification andextraction of their main content is critical in many applications; such as indexing orclassification. We present a novel unsupervised approach for the extraction of Web articlesfrom dynamically-generated Web pages. Our system; called Forest; combines structural andinformation-based features to target the main content generated by a Web source; andpublished in associated Web pages. We extensively evaluate Forest with respect to variousbaselines and datasets; and report improved results over state-of-the art techniques incontent extraction.,*,2012,4
The ERC webdam on foundations of web data management,Serge Abiteboul; Pierre Senellart; Victor Vianu,Abstract The Webdam ERC grant is a five-year project that started in December 2008. Thegoal is to develop a formal model for Web data management that would open new horizonsfor the development of the Web in a well-principled way; enhancing its functionality;performance; and reliability. Specifically; the goal is to develop a universally accepted formalframework for describing complex and flexible interacting Web applications featuring notablydata exchange; sharing; integration; querying; and updating. We also propose to developformal foundations that will enable peers to concurrently reason about global datamanagement activities; cooperate in solving specific tasks; and support services withdesired quality of service. Although the proposal addresses fundamental issues; its goal is toserve as the basis for future software development for Web data management.,Proceedings of the 21st International Conference on World Wide Web,2012,4
Ontology Alignment at the Instance and Schema Level,Fabian Suchanek; Serge Abiteboul; Pierre Senellart,Abstract: We present PARIS; an approach for the automatic alignment of ontologies. PARISaligns not only instances; but also relations and classes. Alignments at the instance-levelcross-fertilize with alignments at the schema-level. Thereby; our system provides a trulyholistic solution to the problem of ontology alignment. The heart of the approach isprobabilistic. This allows PARIS to run without any parameter tuning. We demonstrate theefficiency of the algorithm and its precision through extensive experiments. In particular; weobtain a precision of around 90% in experiments with two of the world's largest ontologies.,arXiv preprint arXiv:1105.5516,2011,4
Integration of SYSTRAN MT systems in an open workflow,Mats Attnäs; Pierre Senellart; Jean Senellart,Facts 35-year-old company 40+ language pairs 20+ different languages Translation servicefor major portals (Babelfish; Google; Yahoo!...) ≈ 35;000;000 on-line translations a day Largerange of products (from PDA to Web servers) Services for corporate and institutions (Ford;Cisco; US Gov; EU...) Product life: v4 (2001); v5 (2004); v6 (June 2006) … Atnäs; Senellart; SenellartIntegration of SYSTRAN MT systems in an open workflow … Facts 35-year-old company 40+language pairs 20+ different languages Translation service for major portals (Babelfish;Google; Yahoo!...) ≈ 35;000;000 on-line translations a day Large range of products (from PDAto Web servers) Services for corporate and institutions (Ford; Cisco; US Gov; EU...) Productlife: v4 (2001); v5 (2004); v6 (June 2006) … Atnäs; Senellart; Senellart Integration of SYSTRANMT systems in an open workflow … Facts 35-year-old company 40+ language pairs 20+ …,MT Summit X; Phuket; Thailand,2005,4
Identifying websites with flow simulation,Pierre Senellart,Abstract We present in this paper a method to discover the set of webpages contained in alogical website; based on the link structure of the Web graph. Such a method is useful in thecontext of Web archiving and website importance computation. To identify the boundaries ofa website; we combine the use of an online version of the preflow-push algorithm; analgorithm for the maximum flow problem in traffic networks; and of the Markov CLuster (MCL)algorithm. The latter is used on a crawled portion of the Web graph in order to build a seedof initial webpages; a seed which is extended using the former. An experiment on a subsiteof the INRIA Website is described.,International Conference on Web Engineering,2005,4
Conjunctive Queries on Probabilistic Graphs: Combined Complexity,Antoine Amarilli; Mikaël Monet; Pierre Senellart,Abstract Query evaluation over probabilistic databases is known to be intractable in manycases; even in data complexity; ie; when the query is fixed. Although some restrictions of thequeries and instances [4] have been proposed to lower the complexity; these knowntractable cases usually do not apply to combined complexity; ie; when the query is not fixed.This leaves open the question of which query and instance languages ensure the tractabilityof probabilistic query evaluation in combined complexity. This paper proposes the firstgeneral study of the combined complexity of conjunctive query evaluation on probabilisticinstances over binary signatures; which we can alternatively phrase as a probabilisticversion of the graph homomorphism problem; or of a constraint satisfaction problem (CSP)variant. We study the complexity of this problem depending on whether instances and …,Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,2017,3
Online influence maximization (extended version),Siyu Lei; Silviu Maniu; Luyi Mo; Reynold Cheng; Pierre Senellart,Abstract: Social networks are commonly used for marketing purposes. For example; freesamples of a product can be given to a few influential social network users (or" seednodes"); with the hope that they will convince their friends to buy it. One way to formalizemarketers' objective is through influence maximization (or IM); whose goal is to find the bestseed nodes to activate under a fixed budget; so that the number of people who getinfluenced in the end is maximized. Recent solutions to IM rely on the influence probabilitythat a user influences another one. However; this probability information may be unavailableor incomplete. In this paper; we study IM in the absence of complete information on influenceprobability. We call this problem Online Influence Maximization (OIM) since we learninfluence probabilities at the same time we run influence campaigns. To solve OIM; we …,arXiv preprint arXiv:1506.01188,2015,3
Dealing with the Deep Web and all its Quirks.,Meghyn Bienvenu; Daniel Deutch; Davide Martinenghi; Pierre Senellart; Fabian M Suchanek,ABSTRACT Several approaches harvest; query; or combine Deep Web sources. Yet; inaddition to well-studied aspects of the problem such as query answering using views;access limitations; or top-k querying; the Deep Web exhibits a number of peculiarities thatare often neglected. First; the services usually deliver not all results; but only the top-nresults according to some ranking function. This function may not be compatible with theordering specified in a user's query. Subsequent results have to be obtained by paging; ormay not even be accessible. Second; the services may deliver results in a granularity that isincompatible with the query or joinable services (eg; months vs. exact dates). Moreover; theservices may perform selections or ranking over attributes that are not exposed in theresults: this poses an incompleteness problem. Additional challenges come from …,VLDS,2012,3
Auto-Completion Learning for XML,Serge Abiteboul; Yael Amsterdamer; Tova Milo; Pierre Senellart,Abstract Editing an XML document manually is a complicated task. While many XML editorsexist in the market; we argue that some important functionalities are missing in all of them.Our goal is to makes the editing task simpler and faster. We present ALEX (Auto-completionLearning Editor for XML); an editor that assists the users by providing intelligent auto-completion suggestions. These suggestions are adapted to the user needs; simply byfeeding ALEX with a set of example XML documents to learn from. The suggestions are alsoguaranteed to be compliant with a given XML schema; possibly including integrityconstraints. To fulfill this challenging goal; we rely on novel; theoretical foundations by usand others; which are combined here in a system for the first time.,*,2011,3
Un système de gestion de données XML probabilistes,Pierre Senellart; Asma Souihli,Résumé Cette proposition de démonstration porte sur un système de gestion de donnéesprobabilistes semistructurées. Le système présenté repose sur une généralisation desmodèles de représentation de données incertaines en XML proposés dans la littérature etpermet une interrogation efficace des données dans un sous-ensemble du langage derequêtes XPath; moyennant des techniques de calculs exacts ou d'approximations durésultat.,Bases de Données Avancées. BDA,2010,3
Combined Tractability of Query Evaluation via Tree Automata and Cycluits (Extended Version),Antoine Amarilli; Pierre Bourhis; Mikaël Monet; Pierre Senellart,Abstract: We investigate parameterizations of both database instances and queries thatmake query evaluation fixed-parameter tractable in combined complexity. We introduce anew Datalog fragment with stratified negation; intensional-clique-guarded Datalog (ICG-Datalog); with linear-time evaluation on structures of bounded treewidth for programs ofbounded rule size. Such programs capture in particular conjunctive queries with simplicialdecompositions of bounded width; guarded negation fragment queries of bounded CQ-rank;or two-way regular path queries. Our result proceeds via compilation to alternating two-wayautomata; whose semantics is defined via cyclic provenance circuits (cycluits) that can betractably evaluated. Last; we prove that probabilistic query evaluation remains intractable incombined complexity under this parameterization.,arXiv preprint arXiv:1612.04203,2016,2
Adaptive Web Crawling Through Structure-Based Link Classification,Muhammad Faheem; Pierre Senellart,Abstract Generic web crawling approaches cannot distinguish among various page typesand cannot target content-rich areas of a website. We study the problem of efficientunsupervised web crawling of content-rich webpages. We propose ACEBot (A daptive Crawler Bot for data E xtraction); a structure-driven crawler that uses the inner structure of thepages and guides the crawling process based on the importance of their content. ACEBotworks in two phases: in the learning phase; it constructs a dynamic site map (limiting thenumber of URLs retrieved) and learns a traversal strategy based on the importance ofnavigation patterns (selecting those leading to valuable content); in the intensive crawlingphase; ACEBot performs massive downloading following the chosen navigation patterns.Experiments over a large dataset illustrate the effectiveness of our system.,International Conference on Asian Digital Libraries,2015,2
Probabilities and provenance via tree decompositions,Antoine Amarilli; Pierre Bourhis; Pierre Senellart,ABSTRACT Query evaluation is hard on probabilistic databases; even on very simpleprobabilistic data frameworks and fairly simple queries; except for limited classes of safequeries. We study the problem from a different angle: rather than restricting the queries; atwhich conditions on the data can we tractably evaluate expressive queries on probabilisticinstances? More specifically; we restrict the data treewidth; which we define on a circuit-based generalization of c-tables; in a natural way that restricts both the underlying instanceand the annotations. We then leverage known tree-automata constructions to evaluatequeries on bounded-treewidth instances; for such logical fragments as monadic second-order logic or frontier-guarded Datalog. We prove that we can compute in linear time aboundedtreewidth lineage circuit for automaton runs on tree decompositions of bounded …,Preprint: http://a3nm. net/publications/amarilli2015probabilities. pdf,2014,2
The ARCOMEM Approach for Social and Semantic Driven Web Archiving,Thomas Risse; Wim Peters; Pierre Senellart,Abstract. The constantly growing amount of Web content and the success of the Social Weblead to increasing needs for Web archiving. These needs go beyond the pure preservationof Web pages. Web archives are turning into “community memories” that aim at building abetter understanding of the public view on eg celebrities; court decisions and other events.Due to the size of the Web; the traditional “collect-all” strategy is in many cases not the bestmethod to build Web archives. In this paper we present the ARCOMEM architecture thatuses semantic information such as entities; topics; and events complemented withinformation from the social Web to guide a novel Web crawler. The resulting archives areautomatically enriched with semantic meta-information to ease the access and allowretrieval based on conditions that involve high-level concepts.,Proc. 1st Int. Workshop on Archiving Community Memories; Lisbon; Portugal,2013,2
Exploration adaptative de graphes sous contrainte de budget,Georges Gouriten; Silviu Maniu; Pierre Senellart,Nous nous intéressons dans cet articlea l'exploration d'un graphe tel celui du Web ou d'unréseau social dans un contexte ou les nœuds (et les ar^ etes qui en sont issues) sontdécouverts una un; et ou le nombre total de nœuds que l'on peut explorer est contraint. Lebut est d'optimiser un score global du sous-graphe découvert; fonction monotone de scoresélémentaires sur chaque nœud. Ce probleme se pose en particulier quand on souhaitecollecter les pages du Web correspondanta un sujet donné ou quand on utilise l'API du sited'un réseau social tel Twitter pour constituer un jeu de données centré sur d'un theme. Nousprésentons une abstraction de ce probleme faisant appela deux composants principaux:une stratégie d'exploration et un estimateur du score des nœuds de la frontiere du graphe.Nous montrons qu'une stratégie gloutonne est suffisante en pratique; et qu'il est possible …,*,2013,2
ProFoUnd: program-analysis-based form understanding,Michael Benedikt; Tim Furche; Andreas Savvides; Pierre Senellart,Abstract An important feature of web search interfaces are the restrictions enforced on inputvalues-those reflecting either the semantics of the data or requirements specific to theinterface. Both integrity constraints and" access restrictions" can be of great use to webexploration tools. We demonstrate here a novel technique for discovering constraints thatrequires no form submissions whatsoever. We work via statically analyzing the JavaScriptclient-side code used to enforce the constraints; when such code is available. We combinecustom recognizers for JavaScript functions relevant to constraint checking with a genericprogram analysis layer. Integrated with a web browser; our system shows the constraintsdetected on accessed web forms; and allows a user to see the corresponding JavaScriptcode fragment.,Proceedings of the 21st International Conference on World Wide Web,2012,2
XML content warehousing: Improving sociological studies of mailing lists and web data,Benjamin Nguyen; Antoine Vion; François-Xavier Dudouet; Dario Colazzo; Ioana Manolescu; Pierre Senellart,In this paper; we present the guidelines for an XML-based approach for the sociologicalstudy of Web data such as the analysis of mailing lists or databases available online. Theuse of an XML warehouse is a flexible solution for storing and processing this kind of data.We propose an implemented solution and show possible applications with our case study ofprofiles of experts involved in W3C standard-setting activity. We illustrate the sociologicaluse of semi-structured databases by presenting our XML Schema for mailing-listwarehousing. An XML Schema allows many adjunctions or crossings of data sources;without modifying existing data sets; while allowing possible structural evolution. We alsoshow that the existence of hidden data implies increased complexity for traditional SQLusers. XML content warehousing allows altogether exhaustive warehousing and …,Bulletin of Sociological Methodology/Bulletin de Méthodologie Sociologique,2011,2
Connecting Width and Structure in Knowledge Compilation,Antoine Amarilli; Mikaël Monet; Pierre Senellart,Abstract: Several query evaluation tasks can be done via knowledge compilation: the queryresult is compiled as a lineage circuit from which the answer can be determined. For suchtasks; it is important to leverage some width parameters of the circuit; such as boundedtreewidth or pathwidth; to convert the circuit to structured classes; eg; deterministic structuredNNFs (d-SDNNFs) or OBDDs. In this work; we show how to connect the width of circuits tothe size of their structured representation; through upper and lower bounds. For the upperbound; we show how bounded-treewidth circuits can be converted to a d-SDNNF; in timelinear in the circuit size. Our bound; unlike existing results; is constructive and only singlyexponential in the treewidth. We show a related lower bound on monotone CNF or DNFformulas; assuming a constant bound on the arity (size of clauses) and degree (number of …,arXiv preprint arXiv:1709.06188,2017,1
Top-k Querying of Unknown Values under Order Constraints (Extended Version),Antoine Amarilli; Yael Amsterdamer; Tova Milo; Pierre Senellart,Abstract: Many practical scenarios make it necessary to evaluate top-k queries over dataitems with partially unknown values. This paper considers a setting where the values aretaken from a numerical domain; and where some partial order constraints are given overknown and unknown values: under these constraints; we assume that all possible worldsare equally likely. Our work is the first to propose a principled scheme to derive the valuedistributions and expected values of unknown items in this setting; with the goal ofcomputing estimated top-k results by interpolating the unknown values from the known ones.We study the complexity of this general task; and show tight complexity bounds; proving thatthe problem is intractable; but can be tractably approximated. We then consider the case oftree-shaped partial orders; where we show a constructive PTIME solution. We also …,arXiv preprint arXiv:1701.02634,2017,1
Routing an Autonomous Taxi with Reinforcement Learning,Miyoung Han; Pierre Senellart; Stéphane Bressan; Huayu Wu,Abstract Singapore's vision of a Smart Nation encompasses the development of effectiveand efficient means of transportation. The government's target is to leverage newtechnologies to create services for a demand-driven intelligent transportation modelincluding personal vehicles; public transport; and taxis. Singapore's government is stronglyencouraging and supporting research and development of technologies for autonomousvehicles in general and autonomous taxis in particular. The design and implementation ofintelligent routing algorithms is one of the keys to the deployment of autonomous taxis. Inthis paper we demonstrate that a reinforcement learning algorithm of the Q-learning family;based on a customized exploration and exploitation strategy; is able to learn optimal actionsfor the routing autonomous taxis in a real scenario at the scale of the city of Singapore …,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,2016,1
Regularized Cost-Model Oblivious Database Tuning with Reinforcement Learning,Debabrota Basu; Qian Lin; Weidong Chen; Hoang Tam Vo; Zihong Yuan; Pierre Senellart; Stéphane Bressan,Abstract In this paper; we propose a learning approach to adaptive performance tuning ofdatabase applications. The objective is to validate the opportunity to devise a tuning strategythat does not need prior knowledge of a cost model. Instead; the cost model is learnedthrough reinforcement learning. We instantiate our approach to the use case of index tuning.We model the execution of queries and updates as a Markov decision process whose statesare database configurations; actions are configuration changes; and rewards are functionsof the cost of configuration change and query and update evaluation. During thereinforcement learning process; we face two important challenges: the unavailability of acost model and the size of the state space. To address the former; we iteratively learn thecost model; in a principled manner; using regularization to avoid overfitting. To address …,*,2016,1
A Framework for Sampling-Based XML Data Pricing,Ruiming Tang; Antoine Amarilli; Pierre Senellart; Stéphane Bressan,Abstract While price and data quality should define the major trade-off for consumers in datamarkets; prices are usually prescribed by vendors and data quality is not negotiable. In thispaper we study a model where data quality can be traded for a discount. We focus on thecase of XML documents and consider completeness as the quality dimension. In our setting;the data provider offers an XML document; and sets both the price of the document and aweight to each node of the document; depending on its potential worth. The data consumerproposes a price. If the proposed price is lower than that of the entire document; then thedata consumer receives a sample; ie; a random rooted subtree of the document whoseselection depends on the discounted price and the weight of nodes. By requesting severalsamples; the data consumer can iteratively explore the data in the document. We present …,*,2016,1
Intensional data on the web,Antoine Amarilli; Silviu Maniu; Pierre Senellart,Abstract We call data intensional when it is not directly available; but must be accessedthrough a costly interface. Intensional data naturally arises in a number of Web datamanagement scenarios; such as Web crawling or ontology-based data access. Suchscenarios require us to model an uncertain view of the world; for which; given a query; wemust answer the question" What is the best thing to do next?" Once data has been retrieved;the knowledge of the world is revised; and the whole process is repeated; until enoughknowledge about the world has been obtained for the particular application considered. Inthis article; we give an overview of the steps underlying all intensional data managementscenarios; and illustrate them on three concrete applications: focused crawling; onlineinfluence maximization in social networks; and mining crowdsourced data.,ACM Sigweb Newsletter,2015,1
A Framework for Conditioning Probabilistic XML Data (Extended Version),Ruiming Tang; Dongxu Shao; M Lamine Ba; Pierre Senellart; Stéphane Bressan,*,*,2014,1
Crawl intelligent et adaptatif d’applications web pour l’archivage du web,Muhammad Faheem; Pierre Senellart,RÉSUMÉ. Les sites web sont par nature dynamiques; leur contenu et leur structurechangeant au fil du temps; de nombreuses pages sur le web sont produites par dessystèmes de gestion de contenu (CMS). Les outils actuellement utilisés par les archivistesdu web pour préserver le contenu du web collectent et stockent de manière aveugle lespages web; en ne tenant pas compte du CMS sur lequel le site est construit ni du contenustructuré de ces pages web. Nous présentons dans cet article un application-aware helper(AAH) qui s' intègre à une chaine d'archivage classique pour accomplir une collecteintelligente et adaptative des applications web. Parce que l'AAH est conscient desapplications web actuellement collectées; il est capable de raffiner la liste des URL à traiteret d'ajouter à l'archive de l'information sémantique sur le contenu extrait. Afin de traiter les …,ISI,2014,1
Demonstrating intelligent crawling and archiving of web applications,Muhammad Faheem; Pierre Senellart,Abstract We demonstrate here a new approach to Web archival crawling; based on anapplication-aware helper that drives crawls of Web applications according to their types(especially; according to their content management systems). By adapting the crawlingstrategy to the Web application type; one is able to crawl a given Web application (say; agiven forum or blog) with fewer requests than traditional crawling techniques. Additionally;the application-aware helper is able to extract semantic content from the Web pagescrawled; which results in a Web archive of richer value to an archive user. In ourdemonstration scenario; we invite a user to compare application-aware crawling to regularWeb crawling on the Web site of their choice; both in terms of efficiency and of experience inbrowsing and searching the archive.,Proceedings of the 22nd ACM international conference on Information & Knowledge Management,2013,1
An Architecture for Selective Web Harvesting: The Use Case of Heritrix,Vassilis Plachouras; Florent Carpentier; Julien Masanes; Thomas Risse; Pierre Senellart; Patrick Siehndel; Yannis Stavrakas,Abstract. In this paper we provide a brief overview of the crawling architecture of ARCOMEMand how it addresses the challenges arising in the context of selective web harvesting. Wedescribe some of the main technologies developed to perform selective harvesting and wefocus on a modified version of the open source crawler Heritrix; which we have adapted to fitin ACROMEM's crawling architecture. The simulation experiments we have performed showthat the proposed architecture is effective in a focused crawling setting.,Proceedings of the 1st International Workshop on Archiving Community Memories; Lisbon; Portugal,2013,1
Demonstrating ProApproX 2.0: a predictive query engine for probabilistic XML,Asma Souihli; Pierre Senellart,Abstract ProApproX 2.0 allows users to query uncertain tree-structured data in the form ofprobabilistic XML documents. The demonstrated version integrates a fully redesigned queryengine that; first; produces a propositional formula that represents the probabilistic lineageof a given answer over the probabilistic XML document; and; second; searches for anoptimal strategy to approximate the probability of the lineage. This latter part relies on aquery-optimizer-like approach: exploring different evaluation plans for different parts of theformula and predicting the cost of each plan; using a cost model for the various evaluationalgorithms. The demonstration presents the graphical user interface of ProApproX 2.0; thatallows a user to input an XPath query and approximation parameters; and lists query resultswith their probabilities; the interface also gives insight into the way the computation is …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,1
Determining relevance of accesses at runtime (extended version),Michael Benedikt; Georg Gottlob; Pierre Senellart,Abstract: Consider the situation where a query is to be answered using Web sources thatrestrict the accesses that can be made on backend relational data by requiring someattributes to be given as input of the service. The accesses provide lookups on the collectionof attributes values that match the binding. They can differ in whether or not they requirearguments to be generated from prior accesses. Prior work has focused on the question ofwhether a query can be answered using a set of data sources; and in developing staticaccess plans (eg; Datalog programs) that implement query answering. We are interested indynamic aspects of the query answering problem: given partial information about the data;which accesses could provide relevant data for answering a given query? We considerimmediate and long-term notions of" relevant accesses"; and ascertain the complexity of …,arXiv preprint arXiv:1104.0553,2011,1
Optimal probabilistic generators for XML corpora,Serge Abiteboul; Yael Amsterdamer; Daniel Deutch; Tova Milo; Pierre Senellart,Abstract We study the problem of; given a corpus of XML documents and its schema; findingan optimal probabilistic model (optimality meaning maximizing the likelihood of the corpus tobe generated). We present an efficient algorithm for finding the best probabilistic model; inabsence of constraints. We further study the problem in presence of integrity constraints(key; inclusion; and domain constraints) and consider in this case two different kinds ofgenerators: a continuation-test generator that performs; while generating; some tests ofschema satisfiability; these tests allow avoiding the violation of constraints (but as we show;are costly to implement); and a restart generator that may generate an invalid document andthen restart and try again.,BDA (Bases de données avancées),2011,1
Corroboration de vues discordantes fondées sur la confiance,Alban Galland; Serge Abiteboul; Amélie Marian; Pierre Senellart,Résumé. Cet article traite de la corroboration d'informations; dans le contexte de vuesexprimant des opinions sur des faits de façon éventuellement contradictoire. Il s' agit deprédire si un fait est vrai ou faux. Des méthodes d'agrégation simples comme le votedonnent déja de bons résultats; mais nous présentons dans cet article des algorithmes quitiennent compte de la confiance dans les vues pour améliorer les prédictions. Les troisalgorithmes proposés sont des algorithmes de point fixe correspondanta différents niveauxde complexité du modele probabiliste sous-jacent. Ils estimenta la fois la valeur de véritédes faits et la confiance dans les vues. Cet article présente une étude expérimentale sur desdonnées synthétiques et réelles. Ces expériences montrent dans quelle mesure et dansquel contexte nos algorithmes peuvent améliorer les résultats par rapport au vote. La …,Proc. BDA; Namur; Belgium,2009,1
Agrégation de documents XML probabilistes,Serge Abiteboul; T-H Hubert Chan; Evgeny Kharlamov; Werner Nutt; Pierre Senellart,The study of queries over imprecise data has generated much attention in the setting ofrelational databases [4; 9; 20; 28]. The Web (with HTML or XML data) in particular is animportant source of uncertain data; for instance; when dealing with imprecise automatictasks such as information extraction. A natural way to model this uncertainty is to annotatesemi-structured data with probabilities. Some works have recently addressed queries oversuch imprecise hierarchical information [2; 14; 15; 17; 19; 22; 26; 27]. An essential aspect ofquery processing has been ignored in these works; namely aggregate queries. This is theproblem we study here. In this article; we consider probabilistic XML documents; describedusing the unifying model of p-documents [1; 17]. A p-document can be thought of as aprobabilistic process that generates a random XML document. Some nodes; namely …,Proc. BDA,2009,1
Provenance and Probabilities in Relational Databases,Pierre Senellart,Abstract We review the basics of data provenance in relational databases. We describedifferent provenance formalisms; from Boolean provenance to provenance semirings andbeyond; that can be used for a wide variety of purposes; to obtain additional information onthe output of a query. We discuss representation systems for data provenance; circuits inparticular; with a focus on practical implementation. Finally; we explain how provenance ispractically used for probabilistic query evaluation in probabilistic databases.,ACM SIGMOD Record,2018,*
Computing Possible and Certain Answers over Order-Incomplete Data,Antoine Amarilli; Mouhamadou Lamine Ba; Daniel Deutch; Pierre Senellart,Abstract: This paper studies the complexity of query evaluation for databases whoserelations are partially ordered; the problem commonly arises when combining ordered datafrom multiple sources. We focus on queries in a useful fragment of SQL; namely positiverelational algebra with aggregates; whose bag semantics we extend to the partially orderedsetting. Our semantics leads to the study of two main computational problems; namely thepossibility and certainty of query answers. We show that these problems are respectively NP-complete and coNP-complete; but identify tractable cases depending on the query operatorsor input partial orders. We further introduce a duplicate elimination operator and study itseffect on the complexity results.,arXiv preprint arXiv:1801.06396,2018,*
Provenance and Probabilities in Relational Databases: From Theory to Practice,Pierre Senellart,We review the basics of data provenance in relational databases. We describe differentprovenance formalisms; from Boolean provenance to provenance semirings and beyond;that can be used for a wide variety of purposes; to obtain additional information on the outputof a query. We discuss representation systems for data provenance; circuits in particular;with a focus on practical implementation. Finally; we explain how provenance is practicallyused for probabilistic query evaluation in probabilistic databases.,SIGMOD record,2017,*
Connecting Width and Structure in Knowledge Compilation,Pierre Senellart; Antoine Amarilli; Mikaël Monet,Several query evaluation tasks can be done via knowledge compilation: the query result iscompiled as a lineage circuit from which the answer can be determined. For such tasks; it isimportant to leverage some width parameters of the circuit; such as bounded treewidth orpathwidth; to convert the circuit to structured classes; eg; deterministic structured NNFs (d-SDNNFs) or OBDDs. In this work; we show how to connect the width of circuits to the size oftheir structured representation; through upper and lower bounds. For the upper bound; weshow how bounded-treewidth circuits can be converted to a d-SDNNF; in time linear in thecircuit size. Our bound; unlike existing results; is constructive and only singly exponential inthe treewidth. We show a related lower bound on monotone CNF or DNF formulas;assuming a constant bound on the arity (size of clauses) and degree (number of …,*,2017,*
Towards Approximating Incomplete Queries over Partially Complete Databases,Ognjen Savković; Evgeny Kharlamov; Werner Nutt; Pierre Senellart,Building reliable systems over partially complete data poses significant challenges becausequeries they send to the available data retrieve answers that may significantly differ from thereal answers. This may lead to a wrong understanding of the data and the events andprocesses it describes. This problem is especially critical for analytical systems thataggregate retrieved data since missing answers may significantly change results ofanalytical computations; eg; computation of minimal or average values is sensitive tomissing values. One way to ensure reliability of (analytical) systems over partially completedata is to guarantee that whatever data they touch is complete wrt to the real data.,AMW,2017,*
Proceedings of the 20th International Workshop on the Web and Databases; WebDB 2017,Alexandra Meliou; Pierre Senellart,*,*,2017,*
Archivage du Web,Pierre Senellart,Le World Wide Web est la plus vaste source d'informations ayant jamais existé. Mais cesinformations sont très volatiles: la moitié du contenu disparaît en moins de quelquesannées. Ce caractère éphémère de l'information est encore plus évident dans le Web social;dont le contenu est fourni par les utilisateurs du Web; et dans lequel l'accès à l'information;contrôlé par quelques grandes entreprises (cf. VII. 6); n'est parfois plus possible après uncertain délai. L'archivage du Web est un processus de collecte; de sélection;d'enrichissement; de stockage; de préservation et de mise à disposition des informations duWeb actuel; afin qu'elles restent accessibles aux utilisateurs dans l'avenir. L'objectif de cettedémarche est de permettre; par exemple; à un historien dans trente ans de pouvoir étudierla manière dont un événement politique a été commenté par les parties prenantes; les …,*,2017,*
A Knowledge Base for Personal Information Management,David Montoya; Thomas Pellissier Tanon; Serge Abiteboul; Pierre Senellart; Fabian M Suchanek,Internet users have personal data spread over several devices and across several websystems. In this paper; we introduce a novel open-source framework for integrating the dataof a user from different sources into a single knowledge base. Our framework integrates dataof different kinds into a coherent whole; starting with email messages; calendar; contacts;and location history. We show how event periods in the user's location data can be detectedand how they can be aligned with events from the calendar. This allows users to query theirpersonal information within and across different dimensions; and to perform analytics overtheir emails; events; and locations. Our system models data using RDF; extending theschema. org vocabulary and providing a SPARQL interface.,*,2016,*
Thymeflow; An Open-Source Personal Knowledge Base System,David Montoya; Thomas Pellissier Tanon; Serge Abiteboul; Pierre Senellart; Fabian Suchanek,The typical Internet user has data spread over several devices and across several onlinesystems. In this paper; we introduce a novel framework for integrating a user's data fromdifferent sources into a single Knowledge Base. Our framework integrates data of differentkinds into a coherent whole; starting with email messages; calendar; contacts; and locationhistory. We show how event periods in the user's location data can be detected; how theycan be aligned with events from the calendar; and how they can be linked to relevant emails.This allows users to query their personal information within and across different dimensions;and to perform analytics over their emails; events; and locations. To this end; our systemextends the schema. org vocabulary and provides a SPARQL interface.,*,2016,*
Optimal Probabilistic Generation of XML Documents,Serge Abiteboul; Yael Amsterdamer; Daniel Deutch; Tova Milo; Pierre Senellart,Abstract We study the problem of; given a corpus of XML documents and its schema; findingan optimal (generative) probabilistic model; where optimality here means maximizing thelikelihood of the particular corpus to be generated. Focusing first on the structure ofdocuments; we present an efficient algorithm for finding the best generative probabilisticmodel; in the absence of constraints. We further study the problem in the presence ofintegrity constraints; namely key; inclusion; and domain constraints. We study in this casetwo different kinds of generators. First; we consider a continuation-test generator thatperforms; while generating documents; tests of schema satisfiability; these tests prevent fromgenerating a document violating the constraints but; as we will see; they are computationallyexpensive. We also study a restart generator that may generate an invalid document and …,Theory of Computing Systems,2015,*
Requêtes sur des données à ordre incomplet,Antoine Amarilli; M Lamine Ba; Daniel Deutch; Pierre Senellart,Page 1 …,*,2015,*
Guest Editorial: Special Issue on Databases and Crowdsourcing,Reynold Cheng; Silviu Maniu; Pierre Senellart,Crowdsourcing; which employs human workers to perform tasks on the Internet; hasgarnered a lot of attention. This is because crowdsourcing helps solving many problems thatare considered difficult for computers; including entity resolution; question answering; imagetagging; and content rating. The goal of this Special Issue is to study the issues ofharnessing the power of crowdsourcing. To achieve this goal; several technical challengesneed to be encountered. First; how should crowdsourcing tasks be designed? Second; insome crowdsourcing systems (eg; Amazon Mechanical Turk); rewards; or incentives; can begiven to workers when their tasks have been completed successfully. How should theseincentives be allocated to tasks? Third; are existing crowdsourcing user interface designedwell (eg; on mobile platforms)? Fourth; although many crowdsourcing workers are …,Distributed and Parallel Databases,2015,*
Monitoring moving objects using uncertain web data,Mouhamadou Lamine Ba; Sébastien Montenez; Talel Abdessalem; Pierre Senellart,Abstract A number of applications deal with monitoring moving objects: cars; aircrafts; ships;persons; etc. Traditionally; this requires capturing data from sensor networks; image or videoanalysis; or using other application-specific resources. We show in this demonstration paperhow Web content can be exploited instead to gather information (trajectories; metadata)about moving objects. As this content is marred with uncertainty and inconsistency; wedevelop a methodology for estimating uncertainty and filtering the resulting data. We presentas an application a demonstration of a system that constructs trajectories of ships from socialnetworking data; presenting to a user inferred trajectories; meta-information; as well asuncertainty levels on extracted information and trustworthiness of data providers.,Proceedings of the 22nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,2014,*
Gestion de versions incertaines de documents XML,Mouhamadou Lamine Ba; Talel Abdessalem; Pierre Senellart,RÉSUMÉ. Les systèmes d'édition collaborative sur le Web permettent des interactions àlarge échelle entre contributeurs afin de faciliter l'enrichissement; l'échange et le partage decontenu. Cette collaboration n'est pas contrainte par une connaissance préalable du niveaud'expertise et de fiabilité des participants. La gestion de versions est donc cruciale pourtracer l'évolution du contenu partagé et la provenance des contributions. Dans de telssystèmes; l'incertitude est malheureusement omniprésente à cause des sources non fiables;des contributions incomplètes et imprécises; des éditions malveillantes et des actes devandalisme possibles. Pour gérer cette incertitude; nous utilisons un modèle XMLprobabiliste. Chaque version d'un document partagé est représentée par un arbre XML et ledocument tout en entier; y compris ses versions; par un document XML probabiliste. Ceci …,ISI,2014,*
Probabilistic models for uncertain data,Pierre Senellart,Two main probabilistic relational DBMS: Trio [Widom; 2005] Various uncertainty operators:unknown value; uncertain tuple; choice between different possible values; with probabilisticannotations. See example later on. MayBMS [Koch; 2009] Implementation of theprobabilistic c-tables model. In addition; uncertain tables can be constucted using a REPAIR-KEY operator; similar to BIDs.,Proceedings of the Fourth Symposium on Information and Communication Technology,2013,*
Un déluge de données,Serge Abiteboul; Pierre Senellart,MIT; de Philips et du Centre médical Beth Israel Deaconess. Elle regroupe des donnéesmédicales portant sur 32 000 personnes hospitalisées en unités de soins intensifs; soit plusde 40 000 séjours. Le volume de données est nettement plus modeste que celui produit parle LHC; mais son analyse n'en nécessite pas moins des compétences spécifiques et desalgorithmes complexes. Les exemples de domaines scientifiques où l'on doit recueillir etgérer des données massives ne manquent pas. On peut citer la génomique (voir l'article deG. Perrière); les relevés astronomiques (voir l'article de C. Reylé); les recensements de laflore et de la faune; la recherche pharmacologique; les études démographiques; etc. On lecomprend; des algorithmes d'analyse de données massives sont indispensables à larecherche scientifique d'aujourd'hui. Mais il en faut également pour des applications plus …,Pour la Science,2013,*
Disseminate your research: style does matter.,Pierre Senellart,Page 1. 3 December 2014; IC2 Group Seminar Disseminate your Research: Style Does MatterPierre Senellart Page 2. Page 2 / 52 Tel Aviv U. Pierre Senellart Substance vs Style The contentof your research is the most important thing. . . Page 3. Page 2 / 52 Tel Aviv U. Pierre SenellartSubstance vs Style The content of your research is the most important thing. . . .. but the wayyou present it can make the difference. Page 4. Page 2 / 52 Tel Aviv U. Pierre SenellartSubstance vs Style The content of your research is the most important thing. . . .. but the wayyou present it can make the difference. Accept or Reject? Should I read this paper? Is this worthfunding? Page 5. Page 3 / 52 Tel Aviv U. Pierre Senellart The role of writing; presentation;and dissemination Serving the substance of your research First and semi-conscious lastingimpression on an article; a presentation; a work …,PIKM@ CIKM,2013,*
Collecte intelligente et adaptative d’applications Web pour l’archivage du Web,Muhammad Faheem; Pierre Senellart,Social Web Archiving The World Wide Web has become an active publishing system and isa rich source of information; thanks to contributions of hundreds of millions of Web users;who use the social Web as a medium for broadcasting their emotions; publishing content;discussing political issues; sharing videos; posting comments; and also stating theirpersonal opinion in ongoing discussions. Part of this public expression is carried out onsocial networking and social sharing sites (Twitter; Facebook; Youtube; etc.); part of it onindependent Web sites powered by content management systems (CMSs; including blogs;wikis; news sites with comment systems; Web forums). Content published on this range ofWeb applications does not only include the ramblings of common Web users but also piecesof information that are newsworthy today or will be valuable to tomorrow's historians …,BDA (Bases de Données Avancées),2013,*
Une démonstration d’un crawler intelligent pour les applications Web,Muhammad Faheem; Pierre Senellart,We demonstrate here a new approach to Web archival crawling; based on anapplicationaware helper that drives crawls of Web applications according to their types(especially; according to their content management systems). By adapting the crawlingstrategy to the Web application type; one is able to crawl a given Web application (say; agiven forum or blog) with fewer requests than traditional crawling techniques. Additionally;the application-aware helper is able to extract semantic content from the Web pagescrawled; which results in a Web archive of richer value to an archive user. In ourdemonstration scenario; we invite a user to compare application-aware crawling to regularWeb crawling on the Web site of their choice; both in terms of efficiency and of experience inbrowsing and searching the archive.,BDA (Bases de Données Avancées),2013,*
Probabilistic XML: A Data Model for the Web,Pierre Senellart,Data extracted from the Web often come with uncertainty: they may contain contradictions orresult from inherently uncertain processes such as data integration or automatic informationextraction. In this habilitation thesis; I present probabilistic XML data models; how they canbe used to represent Web data; and the complexity of the different data managementoperations on these models. I give an exhaustive survey of the state-of-the-art in this field;insisting on my own contributions. I conclude with a summary of my research plans.,*,2012,*
Optimisation des approximations de probabilité des requêtes en XML probabiliste,Asma Souihli; Pierre Senellart,XML probabiliste est un modele probabiliste pour les bases de données incertaines semi-structurées; avec des applications telles que l'intégration incertaine de données; l'extractiond'informations ou le contrôle probabiliste de versions. Nous explorons dans ce travail unesolution efficace pour l'évaluation des requêtes tree-pattern avec jointures sur cesdocuments; ou; plus précisément; pour l'approximation de la probabilité d'une requêtebooléenne sur un document probabiliste. L'approche repose sur; d'une part; la productionde la provenance probabiliste de la requête posée; et; d'autre part; la recherche d'unestratégie optimale pour estimer la probabilité de cette provenance. Cette deuxieme partie s'inspire des approches des optimiseurs de requêtes: l'exploration de différents plansd'évaluation pour différentes parties de la formule et l'estimation du coût de chaque plan …,BDA (Bases de Données Avancées),2012,*
Value Joins are Expensive over (Probabilistic) XML. Extended Version,Werner Nutt; Pierre Senellart,Abstract We address the cost of adding value joins to tree-pattern queries and monadicsecond-order queries over trees in terms of the tractability of query evaluation over two datamodels: XML and probabilistic XML. Our results show that the data complexity rises fromlinear; for joinfree queries; to intractable; for queries with value joins; while combinedcomplexity remains essentially the same. For tree-pattern queries with joins (TPJ) thecomplexity jump is only on probabilistic XML; while for monadic second-order logic overtrees with joins (TMSOJ) it already appears for deterministic XML documents. Moreover; forTPJ queries that have a single join; we show a dichotomy: every query is either essentiallyjoin-free; and in this case it is tractable over probabilistic XML; or it is intractable. In this lightwe study the problem of deciding whether a query with joins is essentially join-free. For …,*,2011,*
Cultural Diversity in the French Recorded Music Industry (2003-2008),Marc Bourreau; François Moreau; Pierre Senellart,Cultural diversity is now a central aim of public cultural policies; particularly since adoptionof the 2005 UNESCO Convention on the Protection and Promotion of the Diversity ofCultural Expressions; effective as of 18 March 2007 after its ratification by France and theEuropean Union. Numerous cultural policy measures refer back to it; particularly within thecultural industries sectors. A largely political concern; there are nevertheless economicaspects of cultural diversity: it relates to important issues such as competition; industrialconcentration; market power and economic efficiency; which are once again being broughtto the fore in the present climate by economic globalisation and the effects of the digitalrevolution.,Culture études,2011,*
Ontology Matching at the Instance and Schema Level,Fabian M Suchanek; Serge Abiteboul; Pierre Senellart,Toggle navigation. HAL: HAL; HALSHS; TEL; MédiHAL; Liste des portails; AURéHAL; API;Documentation. Episciences.org; Sciencesconf.org; Support. Connexion: Connexion;Connexion avec ORCID; Créer un compte; Mot de passe oublié ? Login oublié ? fr; en.Accueil; Dépôt; Consultation: Les derniers dépôts; Par type de publication; Par discipline;Par année de publication; Par structure de recherche; Les portails de l'archive; Lescollections. Recherche; Documentation: Tutoriels; Compte et profil: Pourquoi créer uncompte et un profil dans HAL; Créer son compte et son profil dans HAL; Modifier son compteou son profil dans HAL; Modifier son mot de passe; Login ou mot de passe oublié; Lesdroits associés au profil. Déposer: Avant de commencer; Les …,BDA (Bases de données avancées),2011,*
Databases,Michael Benedikt; Pierre Senellart,Abstract This chapter is about database research (or as we abbreviate DBR). To peopleoutside of computer science–and perhaps to many within–it will be unclear what this termmeans. First of all; what is a “database”? Used generally; it could mean any collection ofinformation. It is obvious that there are deep scientific issues involved in managinginformation. But information and data are very general notions. Doesn't much of computingdeal with manipulating data or information? Isn't everything data? Clearly the databases thatDBR deals with must be something more specific.,*,2011,*
The WebStand Project,Benjamin Nguyen; François-Xavier Dudouet; Dario Colazzo; Antoine Vion; Ioana Manolescu; Pierre Senellart,Abstract: In this paper we present the state of advancement of the French ANR WebStandproject. The objective of this project is to construct a customizable XML based warehouseplatform to acquire; transform; analyze; store; query and export data from the web; inparticular mailing lists; with the final intension of using this data to perform sociologicalstudies focused on social groups of World Wide Web; with a specific emphasis on thetemporal aspects of this data. We are currently using this system to analyze thestandardization process of the W3C; through its social network of standard setters. Subjects:Databases (cs. DB) Journal reference: WebSci'09: Society On-Line Conference; Greece(2009) Cite as: arXiv: 1002.0971 [cs. DB](or arXiv: 1002.0971 v1 [cs. DB] for this version)Submission history From: Benjamin Nguyen [view email][via CCSD proxy][v1] Thu; 4 Feb …,arXiv preprint arXiv:1002.0971,2010,*
Traiter des corpus d’information sur le Web. Vers de nouveaux usages informatiques de l’enquête.,Dario Colazzo; François-Xavier Dudouet; Ioana Manolescu; Benjamin Nguyen; Pierre Senellart; Antoine Vion,*,Congrès de l'Association française de sciences politiques,2007,*
Website Identification DEA Internship Report,Pierre P Senellart,Abstract I present in this paper a method to discover the set of webpages contained in alogical website; based on the link structure of the Web graph. Such a method is useful toidentify the boundaries of what to crawl; in the context of Web archiving. For this purpose; Icombine the use of an online version of the preflow-push algorithm; an algorithm for themaximum flow problem in traffic networks; and of the Markov CLuster (MCL) algorithm. Thelatter is used on a crawled portion of the Web graph in order to build a seed of initialwebpages; a seed which is extended by the former. Experiments on subsites of the INRIAWebsite; which give satisfactory results; are described.,*,2003,*
Vérification automatique des multiplicateurs,Pierre Senellart,• BDDs [1] very powerful tools for veifying arithmetic circuits … • *BMDs [2] give a polynomialalgorithm but need high-level information … (x1;...;xi−1;xi+1;...;xn) ↦→ f(x1;...;xi−1;0;xi+1;...;xn) … (x1;...;xi−1;xi+1;...;xn) ↦→ f(x1;...;xi−1;1;xi+1;...;xn) … • Some initial total ordering of the variables… • BDDs very efficient for a large class of circuits … Theorem. [Bryant;1986] For any orderingof the variables; the BDD represen … (x1;...;xi−1;xi+1;...;xn) ↦→ f(x1;...;xi−1;0;xi+1;...;xn) …(x1;...;xi−1;xi+1;...;xn) ↦→ f(x1;...;xi−1;1;xi+1;...;xn) … +xi f ˙xi (x1;...;xi−1;xi+1;...;xn) … 8 −20 24 12 24 15 … *BMDs of classical arithmetic operations are of linear size … Circuit: interconnectionof components; described at both bit and word levels … 1. Check that the bit-level interpretationof a component matches its word-level … 2. Check that the composition of word-level interpretationsof components matches … Need of high-level knowledge about the circuit.,*,2002,*
Connecting Width and Structure in Knowledge Compilation (Extended Version),Antoine Amarilli; Mikaël Monet; Pierre Senellart,Abstract Several query evaluation tasks can be done via knowledge compilation: the queryresult is compiled as a lineage circuit from which the answer can be determined. For suchtasks; it is important to leverage some width parameters of the circuit; such as boundedtreewidth or pathwidth; to convert the circuit to structured classes; eg; deterministic structuredNNFs (d-SDNNFs) or OBDDs. In this work; we show how to connect the width of circuits tothe size of their structured representation; through upper and lower bounds. For the upperbound; we show how bounded-treewidth circuits can be converted to a d-SDNNF; in timelinear in the circuit size. Our bound; unlike existing results; is constructive and only singlyexponential in the treewidth. We show a related lower bound on monotone DNF or CNFformulas; assuming a constant bound on the arity (size of clauses) and degree (number of …,*,*,*
Evaluating Datalog via Tree Automata and Cycluits,Antoine Amarilli; Pierre Bourhis; Mikaël Monet; Pierre Senellart,Abstract We investigate parameterizations of both database instances and queries thatmake query evaluation fixed-parameter tractable in combined complexity. We show thatclique-frontier-guarded Datalog with stratified negation (CFG-Datalog) enjoys linear-timeevaluation on structures of bounded treewidth for programs of bounded rule size. Suchprograms capture in particular conjunctive queries with simplicial decompositions ofbounded width; guarded negation fragment queries of bounded CQ-rank; or two-way regularpath queries. Our result is shown by compiling to alternating two-way automata; whosesemantics is defined via cyclic provenance circuits (cycluits) that can be tractably evaluated.,*,*,*
17. Archivage du Web,Pierre Senellart,Pierre Senellart tout en visitant plus rarement celles qui sont plus stables. Mais celademande de pouvoir prédire le taux de changement d'une page; pour en déduire un taux derevisite optimal. Trop de revisites inutiles entraînent un coût important en utilisation duréseau et en temps de calcul; trop peu de revisites peuvent rendre une archiveWebincomplète.,*,*,*
Lignages efficaces sur les instances quasi-arborescentes: Limites et extensions,Antoine Amarilli; Pierre Bourhis; Pierre Senellart,ABSTRACT Il est généralement infaisable (# P-difficile) d'évaluer des requêtes sur les basesde données probabilistes. Des résultats de dichotomie ont permis d'identifier [20; 19; 24]quelles requêtes (dites safe) peuvent être évaluées efficacement; en rattachant celaa desreprésentations du lignage [35]. Nous avons précédemment montré [2];a l'aide detechniques différentes; que l'évaluation de requêtes arbitraires en logique monadique dusecond ordre est faisable en temps linéaire sur les bases de données probabilistes;acondition de borner la largeur d'arbre des instances. Dans ce travail; nous étudions leslimites et les extensions possibles de ce résultat. Nous montrons d'abord; pour l'évaluationprobabiliste de requêtes; qu'il est nécessaire de borner la largeur d'arbre pour assurer lafaisabilité de MSO: en effet; il ya même des requêtes FO dont l'évaluation probabiliste est …,*,*,*
Circuits de provenance pour les arbres et les instances quasi-arborescentes,Antoine Amarilli; Pierre Bourhis; Pierre Senellart,ABSTRACT L'évaluation de requêtes en logique monadique du second ordre (MSO) est defaible complexité sur les arbres et les instances quasi-arborescentes (c'est-a-dire de largeurd'arbre bornée); alors qu'elle est difficile sur les instances arbitraires. Ce résultat a étéétendua certaines tâches liéesa l'évaluation de requêtes; comme compter les résultats d'unerequête [3] ou évaluer des requêtes sur des arbres probabilistes [11]. Nous voyons lecomptage et l'évaluation probabiliste comme deux cas particuliers du probleme plus généralconsistanta calculer des résultats de requête enrichis avec des informations de provenance.Cet article présente une construction de provenance pour les arbres et les instances quasi-arborescentes; en expliquant comment calculer en temps linéaire une représentation de laprovenance sous forme de circuit pour les requêtes MSO. Nous montrons comment cette …,*,*,*
Apprentissage par renforcement pour optimiser les bases de données indépendamment du modèle de coût,Debabrota Basu; Qian Lin; Zihong Yuan; Pierre Senellart; Stéphane Bressan,ABSTRACT Dans cet article; nous proposons une approche basée sur l'apprentissage pourl'optimisation adaptative des performances des applications de gestion de données. Il s' agitde valider l'opportunité de concevoir une stratégie d'optimisation qui ne requiert aucuneconnaissance d'un modèle de coût. Au lieu de cela; le modèle de coût est appris parapprentissage par renforcement. Nous appliquons notre approche au cas de l'optimisationdes index. Nous modélisons l'exécution des requêtes et mises à jour comme un processusde décision markovien dont les états sont les configurations de la base de données; lesactions sont les changements de configurations; et les récompenses sont fonctions du coûtdu changement de configuration et de l'évaluation des requêtes et mises à jour. Au cours duprocessus d'apprentissage par renforcement; nous faisons face à deux défis importants …,*,*,*
Collecte; integration et visualisation de donnees Web incertaines sur des objets mobiles,Mouhamadou Lamine Ba; Sébastien Montenez; Talel Abdessalem; Pierre Senellart,ABSTRACT Nombreuses sont aujourd'hui les applications de veille sur objets mobiles:voitures; trains; avions; bateaux; personnes; ou; plus globalement; populations ouphénomenes tels que cyclones. De façon classique; cela exige la collecte de donnéesapartir de réseaux de capteurs; d'analyse d'images ou de vidéos; ou l'utilisation deressources spécifiquesa une application cible. Nous montrons dans ce papier dedémonstration comment le contenu Web peut êtrea la place exploité pour collecter desinformations (trajectoires; métadonnées) concernant certains objets mobiles. Cependant;l'incertitude et les incohérences vont de pair avec les données Web. Nous développonsainsi une méthodologie pour l'estimation de l'incertitude et le filtrage des données extraites.En guise de démonstration; nous présentons sous forme d'une application Web un …,*,*,*
DBCrowd 2013,Reynold Cheng; Anish Das Sarma; Silviu Maniu; Pierre Senellart,DBCrowd 2013: First VLDB Workshop on Databases and Crowdsourcing Contents Organization3 I. Invited Keynotes 4 Multi-Platform; Reactive Crowdsourcing. Stefano Ceri 5 Mining theCrowd. Tova Milo 6 II. Research Papers 7 Wrapper Generation Supervised by a NoisyCrowd. Valter Crescenzi; Paolo Merialdo and Disheng Qiu 8 Crowdsourcing to MobileUsers: A Study of the Role of Platforms and Tasks. Vincenzo Della Mea; Eddy Maddalena andStefano Mizzaro 14 Condition-Task-Store: A Declarative Abstraction for Microtask-based ComplexCrowd- sourcing. Kenji Gonnokami; Atsuyuki Morishima and Hiroyuki Kitagawa 20 ThePalm-tree Index: Indexing with the crowd. Ahmed Mahmood; Walid Aref; Eduard Dragut andSaleh Basalamah 26 Crowdsourcing Feedback for PayAsYouGo Data Integration. FernandoOsorno-Gutierrez; Norman Paton and Alvaro AA Fernandes 32 III. Vision Papers 38 …,*,*,*
Contrôle de version incertain dans l’édition collaborative ouverte de documents arborescents,M Lamine Ba; Talel Abdessalem; Pierre Senellart,Version Control in Open Environments. In many collaborative editing systems; whereseveral users can provide content; content management is based on version control. Aversion control system tracks the versions of the content as well as changes. Such a systemenables fixing error made in the revision process; querying past versions; and integratingcontent from different contributors. As surveyed in [12; 27]; much effort related to versioncontrol has been carried out both in research and in applications. The prime applicationswere collaborative document authoring; computer-aided design; and software developmentsystems. Currently; powerful version control tools; such as Subversion [19] and Git [16];efficiently manage large source code repositories and shared filesystems. However; existingapproaches leave no room for uncertainty handling; for instance; uncertain data resulting …,*,*,*
Birds of a tag flock together,Serge Abiteboul; Sihem Amer-Yahia; Alban Galland; Amélie Marian; Pierre Senellart,Motivation and context. Recently; extracting knowledge from user-generated social data hasattracted a lot of attention. Several works have focused on modeling user-generated tagssuch as the study of tag clouds [3]; cross-floksonomy analysis [7]; or the use of tag-drivencommunities for content search [4] or recommendation [6]. The huge and increasing amountof raw tags and annotations clearly contains valuable social information and is thus anessential asset for helping community members find information they are interested in. Forexample; the exploration of communities in del. icio. us; a well known social tagging website;can be enhanced through the use of tags; see eg;[1]. Our goal is twofold: extract knowledgefrom this rich social information by clustering social data based on affinity (ie; proximity in thesocial network); and provide better query support and navigation on the semantically …,*,*,*
