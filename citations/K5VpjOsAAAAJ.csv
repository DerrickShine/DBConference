Column-oriented storage techniques for MapReduce,Avrilia Floratou; Jignesh M Patel; Eugene J Shekita; Sandeep Tata,Abstract Users of MapReduce often run into performance problems when they scale up theirworkloads. Many of the problems they encounter can be overcome by applying techniqueslearned from over three decades of research on parallel DBMSs. However; translating thesetechniques to a Map-Reduce implementation such as Hadoop presents unique challengesthat can lead to new design choices. This paper describes how column-oriented storagetechniques can be incorporated in Hadoop in a way that preserves its popular programmingAPIs. We show that simply using binary storage formats in Hadoop can provide a 3xperformance boost over the naive use of text files. We then introduce a column-orientedstorage format that is compatible with the replication and scheduling constraints of Hadoopand show that it can speed up MapReduce jobs on real workloads by an order of …,Proceedings of the VLDB Endowment,2011,153
Using paxos to build a scalable; consistent; and highly available datastore,Jun Rao; Eugene J Shekita; Sandeep Tata,Abstract Spinnaker is an experimental datastore that is designed to run on a large cluster ofcommodity servers in a single datacenter. It features key-based range partitioning; 3-wayreplication; and a transactional get-put API with the option to choose either strong or timelineconsistency on reads. This paper describes Spinnaker's Paxos-based replication protocol.The use of Paxos ensures that a data partition in Spinnaker will be available for reads andwrites as long a majority of its replicas are alive. Unlike traditional master-slave replication;this is true regardless of the failure sequence that occurs. We show that Paxos replicationcan be competitive with alternatives that provide weaker consistency guarantees. Comparedto an eventually consistent datastore; we show that Spinnaker can be as fast or even fasteron reads and only 5% to 10% slower on writes.,Proceedings of the VLDB Endowment,2011,138
SQAK: doing more with keywords,Sandeep Tata; Guy M Lohman,Abstract Today's enterprise databases are large and complex; often relating hundreds ofentities. Enabling ordinary users to query such databases and derive value from them hasbeen of great interest in database research. Today; keyword search over relationaldatabases allows users to find pieces of information without having to write complicated SQLqueries. However; in order to compute even simple aggregates; a user is required to write aSQL statement and can no longer use simple keywords. This not only requires the ordinaryuser to learn SQL; but also to learn the schema of the complex database in detail in order tocorrectly construct the required query. This greatly limits the options of the user who wishesto examine a database in more depth. As a solution to this problem; we propose aframework called SQAK 1 (SQL Aggregates using Keywords) that enables users to pose …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,118
Estimating the selectivity of tf-idf based cosine similarity predicates,Sandeep Tata; Jignesh M Patel,Abstract An increasing number of database applications today require sophisticatedapproximate string matching capabilities. Examples of such application areas include dataintegration and data cleaning. Cosine similarity has proven to be a robust metric for scoringthe similarity between two strings; and it is increasingly being used in complex queries. Animmediate challenge faced by current database optimizers is to find accurate and efficientmethods for estimating the selectivity of cosine similarity predicates. To the best of ourknowledge; there are no known methods for this problem. In this paper; we present the firstapproach for estimating the selectivity of tf. idf based cosine similarity predicates. Weevaluate our approach on three different real datasets and show that our method oftenproduces estimates that are within 40% of the actual selectivity.,ACM Sigmod Record,2007,111
Practical suffix tree construction,Sandeep Tata; Richard A Hankins; Jignesh M Patel,Abstract Large string datasets are common in a number of emerging text and biologicaldatabase applications. Common queries over such datasets include both exact andapproximate string matches. These queries can be evaluated very efficiently by using asuffix tree index on the string dataset. Although suffix trees can be constructed quickly inmemory for small input datasets; constructing persistent trees for large datasets has beenchallenging. In this paper; we explore suffix tree construction algorithms over a widespectrum of data sources and sizes. First; we show that on modern processors; a cache-efficient algorithm with O (n 2) complexity outperforms the popular O (n) Ukkonen algorithm;even for in-memory construction. For larger datasets; the disk I/O requirement quicklybecomes the bottleneck in each algorithm's performance. To address this problem; we …,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,110
Practical methods for constructing suffix trees,Yuanyuan Tian; Sandeep Tata; Richard A Hankins; Jignesh M Patel,Abstract Sequence datasets are ubiquitous in modern life-science applications; andquerying sequences is a common and critical operation in many of these applications. Thesuffix tree is a versatile data structure that can be used to evaluate a wide variety of querieson sequence datasets; including evaluating exact and approximate string matches; andfinding repeat patterns. However; methods for constructing suffix trees are often very time-consuming; especially for suffix trees that are large and do not fit in the available mainmemory. Even when the suffix tree fits in memory; it turns out that the processor cachebehavior of theoretically optimal suffix tree construction methods is poor; resulting in poorperformance. Currently; there are a large number of algorithms for constructing suffix trees;but the practical tradeoffs in using these algorithms for different scenarios are not well …,The VLDB Journal,2005,105
Efficient and accurate discovery of patterns in sequence data sets,Avrilia Floratou; Sandeep Tata; Jignesh M Patel,Existing sequence mining algorithms mostly focus on mining for subsequences. However; alarge class of applications; such as biological DNA and protein motif mining; require efficientmining of “approximate” patterns that are contiguous. The few existing algorithms that can beapplied to find such contiguous approximate pattern mining have drawbacks like poorscalability; lack of guarantees in finding the pattern; and difficulty in adapting to otherapplications. In this paper; we present a new algorithm called FLexible and Accurate MotifDEtector (FLAME). FLAME is a flexible suffix-tree-based algorithm that can be used to findfrequent patterns with a variety of definitions of motif (pattern) models. It is also accurate; as italways finds the pattern if it exists. Using both real and synthetic data sets; we demonstratethat FLAME is fast; scalable; and outperforms existing algorithms on a variety of …,IEEE Transactions on Knowledge and Data Engineering,2011,69
Clydesdale: structured data processing on MapReduce,Tim Kaldewey; Eugene J Shekita; Sandeep Tata,Abstract MapReduce has emerged as a promising architecture for large scale data analyticson commodity clusters. The rapid adoption of Hive; a SQL-like data processing language onHadoop (an open source implementation of MapReduce); shows the increasing importanceof processing structured data on MapReduce platforms. MapReduce offers several attractiveproperties such as the use of low-cost hardware; fault-tolerance; scalability; and elasticity.However; these advantages have required a substantial performance sacrifice. In this paperwe introduce Clydesdale; a novel system for structured data processing on Hadoop--apopular implementation of MapReduce. We show that Clydesdale provides more than anorder of magnitude in performance improvements compared to existing approaches withoutrequiring any changes to the underlying platform. Clydesdale is aimed at workloads …,Proceedings of the 15th international conference on extending database technology,2012,57
Declarative querying for biological sequences,Sandeep Tata; James S Friedman; Anand Swaroop,The ongoing revolution in life sciences research is producing vast amounts of genetic andproteomic sequence data. Scientists want to pose increasingly complex queries on this data;but current methods for querying biological sequences are primitive and largely procedural.This limits the ease with which complex queries can be posed; and often results in veryinefficient query plans. There is a growing and urgent need for declarative and efficientmethods for querying biological sequence data. In this paper; we introduce a system calledPeriscope/SQ which addresses this need. Queries in our system are based on a well-defined extension of relational algebra. We introduce new physical operators and supportfor novel indexes in the database. As part of the optimization framework; we describe a newtechnique for selectivity estimation of string pattern matching predicates that is more …,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,35
BlueSNP: R package for highly scalable genome-wide association studies using Hadoop clusters,Hailiang Huang; Sandeep Tata; Robert J Prill,Abstract Summary: Computational workloads for genome-wide association studies (GWAS)are growing in scale and complexity outpacing the capabilities of single-threaded softwaredesigned for personal computers. The BlueSNP R package implements GWAS statisticaltests in the R programming language and executes the calculations across computerclusters configured with Apache Hadoop; a de facto standard framework for distributed dataprocessing using the MapReduce formalism. BlueSNP makes computationally intensiveanalyses; such as estimating empirical p-values via data permutation; and searching forexpression quantitative trait loci over thousands of genes; feasible for large genotype–phenotype datasets. Availability and implementation: http://github. com/ibm-bioinformatics/bluesnp Contact: rjprill@ us. ibm. com Supplementary information …,Bioinformatics,2012,31
Sparkler: Supporting large-scale matrix factorization,Boduo Li; Sandeep Tata; Yannis Sismanis,Abstract Low-rank matrix factorization has recently been applied with great success onmatrix completion problems for applications like recommendation systems; link predictionsfor social networks; and click prediction for web search. However; as this approach isapplied to increasingly larger datasets; such as those encountered in web-scalerecommender systems like Netflix and Pandora; the data management aspects quicklybecome challenging and form a road-block. In this paper; we introduce a system calledSparkler to solve such large instances of low rank matrix factorizations. Sparkler extendsSpark; an existing platform for running parallel iterative algorithms on datasets that fit in theaggregate main memory of a cluster. Sparkler supports distributed stochastic gradientdescent as an approach to solving the factorization problem--an iterative technique that …,Proceedings of the 16th international conference on extending database technology,2013,29
Towards a scalable enterprise content analytics platform,K Beyer,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,Bulletin of the IEEE Computer Society Technical Committee on Data Engineering; 2009,2009,23
Leveraging a scalable row store to build a distributed text index,Ning Li; Jun Rao; Eugene Shekita; Sandeep Tata,Abstract Many content-oriented applications require a scalable text index. Building such anindex is challenging. In addition to the logic of inserting and searching documents;developers have to worry about issues in a typical distributed environment; such as faulttolerance; incrementally growing the index cluster; and load balancing. We developed adistributed text index called HIndex; by judiciously exploiting the control layer of HBase;which is an open source implementation of Google's Bigtable. Such leverage enables us toinherit the support on availability; elasticity and load balancing in HBase. We present thedesign; implementation; and a performance evaluation of HIndex in this paper.,Proceedings of the first international workshop on Cloud data management,2009,21
PiQA: An algebra for querying protein data sets,Sandeep Tata; Jignesh M Patel,Life science researchers frequently need to query large protein data sets in a variety ofdifferent ways. Protein data sets have a rich structure that includes its primary structure;which is described as a sequence of amino acids; and its secondary structure; which isdescribed as a sequence of folding patterns of the protein. Both these structures areimportant as the amino acid sequence is often used to find homologous proteins; and thesecondary structure can produce important hints about the functionality of proteins. Whilethere are tools for querying each of these structures independently; there are no tools fordeclarative querying on both these structures. Even the tools that allow querying on eitherone of these structures are not based on any formal algebra; and as a result require complexrewriting of the tools programming logic when the" query evaluation plan" changes. This …,Scientific and Statistical Database Management; 2003. 15th International Conference on,2003,20
Clydesdale: structured data processing on hadoop,Andrey Balmin; Tim Kaldewey; Sandeep Tata,Abstract There have been several recent proposals modifying Hadoop; radically changingthe storage organization or query processing techniques to obtain good performance forstructured data processing. We will showcase Clydesdale; a research prototype forstructured data processing on Hadoop that can achieve dramatic performanceimprovements over existing solutions; without any changes to the underlying MapReduceimplementation. Clydesdale achieves this through a novel synthesis of several techniquesfrom the database literature and carefully adapting them to the Hadoop environment. On thestar schema benchmark; we show that Clydesdale is on average 38x faster than Hive; thedominant approach for structured data processing on Hadoop today. To the best of ourknowledge; Clydesdale is the fastest solution for processing workloads on structured data …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,17
Diff-Index: Differentiated Index in Distributed Log-Structured Data Stores.,Wei Tan; Sandeep Tata; Yuzhe Tang; Liana L Fong,ABSTRACT Log-Structured-Merge (LSM) Tree gains much attention recently because of itssuperior performance in write-intensive workloads. LSM Tree uses an append-only structurein memory to achieve low write latency; at memory capacity; in-memory data are flushed toother storage media (eg disk). Consequently; read access is slower comparing to write.These specific features of LSM; including no in-place update and asymmetric read/writeperformance raise unique challenges in index maintenance for LSM. The structuraldifference between LSM and B-Tree also prevents mature B-Tree based approaches frombeing directly applied. To address the issues of index maintenance for LSM; we propose Diff-Index to support a spectrum of index maintenance schemes to suit different objectives inindex consistency and performance. The schemes consist of sync-full; sync-insert; async …,EDBT,2014,15
Client-based index advisor,*,A common interface to manage heterogeneous databases and develop enterprise classapplications is provided. In particular; it is shown that a client-based system and methodcan:(a) provide a uniform interface for the DBA or the application developer to use across allthe database deployments;(b) provide flexibility in the number and kinds of scenarios it canbe used; and finally (c) reduce the total cost of ownership for the enterprise.,*,2013,14
Periscope/SQ: interactive exploration of biological sequence databases,Sandeep Tata; Willis Lang; Jignesh M Patel,Abstract Life science laboratories today have to rely on procedural techniques to store andmanage large sequence datasets. Procedural techniques are cumbersome to use and areoften very inefficient compared to optimized declarative techniques. We have designed andimplemented a system called Periscope/SQ that makes it possible to rapidly expresscomplex queries within a declarative framework and take advantage of database-style queryoptimization. As a result; queries in Periscope/SQ run orders of magnitude faster than typicalprocedural implementations. We demonstrate the power of Persicope/SQ through anapplication called Gene-Locator which allows biologists to rapidly explore large genomicsequence databases.,Proceedings of the 33rd international conference on Very large data bases,2007,13
Scalable row-store with consensus-based replication,*,A method for updating a scalable row-store; including: receiving an update to a key within arange of keys in a database table; wherein the database table is distributed across nodes ina cluster of computing devices; and replicating the update over a group of the nodes using aconsensus-based replication algorithm; wherein the replication algorithm includescompleting the update in response to receiving acknowledgement messages from a majorityof the nodes in the group indicating that the majority has received notification of the update.,*,2015,11
A platform for eXtreme Analytics,Andrey Balmin; Kevin Beyer; Vuk Ercegovac; John McPherson; Fatma Oezcan; Hamid Pirahesh; Eugene Shekita; Yannis Sismanis; Sandeep Tata; Yuanyuan Tian,With the rapid increase in the volume of data that enterprises are producing; enterprises areadopting large-scale data processing platforms such as Hadoop® to store; manage; and rundeep analytics to gain actionable insights from their “big data.” At IBM Research-Almaden;we have been helping enterprise customers build solutions exploiting data-intensiveanalytics. Our deep experience with actual users has led to an extensive understanding ofthe platform requirements needed to support these solutions; and our goal is to provide apowerful analytics platform; which we call eXtreme Analytics Platform (XAP); that can beused to create solutions for customer problems that have not been economically feasible tosolve until now. XAP provides Jaql [ie; JavaScript® Object Notation (JSON) query language;a scripting language to specify data flows; tools; and techniques to optimize the runtime …,IBM Journal of Research and Development,2013,6
Declarative Querying For Biological Sequences.,Sandeep Tata,Life science research labs today manage increasing volumes of sequence data. Much of thedata management and querying today is accomplished procedurally using Perl; Python; orJava programs that integrate data from different sources and query tools. The dangers of thisprocedural approach are well known to the database community--a) severe limitations onthe ability to rapidly express queries and b) inefficient query plans due to the lack ofsophisticated optimization tools. This situation is likely to get worse with advances in high-throughput technologies that make it easier to quickly produce vast amounts of sequencedata. The need for a declarative and efficient system to manage and query biologicalsequence data is urgent. To address this need; we designed the Periscope/SQ system.Periscope/SQ extends current relational systems to enable sophisticated queries on …,*,2007,6
Efficient join with one or more large dimension tables,*,Embodiments of the invention relate to processing queries that utilize fact and/or dimensiontables. In one aspect; a pre-join filtering phase precedes a star join. The necessaryconditions for the pre-join filtering are considered for a given SQL query; including anestimated size of the hash table exceeding a threshold and presence of a local predicateeither on the fact table or one or more dimension tables that is not a large dimension table.Once the necessary conditions are satisfied; the execution of the query exploits the pre-joinfiltering to build a pre-join output filter from columns of a reduced fact table that joins witheach large dimension table. Thereafter; all the dimension tables and the fact table are joinedin a star join while exploiting each pre-join filter.,*,2015,5
Toward a scale-out data-management middleware for low-latency enterprise computing,Liana L Fong; Yuqing Gao; XR Guerin; YG Liu; T Salo; SR Seelam; Wei Tan; Sandeep Tata,Emerging transactional workloads from Internet and mobile commerce require low-latency;massive-scale; and integrated data analytics to enhance user experience and to improve up-selling opportunities. These analytics require new application platforms that must be able toabsorb large volumes of data; provide low-latency access to the data; and cache dataobjects to improve access times in distributed environments. This paper reports on recenttechnologies built at IBM Research to address challenges in data access latency; dataingestion; and caching in the exemplary context of an online product recommendationapplication. We describe three technologies related to the issues and optimizations of key-value data object store and access. First; we describe the architecture of a global secondaryindex to greatly improve data access latency of Hadoop™ Database (HBase™); an open …,IBM Journal of Research and Development,2013,5
On common tools for databases-The case for a client-based index advisor,Sandeep Tata; Lin Qiao; Guy M Lohman,Modern enterprises often deploy multiple databases from different vendors. Managing aheterogeneous mix of databases is a very challenging exercise. To help the DBA tackle thiscomplex administrative task; major database vendors have provided many autonomic tools.The tools help automate common management tasks and even help in performance tuning.However; the DBA now has to face the complexity of dealing with a variety of different toolsfor different tasks; each with different interfaces and capabilities. The application developeralso suffers from a similar problem when trying to use different tools that help him developapplications for different databases. Clearly; there is a need for a common interface tomanage heterogeneous databases and develop enterprise class applications for them. Toaddress this need; we argue for a client-based approach to developing database tools. In …,Data Engineering Workshop; 2008. ICDEW 2008. IEEE 24th International Conference on,2008,4
Towards Declarative Querying for Biological Sequences,Sandeep Tata; J Patel; J Friedman; Anand Swaroop,Abstract The ongoing revolution in life sciences research is producing vast amounts ofgenetic and proteomic sequence data. Scientists want to pose increasingly complex querieson this data; but current methods for querying biological sequences are primitive and largelyprocedural. This limits the ease with which complex queries can be posed; and often resultsin very inefficient query plans. There is a growing and urgent need for declarative andefficient methods for querying biological sequence data. In this paper we introduce a systemcalled Periscope/SQ which addresses this need. Queries in our system are based on awelldefined extension of relational algebra. We introduce new physical operators andsupport for novel indexes in the database. As part of the optimization framework; wedescribe a new technique for selectivity estimation of string pattern matching predicates …,*,2005,4
Atomic incremental load for map-reduce systems on append-only file systems,*,Augmenting data files in a repository of an append-only file system comprises maintainingmetadata corresponding to each data file for tracking a logical end-of-file (EOF) for eachdata file for appending. A global versioning mechanism for the metadata allows selecting thecurrent version of the metadata to read for performing an append job for a set of data files.Each append job comprises multiple append tasks. For each successful append job; theglobal versioning mechanism increments a valid metadata version to use for each data fileappended. Said valid metadata version indicates the logical EOF corresponding to a newphysical EOF for each of the data files appended.,*,2016,3
Finding Hidden Patterns in Sequences,Avrilia Floratou; Sandeep Tata; Jignesh M Patel,*,Sciences-New York,2010,2
FLAME: Shedding Light on Hidden Frequent Patterns in Sequence Datasets,Sandeep Tata; Jignesh M Patel,Existing database sequence mining algorithms focus on mining for subsequences.However; for many emerging applications; the subsequence model is inadequate fordetecting interesting patterns. Often; an approximate substring model better accommodatesthe notion of a noisy pattern. In this paper; we present a powerful new model for approximatepattern mining. We show that this model can be used to capture the notion of anapproximate match for a variety of different applications. We also present a novel; suffix treebased pattern mining algorithm called FLAME and demonstrate that it is a fast; accurate; andscalable method for discovering hidden patterns in large sequence databases.,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,2
Quick Access: Building a Smart Experience for Google Drive,Sandeep Tata; Alexandrin Popescul; Marc Najork; Mike Colagrosso; Julian Gibbons; Alan Green; Alexandre Mah; Michael Smith; Divanshu Garg; Cayden Meyer; Reuben Kan,Abstract Google Drive is a cloud storage and collaboration service used by hundreds ofmillions of users around the world. Quick Access is a new feature in Google Drive thatsurfaces the most relevant documents when a user visits the home screen. Our metrics showthat users locate their documents in half the time with this feature compared to previousapproaches. The development of Quick Access illustrates many general challenges andconstraints associated with practical machine learning such as protecting user privacy;working with data services that are not designed with machine learning in mind; andevolving product definitions. We believe that the lessons learned from this experience will beuseful to practitioners tackling a wide range of applied machine learning problems.,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2017,1
Hidden in Plain Sight: Classifying Emails Using Embedded Image Contents,Navneet Potti; James B Wendt; Qi Zhao; Sandeep Tata; Marc Najork,Abstract A vast majority of the emails received by people today are machine-generated bybusinesses communicating with consumers. While some emails originate as a result of atransaction (eg; hotel or restaurant reservation confirmations; online purchase receipts;shipping notifications; etc.); a large fraction are commercial emails promoting an offer (aspecial sale; free shipping; available for a limited time; etc.). The sheer number of thesepromotional emails makes it difficult for users to read all these emails and decide whichones are actually interesting and actionable. In this paper; we tackle the problem ofextracting information from commercial emails promoting an offer to the user. Thisinformation enables an email platform to build several new experiences that can unlock thevalue in these emails without the user having to navigate and read all of them. For …,*,2018,*
Atomic incremental load for map-reduce systems on append-only file systems,*,Augmenting data files in a repository of an append-only file system includes maintaining acompanion metadata file for each corresponding data file in a map-reduce system using theappend-only file system. Each companion metadata file tracks a logical end-of-file (EOF) foreach data file. Global versioning of each companion metadata is maintained. A map-reduceappend job is performed for a set of data files using a current global version number for thecompanion metadata file. The map-reduce job including multiple append tasks. For eachsuccessful append job; a logical EOF for each appended file is incremented to a newphysical EOF. For each failed append task of the append job; a logical EOF is maintained foreach failed append task by not incrementing the logical EOF for each failed append task.,*,2016,*
Differentiated secondary index maintenance in log structured nosql data stores,*,There is provided a method for operating multi-node data stores. A data table is stored in afirst computing node and an index table is stored in a second computing node. The indextable provides keys used for accessing data in the first computing node and other multi-nodedata stores. Operations that update or read the data table accessed from the first computingnode and the index table accessed from the second computing node are performed. Theoperations optimize between latency in updating or reading the data table and the indextable and data consistency maintained between data entries in the data table and dataentries pointed by indices in the index table.,*,2015,*
Query Languages and Evaluation Techniques for Biological Sequence Data,Sandeep Tata; Jignesh M Patel,In general; the term Quadtree refers to a class of representations of geometric entities (suchas points; line segments; polygons; regions) in a space of two (or more) dimensions; thatrecursively decompose the space containing these entities into blocks until the data in eachblock satisfy some condition (with respect; for example; to the block size; the number of blockentities; the characteristics of the block entities; etc.). In a more restricted sense; the termQuadtree (Octree) refers to a tree data-structure in which each internal node has four (eight)children and is used for the representation of geometric entities in a two (three) dimensionalspace. The root of the tree represents the whole space/region. Each child of a noderepresents a subregion of the subregion of its parent. The subregions of the siblingsconstitute a partition of the parent's regions. Several variations of quadtrees are possible …,*,2009,*
Practical methods for constructing suffix trees,Richard A Hankins; Sandeep Tata; Jignesh M Patel; Yuanyuan Tian,Sequence datasets are ubiquitous in modern life-science applications; and queryingsequences is a common and critical operation in many of these applications. The suffix treeis a versatile data structure that can be used to evaluate a wide variety of queries onsequence datasets; including evaluating exact and approximate string matches; and findingrepeat patterns. However; methods for constructing suffix trees are often very time-consuming; especially for suffix trees that are large and do not fit in the available mainmemory. Even when the suffix tree fits in memory; it turns out that the processor cachebehavior of theoretically optimal suffix tree construction methods is poor; resulting in poorperformance. Currently; there are a large number of algorithms for constructing suffix trees;but the practical tradeoffs in using these algorithms for different scenarios are not well …,*,2005,*
Massive-Scale Analytics,A Soffer; P Malik; AN Ghoting; JA Gunnels; P Kambadur; EP Pednault; MS Squillante; HP Hofstee; GC Chen; FH Gebara; K Hall; J Herring; D Jamsek; J Li; Y Li; JW Shi; PWY Wong; A Balmin; K Beyer; V Ercegovac; J McPherson; F Ozcan; H Pirahesh; E Shekita; Y Sismanis; S Tata; Y Tian; R Jain; P Sarkar; D Subhraveti; LL Fong; Y Gao; XR Guerin; YG Liu; T Salo; SR Seelam; W Tan,BBig Data [refers to large data sets that are beyond the capability of traditional software toolsto quickly manage; process; and analyze. The development of techniques for gaining insightfrom such information provides potential benefits in such arenas as business; science; andpublic policy. This special issue of the IBM Journal emphasizes applications; analytics;software; and hardware technologies that form the foundational building blocks for massive-scale analytics and the processing of Big Data.,*,*,*
