Design and evaluation of main memory hash join algorithms for multi-core cpus,Spyros Blanas; Yinan Li; Jignesh M Patel,Abstract The focus of this paper is on investigating efficient hash join algorithms for modernmulti-core processors in main memory environments. This paper dissects each internalphase of a typical hash join algorithm and considers different alternatives for implementingeach phase; producing a family of hash join algorithms. Then; we implement these mainmemory algorithms on two radically different modern multi-processor systems; and carefullyexamine the factors that impact the performance of each method. Our analysis reveals someinteresting results--a very simple hash join algorithm is very competitive to the other morecomplex methods. This simple join algorithm builds a shared hash table and does notpartition the input relations. Its simplicity implies that it requires fewer parameter settings;thereby making it far easier for query optimizers and execution engines to use it in …,Proceedings of the 2011 ACM SIGMOD international conference on Management of data,2011,176
Tree indexing on solid state drives,Yinan Li; Bingsheng He; Robin Jun Yang; Qiong Luo; Ke Yi,Abstract Large flash disks; or solid state drives (SSDs); have become an attractivealternative to magnetic hard disks; due to their high random read performance; low energyconsumption and other features. However; writes; especially small random writes; on flashdisks are inherently much slower than reads because of the erase-before-write mechanism.To address this asymmetry of read-write speeds in tree indexing on the flash disk; wepropose FD-tree; a tree index designed with the logarithmic method and fractionalcascading techniques. With the logarithmic method; an FD-tree consists of the head tree--asmall B+-tree on the top; and a few levels of sorted runs of increasing sizes at the bottom.This design is write-optimized for the flash disk; in particular; an index search will potentiallygo through more levels or visit more nodes; but random writes are limited to a small area …,Proceedings of the VLDB Endowment,2010,132
Tree indexing on flash disks,Yinan Li; Bingsheng He; Qiong Luo; Ke Yi,Large flash disks have become an attractive alternative to magnetic hard disks; due to theirhigh random read performance; low energy consumption and other features. However;writes; especially random writes; on the flash disk are inherently much slower than readsbecause of the erase-before-write mechanism. To address this asymmetry of read-writespeeds in indexing on the flash disk; we propose the FD-tree; a tree index designed with thelogarithmic method and fractional cascading techniques. With the logarithmic method; an FD-tree consists of the head tree–a small B+-tree on the top; and a few levels of sorted runs ofincreasing sizes at the bottom. This design is write-optimized for the flash disk; in particular;an index search will potentially go through more levels or visit more nodes; but randomwrites are limited to the head tree and are subsequently transformed into sequential ones …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,120
NUMA-aware algorithms: the case of data shuffling.,Yinan Li; Ippokratis Pandis; Rene Mueller; Vijayshankar Raman; Guy M Lohman,ABSTRACT In recent years; a new breed of non-uniform memory access (NUMA) systemshas emerged: multi-socket servers of multicores. This paper makes the case that datamanagement systems need to employ designs that take into consideration thecharacteristics of modern NUMA hardware. To prove our point; we focus on a primitive that isused as the building block of numerous data management operations: data shuffling. Weperform a comparison of different data shuffling algorithms and show that a naıve datashuffling algorithm can be up to 3× slower than the highest performing; NUMA-aware one.To achieve the highest performance; we employ a combination of thread binding; NUMA-aware thread allocation; and relaxed global coordination among threads. The importance ofsuch NUMA-aware algorithm designs will only increase; as future server systems are …,CIDR,2013,77
BitWeaving: fast scans for main memory data processing,Yinan Li; Jignesh M Patel,Abstract This paper focuses on running scans in a main memory data processing system at"bare metal" speed. Essentially; this means that the system must aim to process data at ornear the speed of the processor (the fastest component in most system configurations).Scans are common in main memory data processing environments; and with the state-of-the-art techniques it still takes many cycles per input tuple to apply simple predicates on a singlecolumn of a table. In this paper; we propose a technique called BitWeaving that exploits theparallelism available at the bit level in modern processors. BitWeaving operates on multiplebits of data in a single cycle; processing bits from different columns in each cycle. Thus; bitsfrom a batch of tuples are processed in each cycle; allowing BitWeaving to drop the cyclesper column to below one in some case. BitWeaving comes in two flavors: BitWeaving/V …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,60
WHAM: a high-throughput sequence alignment method,Yinan Li; Allison Terrell; Jignesh M Patel,Abstract Over the last decade; the cost of producing genomic sequences has droppeddramatically due to the current so-called next-generation sequencing methods. However;these next-generation sequencing methods are critically dependent on fast andsophisticated data processing methods for aligning a set of query sequences to a referencegenome using rich string matching models. The focus of this work is on the design;development and evaluation of a data processing system for this crucial “short readalignment” problem. Our system; called WHAM; employs hash-based indexing methods andbitwise operations for sequence alignments. It allows rich match models and it is significantlyfaster than the existing state-of-the-art methods. In addition; its relative speedup over theexisting method is poised to increase in the future in which read sequence lengths will …,Proceedings of the 2011 international conference on Management of data,2011,53
Enabling JSON Document Stores in Relational Systems.,Craig Chasseur; Yinan Li; Jignesh M Patel,ABSTRACT In recent years;“document store” NoSQL systems have exploded in popularity. Alarge part of this popularity has been driven by the adoption of the JSON data model in theseNoSQL systems. JSON is a simple but expressive data model that is used in many Web 2.0applications; and maps naturally to the native data types of many modern programminglanguages (eg Javascript). The advantages of these NoSQL document store systems (likeMongoDB and CouchDB) are tempered by a lack of traditional RDBMS features; notably asophisticated declarative query language; rich native query processing constructs (eg joins);and transaction management providing ACID safety guarantees. In this paper; weinvestigate whether the advantages of the JSON data model can be added to RDBMSs;gaining some of the traditional benefits of relational systems in the bargain. We present …,WebDB,2013,31
Widetable: An accelerator for analytical data processing,Yinan Li; Jignesh M Patel,Abstract This paper presents a technique called WideTable that aims to improve the speedof analytical data processing systems. A WideTable is built by denormalizing the database;and then converting complex queries into simple scans on the underlying (wide) table. Toavoid the pitfalls associated with denormalization; eg space overheads; WideTable uses acombination of techniques including dictionary encoding and columnar storage. Whendenormalizing the data; WideTable uses outer joins to ensure that queries on tables in theschema graph; which are now nested as embedded tables in the WideTable; are processedcorrectly. Then; using a packed code scan technique; even complex queries on the originaldatabase can be answered by using simple scans on the WideTable (s). We experimentallyevaluate our methods in a main memory setting using the queries in TPC-H; and …,Proceedings of the VLDB Endowment,2014,27
FD-buffer: a buffer manager for databases on flash disks,Sai Tung On; Yinan Li; Bingsheng He; Ming Wu; Qiong Luo; Jianliang Xu,Abstract We design and implement FD-Buffer; a buffer manager for database systemsrunning on flash-based disks. Unlike magnetic disks; flash media has an inherent read-writeasymmetry: writes involve expensive erase operations and as a result are usually muchslower than reads. Therefore; we address this asymmetry in FD-Buffer. Specifically; we usethe average I/O cost per page access as opposed to the traditional miss rate as theperformance metric for a buffer. We develop a new replacement policy in which we separateclean and dirty pages into two pools. The size ratio of the two pools is automatically adaptedto the read-write asymmetry and the runtime workload. We evaluate FD-Buffer with trace-driven experiments on real flash disks. Our evaluation results show that our algorithmachieves up to 33% improvement on the overall performance on commodity flash disks; in …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,15
Implications of emerging 3D GPU architecture on the scan primitive,Jason Power; Yinan Li; Mark D Hill; Jignesh M Patel; David A Wood,Abstract Analytic database workloads are growing in data size and query complexity. At thesame time; computer architects are struggling to continue the meteoric increase inperformance enabled by Moore's Law. We explore the impact of two emerging architecturaltrends which may help continue the Moore's Law performance trend for analytic databaseworkloads; namely 3D die-stacking and tight accelerator-CPU integration; specifically GPUs.GPUs have evolved from fixed-function units; to programmable discrete chips; and now areintegrated with CPUs in most manufactured chips. Past efforts to use GPUs for analytic queryprocessing have not had widespread practical impact; but it is time to re-examine and re-optimize database algorithms for massively data-parallel architectures. We argue that high-throughput data-parallel accelerators are likely to play a big role in future systems as they …,ACM SIGMOD Record,2015,14
Toward GPUs being mainstream in analytic processing: An initial argument using simple scan-aggregate queries,Jason Power; Yinan Li; Mark D Hill; Jignesh M Patel; David A Wood,Abstract There have been a number of research proposals to use discrete graphicsprocessing units (GPUs) to accelerate database operations. Although many of these worksshow up to an order of magnitude performance improvement; discrete GPUs are notcommonly used in modern database systems. However; there is now a proliferation ofintegrated GPUs which are on the same silicon die as the conventional CPU. With theadvent of new programming models like heterogeneous system architecture; theseintegrated GPUs are considered first-class compute units; with transparent access to CPUvirtual addresses and very low overhead for computation offloading. We show thatintegrated GPUs significantly reduce the overheads of using GPUs in a databaseenvironment. Specifically; an integrated GPU is 3x faster than a discrete GPU even …,Proceedings of the 11th International Workshop on Data Management on New Hardware,2015,13
EaseDB: a cache-oblivious in-memory query processor,Bingsheng He; Yinan Li; Qiong Luo; Dongqing Yang,Abstract We propose to demonstrate EaseDB; the first cache-oblivious queryprocessor for in-memory relational query processing. The cache-oblivious notion from the theory communityrefers to the property that no parameters in an algorithm or a data structure need to be tunedfor a specific memory hierarchy for optimality. As a result; EaseDB automatically optimizesthe cache performance as well as the overall performance of query processing on anymemory hierarchy. We have developed a visualization interface to show the detailedperformance of EaseDB in comparison with its cache-conscious counterpart; with both theparameters in the cache-conscious algorithms and the hardware platforms varied.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,9
A padded encoding scheme to accelerate scans by leveraging skew,Yinan Li; Craig Chasseur; Jignesh M Patel,Abstract In-memory data analytic systems that use vertical bit-parallel scan methodsgenerally use encoding techniques. We observe that in such environments; there is anopportunity to turn skew in both the data and predicate distributions (usually a problem forquery processing) into a benefit that can be leveraged to encode the column values. Thispaper proposes a padded encoding scheme to address this opportunity. The proposedscheme creates encodings that map common attribute values to codes that can easily bedistinguished from other codes by only examining a few bits in the full code. Consequently;scans on columns stored using the padded encoding scheme can safely prune thecomputation without examining all the bits in the code; thereby reducing the memorybandwidth and CPU cycles that are consumed when evaluating scan queries. Our …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,5
Data shuffling in a non-uniform memory access device,*,Embodiments relate to the orchestration of data shuffling among memory devices of a non-uniform memory access device. An aspect includes a method of orchestrated shuffling ofdata in a non-uniform memory access device includes running an application on a pluralityof threads executing on a plurality of processing nodes and identifying data to be shuffledamong the plurality of processing nodes. The method includes registering the data to beshuffled and generating a plan for orchestrating the shuffling of the data. The method furtherincludes disabling cache coherency of cache memory associated with the processing nodesand shuffling the data among all of the memory devices upon disabling the cachecoherency; the shuffling performed based on the plan for orchestrating the shuffling. Themethod further includes restoring the cache coherency of the cache memory based on …,*,2016,2
Database system with highly denormalized database structure,*,Abstract A database system converts a multi-table relational database into a wide tableincorporating all of the information of the relational database tables and converts queries forthe relational database system into a form applicable to the wide table. Dictionarycompression and/or columnar store allow faster query processing despite a substantiallylarger size of the wide table.,*,2018,*
Mison: a fast JSON parser for data analytics,Yinan Li; Nikos R Katsipoulakis; Badrish Chandramouli; Jonathan Goldstein; Donald Kossmann,Abstract The growing popularity of the JSON format has fueled increased interest in loadingand processing JSON data within analytical data processing systems. However; in manyapplications; JSON parsing dominates performance and cost. In this paper; we present anew JSON parser called Mison that is particularly tailored to this class of applications; bypushing down both projection and filter operators of analytical queries into the parser. Toachieve these features; we propose to deviate from the traditional approach of buildingparsers using finite state machines (FSMs). Instead; we follow a two-level approach thatenables the parser to jump directly to the correct position of a queried field without having toperform expensive tokenizing steps to find the field. At the upper level; Mison speculativelypredicts the logical locations of queried fields based on previously seen patterns in a …,Proceedings of the VLDB Endowment,2017,*
Data shuffling in a non-uniform memory access device,*,A method of orchestrated shuffling of data in a non-uniform memory access device thatincludes a plurality of processing nodes that are connected by interconnects. The methodincludes running an application on a plurality of threads executing on the plurality ofprocessing nodes. Data to be shuffled is identified from source threads running on sourceprocessing nodes among the processing nodes to target threads executing on targetprocessing nodes among the processing nodes. The method further includes generating aplan for orchestrating the shuffling of the data among the all of the memory devicesassociated with the threads and for simultaneously transmitting data over differentinterconnects to a plurality of different target processing nodes from a plurality of differentsource processing nodes. The data is shuffled among all of the memory devices based on …,*,2016,*
Data shuffling in a non-uniform memory access device,*,A method of orchestrated shuffling of data in a non-uniform memory access device thatincludes a plurality of processing nodes includes running an application on a plurality ofthreads executing on the plurality of processing nodes and identifying data to be shuffledfrom source threads running on source processing nodes among the processing nodes totarget threads executing on target processing nodes among the processing nodes. Themethod further includes generating a plan for orchestrating the shuffling of the data amongthe all of the memory devices associated with the threads and shuffling the data among all ofthe memory devices based on the plan.,*,2016,*
Analytic query processing at bare metal speeds,Yinan Li,Abstract Modern large-scale data processing platforms require techniques to process data athigh speeds; as there is an arms race towards building and deploying near real-timeanalytical systems. The primary goal of this dissertation is to design fast analytical dataprocessing techniques that aim to process data at or near the speed of the underlyinghardware.,*,2015,*
